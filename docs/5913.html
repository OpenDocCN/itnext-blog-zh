<html>
<head>
<title>Configuring Kafka Sources and Sinks in Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Kubernetes中配置Kafka源和接收器</h1>
<blockquote>原文：<a href="https://itnext.io/configuring-kafka-sources-and-sinks-in-kubernetes-271e3757b208?source=collection_archive---------1-----------------------#2021-06-28">https://itnext.io/configuring-kafka-sources-and-sinks-in-kubernetes-271e3757b208?source=collection_archive---------1-----------------------#2021-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="906f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将数据<strong class="jp ir">流式传输到</strong>Kafka集群，以及将<strong class="jp ir">从</strong>Kafka集群流式传输到其他地方，通常通过Kafka connect集群和相关配置来完成。</p><p id="7e24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这通常是Kafka用户真正的痛点。它包括:</p><ul class=""><li id="3256" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">部署和运行Kafka connect集群</li><li id="3029" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">用Java更新和编译连接器</li><li id="bdc7" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">将jar上传到Kafka connect集群中的特定目录</li></ul><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi kz"><img src="../Images/04b464a28fe068939fd74bc37a27efa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_p1smzTpIvmIYGzn.jpg"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">卡夫卡连接来自<a class="ae lp" href="https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/" rel="noopener ugc nofollow" target="_blank">汇流博客</a>的数据管道</figcaption></figure><p id="1b69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然Kafka连接器有一个很好的集合，但融合云上很少完全管理，这使得Kafka用户如果想要有效地管理他们的源和汇，就有很多工作要做。</p><p id="ca06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在前两篇文章中，我展示了如何<a class="ae lp" href="https://sebgoa.medium.com/sending-messages-to-kafka-cfb5a246f5eb" rel="noopener">向Kafka </a>生成消息，以及如何<a class="ae lp" href="https://sebgoa.medium.com/consuming-kafka-messages-in-kubernetes-9e43050d6eb4" rel="noopener">从Kafka</a>消费消息，现在我将向您展示如何以声明方式定义Kafka源和接收器，并在Kubernetes集群中管理它们。</p><h2 id="8f6d" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">配置Kafka源</h2><p id="ac3f" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">从卡夫卡群集的观点来看，卡夫卡源是将一个事件产生为一个卡夫卡主题的东西。在Knative的帮助下，我们可以使用一个叫做T0的对象来配置一个Kafka源，我知道这非常令人困惑，对此我非常抱歉:)一切都是相对的，取决于你的立场。</p><p id="bb38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要在Kubernetes集群中创建一个可寻址的端点，该端点将成为Kafka集群的消息源，您需要创建一个如下所示的对象:</p><pre class="la lb lc ld gt ms mr mt mu aw mv bi"><span id="864a" class="lq lr iq mr b gy mw mx l my mz">apiVersion: eventing.knative.dev/v1alpha1<br/>kind: KafkaSink<br/>metadata:<br/> name: my-kafka-topic<br/>spec:<br/> auth:<br/>   secret:<br/>     ref:<br/>       name: kafkahackathon<br/> bootstrapServers:<br/> — pkc-456q9.us-east4.gcp.confluent.cloud:9092<br/> topic: hackathon</span></pre><p id="28f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意融合云上的引导服务器和指定的主题。有了这个，你现在可以创建一个AWS <a class="ae lp" href="https://github.com/triggermesh/aws-event-sources" rel="noopener ugc nofollow" target="_blank"> SQS源</a>直接发送消息到Kafka，清单如下:</p><pre class="la lb lc ld gt ms mr mt mu aw mv bi"><span id="bca7" class="lq lr iq mr b gy mw mx l my mz">apiVersion: sources.triggermesh.io/v1alpha1<br/>kind: AWSSQSSource<br/>metadata: <br/>  name: samplequeue<br/>spec: <br/>  arn: arn:aws:sqs:us-west-2:1234567890:triggermeshqueue<br/>  credentials: <br/>    accessKeyID: <br/>      valueFromSecret: <br/>        name: awscreds <br/>        key: aws_access_key_id <br/>    secretAccessKey: <br/>      valueFromSecret: <br/>        name: awscreds <br/>        key: aws_secret_access_key <br/>  sink: <br/>    ref: <br/>      apiVersion: eventing.knative.dev/v1alpha1<br/>      kind: KafkaSink<br/>      name: my-kafka-topic</span></pre><p id="9f5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，AWS SQS由它的ARN表示，您可以通过包含AWS API密钥的Kubernetes secret来访问它。<code class="fe mo mp mq mr b">sink </code>部分指向先前创建的<code class="fe mo mp mq mr b">KafkaSink</code>。有了这个清单，所有的SQS消息都将被使用<a class="ae lp" href="https://cloudevents.io/" rel="noopener ugc nofollow" target="_blank"> Cloudevents </a>规范消费并发送给Kafka。</p><blockquote class="na nb nc"><p id="32b2" class="jn jo nd jp b jq jr js jt ju jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj kk ij bi translated">两个Kubernetes对象，你就有了Kafka源代码的声明性定义</p></blockquote><h2 id="5356" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">配置Kafka接收器</h2><p id="11d1" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">对于你的Kafka Sink，我们很遗憾地回到了同样的潜在困惑:从Kafka集群的角度来看，什么是Sink，什么是该集群之外的source。因此，要定义Kafka sink，您需要在Kubernetes集群中定义一个<code class="fe mo mp mq mr b">KafkaSource</code>。</p><p id="bb11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，下面的清单指定了您的引导服务器指向合流云中的Kafka集群，一个从其消费消息的特定主题和一个作为Kafka消息的最终目标的<code class="fe mo mp mq mr b">sink</code>。这里我们要提到一个叫做<code class="fe mo mp mq mr b">display</code>的Kubernetes服务:</p><pre class="la lb lc ld gt ms mr mt mu aw mv bi"><span id="59ca" class="lq lr iq mr b gy mw mx l my mz">apiVersion: sources.knative.dev/v1beta1<br/>kind: KafkaSource<br/>metadata:<br/> name: my-kafka<br/>spec:<br/> bootstrapServers:<br/> — pkc-453q9.us-east4.gcp.confluent.cloud:9092<br/> net:<br/>   sasl:<br/>     enable: true<br/>…<br/> sink:<br/>   ref:<br/>     apiVersion: v1<br/>     kind: Service<br/>     name: display<br/> topics:<br/> — hackathon</span></pre><p id="9c25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，Kafka Sink定义只需要一个Kubernetes清单和一个作为传统Kubernetes服务公开的目标微服务。请注意，它也可以是一个Knative服务，在这种情况下，您的目标将受益于自动扩展，包括扩展到零。</p><h1 id="564c" class="nh lr iq bd ls ni nj nk lv nl nm nn ly no np nq mb nr ns nt me nu nv nw mh nx bi translated">结论</h1><p id="d9a3" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">与编译jar并将它们上传到Kafka connect集群的复杂工作流程不同，您可以利用您的Kubernetes集群并使用Kubernetes对象定义您的Kafka源和接收器。</p><p id="e785" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这给你的Kafka源和汇带来了一个声明性的心态，给你一个真实的来源，并统一了你的Kafka流和你的微服务的管理。此外，当Kafka消息存在时，这简化了在Kubernetes中运行的微服务的定位，并且通过添加Knative，为您提供了处理不断变化的流容量所必需的自动缩放。</p><p id="bfea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你需要一个Kafka源的集合，突然所有的Knative事件源都可以被使用(例如GitHub，GitLab，JIRA，Zendesk，Slack，Kinesis…)</p></div></div>    
</body>
</html>