<html>
<head>
<title>Getting started with Kafka Connector for Azure Cosmos DB using Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Docker开始使用Kafka Connector for Azure Cosmos DB</h1>
<blockquote>原文：<a href="https://itnext.io/getting-started-with-kafka-connector-for-azure-cosmos-db-using-docker-fc3e16936c58?source=collection_archive---------2-----------------------#2021-07-07">https://itnext.io/getting-started-with-kafka-connector-for-azure-cosmos-db-using-docker-fc3e16936c58?source=collection_archive---------2-----------------------#2021-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="96ee" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">学习Kafka和Cosmos DB的本地开发环境——不涉及任何成本！</h2></div><p id="c1ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在尝试一项新的服务或技术时，拥有一个本地开发环境是非常方便的。在这种情况下，码头工人已经成为事实上的选择。在您试图集成多个服务的场景中，它特别有用，并让您能够在每次运行之前从头开始。</p><p id="84e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博客文章是Kafka Connector for Azure Cosmos DB的入门指南。所有组件(包括Azure Cosmos DB)都将在您的本地机器上运行，这得益于:</p><ul class=""><li id="282e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">Azure Cosmos DB Linux模拟器，可以用于本地开发和测试目的，无需创建Azure订阅或产生任何成本。</li><li id="d9e8" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">并且，<a class="ae lb" href="https://docs.docker.com/compose/" rel="noopener ugc nofollow" target="_blank"> Docker Compose </a>是一个用于定义和运行多容器Docker应用的工具。它将编排我们的设置所需的所有组件，包括Azure Cosmos DB模拟器、Kafka、Zookeeper、Kafka连接器等。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/7a7e5ee953fdb8960f5f1120fdd52062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-96bfzSAEyUoZQjE.jpg"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">端到端工作流</figcaption></figure><p id="8630" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使事情变得简单，我们将选择单一的重点场景，并逐步进行:</p><ul class=""><li id="6448" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">步骤0 —检查我们的设置是否正常的简单场景。</li><li id="6cde" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">如何处理流JSON数据</li><li id="0531" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">如何处理与Azure Cosmos DB不兼容的流JSON数据</li><li id="1dbb" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">如何使用模式注册表处理Avro数据</li></ul><blockquote class="mh mi mj"><p id="e012" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">假设您对Kafka很熟悉，并且对Kafka Connect有所了解</p></blockquote><h1 id="4a6d" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">首先要做的是…</h1><p id="6996" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">…这里是Azure Cosmos DB模拟器和Kafka连接器的快速概述。</p><p id="779d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Azure Cosmos DB连接器允许您在Azure Cosmos DB和Kafka之间移动数据。它既可以作为源，也可以作为汇。Azure Cosmos DB接收器连接器将数据从Kafka主题写入Azure Cosmos DB容器，源连接器将更改从Azure Cosmos DB容器写入Kafka主题。在写入时，连接器处于<code class="fe nk nl nm nn b">pre-production</code>模式。你可以在<a class="ae lb" href="https://github.com/microsoft/kafka-connect-cosmosdb" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上了解更多信息，或者从<a class="ae lb" href="https://www.confluent.io/hub/microsoftcorporation/kafka-connect-cosmos" rel="noopener ugc nofollow" target="_blank">汇流中心</a>安装/下载。</p><p id="a3ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/linux-emulator?tabs=ssl-netstd21&amp;WT.mc_id=data-30458-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB Linux模拟器</a>提供了一个本地环境，它模拟Azure Cosmos DB服务用于开发目的(目前，它只支持SQL API)。它提供了Azure Cosmos DB服务的高保真仿真，并支持创建数据、查询数据、提供和扩展容器以及执行存储过程和触发器等功能。</p><blockquote class="mh mi mj"><p id="31c6" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">在撰写本文时，Azure Cosmos DB Linux模拟器处于预览阶段。</p></blockquote><p id="480f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以深入了解如何在<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/linux-emulator?tabs=ssl-netstd21&amp;WT.mc_id=data-30458-abhishgu#run-on-macos" rel="noopener ugc nofollow" target="_blank"> macOS </a>或<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/linux-emulator?tabs=ssl-netstd21&amp;WT.mc_id=data-30458-abhishgu#run-on-linux" rel="noopener ugc nofollow" target="_blank"> Linux </a>、<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/linux-emulator?tabs=ssl-netstd21&amp;WT.mc_id=data-30458-abhishgu#differences-between-the-linux-emulator-and-the-cloud-service" rel="noopener ugc nofollow" target="_blank">上使用模拟器</a>与Azure Cosmos DB云服务有什么不同<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/linux-emulator?tabs=ssl-netstd21&amp;WT.mc_id=data-30458-abhishgu#troubleshoot-issues" rel="noopener ugc nofollow" target="_blank">解决问题</a>等等。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="b4f1" class="mn mo iq bd mp mq nv ms mt mu nw mw mx jw nx jx mz jz ny ka nb kc nz kd nd ne bi translated">开始之前…</h1><p id="a7c6" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">确保您已经安装了<a class="ae lb" href="https://docs.docker.com/engine/install/" rel="noopener ugc nofollow" target="_blank">对接器</a>和<a class="ae lb" href="https://docs.docker.com/compose/install/" rel="noopener ugc nofollow" target="_blank">对接器组合</a>。</p><p id="1b27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另外，从GitHub克隆项目:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="f72d" class="oe mo iq nn b gy of og l oh oi">git clone <a class="ae lb" href="https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker" rel="noopener ugc nofollow" target="_blank">https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker</a><br/>cd cosmosdb-kafka-connect-docker</span></pre><h1 id="f1eb" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">启动所有服务</h1><p id="8738" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">所有组件都在<a class="ae lb" href="https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker" rel="noopener ugc nofollow" target="_blank"> docker-compose </a>文件中定义:</p><ul class=""><li id="b1c7" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">Azure Cosmos DB模拟器</li><li id="87f6" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">卡夫卡和动物园管理员</li><li id="c961" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Azure Cosmos DB和Datagen连接器(作为单独的Kafka Connect workers运行)</li><li id="25b0" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">融合模式注册表</li></ul><p id="a0f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多亏了Docker Compose，只需一个命令就可以启动环境。第一次运行时，下载容器可能需要一段时间(后续执行会更快)。或者，您也可以在启动Docker Compose之前单独下载图像:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="5780" class="oe mo iq nn b gy of og l oh oi">(optional)<br/>docker pull confluentinc/cp-zookeeper:latest<br/>docker pull confluentinc/cp-kafka:latest<br/>docker pull confluentinc/cp-schema-registry:latest</span></pre><p id="9ae7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要启动所有服务:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="d3c0" class="oe mo iq nn b gy of og l oh oi">docker-compose -p cosmosdb-kafka-docker up --build</span></pre><p id="a903" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几分钟后，检查容器:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="04d0" class="oe mo iq nn b gy of og l oh oi">docker-compose -p cosmosdb-kafka-docker ps</span></pre><p id="4b2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦所有的服务都启动并运行，下一个合乎逻辑的步骤就是安装连接器，对吗？嗯，有几件事我们需要处理。对于连接到Azure Cosmos DB模拟器的Java应用程序，您需要在Java证书存储库中安装<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/local-emulator-export-ssl-certificates?WT.mc_id=data-30458-abhishgu#use-the-certificate-with-java-apps" rel="noopener ugc nofollow" target="_blank">证书。在这种情况下，我们将把证书从Azure Cosmos DB模拟器容器植入Cosmos DB Kafka Connect容器。</a></p><blockquote class="mh mi mj"><p id="6c64" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">虽然这个过程可以自动化，但我是手动完成的，以便把事情搞清楚。</p></blockquote><h1 id="839a" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">配置Azure Cosmos DB模拟器证书</h1><p id="7e96" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">执行此命令将证书存储在Java证书存储中(使用<code class="fe nk nl nm nn b">docker exec</code>):</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="37e8" class="oe mo iq nn b gy of og l oh oi">docker exec --user root -it cosmosdb-kafka-docker_cosmosdb-connector_1 /bin/bash</span><span id="bcb2" class="oe mo iq nn b gy oj og l oh oi"># execute the below command inside the container<br/>curl -k <a class="ae lb" href="https://cosmosdb:8081/_explorer/emulator.pem" rel="noopener ugc nofollow" target="_blank">https://cosmosdb:8081/_explorer/emulator.pem</a> &gt; ~/emulatorcert.crt &amp;&amp; keytool -noprompt -storepass changeit -keypass changeit -keystore /usr/lib/jvm/zulu11-ca/lib/security/cacerts -importcert -alias emulator_cert -file ~/emulatorcert.crt</span></pre><blockquote class="mh mi mj"><p id="6629" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">您应该会看到以下输出——证书被添加到密钥库</p></blockquote><p id="1f9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们继续之前，还有最后一件事…</p><h1 id="d9e6" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">创建Azure Cosmos DB数据库和容器</h1><p id="eb89" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">访问位于<a class="ae lb" href="https://localhost:8081/_explorer/index.html" rel="noopener ugc nofollow" target="_blank">https://localhost:8081/_ explorer/index . html</a>的Azure Cosmos DB模拟器门户，并创建以下资源:</p><ul class=""><li id="e48f" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">名为<code class="fe nk nl nm nn b">testdb</code>的数据库</li><li id="4dae" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">集装箱— <code class="fe nk nl nm nn b">inventory</code>、<code class="fe nk nl nm nn b">orders</code>、<code class="fe nk nl nm nn b">orders_avro</code>(确保所有集装箱的分区键都是<code class="fe nk nl nm nn b">/id</code>)</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ok"><img src="../Images/6831d62d51c1df3f419e1cc988dc1e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PO4C3Q3TnzuKA7wI.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">Azure Comos DB本地仿真器</figcaption></figure></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="27c3" class="mn mo iq bd mp mq nv ms mt mu nw mw mx jw nx jx mz jz ny ka nb kc nz kd nd ne bi translated">让我们探索所有的场景</h1><p id="98c8" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">首先，让我们看一下基本场景。在尝试其他东西之前，我们想确保一切都正常。</p><h2 id="5113" class="oe mo iq bd mp ol om dn mt on oo dp mx ko op oq mz ks or os nb kw ot ou nd ov bi translated">1.你好世界！</h2><p id="c5e7" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">启动Cosmos DB的库存数据连接器:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="e8dd" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @cosmosdb-inventory-connector_1.json <a class="ae lb" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a></span><span id="10fd" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8083/connectors/inventory-sink/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/inventory-sink/status</a></span></pre><p id="d7b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了测试端到端流，向Kafka中的<code class="fe nk nl nm nn b">inventory_topic</code>主题发送几条记录:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="a4c1" class="oe mo iq nn b gy of og l oh oi">docker exec -it kafka bash -c 'cd /usr/bin &amp;&amp; kafka-console-producer --topic inventory_topic --bootstrap-server kafka:29092'</span></pre><p id="cd11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦提示准备就绪，就逐个发送JSON记录:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="a734" class="oe mo iq nn b gy of og l oh oi">{"id": "5000","quantity": 100,"productid": 42}<br/>{"id": "5001","quantity": 99,"productid": 43}<br/>{"id": "5002","quantity": 98,"productid": 44}</span></pre><p id="ebdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查Cosmos DB容器，确认记录是否已保存。导航到门户<a class="ae lb" href="https://localhost:8081/_explorer/index.html" rel="noopener ugc nofollow" target="_blank">https://localhost:8081/_ explorer/index . html</a>并检查<code class="fe nk nl nm nn b">inventory</code>容器:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ow"><img src="../Images/0d0f0f7e8d832f3872746669e075a5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AYOfTcVlODgYrtN7.png"/></div></div></figure><p id="db98" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，成功了！让我们继续做一些稍微有用的事情。在继续之前，删除<code class="fe nk nl nm nn b">inventory</code>连接器。</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="0258" class="oe mo iq nn b gy of og l oh oi">curl -X DELETE <a class="ae lb" href="http://localhost:8083/connectors/inventory-sink/" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/inventory-sink/</a></span></pre><h2 id="bd7d" class="oe mo iq bd mp ol om dn mt on oo dp mx ko op oq mz ks or os nb kw ot ou nd ov bi translated">2.将流数据(JSON格式)从Kafka同步到Azure Cosmos DB</h2><p id="7d3b" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">对于剩余的场景，我们将使用一个生产者组件来生成记录。这个<a class="ae lb" href="https://github.com/confluentinc/kafka-connect-datagen" rel="noopener ugc nofollow" target="_blank"> Kafka Connect Datagen连接器</a>是我们的朋友。它是用来生成模拟数据进行测试的，所以让我们好好利用它吧！</p><p id="3ae1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">启动Azure Cosmos DB连接器的一个实例:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="9efb" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @cosmosdb-inventory-connector_2.json <a class="ae lb" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a></span><span id="4fcd" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8083/connectors/inventory-sink/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/inventory-sink/status</a></span></pre><p id="d8ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准备就绪后，继续启动Datagen连接器，它将生成JSON格式的模拟库存数据:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="d7ee" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @datagen-inventory-connector.json <a class="ae lb" href="http://localhost:8080/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors</a></span><span id="1512" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8080/connectors/datagen-inventory/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-inventory/status</a></span></pre><blockquote class="mh mi mj"><p id="3253" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">注意，我们对Datagen连接器使用端口8080，因为它运行在一个单独的Kafka Connect容器中</p></blockquote><p id="031e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看Datagen连接器产生的数据，请查看<code class="fe nk nl nm nn b">inventory_topic1</code> Kafka主题:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="860a" class="oe mo iq nn b gy of og l oh oi">docker exec -it kafka bash -c 'cd /usr/bin &amp;&amp; kafka-console-consumer --topic inventory_topic1 --bootstrap-server kafka:29092'</span></pre><p id="4393" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意数据(在您的案例中可能有所不同):</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="262a" class="oe mo iq nn b gy of og l oh oi">{"id":5,"quantity":5,"productid":5}<br/>{"id":6,"quantity":6,"productid":6}<br/>{"id":7,"quantity":7,"productid":7}<br/>...</span></pre><p id="bdd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，id是一个整数值</p><p id="1059" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查Azure Cosmos DB容器以确认记录是否已保存。导航到门户<a class="ae lb" href="https://localhost:8081/_explorer/index.html" rel="noopener ugc nofollow" target="_blank">https://localhost:8081/_ explorer/index . html</a>并检查<code class="fe nk nl nm nn b">inventory</code>容器:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ok"><img src="../Images/05c3aacbf3c2e767ef193caccc0eab9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5HJgI5rbBZ7D1upH.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">库存容器中的数据</figcaption></figure><p id="e0da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Cosmos DB中的记录有一个数据类型为<code class="fe nk nl nm nn b">String</code>的<code class="fe nk nl nm nn b">id</code>属性。Kafka主题中的原始数据有一个类型为<code class="fe nk nl nm nn b">Integer</code>的<code class="fe nk nl nm nn b">id</code>属性——但这不会起作用，因为<a class="ae lb" href="https://docs.microsoft.com/rest/api/cosmos-db/documents?WT.mc_id=data-30458-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB要求</a> <code class="fe nk nl nm nn b"><a class="ae lb" href="https://docs.microsoft.com/rest/api/cosmos-db/documents?WT.mc_id=data-30458-abhishgu" rel="noopener ugc nofollow" target="_blank">id</a></code> <a class="ae lb" href="https://docs.microsoft.com/rest/api/cosmos-db/documents?WT.mc_id=data-30458-abhishgu" rel="noopener ugc nofollow" target="_blank">是唯一的用户定义字符串</a>。这种转换是通过<a class="ae lb" href="https://docs.confluent.io/platform/current/connect/transforms/cast.html" rel="noopener ugc nofollow" target="_blank"> Kafka Connect转换</a>–<code class="fe nk nl nm nn b">Cast</code>将字段(或整个键或值)更新为特定的类型，更新模式(如果存在的话)来实现的。</p><p id="3812" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是<a class="ae lb" href="https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker/blob/master/cosmosdb-inventory-connector_2.json#L15" rel="noopener ugc nofollow" target="_blank">连接器配置</a>中实现这一功能的部分:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="d956" class="oe mo iq nn b gy of og l oh oi">"transforms": "Cast",<br/>"transforms.Cast.type": "org.apache.kafka.connect.transforms.Cast$Value",<br/>"transforms.Cast.spec": "id:string"</span></pre><p id="42e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在继续之前，删除Cosmos DB和Datagen <code class="fe nk nl nm nn b">inventory</code>连接器。</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="ea27" class="oe mo iq nn b gy of og l oh oi">curl -X DELETE <a class="ae lb" href="http://localhost:8080/connectors/datagen-inventory" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-inventory</a><br/>curl -X DELETE <a class="ae lb" href="http://localhost:8083/connectors/inventory-sink/" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/inventory-sink/</a></span></pre><h2 id="0028" class="oe mo iq bd mp ol om dn mt on oo dp mx ko op oq mz ks or os nb kw ot ou nd ov bi translated">3.将流订单数据(JSON格式)从Kafka推送到Azure Cosmos DB</h2><p id="8252" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">现在，让我们换一种方式，使用相同的数据(JSON格式的)数据，但是稍加改动。我们将使用Datagen连接器的变体来生成模拟订单数据，并调整Cosmos DB连接器。</p><p id="92fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要安装Azure Cosmos DB连接器的不同实例:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="fb1a" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @cosmosdb-orders-connector_1.json <a class="ae lb" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a></span><span id="68c7" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8083/connectors/orders-sink/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/orders-sink/status</a></span></pre><p id="a446" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">安装Datagen订单连接器:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="b014" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @datagen-orders-connector.json <a class="ae lb" href="http://localhost:8080/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors</a></span><span id="6a33" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8080/connectors/datagen-orders/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-orders/status</a></span></pre><p id="52db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看Datagen连接器产生的数据，请查看<code class="fe nk nl nm nn b">orders</code> Kafka主题:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="b3f5" class="oe mo iq nn b gy of og l oh oi">docker exec -it kafka bash -c 'cd /usr/bin &amp;&amp; kafka-console-consumer --topic orders_topic --bootstrap-server kafka:29092'</span></pre><p id="f6ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意数据(在您的案例中可能有所不同):</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="5837" class="oe mo iq nn b gy of og l oh oi">{"ordertime":1496251410176,"orderid":3,"itemid":"Item_869","orderunits":3.2897805449886226,"address":{"city":"City_99","state":"State_46","zipcode":50570}}</span><span id="b5c3" class="oe mo iq nn b gy oj og l oh oi">{"ordertime":1500129505219,"orderid":4,"itemid":"Item_339","orderunits":3.6719921257659918,"address":{"city":"City_84","state":"State_55","zipcode":88573}}</span><span id="cd1e" class="oe mo iq nn b gy oj og l oh oi">{"ordertime":1498873571020,"orderid":5,"itemid":"Item_922","orderunits":8.4506812669258,"address":{"city":"City_48","state":"State_66","zipcode":55218}}</span><span id="beb6" class="oe mo iq nn b gy oj og l oh oi">{"ordertime":1513855504436,"orderid":6,"itemid":"Item_545","orderunits":7.82561522361042,"address":{"city":"City_44","state":"State_71","zipcode":87868}}<br/>...</span></pre><p id="f909" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我故意选择订单数据，因为它与库存数据不同。注意，Datagen连接器生成的JSON记录有一个<code class="fe nk nl nm nn b">orderid</code>属性(整数数据类型)，但是没有<code class="fe nk nl nm nn b">id</code>属性——但是我们知道Azure Cosmos DB没有属性就无法工作。</p><p id="8b0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查Cosmos DB容器，确认记录是否已保存。导航到门户<a class="ae lb" href="https://localhost:8081/_explorer/index.html" rel="noopener ugc nofollow" target="_blank">https://localhost:8081/_ explorer/index . html</a>并检查<code class="fe nk nl nm nn b">orders</code>容器:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ow"><img src="../Images/7bbf2e4fa2cad5a4f1354743f1ba7d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eWjrMveMkRkgUf-P.png"/></div></div></figure><p id="f2de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，Azure Cosmos DB中存储的记录中没有<code class="fe nk nl nm nn b">orderid</code>属性。事实上，它已经被替换为<code class="fe nk nl nm nn b">id</code>属性(带有一个<code class="fe nk nl nm nn b">String</code>值)。这是通过<a class="ae lb" href="https://docs.confluent.io/platform/current/connect/transforms/replacefield.html" rel="noopener ugc nofollow" target="_blank">更换现场变压器</a>实现的。</p><p id="7eb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是使这成为可能的<a class="ae lb" href="https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker/blob/master/cosmosdb-orders-connector_1.json#L16" rel="noopener ugc nofollow" target="_blank">连接器配置</a>中的部件:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="c7e7" class="oe mo iq nn b gy of og l oh oi">"transforms": "RenameField,Cast",<br/>"transforms.RenameField.type": "org.apache.kafka.connect.transforms.ReplaceField$Value",<br/>"transforms.RenameField.renames": "orderid:id",<br/>"transforms.Cast.type": "org.apache.kafka.connect.transforms.Cast$Value",<br/>"transforms.Cast.spec": "id:string"</span></pre><blockquote class="mh mi mj"><p id="290c" class="kf kg mg kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">根据您的使用情况，完全删除/重命名字段可能不是理想的解决方案。然而，知道有选择是好的。此外，请记住Kafka topics中的原始数据仍然在那里，没有被触动。其他下游应用程序仍然可以利用它。</p></blockquote><p id="b79e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在继续之前，删除Cosmos DB和Datagen <code class="fe nk nl nm nn b">inventory</code>连接器。</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="d5f9" class="oe mo iq nn b gy of og l oh oi">curl -X DELETE <a class="ae lb" href="http://localhost:8080/connectors/datagen-orders" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-orders</a><br/>curl -X DELETE <a class="ae lb" href="http://localhost:8083/connectors/orders-sink/" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/orders-sink/</a></span></pre><h2 id="748a" class="oe mo iq bd mp ol om dn mt on oo dp mx ko op oq mz ks or os nb kw ot ou nd ov bi translated">4.将流订单数据(AVRO格式)从Kafka推送到Azure Cosmos DB</h2><p id="0213" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">到目前为止，我们讨论了JSON，一种常用的数据格式。但是，<a class="ae lb" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> Avro </a>由于其紧凑的格式导致更好的性能和成本节约，在生产中被大量使用。为了更容易处理<code class="fe nk nl nm nn b">Avro</code>数据模式，有<a class="ae lb" href="https://docs.confluent.io/platform/current/schema-registry/index.html" rel="noopener ugc nofollow" target="_blank">汇合模式注册表</a>，它为元数据提供了一个服务层，并提供了一个RESTful接口来存储和检索Avro(以及JSON和Protobuf模式)。为了这篇博文的目的，我们将使用Docker版本。</p><p id="0cf4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">安装一个可以处理<code class="fe nk nl nm nn b">Avro</code>数据的Azure Cosmos DB连接器的新实例:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="f118" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @cosmosdb-orders-connector_2.json <a class="ae lb" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a></span><span id="cb0d" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8083/connectors/orders-sink/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/orders-sink/status</a></span></pre><p id="802e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">安装Datagen连接器，该连接器将生成<code class="fe nk nl nm nn b">Avro</code>格式的模拟订单数据:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="ab89" class="oe mo iq nn b gy of og l oh oi">curl -X POST -H "Content-Type: application/json" -d @datagen-orders-connector-avro.json <a class="ae lb" href="http://localhost:8080/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors</a></span><span id="3d3c" class="oe mo iq nn b gy oj og l oh oi"># to check the connector status<br/>curl <a class="ae lb" href="http://localhost:8080/connectors/datagen-orders/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-orders/status</a></span></pre><p id="cd28" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看Datagen连接器生成的<code class="fe nk nl nm nn b">Avro</code>数据，请查看<code class="fe nk nl nm nn b">orders_avro_topic</code> Kafka主题:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="9cff" class="oe mo iq nn b gy of og l oh oi">docker exec -it kafka bash -c 'cd /usr/bin &amp;&amp; kafka-console-consumer --topic orders_avro_topic --bootstrap-server kafka:29092'</span></pre><p id="7d64" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于<code class="fe nk nl nm nn b">Avro</code>的数据是二进制格式，它不是人类可读的:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="fc14" class="oe mo iq nn b gy of og l oh oi">�����VItem_185lqf�@City_61State_73��<br/>����WItem_219[�C��@City_74State_77��<br/>�����VItem_7167Ix�dF�?City_53State_53��<br/>���֩WItem_126*���?@City_58State_21��<br/>�����VItem_329X�2,@City_49State_79��<br/>�����XItem_886��&gt;�|�@City_88State_27��<br/>��V Item_956�r#�!@City_45State_96��<br/>�ѼҕW"Item_157E�)$���?City_96State_63��<br/>...</span></pre><p id="331a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查Cosmos DB容器，确认记录是否已保存。导航到门户<a class="ae lb" href="https://localhost:8081/_explorer/index.html" rel="noopener ugc nofollow" target="_blank">https://localhost:8081/_ explorer/index . html</a>并检查<code class="fe nk nl nm nn b">orders_avro</code>容器:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ow"><img src="../Images/34938191bfb1cc8d5200463600a8e7de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HS-lQc0YRPMQJNRR.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated"><em class="ox">订单_avro </em>容器中的数据</figcaption></figure><p id="db08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了，事情按预期进行！<a class="ae lb" href="https://github.com/Azure-Samples/cosmosdb-kafka-connect-docker/blob/master/cosmosdb-orders-connector_2.json" rel="noopener ugc nofollow" target="_blank">连接器配置</a>已更新以处理此问题:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="00aa" class="oe mo iq nn b gy of og l oh oi">"value.converter": "io.confluent.connect.avro.AvroConverter",<br/>"value.converter.schemas.enable": "true",<br/>"value.converter.schema.registry.url": "http://schema-registry:8081",<br/>...</span></pre><p id="7f2f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">变化包括选择<code class="fe nk nl nm nn b">AvroConverter</code>，启用模式并指向模式注册中心(在我们的例子中，在Docker中本地运行)。</p><p id="08ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是这篇博文中涵盖的所有用例。我们只讨论了Sink连接器，但是可以自由地进一步探索和实验！例如，您可以扩展当前的设置以包含源连接器，并将其配置为将记录从Azure Cosmos DB容器发送到Kafka。</p><h1 id="1484" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">打扫</h1><p id="3c5c" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">完成后，您可以删除连接器:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="953c" class="oe mo iq nn b gy of og l oh oi">curl -X DELETE <a class="ae lb" href="http://localhost:8080/connectors/datagen-orders" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/datagen-orders</a><br/>curl -X DELETE <a class="ae lb" href="http://localhost:8083/connectors/orders-sink/" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/orders-sink/</a></span></pre><p id="51f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要停止所有Docker组件:</p><pre class="lr ls lt lu gt oa nn ob oc aw od bi"><span id="ac23" class="oe mo iq nn b gy of og l oh oi">docker-compose -p cosmosdb-kafka-docker down -v</span></pre></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="7870" class="mn mo iq bd mp mq nv ms mt mu nw mw mx jw nx jx mz jz ny ka nb kc nz kd nd ne bi translated">结论</h1><p id="6f99" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">尽管我们出于演示的目的讨论了简单的场景，但是它将展示如何利用现成的解决方案(连接器、转换器、模式注册中心等)。)并专注于基于Azure Cosmos DB的应用程序或数据管道所需的繁重工作。由于这个例子采用了基于Docker的方法进行本地开发，所以它是有成本效益的(嗯，免费！)并可根据您的需求轻松定制。</p><p id="2cee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于生产场景，您需要设置、配置和操作这些连接器。Kafka Connect workers只是简单的JVM进程，因此本质上是无状态的(所有的状态处理都被卸载给Kafka)。在整体架构和编排方面有很大的灵活性——例如，您可以在Kubernetes中运行它们以实现容错和可伸缩性。</p></div></div>    
</body>
</html>