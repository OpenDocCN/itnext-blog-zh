<html>
<head>
<title>Fun with Kubernetes &amp; Tensorflow Serving</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes &amp; Tensorflow服务带来的乐趣</h1>
<blockquote>原文：<a href="https://itnext.io/fun-with-kubernetes-tensorflow-serving-4fef8d7502b9?source=collection_archive---------2-----------------------#2018-02-23">https://itnext.io/fun-with-kubernetes-tensorflow-serving-4fef8d7502b9?source=collection_archive---------2-----------------------#2018-02-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="09c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Tensorflow服务有多种可用的演练，可以在K8s或其他平台上运行。大多数情况下，您仍然需要使用Tensorflow Python客户端来发布图像或您想要分析的任何内容。</p><p id="5300" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然你可以从<a class="ae kl" href="https://www.tensorflow.org/performance/performance_guide" rel="noopener ugc nofollow" target="_blank">文档</a>中找到关于Tensorflow本身性能优化的数据，但它并没有真正涵盖一些运营细节，当你打算运行这项服务时，这些细节可能会很有趣。对于一个初始模型，你应该使用PNG图像吗？JPEG文件？如果使用高质量的图像，性能会更好吗？还是应该缩小图像的尺寸？如果使用高质量的图像，准确性会更好吗？</p><p id="1cbf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了开始回答这些问题，我与提供硬件访问的<a class="ae kl" href="https://symkloud.com/" rel="noopener ugc nofollow" target="_blank"> Kontron </a>和我所知道的最好的Python大师<a class="ae kl" href="https://www.linkedin.com/in/ronan-delacroix/" rel="noopener ugc nofollow" target="_blank">罗南·德拉克洛瓦</a>合作。</p><p id="8f5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们做到了:</p><ol class=""><li id="b9f5" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">使用从文档中获取的参数，以优化和非优化的方式，从为CPU和GPU提供二进制文件的源TF构建；</li><li id="733b" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">用这些新的二进制文件构建Docker映像；</li><li id="9078" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">看看如何准备由TF Serving服务的inception模型；</li><li id="c158" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">构建一个Kubernetes清单来部署具有各种资源约束的TF服务；</li><li id="960e" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用简单的API构建一个web应用程序，通过它我们可以发布图像，运行简单的预处理管道并比较结果；</li><li id="faf9" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">得出一些早期结论。</li></ol><p id="4711" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们想分享这种令人敬畏的体验！并收集您的反馈以对其进行迭代。</p><h1 id="09ad" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">先决条件</h1><p id="ea9e" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">要复制这篇文章，您需要访问Kubernetes 1.6+集群，最好是其中有GPU的集群。</p><p id="a4f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们这里的例子中，我们使用了Kubernetes 的1.8.7版本的<a class="ae kl" href="https://www.ubuntu.com/kubernetes" rel="noopener ugc nofollow" target="_blank">规范发行版，该版本使用</a><a class="ae kl" href="https://www.kontron.com/products/systems/cloud-systems/symkloud-ms2910.html" rel="noopener ugc nofollow" target="_blank"> Kontron Symkloud MS2911 </a>部署在一个6 worker HA集群上。其中两个节点配备了nVidia Tesla P4卡。</p><h1 id="12d0" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">准备Tensorflow服务</h1><p id="c213" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">构建“恰到好处”的TF服务绝非易事，尤其是因为它是一个快速移动的目标。这个练习是基于TF 1.5的，我不能保证它是可重复的。我花了很多时间把它做好，但我仍然对整件事不满意。</p><h2 id="6d60" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">开发Docker图像</h2><p id="8a46" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">首先，我们需要构建一个基础映像，然后我们可以用它来构建模型服务器的各种版本。我们可以使用多级Docker图像，但为了理解我们在做什么，我在这里只是手动操作。</p><p id="556b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基础“FROM”来自最新的CUDA映像，因此我们可以同时进行CPU和GPU构建，您可以在repo中找到源代码。</p><p id="30bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个repo的src文件夹中，您会找到一个很好的docker文件。构建方式:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="425d" class="md lb iq mu b gy my mz l na nb">$ cd src<br/>$ docker build — rm -t ${USER}/tf-dev -f Dockerfile.tf-dev .<br/>$ cd ..</span></pre><p id="c3c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们需要下载Tensorflow服务。在1.4和1.5之间有一个很大的变化，子模块被删除了。这个变化在文档和构建系统中没有完全考虑到，所以我们需要在这里做一点修改。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="d0fc" class="md lb iq mu b gy my mz l na nb">$ git clone --recurse-submodules <a class="ae kl" href="https://github.com/tensorflow/serving" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/serving</a><br/># This will in the end NOT download some required dependencies, so<br/>$ cd serving<br/>$ git clone --recursive <a class="ae kl" href="https://github.com/tensorflow/tensorflow.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow.git</a><br/>$ git clone --recursive <a class="ae kl" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a> tf_models</span></pre><p id="86b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此时，您已经准备好了docker映像以及要构建的源代码。现在让我们运行它</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="34f9" class="md lb iq mu b gy my mz l na nb">$ docker run -it -name tf-dev -v $PWD/serving:/serving ${USER}/tf-dev bash</span></pre><h2 id="ee65" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">建筑TF服务</h2><p id="8ad1" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在你在容器中，要构建TF服务器，你有几个选择:</p><ol class=""><li id="170c" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">GPU，非优化:</li></ol><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="9a9a" class="md lb iq mu b gy my mz l na nb"># cd /serving<br/># bazel build -c opt --config=cuda \<br/>    --crosstool_top=<a class="ae kl" href="http://twitter.com/local_config_cuda" rel="noopener ugc nofollow" target="_blank">@local_config_cuda</a>//crosstool:toolchain \<br/>    tensorflow_serving/model_servers:tensorflow_model_server \<br/>    &amp;&amp; cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \<br/> /usr/local/bin/tensorflow_model_server.gpu.standard \<br/>    &amp;&amp; bazel clean --expunge</span></pre><p id="b998" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.GPU，优化:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="1799" class="md lb iq mu b gy my mz l na nb"># cd /serving<br/># bazel build -c opt --config=cuda \<br/>    --crosstool_top=<a class="ae kl" href="http://twitter.com/local_config_cuda" rel="noopener ugc nofollow" target="_blank">@local_config_cuda</a>//crosstool:toolchain \<br/>    --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 — copt=-mfma — copt=-O3 \<br/>    tensorflow_serving/model_servers:tensorflow_model_server \<br/>    &amp;&amp; cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \<br/> /usr/local/bin/tensorflow_model_server.gpu.optimized \<br/>    &amp;&amp; bazel clean --expunge</span></pre><p id="735b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.CPU，非优化</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="59f8" class="md lb iq mu b gy my mz l na nb"># cd /serving<br/># bazel build -c opt \<br/>    tensorflow_serving/model_servers:tensorflow_model_server \<br/>    &amp;&amp; cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \<br/> /usr/local/bin/tensorflow_model_server.cpu.standard \<br/>    &amp;&amp; bazel clean --expunge</span></pre><p id="cfcf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.优化的CPU:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="4ea0" class="md lb iq mu b gy my mz l na nb"># cd /serving<br/># bazel build -c opt \<br/>    --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-O3 \<br/>    tensorflow_serving/model_servers:tensorflow_model_server \<br/>    &amp;&amp; cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \<br/> /usr/local/bin/tensorflow_model_server.cpu.optimized \<br/>    &amp;&amp; bazel clean --expunge</span></pre><p id="af79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这需要很多时间。在我的至强E5 24内核上，非优化CPU版本为521秒(9分钟)，优化GPU版本高达<br/> 1427秒(22分钟)。在这个过程的最后，您将在docker容器的/usr/local/bin/中获得这4个二进制文件。</p><p id="123d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们还需要构建另一个dev二进制文件来服务于Inception。如果您已经有了自己的模型，则无需执行此步骤:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="f557" class="md lb iq mu b gy my mz l na nb"># cd /serving<br/># bazel build -c opt \<br/>    tensorflow_serving/example:inception_saved_model</span></pre><p id="9364" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一方面，如果您在tensorflow_serving/…上运行构建，您将构建更多的示例，尽管这会花费更长的时间。可能对某些用例有用。</p><p id="a5a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一方面，这应该是工作的<em class="nc">，但是这里报告的<a class="ae kl" href="https://github.com/tensorflow/serving/issues/737" rel="noopener ugc nofollow" target="_blank">有一个错误，阻止了它正常工作。如果你真的需要这个，好消息是bitnami docker映像<strong class="jp ir">bitnami/tensor flow-inception:latest</strong>在<strong class="jp ir">/opt/bitnami/tensor flow-inception/bazel-bin/tensor flow _ serving/example/inception _ saved _ model</strong>包含一个工作二进制文件</a></em></p><h2 id="cad4" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">提取二进制文件</h2><p id="2eee" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">所有的二进制文件都构建好了，现在您可以使用以下命令从另一个shell中提取它们:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="c457" class="md lb iq mu b gy my mz l na nb">$ mkdir bin<br/>$ for type in gpu cpu; do<br/>    for version in standard optimized; do<br/>      docker cp tf-dev:/usr/local/bin/tensorflow_model_server.${type}.${version} ./bin/<br/>    done<br/>  done</span></pre><p id="36f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了保存我们将用于解包模式的工具，我们使用以下内容提交docker映像:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="0d44" class="md lb iq mu b gy my mz l na nb">$ docker commit tf-dev ${USER}/tf </span></pre><p id="c5d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您打算使用bitnami映像，则不必这样做。</p><h1 id="a2c8" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">构建TF服务图像</h1><p id="44c8" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在您已经准备好了所有的二进制文件，可以用它们来构建相对较小的Docker映像了</p><p id="ee5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，您可以在这个存储库的src文件夹中找到源代码。您也可以修改文件来运行非优化版本</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="d839" class="md lb iq mu b gy my mz l na nb">$ for type in gpu cpu; do<br/>    docker build — rm -t ${USER}/tf-serving:${type} -f src/Dockerfile.${type} .<br/>    docker push ${USER}/tf-serving:${type}<br/>  done</span></pre><h1 id="a825" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">创建可服务的初始模型</h1><p id="379d" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">奇怪的是，当你有更多的操作背景时，你下载的模型不能开箱即用。首先，您需要将它们转换成一个冻结的模型，为变量添加一个文件，然后，也只有到那时，您才能为它们服务。不太实际，但很好，就是这样…</p><p id="dc12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从Google Storage下载Inception模型，然后提取它:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="9b0e" class="md lb iq mu b gy my mz l na nb">$ cd /tmp<br/>$ curl -sL <a class="ae kl" href="http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz" rel="noopener ugc nofollow" target="_blank">http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz</a><br/>$ tar xfz inception-v3–2016–03–01.tar.gz<br/>$ cd -</span></pre><p id="00a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在你需要把它转换成可以被TF服务的东西:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="8779" class="md lb iq mu b gy my mz l na nb">$ mkdir model-data<br/>$ docker run — rm \<br/>    -v $PWD/model-data:/model-data \<br/>    -v $PWD/serving:/serving \<br/>    -v /tmp/inception-v3:/inception \<br/>    ${USER}/tf \<br/>    /serving/bazel-bin/tensorflow_serving/example/inception_saved_model \<br/>       --checkpoint_dir=/inception \<br/>       --output_dir=/model-data</span></pre><p id="dcdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此操作的输出是模型数据文件夹中的一个子文件夹，其中包含saved_model.pb文件和variables文件夹。这是model_server用来服务模型的。</p><p id="a7f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意</strong>:如果您陷入了上面报告的tensorflow bug，请使用以下代码:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="3755" class="md lb iq mu b gy my mz l na nb">$ mkdir model-data<br/>$ docker run — rm \<br/>    -v $PWD/model-data:/model-data \<br/>    -v /tmp/inception-v3:/inception \<br/>    bitnami/tensorflow-inception \<br/>    /opt/bitnami/tensorflow-inception/bazel-bin/tensorflow_serving/example/inception_saved_model \<br/>      --checkpoint_dir=/inception \<br/>      --output_dir=/model-data</span></pre><p id="d860" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它将输出如下内容:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="aff2" class="md lb iq mu b gy my mz l na nb">Welcome to the Bitnami tensorflow-inception container<br/>Subscribe to project updates by watching <a class="ae kl" href="https://github.com/bitnami/bitnami-docker-tensorflow-inception" rel="noopener ugc nofollow" target="_blank">https://github.com/bitnami/bitnami-docker-tensorflow-inception</a><br/>Submit issues and feature requests at <a class="ae kl" href="https://github.com/bitnami/bitnami-docker-tensorflow-inception/issues" rel="noopener ugc nofollow" target="_blank">https://github.com/bitnami/bitnami-docker-tensorflow-inception/issues</a><br/>Send us your feedback at <a class="ae kl" href="mailto:containers@bitnami.com" rel="noopener ugc nofollow" target="_blank">containers@bitnami.com</a></span><span id="1ef6" class="md lb iq mu b gy nd mz l na nb">2018-02-22 17:25:00.723742: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA<br/>Successfully loaded model from /inception/model.ckpt-157585 at step=157585.<br/>Exporting trained model to /model-data/1<br/>Successfully exported model to /model-data</span></pre><h1 id="71d1" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">开发Python API来发布图像</h1><p id="989e" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">Ronan开发了一个应用程序，它具有以下功能:</p><ul class=""><li id="c62a" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk ne ks kt ku bi translated">允许上传(猫的)图像</li><li id="7490" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">从适合2048x2048的盒子到适合128x128的盒子(我们实际上缩小到了32x32，但是效果不够好)</li><li id="611a" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">将每个版本代码转换为PNG格式和JPEG格式</li><li id="a9e4" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">同时将每个版本发布到3台Tensorflow服务器</li><li id="b5fd" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">显示结果的比较图</li></ul><p id="214d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个应用程序的代码是<a class="ae kl" href="https://github.com/ronhanson/tensorflow-image-resizer.git" rel="noopener ugc nofollow" target="_blank">这里</a>，它被打包成一个docker图像，你可以下载</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="a2a2" class="md lb iq mu b gy my mz l na nb">docker pull ronhanson/tensorflow-image-resizer </span></pre><h1 id="3462" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">在Kubernetes部署</h1><h2 id="cba0" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">将模型部署到节点</h2><p id="b740" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">好吧，所以我没有机会有任何可用的存储，我不希望我的演示出现带宽和IO问题。所以我使用hostPath来存储模型(是的，我知道，真可耻)</p><p id="13ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您应该能够做一些事情，比如</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7259" class="md lb iq mu b gy my mz l na nb">$ scp -r model-data &lt;remote-instance&gt;:model-data</span></pre><p id="dca7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于您的每个工作节点，然后SSH到每个工作节点，并且:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7f49" class="md lb iq mu b gy my mz l na nb">remote-instance:$ sudo mv model-data /<br/>remote-instance:$ exit</span></pre><p id="4098" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，在这个阶段，你已经在所有节点上共享了你的模型。显然，如果您在云中运行，请使用存储类并将内容发布到其中。如果你在这一步挣扎，请给我发消息。</p><h2 id="a1cd" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">部署TF</h2><p id="3bb5" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">在src文件夹中，您将找到3份清单，部署3个Tensorflow服务实例，其中包括1个GPU、1个CPU和8个CPU核心。使它们适应您的需要(根据需要更改TF映像和约束)，然后使用</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7eea" class="md lb iq mu b gy my mz l na nb">kubectl create -f src/manifest-tensorflow-serving-gpu.yaml<br/>kubectl create -f src/manifest-tensorflow-serving-1cpu.yaml<br/>kubectl create -f src/manifest-tensorflow-serving-8cpu.yaml</span></pre><h2 id="8d55" class="md lb iq bd lc me mf dn lg mg mh dp lk jy mi mj lo kc mk ml ls kg mm mn lw mo bi translated">部署前端</h2><p id="3633" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">您还可以在src中找到将Python前端部署到K8s的清单。注意，出于实际原因，我们在这个例子中调整服务器端的大小，这是CPU密集型的。您可以更改资源请求以缩短响应时间。结论中对此有更多的说明。</p><p id="3ce2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另请注意，我们使用的是节点端口，这也是出于实际原因，因为我们只运行裸机集群。您可以将其更改为更适合您的用例的东西，例如负载平衡器。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="434c" class="md lb iq mu b gy my mz l na nb">kubectl create -f src/manifest-tensorflow-image-resizer.yaml</span></pre><h1 id="0e24" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">玩我们的集群</h1><p id="9d6d" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">太好了！！现在，您可以在端口30501 (http:// <node-ip> :30501)上连接任何节点的IP地址，并查看UI:</node-ip></p><figure class="mp mq mr ms gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nf"><img src="../Images/1bb96c9d108d0777cce85b1672c44184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xgggLy0-ZUhcHjyTbsBXxA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk translated">一只猫的2400万像素图像分析</figcaption></figure><figure class="mp mq mr ms gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nf"><img src="../Images/4b230761899e5178a4f6fc89bf2bbd24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_1hIW365_Pu9U2Z1jCZiWg.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk translated">(另一只猫的)1400万像素图像分析</figcaption></figure><h1 id="696c" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">结论</h1><p id="227e" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">老实说，我们得出的一些结论是有道理的，其他的就不那么直观了。请注意，它们是在初始模型上得到的发现，并且您可能在您自己的模型上有不同的发现。我们相信这很容易复制，你可以运行(和分享！！)你的结果和想法</p><ol class=""><li id="4cf7" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated"><strong class="jp ir">图像大小(因此带宽)对预测精度的影响非常小</strong>。这意味着在将图像提交给Tensorflow服务模型服务器之前，将图像大小调整为1024x1024甚至512x512几乎总是有益的。您损失了不到5%的准确性，但节省了99%的带宽！！<br/>所以，如果你运行一个公开可用的系统，你可以调整图像客户端的大小来优化你的管道。使用javascript很容易做到这一点(实际上Ronan的代码禁用了它，但你可以很容易地打开它)<br/>如果你只使用M2M运行数据中心或边缘计算，那么调整大小/代码转换管道将提高整体性能并节省带宽。</li><li id="3cee" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><strong class="jp ir">形象类型确实重要</strong>。您不会在UI中直接看到这一点，但是您可以从API中收集JSON输出，并注意到在PNG中分析相同大小的相同图像所需的时间是在JPEG中的4到5倍。这告诉我们，压缩显然是好的，颜色空间对于初始模型的性能来说可能不是太大的问题。我们需要更多的研究和文件类型来解决这个问题。</li><li id="11ec" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">图像大小对预测的持续时间没有太大的影响，至少在我们开始调整大小时。我们使用的原始源(每个超过10M像素)将需要很长时间来运行，但是当我们低于4MP时，预测持续时间大约是恒定的。这一张很奇怪，因为我预计“小”图像的预测会快得多。事实并非如此。</li><li id="20db" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><strong class="jp ir">一旦调整了图像的大小，1x GPU (nVidia P4)大约相当于8个英特尔至强处理器超线程核心</strong>，但是如果您查看全尺寸图像，它会更好。所以我想这是一个用例的问题。<br/>因此，如果您寻求绝对的精度，您将需要一个GPU来获得不错的性能并使用大图像<br/>如果您以精度/准确度为代价来寻求速度，那么使用CPU的传统高密度方法可能更有意义。</li></ol><p id="fd49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你认为我们应该运行更多的用例和测试，让我们知道(欢迎PRs)。</p><p id="e95e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您希望在真实的客户场景中运行，以下内容可以帮助您提高性能:</p><ul class=""><li id="5a80" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk ne ks kt ku bi translated">用于TF服务的<a class="ae kl" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/batching/README.md" rel="noopener ugc nofollow" target="_blank">批处理API</a>应该是提高性能的一个很好的方法，特别是对于GPU</li><li id="5285" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">ZenDesk发布了一篇关于一些深度细节的论文<a class="ae kl" href="https://medium.com/zendesk-engineering/how-zendesk-serves-tensorflow-models-in-production-751ee22f0f4b" rel="noopener">这里</a></li></ul><p id="1d09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您正在考虑复制和扩展这篇文章，请注意这个应用程序有一个完整的API，您可以使用它来自动测试和处理JSON输出。详细信息在自述文件中。欢迎您测试和发布:</p><ul class=""><li id="a37d" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk ne ks kt ku bi translated">更多编译选项</li><li id="7fe2" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">其他GPU性能指标。我们使用P4是因为它对高模块化MSP平台的功耗要求低，外形友好。</li><li id="13b5" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">K8s与其他解决方案？(实际上，所有这些都可以在Docker和K8s之外运行，这样设置对我们来说更容易)</li></ul><p id="8d48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">无论如何，我们希望你像我们喜欢建造它一样喜欢它！别忘了为它鼓掌！！如果你有其他用例或研究，罗南和我也可以帮助你开始使用Kubernetes。</p><p id="81f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该演示将在<a class="ae kl" href="https://www.mobileworldcongress.com/exhibitor/kontron/" rel="noopener ugc nofollow" target="_blank">世界移动通信大会上的Kontron展台</a>上展示。来看看，讨论一下！</p><h1 id="59e1" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">参考</h1><p id="032b" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">你可以在这里找到代码:</p><ul class=""><li id="42ac" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk ne ks kt ku bi translated">python App:【https://github.com/ronhanson/tensorflow-image-resizer/ T2】</li><li id="7124" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk ne ks kt ku bi translated">Blogpost及来源:<a class="ae kl" href="https://github.com/madeden/blogposts/tree/master/k8s-tf-serving" rel="noopener ugc nofollow" target="_blank">https://github . com/madeden/blog posts/tree/master/k8s-TF-serving</a></li></ul></div></div>    
</body>
</html>