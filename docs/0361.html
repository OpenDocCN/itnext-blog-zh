<html>
<head>
<title>Setting up a GPU Enabled Kubernetes for Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">设置GPU使Kubernetes能够进行深度学习</h1>
<blockquote>原文：<a href="https://itnext.io/setting-up-a-gpu-enabled-kubernetes-for-deep-learning-aef8e198931b?source=collection_archive---------5-----------------------#2018-02-26">https://itnext.io/setting-up-a-gpu-enabled-kubernetes-for-deep-learning-aef8e198931b?source=collection_archive---------5-----------------------#2018-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class="gl gn jn jo jp ab cb"><figure class="jq jr js jt ju jv jw paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/cedbd85e34e8dd4089af40382f4a0b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*ury-vgUk7f6o6dIHkEpK1Q.png"/></div></figure><figure class="jq jr kd jt ju jv jw paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/02284e4de860b1c3272b0ac5c16ea2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*2hod4Lwb9wDrzSTLFVcpOg.png"/></div></figure><figure class="jq jr ke jt ju jv jw paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/e3e7d66abc56fc007394d463901edbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*11YYlAKyhX0wEmdJNCYyXw.png"/></div></figure></div><p id="d668" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated"><a class="ae ld" href="https://www.linkedin.com/cws/share?url=https%3A%2F%2Fitnext.io%2Fsetting-up-a-gpu-enabled-kubernetes-for-deep-learning-aef8e198931b" rel="noopener ugc nofollow" target="_blank"> <em class="le">点击这里在LinkedIn上分享这篇文章</em> </a></p><p id="8946" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">Kubernetes在2017年像野火一样蔓延，不开玩笑！以下是来自斯科特帖子的一些数字:</p><blockquote class="lf lg lh"><p id="5476" class="kf kg le kh b ki kj kk kl km kn ko kp li kr ks kt lj kv kw kx lk kz la lb lc ij bi translated"><em class="iq">“对于拥有超过5000名员工的公司，48%的公司使用Kubernetes，33%的公司使用主要协调工具。”</em></p><p id="bc58" class="kf kg le kh b ki kj kk kl km kn ko kp li kr ks kt lj kv kw kx lk kz la lb lc ij bi translated"><em class="iq">“79%的样本选择Docker作为他们的主要容器技术。”</em></p></blockquote><p id="cab0" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">乘着Kubernetes的浪潮，2017年对于基础设施/开发人员来说是特别有趣的一年。经过多年的黑暗之后，我们终于有了一些很酷的工具可以玩了。我们开始思考如何应对这种范式转变。我们试图用<a class="ae ld" href="https://overflow.buffer.com/2017/08/31/buffer-deploy-code-kubernetes/" rel="noopener ugc nofollow" target="_blank"> Jenkins和Helm Chart </a>以及其他更多即将到来的:D来优化开发者速度</p><p id="8543" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">我心中最珍视的一件事是为数据团队民主化Kubernetes。众所周知，为了保持生产力和竞争力，当今的数据团队必须采用一系列尖端技术。几年前，MapReduce被广泛使用，现在仍然如此。即使以今天的标准来看，基础设施要求也不是在公园里散步。快进到2018年，我们看到深度学习再次发生同样的事情。对我来说，数据团队不应该因为基础架构挑战而分心，不得不重新发明轮子。公司的系统团队应该与他们并肩工作。</p><p id="a7f8" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">受KubeCon 2017上<a class="ae ld" href="https://twitter.com/LachlanEvenson" rel="noopener ugc nofollow" target="_blank"> Lachlan Evenson </a>关于他如何帮助数据团队使用Kubernetes的<a class="ae ld" href="https://kccncna17.sched.com/event/CU6U/democratizing-machine-learning-on-kubernetes-i-joy-qiao-lachlan-evenson-microsoft" rel="noopener ugc nofollow" target="_blank">演讲</a>的启发，我决定进行我的小实验，建立一个GPU就绪集群。</p><h1 id="0f88" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">创建集群</h1><p id="7639" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">首先，让我们创建一个带有GPU加速节点的k8s集群。在这个例子中，我们将使用AWS <code class="fe mo mp mq mr b">p2.xlarge</code> EC2实例，因为它是这个PoC(概念验证)的最便宜的可用选项。如果您也在尝试这种方法，我建议您使用这种实例类型，以避免严重影响您的账单。</p><p id="b6d6" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">同样，在这个例子中，我使用<a class="ae ld" href="https://github.com/kubernetes/kops" rel="noopener ugc nofollow" target="_blank"> kops </a>在AWS上创建一个k8s集群，有1个主节点和2个GPU节点。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="dcca" class="na lm iq mr b gy nb nc l nd ne">$ kops create cluster \ <br/>--name steven.buffer-k8s.com \ <br/>--cloud aws \ <br/>--master-size t2.medium \ <br/>--master-zones=us-east-1b \ <br/>--node-size p2.xlarge \ <br/>--zones=us-east-1a,us-east-1b,us-east-1c,us-east-1d,us-east-1e,us-east-1f \ <br/>--node-count=2 \ <br/>--kubernetes-version=1.8.6 \ <br/>--vpc=vpc-1234567a \ <br/>--network-cidr=10.0.0.0/16 \ <br/>--networking=flannel \ <br/>--authorization=RBAC \ <br/>--ssh-public-key="~/.ssh/kube_aws_rsa.pub" \ <br/>--yes</span></pre><h1 id="38d5" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">添加GPU节点</h1><p id="733b" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">kops成功创建集群后，k8s上将有一些GPU加速的节点。但这并不意味着你可以从Kubernetes访问GPU资源。为了让它工作，我们必须通过几道关卡，我发现这对大多数人来说可能很棘手。</p><p id="22b8" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">首先，我们需要更新节点，以正确配置k8s。这个<code class="fe mo mp mq mr b">kops</code>命令将为默认的minion节点配置打开一个编辑器。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="cf66" class="na lm iq mr b gy nb nc l nd ne">$ kops edit ig nodes</span></pre><p id="c025" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">我们将把默认AMI改为<code class="fe mo mp mq mr b">kope.io/k8s-1.8-debian-stretch-amd64-hvm-ebs-2018-01-05</code>，因为<code class="fe mo mp mq mr b">nvidia-docker</code>需要某个版本的包，而<code class="fe mo mp mq mr b">stretch</code>有，而<code class="fe mo mp mq mr b">jessie</code>没有。</p><p id="f220" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">然后我们为<code class="fe mo mp mq mr b">kublet</code>添加一个配置来启用<code class="fe mo mp mq mr b">DevicePlugins</code>。稍后详细介绍。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="7d1c" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">完成配置编辑后，执行此操作以应用更新。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="1397" class="na lm iq mr b gy nb nc l nd ne">$ kops update cluster steven.buffer-k8s.com --yes</span></pre><p id="bea4" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">Kubernetes现在可以通过Docker访问GPU了。但是等等，Docker运行时还没有准备好从主机访问GPU。继续读下去，我会告诉你怎么做。</p><h1 id="93a2" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">配置节点</h1><p id="33b4" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">因为<code class="fe mo mp mq mr b">kops</code>的默认AMI没有安装CUDA驱动。我们将不得不在每个节点中使用SSH来管理这一部分。</p><p id="aff1" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">复制这些命令来安装驱动程序。</p><h1 id="365f" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">安装CUDA潜水员</h1><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="9c3a" class="na lm iq mr b gy nb nc l nd ne">$ wget https://developer.nvidia.com/compute/cuda/9.1/Prod/local_installers/cuda_9.1.85_387.26_linux </span><span id="1ddc" class="na lm iq mr b gy nh nc l nd ne">$ sudo apt-get update &amp;&amp; sudo apt-get install -y \ <br/>build-essential</span><span id="158b" class="na lm iq mr b gy nh nc l nd ne">$ sudo sh cuda_9.1.85_387.26_linux </span><span id="481f" class="na lm iq mr b gy nh nc l nd ne">// Verify <br/>$ nvidia-smi</span></pre><h1 id="f80a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">安装docker-ce和nvidia-docker2</h1><p id="3fa0" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">现在我们需要正确设置Docker来通过CUDA访问GPU。为此，让我们安装<code class="fe mo mp mq mr b">nvidia-docker</code>和<code class="fe mo mp mq mr b">docker-ce</code>，更改一些配置并重启。</p><p id="defb" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">正如你所看到的，有一个铁环要跳过。我将告诉你让它工作的具体步骤。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="91fe" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">1-25行是关于安装<code class="fe mo mp mq mr b">docker-ce</code>和<code class="fe mo mp mq mr b">nvidia-docker</code>。第27行打开了docker的配置文件。将<code class="fe mo mp mq mr b">ExecStart</code>改为<code class="fe mo mp mq mr b">ExecStart=/usr/bin/dockerd -H fd:// -s=overlay2</code>。第36 - 46行将默认的docker运行时切换到使用<code class="fe mo mp mq mr b">nvidia</code>，这样就可以从docker容器中访问GPU。第48 - 50行重启<code class="fe mo mp mq mr b">kublet</code>，这样Kubernetes可以正确访问新的<code class="fe mo mp mq mr b">nvidia</code>运行时。最后一个命令将验证docker能够从容器访问CUDA。我们现在非常接近了！</p><h1 id="4a4e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">配置Kubernetes</h1><h1 id="7964" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">安装设备插件</h1><p id="b481" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">不确定最后一部分结束后你是否还在？我知道这很残忍。如果您有任何问题，请随时在<a class="ae ld" href="https://twitter.com/stevenc81" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上联系我。现在，Kubernetes需要最后一件事，最后一部分非常简单。似乎从Kubernetes 1.8 GPU设备是通过插件访问的。运行下面的命令将插件安装为DaemonSet，这样就设置好了。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="0e6e" class="na lm iq mr b gy nb nc l nd ne"># For Kubernetes v1.8 <br/>$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.8/nvidia-device-plugin.yml </span><span id="9bea" class="na lm iq mr b gy nh nc l nd ne"># For Kubernetes v1.9 <br/>$ kubectl create -f <a class="ae ld" href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.9/nvidia-device-plugin.yml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.9/nvidia-device-plugin.yml</a></span></pre><h1 id="7ef3" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">请求GPU</h1><p id="33c1" class="pw-post-body-paragraph kf kg iq kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ij bi translated">现在我们有了一个完全支持GPU的Kubernetes集群。想象力是你唯一的限制:D要利用GPU的力量，pod需要知道GPU是可用的，并请求它。这不像内存或CPU等其他资源那样直观。但这可能是一件好事，因为看一眼pod模板就知道它对GPU的要求。搞清楚总是件好事。pod模板演示了如何请求集群中现在可用的GPU。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h1 id="a148" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结束语</h1><ul class=""><li id="1f3e" class="ni nj iq kh b ki mj km mk kq nk ku nl ky nm lc nn no np nq bi translated">数据团队的速度不应受到基础设施需求的限制</li><li id="a0fd" class="ni nj iq kh b ki nr km ns kq nt ku nu ky nv lc nn no np nq bi translated">越来越多的数据技术需要不容易组装的专门设置</li><li id="8600" class="ni nj iq kh b ki nr km ns kq nt ku nu ky nv lc nn no np nq bi translated">支持GPU的k8s集群就是一个例子。以下是如何为深度学习工作负载创建一个。</li></ul></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="c73f" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated"><em class="le">最初发表于</em><a class="ae ld" href="https://gist.github.com/stevenc81/1cad3a0ebca9303923d1cd4c3641f8bc" rel="noopener ugc nofollow" target="_blank">T5【gist.github.com】</a><em class="le">。</em></p></div></div>    
</body>
</html>