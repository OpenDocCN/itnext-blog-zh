<html>
<head>
<title>Big Data Pipeline Recipe</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据管道配方</h1>
<blockquote>原文：<a href="https://itnext.io/big-data-pipeline-recipe-c416c1782908?source=collection_archive---------0-----------------------#2020-08-13">https://itnext.io/big-data-pipeline-recipe-c416c1782908?source=collection_archive---------0-----------------------#2020-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="6f3e" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="ffea" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果您从<a class="ae lm" href="https://en.wikipedia.org/wiki/Big_data" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">大数据</strong> </a>开始，通常会对大量可供选择的工具、框架和选项感到不知所措。在本文中，我将尝试总结出<strong class="kq iu">的要素</strong>和<strong class="kq iu">的基本配方</strong>，帮助您开始大数据之旅。我的目标是对不同的工具进行分类，并尝试解释每个工具的用途以及它如何适应生态系统。</p><p id="a08e" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">首先让我们回顾一些注意事项，并检查您是否真的有<em class="ls"> </em> <strong class="kq iu"> <em class="ls">大数据问题</em> </strong> <em class="ls">。</em>我将重点介绍可以在<strong class="kq iu">本地部署的<strong class="kq iu">开源</strong>解决方案。云提供商为您的数据需求提供了几种解决方案，我将在本文中略微提到它们。如果您在云中运行，您应该真正检查一下您有哪些选项，并从成本、可操作性、可管理性、监控和上市时间等方面将它们与开源解决方案进行比较。</strong></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi gj"><img src="../Images/63cef512929aa3352ac9b2b490b59f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eEQOHZ8RcC4cc46e"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">大数据生态系统</figcaption></figure><h1 id="19a9" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据考虑因素</h1><p id="f517" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="ls">(如果您有大数据方面的经验，请跳到下一部分……)</em></p><p id="5e46" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">大数据很复杂</strong>，除非万不得已，否则不要轻易涉足。要获得洞察力，从小处着手，也许可以使用<a class="ae lm" href="https://en.wikipedia.org/wiki/Elasticsearch" rel="noopener ugc nofollow" target="_blank">弹性搜索</a>和<a class="ae lm" href="https://prometheus.io/docs/introduction/overview/" rel="noopener ugc nofollow" target="_blank">普罗米修斯</a> / <a class="ae lm" href="https://grafana.com/" rel="noopener ugc nofollow" target="_blank">格拉法纳</a>开始收集信息，并创建仪表板来获得关于你的业务的信息。随着数据的扩展，这些工具可能不够好，或者维护起来过于昂贵。这时，您应该开始考虑数据湖或数据仓库；并切换你的思维设定开始<strong class="kq iu">思考</strong>大<strong class="kq iu">大</strong>。</p><p id="459a" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">检查您的数据的<strong class="kq iu">容量，您有多少数据，需要存储多长时间。检查数据的<strong class="kq iu">温度</strong>，它会随着时间的推移而失去值，那么您需要将数据存储多长时间？您需要多少储物层(热/暖/冷)？你能存档或删除数据吗？</strong></p><p id="ff56" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">你需要问自己的其他<strong class="kq iu">问题</strong>是:你存储的是什么类型的数据？你使用哪种格式？你有法律义务吗？您需要以多快的速度接收数据？您需要多快获得可供查询的数据？您期待什么类型的查询？OLTP还是OLAP？您的基础架构有哪些限制？您的数据是什么类型？关系？图表？文档？您是否有要实施的模式？</p><p id="0a48" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">我可以写几篇关于这个的文章，理解你的数据、设定<a class="ae lm" href="https://en.wikipedia.org/wiki/Domain-driven_design" rel="noopener ugc nofollow" target="_blank">界限</a>、要求、义务等对于这个食谱的工作是非常重要的。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/e2eddcda45b8bf5068f899b28fb2dab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/0*kMEEo80Ndn-BVlXV"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">大数据的4v</figcaption></figure><p id="f570" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">数据<strong class="kq iu">量</strong>是关键，如果你每天处理数十亿个事件或海量数据集，你需要将大数据原则应用到你的管道中。然而，<strong class="kq iu">没有单一的界限将<em class="ls">小</em>和<em class="ls">大</em>数据</strong>分开，其他方面，如<strong class="kq iu">速度</strong>、您的<strong class="kq iu">团队组织</strong>、<strong class="kq iu">公司</strong>的规模、所需的分析类型、<strong class="kq iu">基础设施</strong>或<strong class="kq iu">业务目标</strong>将影响您的大数据之旅。让我们回顾其中的一些…</p><h2 id="b9b5" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">OLTP与OLAP</h2><p id="a05b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">几年前，企业曾经拥有由关系数据库支持的在线应用程序，该数据库用于存储用户和其他结构化数据(<a class="ae lm" href="https://en.wikipedia.org/wiki/Online_transaction_processing" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> OLTP </strong> </a>)。一夜之间，这些数据通过复杂的作业归档到一个<strong class="kq iu">数据仓库</strong>中，该数据仓库针对数据分析和商业智能进行了优化(<a class="ae lm" href="https://en.wikipedia.org/wiki/Online_analytical_processing" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">【OLAP】</strong></a>)。历史数据被复制到数据仓库，并用于生成用于制定业务决策的报告。</p><h2 id="851e" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">数据仓库与数据湖</h2><p id="b7ea" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">随着数据的增长，数据仓库变得昂贵且难以管理。此外，公司开始存储和处理非结构化数据，如图像或日志。有了<strong class="kq iu">大数据</strong>，公司开始创建<a class="ae lm" href="https://medium.com/@javier.ramos1/introduction-to-data-lakes-afec9e1500ad" rel="noopener"> <strong class="kq iu">数据湖</strong> </a>来集中他们的结构化和非结构化数据，创建一个包含所有数据的存储库。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/cb9d020b7243a27a16fff74fb987d2ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/0*FDDNQHNVFwU9H0_2.png"/></div></figure><p id="9624" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">简而言之，数据湖只是一组将数据存储在<strong class="kq iu"> HA </strong> <strong class="kq iu">文件系统</strong>中的计算机节点和一组<a class="ae lm" href="http://www.bmc.com/guides/hadoop-ecosystem.html" rel="noopener ugc nofollow" target="_blank">T5】工具 </a>来处理数据并从中获得洞察力。基于<a class="ae lm" href="https://en.wikipedia.org/wiki/MapReduce" rel="noopener ugc nofollow" target="_blank"> Map Reduce </a>创建了一个庞大的工具生态系统，如<a class="ae lm" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Spark </a>使用更具<strong class="kq iu">成本效益的商用硬件来处理任何类型的数据</strong>。这个想法是，你可以在便宜的硬件上处理和存储数据，然后直接查询存储的文件，而不使用数据库，而是依靠文件格式和外部模式，我们将在后面讨论。Hadoop使用<a class="ae lm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> HDFS </strong> </a>文件系统以经济高效的方式存储数据。</p><p id="3ad8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于<strong class="kq iu"> OLTP </strong>来说，最近几年，有一种向<a class="ae lm" href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu"/></a>的转移，使用的数据库有<a class="ae lm" href="https://www.mongodb.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> MongoDB </strong> </a>或<a class="ae lm" href="https://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Cassandra </strong> </a>这样的数据库，它们可以扩展到SQL数据库的限制之外。然而，<strong class="kq iu">最新的数据库可以处理大量的数据</strong>并且可以用于OLTP和OLAP，并且以较低的成本用于流和批处理；甚至像<a class="ae lm" href="https://www.yugabyte.com/" rel="noopener ugc nofollow" target="_blank">yugabytdb</a>这样的事务型数据库也能处理海量数据。拥有许多系统、应用程序、来源和数据类型的大型组织将需要数据仓库和/或数据湖来满足他们的分析需求，但是如果您的公司没有太多的信息渠道和/或您在云中运行，一个单一的大规模数据库就足够了，<strong class="kq iu">简化</strong>您的架构并大幅<strong class="kq iu">降低成本</strong>。</p><h2 id="db84" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">Hadoop或无Hadoop</h2><p id="d77a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">自2006年发布以来，<a class="ae lm" href="https://en.wikipedia.org/wiki/Apache_Hadoop" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Hadoop </strong> </a>一直是大数据世界的主要参考。基于<a class="ae lm" href="https://en.wikipedia.org/wiki/MapReduce" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> MapReduce </strong> </a>编程模型，它允许使用简单的编程模型处理大量数据。这些年来，生态系统呈指数级增长，创建了一个丰富的生态系统来处理任何用例。</p><p id="9a36" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最近，有一些对Hadoop生态系统的<a class="ae lm" href="https://www.datanami.com/2018/10/18/is-hadoop-officially-dead/" rel="noopener ugc nofollow" target="_blank">批评</a>，很明显，在过去几年中，使用一直在减少。新的<strong class="kq iu"> OLAP </strong>引擎能够使用自己的数据格式以超低延迟接收和查询，已经取代了Hadoop中一些最常见的查询引擎；但最大的影响是云提供商发布的<a class="ae lm" href="https://aws.amazon.com/big-data/datalakes-and-analytics/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">无服务器分析</strong> </a>解决方案数量的增加，在这些解决方案中，您可以执行任何大数据任务<strong class="kq iu">而无需管理任何基础架构</strong>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mw"><img src="../Images/b90946b31ed3a8b1d0592b6f36338ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_ub60CBcQ55y_sXZ"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">简化的Hadoop生态系统</figcaption></figure><p id="59c2" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">鉴于Hadoop生态系统的规模和庞大的用户群，它似乎还远未消亡，许多较新的解决方案除了创建兼容的API和与Hadoop生态系统的集成之外别无选择。虽然HDFS是生态系统的核心，但它现在只在内部使用，因为云提供商已经建立了更便宜更好的深度存储系统，如S3或T21。云提供商也提供开箱即用的<strong class="kq iu">托管Hadoop集群</strong>。看起来，Hadoop仍然生机勃勃，但你应该记住，在你开始构建你的Hadoop生态系统之前，还有其他更新的替代方案。在本文中，我将尝试提及哪些工具是Hadoop生态系统的一部分，哪些工具与其兼容，哪些工具不是Hadoop生态系统的一部分。</p><h2 id="d494" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">批处理与流</h2><p id="759f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">根据您对数据温度的分析，您需要决定是否需要实时流、批处理或在许多情况下两者都需要<strong class="kq iu"/>。</p><p id="1081" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">在一个完美的世界里，你可以从实时的数据中获得所有的洞察力，执行基于窗口的聚合。然而，对于某些用例来说，这是不可能的，而对于另一些用例来说，这是不经济的；这就是为什么许多公司同时使用批处理和流处理。您应该检查您的业务需求，并决定哪种方法更适合您。例如，如果您只需要创建一些报告，批处理应该就足够了。<strong class="kq iu">批量更简单更便宜</strong>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e38632eb1bf81c44e68d0f4184726cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*H6asuVKeYGWlUOrN"/></div></figure><p id="afc4" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最新的处理引擎，如<a class="ae lm" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Flink </a>或<a class="ae lm" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Beam </a>，也被称为<strong class="kq iu">第四代大数据引擎</strong>，为批处理和流数据提供了统一的编程模型，其中批处理只是每24小时进行一次的流处理。这简化了编程模型。</p><p id="2543" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">一种常见的模式是为信用卡欺诈等时间关键型洞察提供流数据，为报告和分析提供批处理数据。较新的OLAP引擎允许以统一的方式查询两者。</p><h2 id="1235" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">ETL与ELT</h2><p id="f05a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">根据您的使用情况，您可能希望<strong class="kq iu">在加载或读取时转换数据</strong>。ELT意味着您可以执行查询，将转换和聚合数据作为查询的一部分，这可以使用SQL来实现，您可以在SQL中应用函数、过滤数据、重命名列、创建视图等。这可以通过大数据OLAP引擎实现，它提供了一种以ELT方式进行实时和批量查询的方法。另一个选择是在加载时转换数据(<strong class="kq iu"> ETL </strong>)，但是请注意，在处理过程中进行连接和聚合并不是一项简单的任务。一般来说，<strong class="kq iu">数据仓库使用ETL </strong>，因为它们倾向于需要固定的模式(星型或雪花型)，而<strong class="kq iu">数据湖更加灵活，可以在读取时执行ELT和模式</strong>。</p><p id="b75d" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">每种方法都有自己的优点和缺点。简而言之，读取时的转换和聚合较慢，但提供了更大的灵活性。如果您的查询很慢，您可能需要在处理阶段进行预连接或聚合。稍后讨论的OLAP引擎可以在接收期间执行预聚合。</p><h2 id="77b6" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">团队结构和方法</h2><p id="261a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">最后，您的<strong class="kq iu">公司政策、组织、方法、基础设施、团队结构和技能在您的大数据决策中发挥着重要作用</strong>。例如，您可能有一个数据问题，需要您创建一个管道，但您不必处理大量的数据，在这种情况下，您可以编写一个流应用程序，在单个管道中执行接收、丰富和转换，这更容易；但是，如果您的公司已经有了一个数据湖，您可能希望使用现有的平台，这是您不会从头开始构建的。</p><p id="6edd" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">再比如ETL vs ELT。开发人员倾向于构建ETL系统，其中的数据可以以简单的格式进行查询，因此非技术人员可以构建仪表板并获得洞察力。然而，如果您有一个强大的数据分析师团队和一个小的开发人员团队，您可能更喜欢ELT方法，其中开发人员只关注摄取；数据分析师编写复杂的查询来转换和聚合数据。这表明在您的大数据之旅中考虑您的团队结构和技能是多么重要。</p><p id="7af9" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">由于数据是整个组织中的一个跨职能方面，因此建议让一个拥有不同技能和背景的多元化团队一起工作。<strong class="kq iu">数据湖非常擅长在维护数据治理和安全性的同时实现轻松协作</strong>。</p><h1 id="a3ac" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">佐料</h1><p id="d619" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在回顾了大数据世界的几个方面之后，我们来看看有哪些基本成分。</p><h2 id="445e" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">数据(存储)</h2><p id="960d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">你首先需要的是一个存储所有数据的地方。不幸的是，没有一款产品能满足您的需求，这就是为什么您需要根据您的使用案例选择合适的存储。</p><p id="462a" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于实时<strong class="kq iu">数据摄取</strong>，通常使用追加日志来存储实时事件，最著名的引擎是<a class="ae lm" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Kafka </strong> </a>。一个备选就是<strong class="kq iu">阿帕奇</strong> <a class="ae lm" href="https://pulsar.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">脉冲星</strong> </a>。两者都提供流媒体功能，同时也为您的活动提供存储空间。这通常是热数据的短期存储(记住数据温度！)因为它不具有成本效益。还有其他工具，如<a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache NiFi </strong> </a>用于摄取数据，它们有自己的存储。最后，数据从附加日志转移到另一个存储，可能是数据库或文件系统。</p><p id="b475" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">海量数据库</strong></p><p id="65d3" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">然而，Hadoop HDFS是数据湖最常见的格式；大型数据库可以用作数据管道的后端，而不是文件系统；查看我以前关于<a class="ae lm" rel="noopener ugc nofollow" target="_blank" href="/massive-scale-databases-5b5917ed94e5"> <strong class="kq iu">大规模数据库</strong> </a> <strong class="kq iu"> </strong>的文章，了解更多信息。总之，像<a class="ae lm" href="https://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Cassandra </strong> </a>，<a class="ae lm" href="https://www.yugabyte.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">yugabytdb</strong></a>或<a class="ae lm" href="https://cloud.google.com/bigtable/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> BigTable </strong> </a>这样的数据库可以比数据湖更快地保存和处理大量数据，但并不便宜；然而，数据湖文件系统和数据库之间的价格差距一年比一年小；这是你在<strong class="kq iu"> Hadoop/NoHadoop决策</strong>中需要考虑的一部分。越来越多的公司现在选择大数据数据库而不是数据湖来满足其数据需求，并使用深度存储文件系统进行归档。</p><p id="c222" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">总结一下Hadoop生态系统之外的数据库和存储选项<strong class="kq iu"/>要考虑的有:</p><ul class=""><li id="c7d8" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Cassandra</strong></a><strong class="kq iu">:</strong>可以存储大量数据的NoSQL数据库，提供最终的一致性和许多配置选项。非常适合OLTP，但也可用于具有预先计算的聚合的OLAP(不灵活)。另一个选择是<a class="ae lm" href="https://www.scylladb.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> ScyllaDB </strong> </a>，它对于<a class="ae lm" href="https://www.scylladb.com/2019/05/23/workload-prioritization-running-oltp-and-olap-traffic-on-the-same-superhighway/" rel="noopener ugc nofollow" target="_blank"> OLAP </a> ( <a class="ae lm" href="https://www.scylladb.com/2019/05/23/workload-prioritization-running-oltp-and-olap-traffic-on-the-same-superhighway/" rel="noopener ugc nofollow" target="_blank">高级调度器</a>)来说更快更好</li><li id="d042" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://www.yugabyte.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">yugabytdb</strong></a>:可以处理全局事务的大规模关系数据库。关系数据的最佳选择。</li><li id="1072" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://www.mongodb.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> MongoDB </strong> </a>:强大的基于文档的NoSQL数据库，可用于摄取(临时存储)或作为仪表板的快速数据层</li><li id="d2c0" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://www.influxdata.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> InfluxDB </strong> </a>为时间序列数据。</li><li id="35f0" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://prometheus.io/docs/introduction/overview/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">普罗米修斯</strong> </a>为监测数据。</li><li id="c197" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Elasticsearch" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> ElasticSearch </strong> </a>:可以存储大量数据的分布式倒排索引。有时被许多人忽略或仅用于日志存储，ElasticSearch可用于广泛的用例，包括OLAP分析、机器学习、日志存储、非结构化数据存储等等。绝对是您的大数据生态系统中必备的工具。</li></ul><p id="64ea" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">记住<a class="ae lm" href="https://www.bmc.com/blogs/sql-vs-nosql/" rel="noopener ugc nofollow" target="_blank"> SQL和NoSQL </a>、<strong class="kq iu">之间的区别在NoSQL世界中，你不要对数据建模，你要对你的查询建模。</strong></p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nm nn l"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">数据库比较</figcaption></figure><p id="af68" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu"> Hadoop数据库</strong></p><p id="1f1c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://hbase.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> HBase </strong> </a>是Hadoop生态系统内最受欢迎的数据库<strong class="kq iu">。它可以以列格式保存大量数据。它基于<a class="ae lm" href="https://research.google.com/archive/bigtable.html" rel="noopener ugc nofollow" target="_blank"> BigTable </a>。</strong></p><p id="7a36" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">文件系统</strong> </a> <strong class="kq iu">(深层存储)</strong></p><p id="c5ad" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于<strong class="kq iu">数据湖</strong>，在Hadoop生态系统中，使用<a class="ae lm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> HDFS </strong> </a>文件系统。然而，大多数云提供商已经将其替换为自己的深度存储系统，如<a class="ae lm" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu"/></a>或<a class="ae lm" href="https://cloud.google.com/storage/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> GCS </strong> </a>。</p><p id="a95f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">这些文件系统或深度存储系统比数据库便宜，但只提供基本存储，不提供强有力的保证。</p><p id="26d8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">您需要根据您的需求和预算，为您的使用情形选择合适的存储。例如，如果预算允许，您可以使用数据库进行接收，然后一旦数据被转换，就将其存储在您数据湖中以供OLAP分析。或者，您可以将所有内容存储在深层存储中，而将一小部分热数据存储在快速存储系统(如关系数据库)中。</p><p id="5ba8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">文件格式</strong></p><p id="6f60" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">如果你使用<strong class="kq iu"> HDFS </strong>，另一个重要的决定是你将使用什么格式存储你的文件。请注意，深度存储系统将数据存储为文件，不同的文件格式和压缩算法为某些用例提供了好处。<strong class="kq iu">如何在数据湖中存储数据至关重要</strong>，你需要考虑<strong class="kq iu">格式</strong>、<strong class="kq iu">压缩</strong>，尤其是<strong class="kq iu">你如何</strong> <a class="ae lm" href="https://mungingdata.com/apache-spark/partitionby/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">分割</strong> </a> <strong class="kq iu">你的数据。</strong></p><p id="6854" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最常见的格式有CSV，JSON，<a class="ae lm" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu"/></a><strong class="kq iu">，</strong> <a class="ae lm" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">协议缓冲区</strong> </a> <strong class="kq iu">，</strong> <a class="ae lm" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Parquet </strong> </a>，以及<a class="ae lm" href="https://orc.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> ORC </strong> </a>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi no"><img src="../Images/bfeb73f984fdeee4f2b9db17769ed540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I0tnwDCXY-yF16u9.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">文件格式之间的比较</figcaption></figure><p id="249e" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">选择格式时要考虑的一些事情有:</p><ul class=""><li id="28f2" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated">数据的结构:一些格式接受嵌套数据，比如JSON、Avro或Parquet，而其他格式则不接受。即使有，也可能不是高度优化的。Avro是嵌套数据最有效的格式，我建议不要使用Parquet嵌套类型，因为它们非常低效。处理嵌套的JSON也非常耗费CPU资源。一般来说，建议在摄取数据时将数据拉平。</li><li id="46e6" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">性能</strong>:Avro和Parquet等一些格式的性能比其他JSON等要好。即使在Avro和Parquet之间，对于不同的用例，一个会比另一个更好。例如，因为Parquet是一种基于列的格式，所以使用SQL查询数据湖很好，而Avro更适合ETL行级转换。</li><li id="fe75" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">易读</strong>:考虑你是否需要人们阅读数据。JSON或CSV是文本格式，是人类可读的，而更高性能的格式如parquet或Avro是二进制的。</li><li id="54d0" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">压缩</strong>:有些格式比其他格式提供更高的压缩率。</li><li id="a193" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">模式演变</strong>:在数据湖中添加或删除字段远比在数据库中复杂。像Avro或Parquet这样的格式提供了某种程度的模式进化，允许您在更改数据模式的同时查询数据。像<a class="ae lm" href="https://delta.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">三角洲湖</strong> </a>格式这样的工具提供了更好的工具来处理模式的变化。</li><li id="aed2" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">兼容性</strong> : JSON或CSV被广泛采用，几乎与任何工具兼容，而性能更高的选项集成点更少。</li></ul><p id="0c8f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">正如我们所看到的，CSV和JSON是易于使用、人类可读的常见格式，但缺乏其他格式的许多功能，这使得它太慢，无法用于查询数据湖。<strong class="kq iu"> ORC和Parquet </strong>在Hadoop生态系统中广泛用于<strong class="kq iu">查询数据</strong>，而<a class="ae lm" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Avro </strong> </a>也在Hadoop之外使用，尤其是与Kafka一起用于摄取，非常适合<strong class="kq iu">行级ETL </strong>处理。面向行的格式比面向列的格式具有更好的模式进化能力，这使它们成为数据摄取的一个很好的选择。</p><p id="f145" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最后，你还需要考虑如何<strong class="kq iu">压缩文件中的数据</strong>考虑文件大小和CPU成本之间的权衡。一些压缩算法速度较快，但文件较大，而另一些速度较慢，但压缩率较高。更多详情请查看这篇<a class="ae lm" href="http://www.dbtalks.com/article/what-are-different-data-compression-methods-in-hadoop/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">文章</strong> </a>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi np"><img src="../Images/de5e404678d465e2472fdf7cf309689d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*I90pjcqqndBBInUuiZGi_w.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">压缩选项</figcaption></figure><p id="ba4b" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">我推荐使用snappy来传输数据流，因为它不需要太多的CPU能力。对于批量bzip2是一个很好的选择。</p><p id="ca98" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">同样，您需要回顾我们之前提到的注意事项，并根据我们回顾的所有方面做出决定。让我们以一些使用案例为例:</p><p id="5dd6" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">用例</strong></p><ul class=""><li id="ddf3" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated">作为ETL管道的一部分，您需要接收实时数据并存储在某个地方，以便进一步处理。如果性能很重要，预算不是问题，你可以使用Cassandra。标准的方法是使用优化的格式将它存储在HDFS，如AVRO。</li><li id="296b" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">您需要处理您的数据，并将其存储在某个地方，以供高度交互式的用户使用，面向延迟很重要的应用程序(OLTP)，您事先知道查询。在这种情况下，根据数据量使用Cassandra或其他数据库。</li><li id="7cfd" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">您需要将处理过的数据提供给用户群，一致性很重要，并且您不知道预先的查询，因为UI提供了高级查询。在这种情况下，您需要一个关系型SQL数据库，根据您的情况，一个经典的SQL DB(如MySQL)就足够了，或者您可能需要使用YugaByteDB或其他关系型大规模数据库。</li><li id="067a" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">您需要存储已处理的数据，以便内部团队进行OLAP分析，这样他们就可以运行特殊查询并创建报告。在这种情况下，您可以将数据以Parquet或ORC格式存储在深层存储文件系统中。</li><li id="34fc" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">您需要使用SQL来运行历史数据的即席查询，但是您还需要需要在不到一秒钟内做出响应的仪表板。在这种情况下，您需要一种混合方法，将数据的子集存储在一个快速存储中，比如MySQL数据库，并将历史数据以Parquet格式存储在数据湖中。然后，使用查询引擎通过SQL查询不同的数据源。</li><li id="85e0" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">您需要执行需要在几毫秒内响应的非常复杂的查询，您可能还需要在读取时执行聚合。在这种情况下，使用ElasticSearch或一些更新的OLAP系统来存储数据，比如我们稍后将讨论的<a class="ae lm" href="https://docs.pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Pinot </a>。</li><li id="1bf8" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">你需要搜索非结构化的文本。在这种情况下，使用ElasticSearch。</li></ul><h2 id="1ba1" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">基础设施</h2><p id="e51b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在决定使用哪些工具时，您当前的基础设施会限制您的选择。首先要问的问题是:<strong class="kq iu">云vs本地</strong>。云提供商提供了许多选择和灵活性。此外，它们为您的大数据需求提供了无需服务器的解决方案，更易于管理和监控。毫无疑问，云是大数据的去处；即使对于Hadoop生态系统，<strong class="kq iu">云提供商也提供托管集群</strong>和比本地更便宜的存储。查看我关于云解决方案的其他文章。</p><p id="893f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">如果您在内部运行<strong class="kq iu">，您应该考虑以下几点:</strong></p><ul class=""><li id="91a2" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu">我在哪里运行我的工作负载？</strong>肯定<a class="ae lm" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Kubernetes </strong> </a>或者<strong class="kq iu">Apache</strong><a class="ae lm" href="https://mesos.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Mesos</strong></a><strong class="kq iu"/>提供统一的编排框架，以统一的方式运行你的应用。无论您使用何种框架，部署、监控和警报方面都是相同的。相比之下，如果您在裸机上运行，您需要考虑和管理部署的所有横切方面。在这种情况下，托管集群和工具比库和框架更合适。</li><li id="2d61" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">我有什么类型的硬件？如果你有配备快速固态硬盘和高端服务器的专用硬件，那么你可能能够部署像Cassandra这样的大规模数据库，并获得出色的性能。如果你只是拥有商用硬件，Hadoop生态系统将是一个更好的选择。理想情况下，您希望有几种类型的服务器用于不同的工作负载；对卡珊德拉的要求与HDFS大不相同。</li></ul><h2 id="161c" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">监控和警报</h2><p id="adbd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下一个要素对于数据管道的成功至关重要。在大数据世界里，<strong class="kq iu">你需要关于你的流程和数据的持续反馈</strong>。您需要<strong class="kq iu">收集指标、收集日志、</strong>监控您的系统、创建<strong class="kq iu">警报</strong>、<strong class="kq iu">仪表板</strong>等等。</p><p id="cb79" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">使用开源工具如<a class="ae lm" href="https://prometheus.io/docs/introduction/overview/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Prometheus </strong> </a>和<a class="ae lm" href="https://grafana.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Grafana </strong> </a>进行监控和报警。使用日志聚合技术收集日志并存储在类似<a class="ae lm" href="https://en.wikipedia.org/wiki/Elasticsearch" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">elastic search</strong></a>的地方。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nq"><img src="../Images/1db6b1ad47a4e35c360e1a4b8d1dcfb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UrteUuCBUBCehY2d"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">Grafana监控</figcaption></figure><p id="f026" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">尽可能利用云提供商的能力</strong>进行监控和警报。根据您的平台，您将使用不同的工具集。对于云无服务器平台，您将依赖您的云提供商工具和最佳实践。对于Kubernetes，您将使用开源监视器解决方案或企业集成。我非常推荐这个<a class="ae lm" href="https://openapm.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">网站</strong> </a>，在这里你可以浏览和检查不同的解决方案，并构建你自己的<a class="ae lm" href="https://en.wikipedia.org/wiki/Application_performance_management" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> APM </strong> </a>解决方案。</p><p id="40aa" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">大数据世界中需要考虑的另一件事是可审计性和问责制。由于不同的法规，您可能需要跟踪数据，在数据流经管道时捕获并记录每一个变化。这被称为<strong class="kq iu">数据起源或血统</strong>。像<a class="ae lm" href="https://atlas.apache.org/#/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇图集</strong> </a>这样的工具被用来控制、记录和治理你的数据。其他工具如<a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache NiFi </strong> </a>支持开箱即用的数据沿袭。对于<strong class="kq iu">实时痕迹，</strong>检查<a class="ae lm" href="https://opentelemetry.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">打开遥测</strong> </a> <strong class="kq iu">或</strong> <a class="ae lm" href="https://www.jaegertracing.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">耶格</strong> </a> <strong class="kq iu">。</strong>还有很多云服务比如<strong class="kq iu"/><a class="ae lm" href="https://www.datadoghq.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Datadog</strong></a><strong class="kq iu">。</strong></p><p id="7484" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于Hadoop使用，<a class="ae lm" href="http://ganglia.sourceforge.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Ganglia </strong> </a>。</p><h2 id="8a4d" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">安全性</h2><p id="4508" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><a class="ae lm" href="https://ranger.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Ranger</strong></a><strong class="kq iu"/>为您的Hadoop平台提供统一的安全监控框架。提供集中的安全管理，在一个中央用户界面中管理所有与安全相关的任务。它提供了使用不同方法的<strong class="kq iu">授权</strong>，以及跨整个Hadoop平台的完全可审计性。</p><h2 id="d741" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">人</h2><p id="1b74" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">你的团队是成功的关键。大数据工程师可能很难找到。投资培训、技能提升和研讨会。去除孤岛和繁文缛节，简化迭代，使用<a class="ae lm" href="https://en.wikipedia.org/wiki/Domain-driven_design" rel="noopener ugc nofollow" target="_blank">域驱动设计</a>来设定你的团队边界和职责。</p><p id="f010" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于大数据，您将有<strong class="kq iu">两大类别</strong>:</p><ul class=""><li id="d8a3" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu">数据工程师</strong>负责摄取、浓缩和转换。这些工程师拥有<strong class="kq iu">强大的开发和运营背景</strong>，负责创建数据管道。开发人员、管理员、DevOps专家等都属于这一类。</li><li id="045f" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">数据科学家</strong>:他们可以是商业智能专家、数据分析师等。负责生成报告、仪表板和收集见解。这些人专注于<strong class="kq iu"> OLAP </strong>，凭借对商业的深刻理解，收集将用于做出关键商业决策的数据。<strong class="kq iu">擅长SQL </strong>和可视化，但在软件开发方面较弱。机器学习专家也可能属于这一类。</li></ul><h2 id="bff6" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">预算</h2><p id="fbc6" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这是一个重要的考虑因素，你需要钱来购买所有其他成分，而这是一种有限的资源。如果你有无限的资金，你可以部署一个大规模的数据库，并使用它来满足你的大数据需求，而不会有很多复杂性，但这将花费你。因此，本文中提到的每项技术都需要有技能的人来使用、部署和维护它。有些技术比其他技术更复杂，所以你需要考虑到这一点。</p><h1 id="1d41" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">秘诀</h1><p id="6724" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在我们有了原料，让我们来烹饪大数据食谱。简而言之，这个过程很简单；您需要从不同的来源接收数据、丰富数据、将数据存储在某个地方、存储元数据(模式)、清理数据、规范化数据、处理数据、隔离坏数据、以最佳方式聚合数据，并最终将数据存储在某个地方供下游系统使用。</p><p id="966f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">让我们更详细地看一下每一步…</p><h2 id="28ac" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">摄取</h2><p id="cf57" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">第一步是获取数据，<strong class="kq iu">这个阶段的目标是获取您需要的所有数据，并将其以原始格式存储在一个存储库中。</strong>这通常由其他团队所有，他们将数据推送到Kafka或数据存储中。</p><p id="021c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于没有大量数据的简单管道，您可以构建一个简单的微服务工作流，在单个管道中接收、丰富和转换数据(接收+转换)，您可以使用工具<a class="ae lm" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache air flow</strong></a>来编排依赖关系。然而，对于大数据，建议您<strong class="kq iu">将接收与处理</strong>分开，可以并行运行的大规模处理引擎不太适合处理阻塞调用、重试、反压力等。因此，建议在开始处理之前保存所有数据。作为摄取的一部分，您应该通过调用其他系统来丰富您的数据，以确保所有数据(包括参考数据)在处理之前都已进入湖中。</p><p id="9dbe" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">有两种摄取方式:<strong class="kq iu">:</strong></p><ul class=""><li id="95e5" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu">拉</strong>:从数据库、文件系统、队列或API等地方拉数据</li><li id="a2a4" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">推送</strong>:应用程序也可以将数据推送到你的湖中，但我们总是建议在两者之间有一个像<strong class="kq iu">卡夫卡</strong>那样的消息平台。一个常见的模式是<strong class="kq iu">变更数据捕获</strong> ( <a class="ae lm" href="https://en.wikipedia.org/wiki/Change_data_capture" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> CDC </strong> </a>)，它允许我们实时地将数据从数据库和其他系统转移到湖中。</li></ul><p id="8741" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">正如我们已经提到的，使用<strong class="kq iu"/><a class="ae lm" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Kafka</strong></a><strong class="kq iu">或</strong><a class="ae lm" href="https://pulsar.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Pulsar</strong></a><strong class="kq iu"/>作为数据摄取的<strong class="kq iu">中介</strong>来实现持久性、反压、并行化和对摄取的监控是非常常见的。然后，使用<a class="ae lm" href="https://docs.confluent.io/current/connect/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Kafka Connect </strong> </a>将数据保存到您的数据湖中。这个想法是，您的OLTP系统将向Kafka发布事件，然后将它们摄取到您的湖中。<strong class="kq iu">避免直接通过API</strong>批量摄取数据；您可以调用HTTP端点来丰富数据，但请记住，从API获取数据在大数据世界中并不是一个好主意，因为它速度慢、容易出错(网络问题、延迟……)，并且会导致源系统停机。虽然，API在OLTP世界中设置领域边界很棒，但是这些边界是由大数据 <strong class="kq iu">世界</strong>中<strong class="kq iu"> Kafka中的数据存储(批处理)或主题(实时)设置的。当然，这总是取决于你的数据的大小，但是如果你没有其他选择的话，尽可能使用Kafka或者Pulsar。从API中以流式方式提取少量数据，而不是批量提取。对于数据库，使用<a class="ae lm" href="https://debezium.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Debezium </strong> </a>等工具将数据流式传输到Kafka (CDC)。</strong></p><p id="a914" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">为了最大限度地减少依赖性，如果<strong class="kq iu">源系统将数据推送到Kafka </strong>而不是您的团队拉数据，这总是更容易，因为您将与其他源系统紧密耦合。如果这是不可能的，并且您仍然需要拥有摄取过程，我们可以看一下<strong class="kq iu">摄取的两大类别:</strong></p><ul class=""><li id="e2f1" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu"> Un Managed Solutions </strong>:这些是您开发的应用程序，用于将数据接收到您的数据湖中；你可以在任何地方运行它们。当从没有现成解决方案的API或其他I/O阻塞系统获取数据时，或者当您不使用Hadoop生态系统时，这种<strong class="kq iu">非常常见。这个想法是使用流库从不同的主题、端点、队列或文件系统接收数据。因为你正在开发应用程序，所以你有充分的<strong class="kq iu">灵活性</strong>。大多数库提供重试、反压、监控、批处理等等。这是一种<strong class="kq iu">自己编码</strong>的方法，因此您将需要其他工具来进行编排和部署。你得到了更多的控制和更好的性能，但需要付出更多的努力。您可以让单个整体或微服务使用服务总线进行通信，或者使用外部工具进行编排。一些可用的库有Apache <a class="ae lm" href="https://camel.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Camel </strong> </a>或<a class="ae lm" href="https://akka.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Akka生态系统</strong></a><strong class="kq iu"/>(<a class="ae lm" href="https://doc.akka.io/docs/akka-http/current/index.html" rel="noopener ugc nofollow" target="_blank">Akka HTTP</a>+<a class="ae lm" href="https://doc.akka.io/docs/akka/current/stream/index.html" rel="noopener ugc nofollow" target="_blank">Akka Streams</a>+<a class="ae lm" href="https://doc.akka.io/docs/akka/current/index-cluster.html" rel="noopener ugc nofollow" target="_blank">Akka Cluster</a>+<a class="ae lm" href="https://doc.akka.io/docs/akka/current/typed/index-persistence.html" rel="noopener ugc nofollow" target="_blank">Akka持久性</a> + <a class="ae lm" href="https://doc.akka.io/docs/alpakka/current/index.html" rel="noopener ugc nofollow" target="_blank"> Alpakka </a>)。根据摄入管道的复杂程度，您可以将其部署为<strong class="kq iu">整体或微服务</strong>。如果您使用<strong class="kq iu"> Kafka或Pulsar </strong>，您可以将它们用作摄取编排工具来获取数据并丰富数据。每个阶段将数据移动到一个新的主题，通过使用主题进行依赖性管理，在基础结构本身</strong>中创建一个<a class="ae lm" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> DAG </strong> </a> <strong class="kq iu">。如果你没有Kafka并且你想要一个更加可视化的工作流，你可以使用<a class="ae lm" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache air flow</strong></a>来编排依赖关系并运行DAG。这个想法是要有一系列的服务来接收和丰富数据，然后将其存储在某个地方。每一步完成后，执行下一步，由气流协调。最后，数据被存储在某种存储器中。</strong></li><li id="6b42" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">托管解决方案</strong>:在这种情况下，您可以使用部署在集群中用于接收的工具。这在Hadoop生态系统中很常见，您可以使用<a class="ae lm" href="https://sqoop.apache.org/docs/1.99.7/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Sqoop </strong> </a>等工具从OLTP数据库中获取数据，使用<a class="ae lm" href="https://flume.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Flume </strong> </a>获取流数据。这些工具提供监控、重试、增量加载、压缩等等。</li></ul><p id="e81c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇尼菲</strong> </a></p><p id="4ca5" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">NiFi是很难归类的工具之一。它本身就是一头野兽。它可以用于接收、编排甚至简单的转换。所以理论上，它可以解决简单的大数据问题。这是一个<strong class="kq iu">托管解决方案</strong>。它有一个<strong class="kq iu">可视界面</strong>，你可以拖放组件，用它们来获取和丰富数据。它有超过300个内置处理器，可以执行许多任务，你可以通过实现自己的来扩展它。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/acf96c1352f292a2249aa2ff34c490ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*aFV-nCjBVDZYNWFD.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">NiFi工作流</figcaption></figure><p id="3b0c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">它有自己的架构，所以它不使用任何数据库HDFS，但它与Hadoop生态系统中的许多工具进行了集成。可以调用API，集成Kafka，FTP，很多文件系统和云存储。您可以管理执行路由、过滤和基本ETL的数据流。对于某些用例，NiFi可能就是你所需要的。</p><p id="f11f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">然而，NiFi不能扩展到超过某个点，因为超过10个节点的集群中的节点间通信会变得低效。它倾向于更好地垂直扩展，但是您可能会达到它的极限，特别是对于复杂的ETL。但是，您可以将它与Spark等工具集成在一起来处理数据。NiFi是获取和丰富数据的绝佳工具。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="0316" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">现代的<strong class="kq iu"> OLAP </strong>引擎比如<a class="ae lm" href="https://druid.apache.org/technology" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">德鲁伊</strong> </a>或者<a class="ae lm" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">比诺</strong> </a>也提供了批量和流数据的自动摄取，我们将在另一节中谈到它们。</p><p id="bf9f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">您还可以在摄取期间进行一些<strong class="kq iu">初始验证和数据清理</strong>，只要它们不是昂贵的计算或者不跨越有界的上下文，请记住，空字段可能与您无关，但对另一个团队很重要。</p><p id="5218" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最后一步是决定数据的存放位置，我们已经讨论过了。您可以使用数据库或深层存储系统。对于一个数据湖，通常存储在HDFS，格式将取决于下一步；如果你计划执行行级操作，Avro是一个很好的选择。Avro还支持使用<a class="ae lm" href="https://github.com/confluentinc/schema-registry" rel="noopener ugc nofollow" target="_blank">外部注册中心</a>的模式进化，这将允许您相对容易地为摄取的数据更改模式。</p><h2 id="7a5e" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">[计]元数据</h2><p id="18f7" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">存储数据后的下一步是保存元数据(关于数据本身的信息)。最常见的元数据是<strong class="kq iu">模式</strong>。通过使用外部元数据存储库，数据湖或数据管道中的不同工具可以查询它来推断数据模式。</p><p id="de2c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">如果您使用<strong class="kq iu"> Avro </strong>获取原始数据，那么<a class="ae lm" href="https://github.com/confluentinc/schema-registry" rel="noopener ugc nofollow" target="_blank">外部注册表</a>是一个不错的选择。这样你就可以很容易地将摄入与加工分离开来。</p><p id="986a" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">一旦数据被摄取，为了被OLAP引擎查询，使用<strong class="kq iu">SQL</strong><a class="ae lm" href="https://en.wikipedia.org/wiki/Data_definition_language" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">DDL</strong></a>是很常见的。Hadoop生态系统中使用最多的数据湖/数据仓库工具是<a class="ae lm" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Hive</strong></a><strong class="kq iu">，</strong>，它提供了一个元数据存储，因此您可以像使用数据仓库一样使用数据湖和已定义的模式。您可以在Hive上运行SQL查询，并连接许多其他工具如<a class="ae lm" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Spark </a>来使用<a class="ae lm" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> Spark SQL </a>运行SQL查询。Hive是Hadoop生态系统中的一个重要工具，为您的分析查询提供了一个<strong class="kq iu">集中式元数据库</strong>。其他工具如Apache Tajo构建在Hive之上，在您的数据湖中提供数据仓库功能。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/8cb32afbe042ca1ec5311370487fd411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/0*bugYA6Cu17k-3__H"/></div></figure><p id="6eda" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://impala.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Impala</strong></a><strong class="kq iu"/>是Hadoop的原生<strong class="kq iu">分析数据库</strong>，它提供元数据存储，您仍然可以使用<a class="ae lm" href="https://cwiki.apache.org/confluence/display/Hive/HCatalog" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Hcatalog </strong> </a>连接到Hive获取元数据。</p><p id="f66f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://phoenix.apache.org/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Phoenix</strong></a>也有一个metastore，可以和Hive一起工作。Phoenix专注于使用ACID属性对事务进行查询的OLTP。它很灵活，通过利用HBase作为其后备存储，提供了来自NoSQL世界的模式读取功能。<strong class="kq iu">阿帕奇</strong> <a class="ae lm" href="https://druid.apache.org/technology" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">德鲁伊</strong> </a>或<a class="ae lm" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">比诺</strong> </a> <strong class="kq iu"> </strong>也提供元数据存储。</p><h2 id="ebc2" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">处理</h2><p id="1381" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">此阶段的目标是使用单一模式清理、规范化、处理和保存数据。最终结果是一个<strong class="kq iu">可信的数据集，具有定义良好的模式。</strong></p><p id="4eec" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">通常，您需要进行某种处理，例如:</p><ul class=""><li id="5063" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu">验证</strong>:通过将数据存储在单独的存储器中来验证数据并隔离坏数据。根据您的数据质量要求，在达到某个阈值时发送警报。</li><li id="dba1" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">争论和清理</strong>:清理你的数据，并以另一种格式存储以便进一步处理，例如用Avro替换低效的JSON。</li><li id="cecc" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">数值的标准化</strong>和<strong class="kq iu">标准化</strong></li><li id="d0d9" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">重命名</strong>字段</li><li id="95d3" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi">…</li></ul><p id="ea4e" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">记住，我们的目标是创建一个<strong class="kq iu">可信的数据集</strong>，以后可以用于下游系统。这是数据工程师的一个关键角色。<strong class="kq iu">这可以以流或分批的方式进行。</strong></p><p id="76b6" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">在<strong class="kq iu">批量加工</strong>的情况下，管道加工可分为<strong class="kq iu">三个阶段</strong>:</p><ul class=""><li id="55fa" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><strong class="kq iu">预处理阶段</strong>:如果原始数据不干净或者格式不对，需要进行预处理。这一阶段包括一些基本的验证，但目标是<strong class="kq iu">为下一阶段</strong>准备有效处理的数据。在这个阶段，你应该尝试<strong class="kq iu">将数据扁平化，保存为二进制格式</strong>比如Avro。这将加速进一步的处理。这个想法是，下一阶段将执行行级操作，而嵌套查询开销很大，因此现在将数据扁平化将提高下一阶段的性能。</li><li id="0c32" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">可信阶段</strong>:数据被<strong class="kq iu">验证、清理、规范化并被</strong>转换为存储在<strong class="kq iu">配置单元</strong>中的公共模式。目标是创建数据所有者理解的可信公共数据集。通常，会创建一个数据<strong class="kq iu">规范</strong>，数据工程师的角色是应用转换来匹配规范。最终结果是一个可以轻松查询的<strong class="kq iu"> Parquet </strong>格式的数据集。选择正确的分区并优化数据以执行内部查询至关重要。您可能希望在此阶段部分预计算一些聚合，以提高查询性能。</li><li id="374c" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">报告阶段</strong>:这一步是可选的，但经常是必需的。不幸的是，当使用数据湖时，<strong class="kq iu">一个单一的模式不能满足所有的用例</strong>；这是数据仓库和数据湖之间的一个区别。查询HDFS不如数据库或数据仓库高效，因此需要进一步优化。在这个阶段，你可能需要<strong class="kq iu">去规范化</strong>数据，使用不同的分区来存储它，这样不同的利益相关者可以更有效地查询它。这个想法是为不同的下游系统(<a class="ae lm" href="https://en.wikipedia.org/wiki/Data_mart" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">数据集市</strong> </a>)创建不同的<strong class="kq iu">视图</strong>。在此阶段，如果不使用OLAP引擎，您也可以计算聚合(请参见下一节)。可信阶段不知道谁将查询数据，这个阶段为消费者优化数据。如果客户端是高度交互的，您可能希望在这个阶段引入一个快速存储层，比如用于快速查询的关系数据库。或者，你可以使用OLAP发动机，我们将在后面讨论。</li></ul><p id="82a7" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">对于流式传输，逻辑是相同的，但它将以流式方式在定义的DAG内运行。Spark允许你加入带有历史数据的流，但是它有一些限制。我们稍后将讨论<strong class="kq iu"> OLAP引擎</strong>，它更适合将实时数据与历史数据合并。</p><p id="269c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">加工框架</strong></p><p id="74f6" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">一些可用于处理的工具有:</p><ul class=""><li id="c483" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Spark </strong> </a>:这是最广为人知的批处理框架。作为Hadoop生态系统的一部分，它是一个由<strong class="kq iu">管理的</strong>集群，可提供难以置信的<strong class="kq iu">并行性</strong>、监控和出色的UI。它还支持流处理(<a class="ae lm" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">结构化流</a>)。基本上，Spark在内存中运行MapReduce作业，其性能是普通MapReduce的100倍。它与Hive集成以支持<a class="ae lm" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> SQL </a>，并可用于创建Hive表、视图或查询数据。它有很多集成，支持多种格式，有一个巨大的社区。它受到所有云提供商的支持。它可以作为Hadoop集群的一部分运行在<a class="ae lm" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> YARN </strong> </a>上，也可以运行在Kubernetes和其他平台上。它有许多针对特定用例的库，如SQL或机器学习。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/58b0e7dfd0492b5ca55ea5fca5abb8cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*qd1vwAWnb9oEpHkE.png"/></div></figure><ul class=""><li id="40fa" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇Flink </strong> </a>:第一个统一批处理和流式传输但重点放在<strong class="kq iu">流式传输</strong>的引擎。可以作为Kafka这样的微服务的骨干。它可以作为Hadoop集群的一部分运行在YARN上，但从一开始就已经针对Kubernetes或Mesos等其他平台进行了优化。它<strong class="kq iu">极快</strong>并提供实时流，对于<strong class="kq iu">低延迟</strong>流处理，尤其是对于<strong class="kq iu">有状态</strong>流，它比Spark更好。它也有SQL，机器学习和更多的库。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ob"><img src="../Images/ad99326e891372dea730abf4079df781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lQXpOeJl1Kros6S_.png"/></div></div></figure><ul class=""><li id="9094" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://storm.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Storm</strong></a>:Apache Storm是一个免费开源的分布式实时计算系统。它专注于流，是Hadoop生态系统的托管解决方案的一部分。它是可扩展的、容错的，保证您的数据将被处理，并且易于设置和操作。</li><li id="9912" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://samza.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Samza </strong> </a>:另一个伟大的有状态流处理引擎。Samza允许您构建有状态的应用程序，实时处理来自包括Apache Kafka在内的多个来源的数据。托管解决方案运行在YARN之上的Hadoop生态系统的一部分。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oc"><img src="../Images/6302a120a4597702656084c7c02a8d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eYA_M7zSZrBel9_C.png"/></div></div></figure><ul class=""><li id="1617" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Beam</strong></a>:Apache Beam它本身不是一个引擎，而是一个<strong class="kq iu">统一编程模型</strong>的<strong class="kq iu">规范</strong>，集合了所有其他引擎。它提供了一种可以与<strong class="kq iu">不同语言</strong>一起使用的编程模型，因此开发者在处理大数据管道时不必学习新的语言。然后，它插入<strong class="kq iu">不同的后端</strong>用于可以在云上或本地运行的处理步骤。Beam支持前面提到的所有引擎，您可以轻松地在它们之间切换，并在任何平台上运行它们:cloud、YARN、Mesos、Kubernetes。如果您正在开始一个新项目，我真的建议从Beam开始，以确保您的数据管道经得起未来的考验。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi od"><img src="../Images/2c8b41e1727d49bebffcad206d0fb12d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4Qhbcyzg68sVm6OE.png"/></div></div></figure><p id="49c8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">在这个处理阶段结束时，您已经完成了数据，现在可以使用了！，但是为了烹饪，厨师必须与他的团队协调…</p><h2 id="93df" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">管弦乐编曲</h2><p id="4536" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">数据管道编排是一个跨领域的过程，它管理所有其他任务之间的依赖关系。如果您使用流处理，您需要协调每个流应用程序的依赖关系，对于批处理，您需要调度和协调作业。</p><p id="e929" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">任务和应用程序可能会失败，所以你需要一种方法来<strong class="kq iu">调度</strong>，重新调度，<strong class="kq iu">重放</strong>，<strong class="kq iu">监控</strong>，<strong class="kq iu">重试</strong>，并统一调试你的整个数据管道。</p><p id="b225" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">较新的框架如<a class="ae lm" href="https://docs.dagster.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Dagster </strong> </a>或<a class="ae lm" href="https://docs.prefect.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Prefect </strong> </a>增加了更多的功能，并允许您跟踪数据资产，为您的管道添加语义。</p><p id="9518" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">一些<strong class="kq iu">选项</strong>包括:</p><ul class=""><li id="2c5a" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://oozie.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache oo zie</strong></a>:oo zie是Hadoop的<strong class="kq iu">调度器</strong>，作业被创建为Dag，可以由时间或数据可用性触发。它集成了摄取工具，如<a class="ae lm" href="https://sqoop.apache.org/" rel="noopener ugc nofollow" target="_blank"> Sqoop </a>和处理框架，如Spark。</li><li id="8e48" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache air flow</strong></a>:air flow是一个允许<strong class="kq iu">调度、运行和监控工作流</strong>的平台。使用Dag创建复杂的工作流。图中的每个节点都是一个任务，边定义了任务之间的依赖关系。Airflow scheduler在一组工作线程上执行您的任务，同时遵循您描述的指定依赖关系。它为您生成DAG，最大化<strong class="kq iu">并行度</strong>。Dag是用<strong class="kq iu"> Python </strong>编写的，所以你可以在本地运行它们，对它们进行单元测试，并将它们集成到你的开发工作流程中。它还支持<strong class="kq iu">SLA和警报</strong>。<a class="ae lm" href="https://github.com/spotify/luigi" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Luigi </strong> </a>是具有类似功能的气流的替代产品，但是气流比Luigi具有更多的功能，并且扩展性更好。</li><li id="6f95" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://docs.dagster.io/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Dagster</strong></a><strong class="kq iu"/>是机器学习、分析和ETL的较新的编排器。主要不同的是，你可以跟踪数据的输入和输出，类似于<a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache NiFi</strong></a><strong class="kq iu"/>创建数据流解决方案。作为任务的一部分，您还可以具体化其他值。它还可以并行运行几个作业，易于添加参数，易于测试，提供简单的版本控制等等。它仍然有点不成熟，由于它需要跟踪数据，可能很难扩展，这是NiFi共有的问题。</li><li id="cee4" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://docs.prefect.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">提督</strong> </a> <strong class="kq iu"> </strong>类似于Dagster，提供本地测试、版本控制、参数管理等等。与其他产品不同的是，Prefect旨在克服Airflow   <strong class="kq iu"> </strong>执行引擎的<a class="ae lm" href="https://medium.com/the-prefect-blog/why-not-airflow-4cfa423299c4" rel="noopener">限制，如改进的调度程序、参数化的工作流、动态工作流、版本控制和改进的测试。它有一个核心的开源工作流管理系统和一个完全不需要设置的云产品。</a></li><li id="d96f" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache NiFi</strong></a>:NiFi还可以调度作业、监控、路由数据、警报等等。它侧重于数据流，但您也可以处理批处理。它运行在Hadoop之外，但可以触发Spark作业并连接到HDFS/S3。</li></ul><p id="94f0" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">简而言之，如果您的需求只是编排不需要共享数据的独立任务，请使用Airflow或Ozzie。对于需要数据沿袭和跟踪的数据流应用程序，非开发人员使用NiFi，开发人员使用Dagster或Prefect。</p><h2 id="09ef" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">数据质量</h2><p id="fd5f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">大数据中经常被忽视的一个重要方面是数据质量和保证。由于数据质量问题，公司每年都会损失大量资金。问题是，在数据科学中，这仍然是一个不成熟的领域，开发人员已经在这个领域工作了几十年，他们有很好的测试框架和方法，如<a class="ae lm" href="https://en.wikipedia.org/wiki/Behavior-driven_development" rel="noopener ugc nofollow" target="_blank"> BDD </a>或<a class="ae lm" href="https://en.wikipedia.org/wiki/Test-driven_development" rel="noopener ugc nofollow" target="_blank"> TDD </a>，但是你如何测试你的管道呢？</p><p id="9d3f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">这一领域有两个常见问题:</p><ul class=""><li id="7717" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated">被误解的需求:转换和编排逻辑经常会变得非常复杂。业务分析师可能使用他们的领域语言编写需求，这些需求需要由经常犯错的开发人员进行解释，并计划、开发、测试和部署技术上正确但需求错误的解决方案。这类错误代价很高。</li><li id="491c" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><strong class="kq iu">数据验证</strong>:流水线测试和代码差别很大。当开发软件时，你测试功能，这是黑盒测试，确定性的。对于给定的输入，你总是得到相同的输出。对于数据资产，测试更加复杂:您需要断言数据类型、值、约束等等。而且，您需要应用聚合来验证数据集，以确保行数或列数是正确的。例如，很难检测某一天数据量是否减少了10%,或者某些值是否被正确填充。</li></ul><p id="9262" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">公司在数据质量和测试方面还处于起步阶段</strong>，这造成了<strong class="kq iu">巨大的技术债务</strong>。我真心推荐查看这篇<a class="ae lm" href="https://medium.com/@expectgreatdata/down-with-pipeline-debt-introducing-great-expectations-862ddc46782a" rel="noopener"> <strong class="kq iu">文章</strong> </a>了解更多信息。</p><p id="be01" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">为了减轻这些问题，试着遵循DDD原则，并确保设定界限和使用共同语言。使用支持数据血统的框架，如NiFi或Dagster。</p><p id="1742" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">一些专注于数据质量的工具有:</p><ul class=""><li id="b51b" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://griffin.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Griffin</strong></a>:作为Hadoop生态系统的一部分，该工具提供了一个统一的流程来从不同的角度衡量您的数据质量，帮助您构建可信的数据资产。它提供了一个DSL，您可以使用它来为您的数据创建断言，并作为您的管道的一部分来验证它们。它与Spark集成在一起。您可以为您的数据集添加规则和断言，然后作为Spark作业运行验证。Griffin的问题是，DSL可能变得难以管理(JSON ),非技术人员很难理解，这意味着它不能解决被误解的需求问题。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oe"><img src="../Images/58b49d771bb1c56b28915a6e3ef985be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz2AkTq0duFycqC7rdTikQ.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">阿帕奇格里芬进程</figcaption></figure><ul class=""><li id="cc27" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">远大前程:</strong> </a> <strong class="kq iu"> </strong>这是一个用<strong class="kq iu"> Python </strong>编写的较新的工具，专注于数据质量、管道测试和质量保证。它可以轻松地与Airflow或其他编排工具集成，并提供自动化的数据验证。让这个工具与众不同的是，它是人类可读的，可以被数据分析师、BAs和开发人员使用。它提供了一个直观的UI，而且是完全自动化的，因此您可以将验证作为生产管道的一部分运行，并在一个漂亮的<strong class="kq iu"> UI </strong>中查看结果。断言可以由非技术人员使用<a class="ae lm" href="https://jupyter.org/try" rel="noopener ugc nofollow" target="_blank">笔记本</a>编写，笔记本提供了开发人员可以容易理解、翻译成代码并用于测试的文档和正式需求。BAs或测试人员编写数据断言(<a class="ae lm" href="https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html" rel="noopener ugc nofollow" target="_blank">期望</a>)，这些断言在UI中被转换为人类可读的测试，这样每个人都可以看到它们并验证它们。它还可以进行数据分析，为您生成一些断言。它可以直接连接到本地或云中的数据库或文件系统。它非常易于使用和管理。期望可以提交到源代码存储库中，然后集成到您的管道中。<strong class="kq iu">远大前程为参与数据质量的各方创造了一个共同的语言和框架</strong>，使得自动化和测试你的管道变得非常容易<strong class="kq iu"/><strong class="kq iu">。</strong></li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi of"><img src="../Images/53d248c7cc9728879560e3f13e030909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*eGG2fUerxtq8tp6j.gif"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">远大前程UI</figcaption></figure><h1 id="ecc3" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">查询您的数据</h1><p id="0341" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在您已经有了自己的烹饪方法，是时候最终从中获得价值了。此时，您已经使用某种深度存储将数据存储在您的数据湖中，例如HDFS，以可查询的格式存储在OLAP数据库中。</p><p id="a968" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">用于查询数据的工具有很多种，每一种都有其优点和缺点。他们中的大多数关注于OLAP，但是很少有人也针对OLTP进行了优化。一些使用标准格式，只专注于运行查询，而另一些使用自己的格式/存储将处理推送到数据源，以提高性能。有些针对使用星型或雪花型模式的数据仓库进行了优化，而有些则更加灵活。概括来说，这些是不同的考虑因素:</p><ul class=""><li id="89d1" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated">数据仓库与数据湖</li><li id="4f8f" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">Hadoop与独立版</li><li id="8950" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">OLAP vs OLTP</li><li id="f692" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated">查询引擎与OLAP引擎</li></ul><p id="ff82" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">我们还应该考虑具有查询功能的处理引擎。</p><h2 id="1572" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">处理引擎</h2><p id="d192" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们在上一节中描述的大多数引擎可以连接到元数据服务器，如<strong class="kq iu"> Hive </strong>，并运行查询、创建视图等。这是创建细化报告层的常见用例。</p><p id="5809" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Spark SQL </strong> </a>提供了一种无缝混合SQL查询和Spark程序的方法，因此您可以将<a class="ae lm" href="https://www.tutorialspoint.com/spark_sql/spark_sql_dataframes.htm" rel="noopener ugc nofollow" target="_blank"> DataFrame </a> API和SQL混合使用。它具有通过JDBC或ODBC的Hive集成和标准连接；所以你可以通过Spark把<a class="ae lm" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank"> Tableau </a>、<a class="ae lm" href="https://looker.com/" rel="noopener ugc nofollow" target="_blank"> Looker </a>或者任何BI工具连接到你的数据上。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi og"><img src="../Images/ea7bf2dd874eb2e91618814418fb7485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f2PghXmieFcaCxdM.png"/></div></div></figure><p id="7a2b" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu"> Apache Flink </strong>也提供了<a class="ae lm" href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/" rel="noopener ugc nofollow" target="_blank"> SQL </a> API。Flink的SQL支持基于实现SQL标准的<a class="ae lm" href="https://calcite.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache方解石</a>。它还通过<code class="fe oh oi oj ok b">HiveCatalog</code>与<a class="ae lm" href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/hive/" rel="noopener ugc nofollow" target="_blank">蜂巢</a>整合。例如，用户可以使用<code class="fe oh oi oj ok b">HiveCatalog</code>将Kafka或ElasticSearch表存储在Hive Metastore中，并在以后的SQL查询中重用它们。</p><h2 id="060c" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">查询引擎</h2><p id="08b7" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这类工具侧重于以统一的方式查询不同的数据源和格式。这个想法是使用SQL查询来查询你的数据湖，就像它是一个关系数据库一样，尽管它有一些限制。其中一些工具还可以查询NoSQL数据库等等。这些工具为外部工具提供了一个JDBC接口，例如<a class="ae lm" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank"> Tableau </a>或<a class="ae lm" href="https://looker.com/" rel="noopener ugc nofollow" target="_blank"> Looker </a>，以一种安全的方式连接到您的数据湖。<strong class="kq iu">查询引擎是最慢的选项，但提供了最大的灵活性。</strong></p><ul class=""><li id="ffe5" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://pig.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇猪</strong> </a>:它和Hive一起是最早的查询语言之一。它有自己不同于SQL的语言。Pig程序的突出特性是它们的结构服从于大量的<strong class="kq iu">并行化</strong>，这反过来使它们能够处理非常大的数据集。它现在正在衰落，取而代之的是新的基于SQL的引擎。</li><li id="08fd" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://prestodb.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Presto </strong> </a>:由脸书开源发布，它是一个开源的<strong class="kq iu">分布式SQL查询引擎</strong>，用于针对各种规模的数据源运行交互式分析查询。Presto允许查询数据所在的位置，包括Hive、Cassandra、关系数据库和文件系统。它可以在几秒钟内对大型数据集执行查询。它独立于Hadoop，但集成了它的大多数工具，尤其是运行SQL查询的Hive。</li><li id="d0e9" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://drill.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Drill </strong> </a>:为Hadoop、NoSQL甚至云存储提供无模式的SQL查询引擎。它独立于Hadoop，但与Hive等生态系统工具有许多集成。单个查询可以连接来自多个数据存储的数据，执行特定于每个数据存储的优化。它很好地允许分析师像对待表格一样对待任何数据，即使他们正在读一个文件。<strong class="kq iu"> Drill完全支持标准SQL </strong>。业务用户、分析师和数据科学家可以使用标准BI/分析工具，如<a class="ae lm" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank"> Tableau </a>、<a class="ae lm" href="https://www.qlik.com/us" rel="noopener ugc nofollow" target="_blank"> Qlik </a>和Excel，通过利用Drill的JDBC和ODBC驱动程序与非关系型数据存储进行交互。此外，开发人员可以在他们的定制应用程序中利用Drill的简单REST API来创建漂亮的可视化效果。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ol"><img src="../Images/ec77b5b4222e9402b5e010c4c5f333f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*zvz6uJVjwPlOjxz0.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">钻孔模型</figcaption></figure><h2 id="b586" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated"><strong class="ak"> OLTP数据库</strong></h2><p id="871d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">尽管Hadoop针对OLAP进行了优化，但是如果您想为交互式应用程序执行OLTP查询，仍然有一些选项。</p><p id="3ecb" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://hbase.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">h base</strong></a><strong class="kq iu"/>根据设计，它的ACID属性非常有限，因为它是按规模构建的，不提供现成的ACID功能，但它可以用于一些OLTP场景。</p><p id="9b6d" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://phoenix.apache.org/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Phoenix </strong> </a>构建在HBase之上，提供了一种在Hadoop生态系统中执行OTLP查询的方式。Apache Phoenix与Spark、Hive、Pig、Flume和Map Reduce等其他Hadoop产品完全集成。它还可以存储元数据，并通过DDL命令支持表创建和版本化增量变更。它相当<strong class="kq iu">快</strong>，比使用Drill或其他查询引擎要快。</p><p id="a68b" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">你可以使用Hadoop生态系统之外的任何大规模数据库，比如<strong class="kq iu"> Cassandra、YugaByteDB、ScyllaDB for OTLP </strong>。</p><p id="f721" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最后，在任何类型的快速数据库(如MongoDB或MySQL)中有一个数据子集(通常是最新的)是非常常见的。上面提到的<strong class="kq iu">查询引擎</strong>可以在单个查询中连接慢速和快速数据存储之间的数据。</p><h2 id="3e15" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">分布式搜索索引</h2><p id="78f5" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这些工具提供了一种<strong class="kq iu">存储和搜索非结构化文本数据</strong>的方式，它们存在于Hadoop生态系统之外，因为它们需要特殊的结构来存储数据。想法是使用一个<a class="ae lm" href="https://en.wikipedia.org/wiki/Search_engine_indexing" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">倒排索引</strong> </a>来执行快速查找。除了文本搜索之外，这项技术还可以用于广泛的用例，比如存储日志、事件等。有两个主要选项:</p><ul class=""><li id="6a8e" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://lucene.apache.org/solr/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Solr </strong> </a>:它是一个流行的、高速的、开源的企业搜索平台，构建在Apache<a class="ae lm" href="https://lucene.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Lucene</strong></a>之上。Solr是可靠的、可扩展的和容错的，提供分布式索引、复制和负载平衡查询、自动故障转移和恢复、集中式配置等等。它对于文本搜索来说很棒，但与<a class="ae lm" href="https://en.wikipedia.org/wiki/Elasticsearch" rel="noopener ugc nofollow" target="_blank"> ElasticSearch </a>相比，它的使用案例有限。</li><li id="dc07" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Elasticsearch" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> ElasticSearch </strong> </a>:它也是一个非常受欢迎的分布式索引，但它已经发展成为自己的生态系统，涵盖了许多用例，如<a class="ae lm" href="https://www.elastic.co/apm" rel="noopener ugc nofollow" target="_blank"> APM </a>，搜索，文本存储，分析，仪表板，机器学习等等。它绝对是您工具箱中的一个工具，无论是用于开发还是用于数据管道，因为它非常通用。它还可以存储和搜索视频和图像。</li></ul><p id="9bef" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu"> ElasticSearch </strong>可用作<strong class="kq iu">快速存储层f </strong>或高级搜索功能的数据湖。如果您将数据存储在一个键值型的大型数据库中，比如HBase或Cassandra，由于缺少连接，它们提供的搜索功能非常有限；你可以将ElasticSearch放在前面执行查询，返回id，然后在你的数据库上进行快速查找。</p><p id="f084" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">它也可用于<strong class="kq iu">分析</strong>；您可以导出数据，对其进行索引，然后使用<a class="ae lm" href="https://www.elastic.co/kibana" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Kibana </strong> </a>进行查询，创建仪表盘、报告等，您可以添加直方图、复杂聚合，甚至在数据基础上运行机器学习算法。弹性生态系统庞大，值得探索。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi om"><img src="../Images/57cde19fe6e219478e106226e340776d.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/0*VaZVKeu64jFo_HZt.png"/></div></figure><h2 id="710b" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">OLAP数据库</h2><p id="f3a6" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这个类别中，我们有数据库，它也可以为模式和查询功能提供元数据存储。与查询引擎相比，这些工具还提供存储，并可能在数据仓库的情况下实施某些模式(星型模式)。这些工具使用SQL语法和Spark，其他框架可以与之交互。</p><ul class=""><li id="555f" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Hive </strong> </a>:我们已经讨论过Hive作为Spark和其他工具的中央模式存储库，因此它们可以使用<strong class="kq iu"> SQL </strong>，但是Hive也可以存储数据，因此您可以将它用作<strong class="kq iu">数据仓库。</strong>可以访问<strong class="kq iu"> HDFS </strong>或<strong class="kq iu"> HBase </strong>。当查询Hive时，它利用<a class="ae lm" href="http://tez.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Tez </a>、<a class="ae lm" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>或<a class="ae lm" href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" rel="noopener ugc nofollow" target="_blank"> MapReduce </a>，比Tez或Spark快得多。它还有一种叫做HPL-SQL的过程语言。</li><li id="8e7f" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://impala.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Impala </strong> </a>:它是Hadoop的原生<strong class="kq iu">分析数据库</strong>，你可以用它来存储数据，并以高效的方式进行查询。它可以使用<a class="ae lm" href="https://cwiki.apache.org/confluence/display/Hive/HCatalog" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Hcatalog </strong> </a>连接到Hive获取元数据。Impala为Hadoop上的BI/分析查询提供了<strong class="kq iu">低延迟和高并发</strong>(不是Apache Hive等批处理框架提供的)。Impala还可以线性扩展，即使在多租户环境中也比Hive更适合查询。Impala集成了原生Hadoop安全性和Kerberos进行身份验证，因此您可以安全地管理数据访问。它使用<strong class="kq iu"> HBase </strong>和<strong class="kq iu"> HDFS </strong>进行数据存储。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi on"><img src="../Images/e6be90a18a268342c29c624e0ef99283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0ppMu1g5RA7vkahu.png"/></div></div></figure><ul class=""><li id="172b" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://tajo.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Apache Tajo </strong> </a>:是Hadoop的另一个<strong class="kq iu">数据仓库</strong>。Tajo是为存储在HDFS和其他数据源上的大数据集的低延迟和可伸缩的特别查询、在线聚合和ETL而设计的。它与<strong class="kq iu">Hive</strong>Metastore<strong class="kq iu">Metastore</strong>集成，以访问公共模式。它有许多查询优化，它是可伸缩的，容错的，并提供了一个JDBC接口。</li><li id="d463" class="my mz it kq b kr nh kv ni kz nj ld nk lh nl ll nd ne nf ng bi translated"><a class="ae lm" href="https://kylin.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kq iu">Apache Kylin</strong></a>:Apache Kylin是一个较新的分布式<strong class="kq iu">分析数据仓库</strong>。Kylin是<strong class="kq iu">速度极快的</strong>，因此它可以用来补充一些其他数据库，如Hive，用于<strong class="kq iu">性能</strong>很重要的用例，如<strong class="kq iu">仪表盘</strong>或交互式报告，它可能是最好的OLAP数据仓库，但它更难使用，另一个问题是因为高维度，你需要更多的存储空间。其想法是，如果查询引擎或Hive不够快，您可以在Kylin中创建一个“<em class="ls">多维数据集</em>”，这是一个为OLAP优化的多维表，具有<strong class="kq iu">预先计算的</strong>值，您可以从您的仪表板或交互式报告中查询这些值。它可以直接从Spark构建立方体，甚至可以从Kafka近乎实时地构建立方体。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oo"><img src="../Images/1dcaa8e8be0b393de61c9a2c347a0506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PaPq3o1mqJiXW16h.png"/></div></div></figure><h2 id="76c0" class="mj jr it bd js mk ml dn jw mm mn dp ka kz mo mp ke ld mq mr ki lh ms mt km mu bi translated">OLAP发动机</h2><p id="839f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这一类别中，我包括<strong class="kq iu">较新的引擎</strong>，它们是以前的OLAP数据库的演变，提供更多功能，创建了一个<strong class="kq iu">一体化分析平台</strong>。实际上，它们是前两个类别的<strong class="kq iu">混合体</strong>，为你的OLAP数据库添加了<strong class="kq iu">索引</strong>。它们生活在Hadoop平台之外，但是紧密集成在一起。在这种情况下，您通常会跳过处理阶段，直接使用这些工具进行摄取。</p><p id="2432" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">他们试图以统一的方式解决<strong class="kq iu">查询实时和历史数据</strong>的问题，这样一旦实时数据可用，您就可以立即查询实时数据和历史数据，并且延迟较低，这样您就可以构建交互式应用程序和仪表板。这些工具在许多情况下允许查询原始数据，几乎不需要像ELT一样进行转换，但是性能很好，比常规的OLAP数据库更好。</p><p id="69db" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">它们的共同点是，它们提供了一个统一的数据视图、实时和批量数据接收、分布式索引、自己的数据格式、SQL支持、JDBC接口、冷热数据支持、多重集成和元数据存储。</p><ul class=""><li id="11aa" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://druid.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇德鲁伊</strong> </a>:是最著名的实时OLAP引擎。它专注于时间序列数据，但也可以用于任何类型的数据。它使用自己的<strong class="kq iu">列格式</strong>，可以大幅压缩数据，它有很多内置的优化，如<strong class="kq iu">倒排索引</strong>，文本编码，自动数据汇总等等。使用延迟非常低的<a class="ae lm" href="https://druid.apache.org/docs/latest/ingestion/tranquility.html" rel="noopener ugc nofollow" target="_blank">宁静</a>或Kafka实时摄取数据，数据以针对写入优化的行格式保存在内存中，但一旦到达，就可以像以前摄取的数据一样进行查询。负责将数据异步移动到深层存储系统(如HDFS)的后台任务。当数据移动到深层存储时，它被转换成按时间划分的更小的块，称为<strong class="kq iu">段</strong>，这些段针对低延迟查询进行了高度优化。每个段都有一个时间戳，您可以使用几个维度来过滤和执行聚合；和作为预先计算的集合的度量。对于批量接收，它将数据直接保存到数据段中。它支持推和拉摄取。它与<strong class="kq iu"> Hive、</strong>甚至<a class="ae lm" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> NiFi </strong> </a> <strong class="kq iu">有<strong class="kq iu">集成</strong>。</strong>它可以使用Hive metastore，并支持Hive SQL查询，然后转换为Druid使用的JSON查询。Hive集成支持JDBC，因此您可以连接任何BI工具。它也有自己的元数据存储，通常是MySQL。它可以接收大量数据，并且可以很好地扩展。主要问题是它有很多组件，很难管理和部署。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7a88b2dec5740f2a863eeffc3cde1979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/0*3BsQIN3qUIkiQXZa.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">德鲁伊建筑</figcaption></figure><ul class=""><li id="bc78" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">阿帕奇皮诺</strong> </a>:是LinkedIn开源的德鲁伊的较新替代品。与Druid相比，它提供了<strong class="kq iu">更低的延迟</strong>，这要归功于提供部分预计算的<em class="ls"> Startree </em>索引，因此它可以用于面向用户的应用程序(它用于获取LinkedIn提要)。它使用一个<strong class="kq iu">排序索引</strong>，而不是速度更快的倒排索引。它有一个可扩展的插件架构，也有许多集成，但不支持配置单元。它还统一了批处理和实时处理，提供了快速接收、智能索引和分段存储数据。与德鲁伊相比，它更容易部署，速度也更快，但是目前它还有点不成熟。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oq"><img src="../Images/697273feef5fc1b109f0feb7d6382dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kGcXpvCS3jSmDIMb"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">阿帕奇皮诺</figcaption></figure><ul class=""><li id="4548" class="my mz it kq b kr ln kv lo kz na ld nb lh nc ll nd ne nf ng bi translated"><a class="ae lm" href="https://clickhouse.tech/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> ClickHouse </strong> </a>:用C++编写，这个引擎为OLAP查询提供了难以置信的性能，尤其是聚合。它看起来像一个关系数据库，所以你可以很容易地建模数据。它非常容易设置，有许多集成。</li></ul><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi or"><img src="../Images/26b4004b1dbb5497d02a49b7c8b6bbb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ee9qDR42tkkMFuMGWKu7cg.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">点击之家</figcaption></figure><p id="5230" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">查看这篇详细对比三款发动机的<a class="ae lm" href="https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7" rel="noopener"> <strong class="kq iu">文章</strong> </a>。同样，从小处着手，在做决定之前了解你的数据，这些新的引擎非常强大，但很难使用。如果你能等几个小时，那么使用批处理和数据库，如Hive或Tajo然后使用Kylin来加速您的OLAP查询，使它们更具交互性。如果这还不够，你需要更低的延迟和实时数据，考虑OLAP引擎。德鲁伊更适合实时分析。麒麟更专注于OLAP案件。德鲁伊作为实时流和卡夫卡有很好的融合；Kylin从Hive或者Kafka批量取数据；尽管计划在不久的将来实现实时摄取。</p><p id="72fd" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最后，<a class="ae lm" href="https://greenplum.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> Greenplum </strong> </a>是另一个更加<strong class="kq iu">专注AI </strong>的OLAP引擎。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi os"><img src="../Images/a3e3e2f20fd4ad3856217946a166288e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w8kb_--MMZEDJo-hyIM3nA.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">Presto/Drill提供更大的灵活性，麒麟大潜伏，德鲁伊和皮诺，两全其美。</figcaption></figure><p id="0fcf" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">最后，对于<strong class="kq iu">可视化</strong>你有几个商业工具，如<a class="ae lm" href="https://www.qlik.com/us" rel="noopener ugc nofollow" target="_blank"> Qlik </a>、<a class="ae lm" href="https://looker.com/" rel="noopener ugc nofollow" target="_blank"> Looker </a>或<a class="ae lm" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank"> Tableau </a>。对于开源，检查<a class="ae lm" href="https://github.com/apache/incubator-superset" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">超集</strong> </a>，一个支持我们提到的所有工具的神奇工具，有一个很棒的编辑器，它真的很快。<a class="ae lm" href="https://github.com/metabase/metabase" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">元数据库</strong> </a>或者<a class="ae lm" href="https://github.com/uwdata/falcon" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">猎鹰</strong> </a>都是其他很棒的选择。</p><h1 id="c416" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="58f3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们已经谈了很多关于<strong class="kq iu">数据</strong>的内容:不同的形状、格式、如何处理、存储等等。记住:<strong class="kq iu">了解你的数据和你的商业模式</strong>。使用迭代过程<strong class="kq iu">开始慢慢构建你的大数据平台</strong>；不是通过引入新的框架，而是通过<strong class="kq iu">提出正确的问题，寻找给你正确答案的最佳工具。</strong></p><p id="d0a8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">查看您的数据的不同注意事项，根据数据模型(SQL)、查询(NoSQL)、基础架构和您的预算选择合适的存储。记住<strong class="kq iu">与您的云提供商</strong>合作，评估面向大数据的云产品(购买还是构建)。从<a class="ae lm" href="https://en.wikipedia.org/wiki/Serverless_computing" rel="noopener ugc nofollow" target="_blank">无服务器</a>分析管道开始，随着成本的增加，慢慢转向开源解决方案，这种情况非常普遍。</p><p id="dea8" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">由于依赖于您控制范围之外的系统，数据摄取至关重要且复杂</strong>；尝试管理这些依赖关系，并创建可靠的数据流来正确接收数据。如果可能的话，让其他团队负责数据接收。记得添加指标、日志和跟踪来跟踪数据。启用模式进化，并确保在您的平台中设置了适当的安全性。</p><p id="2217" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">使用合适的工具，不要贪多嚼不烂。像Cassandra、Druid或ElasticSearch这样的工具是令人惊叹的技术，但需要大量的知识来正确使用和管理。如果您只需要对特定查询和报告进行OLAP批处理分析，请使用Hive或Tajo。如果需要更好的性能，加麒麟。如果您还需要加入其他数据源，请添加查询引擎，如Drill或Presto。再者，如果需要实时查询，批量使用ClickHouse，Druid或者Pinot。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="a86a" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><strong class="kq iu">更新</strong>:我目前在坦桑尼亚帮助当地的一所学校，我创建了一个<a class="ae lm" href="https://www.gofundme.com/f/help-the-mango-school-children-in-tanzania" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> GoFundMe活动</strong> </a>来帮助孩子们，通过这个<a class="ae lm" href="https://www.gofundme.com/f/help-the-mango-school-children-in-tanzania" rel="noopener ugc nofollow" target="_blank">链接</a>来捐款，每一点帮助！</p><p id="ed4b" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><em class="ls">记得来</em> <strong class="kq iu"> <em class="ls">拍拍</em> </strong> <em class="ls">如果你喜欢这篇文章还有</em> <a class="ae lm" href="https://javier-ramos.medium.com/subscribe" rel="noopener"> <em class="ls"> </em> <strong class="kq iu"> <em class="ls">关注</em> </strong> <em class="ls"> </em> <strong class="kq iu"> <em class="ls">我</em> </strong> </a> <em class="ls">或</em> <a class="ae lm" href="https://javier-ramos.medium.com/membership" rel="noopener"> <strong class="kq iu"> <em class="ls">订阅</em> </strong> </a> <em class="ls">获取更多更新！</em></p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="92a4" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://javier-ramos.medium.com/subscribe" rel="noopener"> <strong class="kq iu">订阅</strong> </a>获得<strong class="kq iu">通知</strong>当我发表一篇文章和<a class="ae lm" href="https://javier-ramos.medium.com/membership" rel="noopener"> <strong class="kq iu">加入Medium.com</strong></a>访问百万或文章！</p></div></div>    
</body>
</html>