<html>
<head>
<title>Processing Engines for Big Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据处理引擎</h1>
<blockquote>原文：<a href="https://itnext.io/processing-engines-for-big-data-5827bfad6b02?source=collection_archive---------2-----------------------#2020-10-29">https://itnext.io/processing-engines-for-big-data-5827bfad6b02?source=collection_archive---------2-----------------------#2020-10-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/b5e9ca31be3265f1ec98b7895173c475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PRfvMCO7Ikt4DgKM"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">托马斯·马丁内斯在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="5d71" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="6a39" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">本文基于我之前的文章“<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/big-data-pipeline-recipe-c416c1782908?source=your_stories_page-------------------------------------"> <strong class="lg iu"> <em class="mc">大数据管道秘方</em> </strong> </a>”，在这篇文章中，我试图快速概述大数据世界的各个方面。</p><p id="f49f" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">本文的目标是关注大数据<a class="ae kf" href="https://en.wikipedia.org/wiki/Extract,_transform,_load" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> ETL </strong> </a>管道的<strong class="lg iu">【T】</strong>，回顾处理大量数据的主要框架。主要焦点将是Hadoop生态系统。</p><p id="bb12" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">但是首先，让我们回顾一下这个阶段是怎么回事。请记住，此时您已经获取了准备进行处理的原始数据。</p><h1 id="f18b" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">大数据处理阶段</h1><p id="26a1" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">此阶段的目标是使用单一模式清理、规范化、处理和保存数据。最终结果是一个具有良好定义的模式的<strong class="lg iu">可信数据集。</strong>像<strong class="lg iu"> Spark </strong>这样的处理框架被用来在一个机器集群中并行处理数据。</p><p id="d7b7" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">通常，您需要进行某种处理，例如:</p><ul class=""><li id="90fe" class="mi mj it lg b lh md ll me lp mk lt ml lx mm mb mn mo mp mq bi translated"><strong class="lg iu">验证</strong>:通过将数据存储在单独的存储器中来验证数据并隔离坏数据。根据您的数据质量要求，在达到某个阈值时发送警报。</li><li id="b81a" class="mi mj it lg b lh mr ll ms lp mt lt mu lx mv mb mn mo mp mq bi translated"><strong class="lg iu">争论和清理</strong>:清理你的数据，并以另一种格式存储以便进一步处理，比如用Avro替换低效的JSON。</li><li id="369c" class="mi mj it lg b lh mr ll ms lp mt lt mu lx mv mb mn mo mp mq bi translated"><strong class="lg iu">标准化</strong>和<strong class="lg iu">数值的标准化</strong></li><li id="7a3c" class="mi mj it lg b lh mr ll ms lp mt lt mu lx mv mb mn mo mp mq bi translated"><strong class="lg iu">重命名</strong>字段</li><li id="402f" class="mi mj it lg b lh mr ll ms lp mt lt mu lx mv mb mn mo mp mq bi">…</li></ul><p id="5caa" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">请记住，我们的目标是创建一个<strong class="lg iu">可信数据集</strong>，稍后可用于下游系统。这是数据工程师的一个关键角色。<strong class="lg iu">这可以以流或分批的方式进行。</strong></p><p id="e556" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated"><strong class="lg iu">批量加工</strong>时，流水线加工可分为<strong class="lg iu">三个阶段</strong>:</p><h2 id="f762" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><strong class="ak">预处理阶段</strong></h2><p id="f8e6" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果原始数据不干净或格式不正确，您需要对其进行预处理。这一阶段包括一些基本的验证，但目标是<strong class="lg iu">为下一阶段准备有效处理的数据</strong>。在这个阶段，你应该尝试<strong class="lg iu">将数据扁平化，并以二进制格式</strong>保存，比如<strong class="lg iu"> Avro </strong>。这将加速进一步的处理。这个想法是，下一阶段将执行行级操作，而嵌套查询开销很大，因此现在将数据扁平化将提高下一阶段的性能。</p><h2 id="5368" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><strong class="ak">可信阶段</strong></h2><p id="f590" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这一阶段，数据被<strong class="lg iu">验证、清理、规范化并</strong>转换为存储在<a class="ae kf" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Hive</strong></a><strong class="lg iu"/>或另一个数据存储中的公共模式。目标是创建数据所有者理解的可信公共数据集。通常，会创建一个数据<strong class="lg iu">规范</strong>，数据工程师的角色是应用转换来匹配规范，包括验证规则、转换、值的标准化、重命名字段等。</p><p id="13dd" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">最终结果是以<a class="ae kf" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">拼花</strong> </a>或其他易于查询的列格式的数据集。选择正确的分区并优化数据来执行内部查询是至关重要的。</p><p id="9b20" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">您可能希望在此阶段部分预先计算一些聚合，以提高查询性能。</p><h2 id="4d61" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><strong class="ak">报告阶段</strong></h2><p id="cdfd" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这一步是可选的，但通常是必需的。不幸的是，当使用数据湖时，<strong class="lg iu">一个单一的模式不能满足所有的用例</strong>；这是数据仓库和数据湖之间的一个区别。查询HDFS不如数据库或数据仓库高效，因此需要进一步优化。</p><p id="719d" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">在这个阶段，您可能需要<strong class="lg iu">将数据反规范化</strong>以使用不同的分区存储数据，这样不同的利益相关者就可以更有效地查询数据。这个想法是为不同的下游系统(<a class="ae kf" href="https://en.wikipedia.org/wiki/Data_mart" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">数据集市</strong> </a>)创建不同的<strong class="lg iu">视图</strong>。</p><p id="725f" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">在此阶段，如果不使用OLAP引擎，也可以计算聚合。可信阶段不知道谁将查询数据，<strong class="lg iu">这个阶段为消费者优化数据</strong>。如果一个客户端是高度交互的，你可能希望在这个阶段<strong class="lg iu">引入一个快速存储层</strong>，比如一个用于快速查询的关系数据库。或者，你可以使用<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/olap-query-engines-for-big-data-5f17b88d6ebc"> OLAP发动机</a>。</p><p id="3322" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">对于流式传输，逻辑是相同的，但它将以流式方式在定义的DAG内运行。Spark允许你加入历史数据流，但是它有一些限制。<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/olap-query-engines-for-big-data-5f17b88d6ebc"> <strong class="lg iu"> OLAP引擎</strong> </a>更适合将实时数据与历史数据合并。</p><h1 id="5fb7" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">处理框架</strong></h1><p id="39de" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一些可用于处理的工具有:</p><h2 id="f38b" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><a class="ae kf" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇火花</strong> </a></h2><p id="5932" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是最著名的批处理框架。作为Hadoop生态系统的一部分，它是一个由<strong class="lg iu">管理的</strong>集群，提供了难以置信的<strong class="lg iu">并行性</strong>、监控和出色的UI。它还支持流处理(<a class="ae kf" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">结构化流</a>)。基本上，Spark在内存中运行MapReduce作业，其性能是普通MapReduce的100倍。它与Hive集成以支持SQL，并可用于创建Hive表、视图或查询数据。它有很多集成，支持多种格式，有一个巨大的社区。它受到所有云提供商的支持。它可以在Hadoop集群的<a class="ae kf" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> YARN </strong> </a>上运行，也可以在Kubernetes和其他平台上运行。它有许多针对特定用例的库，如SQL或机器学习。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ad62e650b879bb5a71fa01c8e6df501f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*7Oh6fWI4qTbU5Y-j.png"/></div></figure><h2 id="bb97" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><a class="ae kf" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇弗林克</strong> </a></h2><p id="6e0f" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">第一个统一批处理和流式传输的引擎，但主要关注于流式传输。可以作为Kafka这样的微服务的骨干。它可以作为Hadoop集群的一部分运行在<a class="ae kf" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> YARN </a>上，但从一开始就已经针对Kubernetes或Mesos等其他平台进行了优化。它的<strong class="lg iu">速度极快</strong>并提供实时流，对于<strong class="lg iu">低延迟</strong>流处理，尤其是对于<strong class="lg iu">有状态</strong>流，它比Spark更好。它也有SQL，机器学习和更多的库。它比Spark更快，是数据流的更好选择。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/fad2d3ce3243b27d56e5da7e96e0add2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8t0H7A5tDz8hlcRo.png"/></div></div></figure><h2 id="59b5" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><a class="ae kf" href="https://storm.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇风暴</strong> </a></h2><p id="9f8d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Apache Storm是一个免费的开源分布式实时计算系统。它专注于流，是Hadoop生态系统的托管解决方案的一部分。它是可扩展的、容错的，保证您的数据将被处理，并且易于设置和操作。</p><h2 id="b86d" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><a class="ae kf" href="https://samza.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇萨姆扎</strong> </a></h2><p id="586e" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">另一个伟大的有状态流处理引擎。Samza允许您构建有状态的应用程序，实时处理来自包括Apache Kafka在内的多个来源的数据。托管解决方案运行在YARN之上的Hadoop生态系统的一部分。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/b5edef42a1c6cb411e734a51de43361d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tR_Omsovs3nNYbUg.png"/></div></div></figure><h2 id="afd0" class="mw kh it bd ki mx my dn km mz na dp kq lp nb nc ku lt nd ne ky lx nf ng lc nh bi translated"><a class="ae kf" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇光束</strong> </a></h2><p id="9fad" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Apache Beam它本身不是一个引擎，而是一个<strong class="lg iu">统一编程模型</strong>的<strong class="lg iu">规范</strong>，它将所有其他引擎集合在一起。它提供了一个可以与<strong class="lg iu">不同语言</strong>一起使用的编程模型，这样开发者在处理大数据管道时就不用学习新的语言了。然后，它为可以在云中或本地运行的处理步骤插入不同的后端。Beam支持前面提到的所有引擎，您可以轻松地在它们之间切换，并在任何平台上运行它们:cloud、YARN、Mesos、Kubernetes。如果您正在开始一个新项目，我真的建议从Beam开始，以确保您的数据管道经得起未来的考验。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/35f7f46bec51fefa106b0434da7c8e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MnvqTtpJCvEtD2do.png"/></div></div></figure><h1 id="afe6" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="2f3a" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">处理引擎是目前大数据领域最著名的工具。作为一名大数据工程师，您将经常使用这些引擎。<strong class="lg iu">您必须了解这些引擎的分布式本质，并知道如何优化、保护和监控它们。</strong></p><p id="0c33" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">请记住，还有一些<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/olap-query-engines-for-big-data-5f17b88d6ebc"> <strong class="lg iu"> OLAP引擎</strong> </a>提供了查询大量数据的单一解决方案，不需要编写复杂的转换，而是以特定格式加载数据，这使得查询性能更高。</p><p id="9db6" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">对于一个新项目，我真的推荐研究一下<strong class="lg iu"> Apache Beam </strong>，因为它在所有其他引擎<strong class="lg iu">之上提供了一个抽象，允许你在不改变代码</strong>的情况下改变处理引擎。</p><p id="1ec5" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated"><strong class="lg iu">对于流处理</strong>，特别是有状态流处理，考虑<strong class="lg iu"> Flink </strong>或Samza。<strong class="lg iu">对于批量，使用Spark。</strong></p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="5a51" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae kf" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"><em class="mc">me</em></strong></a><strong class="lg iu"><em class="mc"/></strong><em class="mc">进行未来的岗位。</em></p></div></div>    
</body>
</html>