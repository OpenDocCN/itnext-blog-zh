<html>
<head>
<title>Exploring Popular Open-source Stream Processing Technologies: Part 2 of 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索流行的开源流处理技术:第2部分，共2部分</h1>
<blockquote>原文：<a href="https://itnext.io/exploring-popular-open-source-stream-processing-technologies-part-2-of-2-2832b7727cd0?source=collection_archive---------2-----------------------#2022-09-26">https://itnext.io/exploring-popular-open-source-stream-processing-technologies-part-2-of-2-2832b7727cd0?source=collection_archive---------2-----------------------#2022-09-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="768b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Apache Spark结构化流、Apache Kafka流、Apache Flink和Apache Pinot与Apache超集的简短演示</h2></div><p id="bfee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据<a class="ae le" href="https://www.techtarget.com/searchdatamanagement/definition/stream-processing" rel="noopener ugc nofollow" target="_blank">TechTarget</a>,<em class="lf">流处理是一种数据管理技术，涉及</em> <strong class="kk iu"> <em class="lf">摄取连续的数据流，以实时快速分析、过滤、转换或增强数据</em> </strong> <em class="lf">。处理后，数据被传递给应用程序、数据存储或另一个流处理引擎。</em> " <a class="ae le" href="https://www.confluent.io/learn/batch-vs-real-time-data-processing/" rel="noopener ugc nofollow" target="_blank"> Confluent </a>，一家完全管理的Apache Kafka市场领导者，将流处理定义为"<em class="lf">一种软件范例，它在连续的数据流还在运动的时候</em> <strong class="kk iu"> <em class="lf">接收、处理和管理它们</em> </strong> <em class="lf">。</em></p><p id="4197" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇由两部分组成的博文和YouTube 上的视频演示探索了四个流行的开源软件(OSS)流处理项目:<a class="ae le" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark结构化流</a>、<a class="ae le" href="https://kafka.apache.org/documentation/streams/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka流</a>、<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Flink </a>和<a class="ae le" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Pinot </a>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/db2425d2402db4cd031b9cc7b140e3a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DlZvpWpto6EwNNzG_v35Fw.png"/></div></div></figure><p id="9e76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章使用了开源项目，使得跟随演示变得更加容易，并且将成本保持在最低。然而，您可以很容易地用开源项目替代您喜欢的SaaS、CSP或COSS服务产品。</p><h2 id="b15f" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">第二部分</h2><p id="2a6d" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们将从第一部开始继续我们的探索。在第二部分中，我们将介绍<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇弗林克</a>和<a class="ae le" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇皮诺</a>。此外，我们将把<a class="ae le" href="https://superset.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache超集</a>合并到演示中，以将我们的流处理管道的实时结果可视化为仪表板。</p><h1 id="4660" class="mq lt it bd lu mr ms mt lx mu mv mw ma jz mx ka md kc my kd mg kf mz kg mj na bi translated">演示#3: Apache Flink</h1><p id="4d08" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在四个演示的第三个中，我们将检查<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇弗林克</a>。对于本文的这一部分，我们还将使用三个GitHub存储库项目中的第三个，<code class="fe nb nc nd ne b"><a class="ae le" href="https://github.com/garystafford/flink-kafka-demo" rel="noopener ugc nofollow" target="_blank">flink-kafka-demo</a></code>。该项目包含一个用Java编写的Flink应用程序，它执行流处理、增量聚合和多流连接。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nf"><img src="../Images/49425e9f6b22e46da97ececf3d17111f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xH64p4S00gAYttXpdzuKrg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">Apache Flink演示的高级工作流</figcaption></figure><h2 id="a156" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">新的流堆栈</h2><p id="cd8a" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">首先，我们需要用第二个<a class="ae le" href="https://github.com/garystafford/streaming-sales-generator/blob/main/docker/flink-pinot-superset-stack.yml" rel="noopener ugc nofollow" target="_blank">流Docker群栈</a>替换在<a class="ae le" href="https://garystafford.medium.com/exploring-popular-open-source-stream-processing-technologies-part-1-of-2-31069337ba0e" rel="noopener">第一部分</a>中部署的第一个<a class="ae le" href="https://github.com/garystafford/streaming-sales-generator/blob/main/docker/spark-kstreams-stack.yml" rel="noopener ugc nofollow" target="_blank">流Docker群栈</a>。第二个堆栈包含<a class="ae le" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡</a>、<a class="ae le" href="https://zookeeper.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇动物园管理员</a>、<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇弗林克</a>、<a class="ae le" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇皮诺</a>、<a class="ae le" href="https://superset.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇超集</a>、阿帕奇卡夫卡的<a class="ae le" href="https://github.com/provectus/kafka-ui" rel="noopener ugc nofollow" target="_blank"> UI、</a><a class="ae le" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank">项目Jupyter </a> (JupyterLab)。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="0f77" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">堆栈将需要几分钟才能完全部署。完成后，堆栈中应该有十个容器在运行。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nm"><img src="../Images/0bd5179762629615519a363e75c64015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0c9jZ0AdtzPOUwMBXX__yg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">查看Docker流堆栈的十个容器</figcaption></figure><h2 id="41b0" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">Flink应用程序</h2><p id="0823" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">Flink应用程序有两个入口类。第一个类<code class="fe nb nc nd ne b"><a class="ae le" href="https://github.com/garystafford/flink-kafka-demo/blob/main/src/main/java/org/example/RunningTotals.java" rel="noopener ugc nofollow" target="_blank">RunningTotals</a></code>，执行与前面的KStreams演示相同的聚合函数。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="ed90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二个类<code class="fe nb nc nd ne b"><a class="ae le" href="https://github.com/garystafford/flink-kafka-demo/blob/main/src/main/java/org/example/JoinStreams.java" rel="noopener ugc nofollow" target="_blank">JoinStreams</a></code>，连接来自<code class="fe nb nc nd ne b">demo.purchases</code>主题和<code class="fe nb nc nd ne b">demo.products</code>主题的数据流，实时处理和组合它们，成为一个丰富的事务，并将结果发布到一个新主题<code class="fe nb nc nd ne b">demo.purchases.enriched</code>。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="9ec2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">产生的丰富的购买信息类似于以下内容:</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">丰富的购买信息示例</figcaption></figure><h2 id="97c1" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">运行Flink作业</h2><p id="daeb" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">要运行Flink应用程序，我们必须首先将它编译成一个uber JAR。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="585f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将JAR复制到Flink容器中，或者通过Apache Flink仪表板(一个基于浏览器的UI)上传。对于这个演示，我们将通过Apache Flink仪表板上传它，可以通过端口8081访问。</p><p id="b840" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">项目的<code class="fe nb nc nd ne b"><a class="ae le" href="https://github.com/garystafford/flink-kafka-demo/blob/main/build.gradle" rel="noopener ugc nofollow" target="_blank">build.gradle</a></code>文件已经预置了主类(Flink的入口类)为<code class="fe nb nc nd ne b">org.example.JoinStreams</code>。可选地，要运行运行总数演示，我们可以更改<code class="fe nb nc nd ne b">build.gradle</code>文件并重新编译，或者简单地将Flink的入口类更改为<code class="fe nb nc nd ne b">org.example.RunningTotals</code>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/a74bc34edd68a30fc50aa2d2b29e733d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2csupuL_MGfGgMMPdTsSCw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">将JAR上传到Apache Flink</figcaption></figure><p id="28f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在运行Flink作业之前，在后台重启销售生成器(<code class="fe nb nc nd ne b">nohup python3 ./producer.py &amp;</code>)以生成新的数据流。然后开始Flink工作。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/c91e55adf4b7ba0674129d8a7d8aa731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_K5oe0Hf0tNS084yyfIYDQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">Apache Flink作业运行成功</figcaption></figure><p id="dd27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了确认Flink应用程序正在运行，我们可以使用Kafka CLI检查新的<code class="fe nb nc nd ne b">demo.purchases.enriched</code>主题的内容。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi no"><img src="../Images/ba4e0de69a145c82ff22b14d4dde419b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rfz6PMiGwIIS4o2rkBsc5g.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">新的demo.purchases.enriched主题填充了来自Apache Flink的消息</figcaption></figure><p id="4325" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者，您可以使用Apache Kafka的UI，可以在端口9080上访问。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi np"><img src="../Images/e760a0132a83c0e6e47ff382bad149a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bjx3GPEbAMAESVc9YyhnQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">查看Apache Kafka用户界面中的消息</figcaption></figure><h1 id="94f3" class="mq lt it bd lu mr ms mt lx mu mv mw ma jz mx ka md kc my kd mg kf mz kg mj na bi translated">示范#4:阿帕奇皮诺</h1><p id="8cb9" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在第四次也是最后一次演示中，我们将探索<a class="ae le" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇皮诺</a>。首先，我们将使用SQL查询来自<a class="ae le" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>的无界数据流，这些数据流由销售生成器和Apache Flink应用程序生成。然后，我们在Apache超集中构建一个实时仪表板，使用Apache Pinot作为我们的数据源。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nq"><img src="../Images/154e15c4d8b4043bd23a4c49b0b554db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zp0myFdNo0jufjIdu5aYw.png"/></div></div></figure><h2 id="a476" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">创建表格</h2><p id="ff97" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">根据Apache Pinot <a class="ae le" href="https://docs.pinot.apache.org/basics/components/table" rel="noopener ugc nofollow" target="_blank">文档</a>，“<em class="lf">表是表示相关数据集合的逻辑抽象。它由列和行组成(在Pinot中称为文档)。</em>“皮诺表有三种类型:离线、实时和混合。在本演示中，我们将创建三个实时表。实时表从流中摄取数据——在我们的例子中是Kafka——并从消耗的数据中构建<a class="ae le" href="https://docs.pinot.apache.org/basics/components/segment" rel="noopener ugc nofollow" target="_blank">段</a>。进一步，根据<a class="ae le" href="https://docs.pinot.apache.org/basics/components/table" rel="noopener ugc nofollow" target="_blank">文档</a>，<em class="lf">中的每一个表都与一个</em> <a class="ae le" href="https://docs.pinot.apache.org/basics/components/schema" rel="noopener ugc nofollow" target="_blank"> <em class="lf">模式</em> </a> <em class="lf">相关联。模式定义了表中的字段和数据类型。该模式存储在Zookeeper中，与</em> <a class="ae le" href="https://docs.pinot.apache.org/configuration-reference/table" rel="noopener ugc nofollow" target="_blank"> <em class="lf">表一起配置</em> </a> <em class="lf">。</em></p><p id="74e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面，我们看到了三个实时表之一<code class="fe nb nc nd ne b">purchasesEnriched</code>的模式和配置。注意这些列是如何被分成三个<a class="ae le" href="https://docs.pinot.apache.org/basics/components/schema" rel="noopener ugc nofollow" target="_blank">类别</a>的:维度、度量和日期时间。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated"><code class="fe nb nc nd ne b">purchasesEnriched Realtime table</code>的模式文件</figcaption></figure><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated"><code class="fe nb nc nd ne b">purchasesEnriched Realtime table</code>的配置文件</figcaption></figure><p id="c4dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，将三个Pinot实时表模式和配置从<code class="fe nb nc nd ne b"><a class="ae le" href="https://github.com/garystafford/streaming-sales-generator" rel="noopener ugc nofollow" target="_blank">streaming-sales-generator</a></code> GitHub项目复制到Apache Pinot控制器容器中。接下来，使用一个<code class="fe nb nc nd ne b">docker exec</code>命令调用Pinot <a class="ae le" href="https://docs.pinot.apache.org/operators/cli" rel="noopener ugc nofollow" target="_blank">命令行接口</a>的(CLI) <code class="fe nb nc nd ne b">AddTable</code>命令来创建三个表:<code class="fe nb nc nd ne b">products</code>、<code class="fe nb nc nd ne b">purchases</code>和<code class="fe nb nc nd ne b">purchasesEnriched</code>。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="1691" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要确认这三个表是正确创建的，请使用可以在端口9000上访问的Apache Pinot数据浏览器。使用集群管理器中的表选项卡。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/5d196dbe44f4c0900689728235c51fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3zVoAVDVnGnH-oEcghOz6Q.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">Cluster Manager的Tables选项卡显示了三个实时表和相应的模式</figcaption></figure><p id="2d11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以从集群管理器的Tables选项卡中进一步检查和编辑表的配置和模式。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/acd8978658164d98a8c618026f0936fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7tFc_Ne_h8lPba4GcQpp0A.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">实时表的可编辑配置和模式</figcaption></figure><p id="584a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这三个表被配置为从相应的Kafka主题:<code class="fe nb nc nd ne b">demo.products</code>、<code class="fe nb nc nd ne b">demo.purchases</code>和<code class="fe nb nc nd ne b">demo.purchases.enriched</code>中读取无界数据流。</p><h2 id="7c41" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">用比诺查询</h2><p id="29e6" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们可以使用Pinot的查询控制台通过SQL查询实时表。根据文档，“<em class="lf"> Pinot提供了一个用于查询的SQL接口。它使用【Apache】</em><a class="ae le" href="https://calcite.apache.org/" rel="noopener ugc nofollow" target="_blank"><em class="lf">方解石</em> </a> <em class="lf"> SQL解析器解析查询，并使用</em> <code class="fe nb nc nd ne b"><em class="lf">MYSQL_ANSI</em></code> <em class="lf">方言。</em>”</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/a33317abf9a39d1ff16ed01b3837425e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IKgoM1B2o78YLslIhxQvNw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">purchases表的架构和查询结果</figcaption></figure><p id="3c15" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在发电机仍然运行的情况下，在查询控制台中重新查询<code class="fe nb nc nd ne b">purchases</code>表(<code class="fe nb nc nd ne b">select count(*) from purchases</code>)。您应该注意到，每次重新运行查询时，文档数量都会增加，因为销售生成器会向<code class="fe nb nc nd ne b">demo.purchases</code>主题发布新消息。</p><p id="984d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lf">如果您没有观察到计数增加，请确保销售生成器和Flink enrichment作业正在运行。</em></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/710df5e8fae8b9cec4655ac473bc0019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ft3TtUUAPKUDaRXnr0OU8Q.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">查询控制台显示采购表的文档数继续增加</figcaption></figure><h2 id="fc49" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">表连接？</h2><p id="a2f7" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">想要复制我们在关于<code class="fe nb nc nd ne b">demo.products</code>和<code class="fe nb nc nd ne b">demo.purchases</code>主题的演示的第三部分中用Apache Flink执行的相同的多流连接似乎是合乎逻辑的。此外，我们可能假设通过在Pinot的查询控制台中编写SQL语句来连接<code class="fe nb nc nd ne b">products</code>和<code class="fe nb nc nd ne b">purchases</code>实时表。然而，根据<a class="ae le" href="https://docs.pinot.apache.org/users/user-guide-query/querying-pinot" rel="noopener ugc nofollow" target="_blank">文档</a>，在本文发表时，Pinot的0.11.0版本[目前]不支持连接或嵌套子查询。</p><p id="2785" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个当前的连接限制是我们创建实时表<code class="fe nb nc nd ne b">purchasesEnriched</code>的原因，它允许我们在<code class="fe nb nc nd ne b">demo.purchases.enriched</code>主题中查询Flink的实时结果。我们将同时使用Flink和Pinot作为我们流处理管道的一部分，充分利用每种工具各自的优势和能力。</p><p id="cfaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，根据主分支上Pinot的最新版本的<a class="ae le" href="https://docs.pinot.apache.org/users/user-guide-query/querying-pinot" rel="noopener ugc nofollow" target="_blank">文档</a>,<em class="lf">最新的Pinot多级支持内部连接、左外连接、半连接和开箱即用的嵌套查询。它针对内存中的进程和延迟进行了优化。</em>"有关作为Pinot新的多阶段查询执行引擎一部分的连接的更多信息，请阅读文档<a class="ae le" href="https://docs.pinot.apache.org/developers/advanced/v2-multi-stage-query-engine" rel="noopener ugc nofollow" target="_blank">多阶段查询引擎</a>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/213ad5c40acb46029793d08b89739291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xE0mxd7saNyGXrv9f7bi-A.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">查询实时显示来自<code class="fe nb nc nd ne b">demo.purchases.enriched</code>主题的结果</figcaption></figure><h2 id="fc71" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">聚集</h2><p id="71eb" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们可以使用Pinot丰富的SQL查询接口执行实时聚合。例如，像以前的Spark和Flink一样，我们可以实时计算售出商品的数量和每种产品的总销售额。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi np"><img src="../Images/7bbe17cde8df3c1663896ea3a2cab0b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hX9Ev-ixky_KvK5WbEC8Ig.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">汇总每个产品的累计总数</figcaption></figure><p id="36a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以对<code class="fe nb nc nd ne b">purchasesEnriched</code>表做同样的事情，它将使用来自Apache Flink应用程序的丰富的连续事务数据流。使用<code class="fe nb nc nd ne b">purchasesEnriched</code>表，我们可以添加产品名称和产品类别以获得更丰富的结果。每次运行查询时，我们都会获得基于正在运行的销售生成器和Flink enrichment作业的实时结果。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/2924b8be11c1dcd6e032c2742dc92618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JqFv_xzng_VqAkVIGt4sRg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">汇总每个产品的累计总数</figcaption></figure><h2 id="2ee5" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">查询选项和索引</h2><p id="3b48" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">注意上面显示的SQL查询开头对<a class="ae le" href="https://docs.pinot.apache.org/basics/indexing/star-tree-index" rel="noopener ugc nofollow" target="_blank">星型树索引</a>的引用。Pinot提供了几个<a class="ae le" href="https://docs.pinot.apache.org/users/user-guide-query/query-options" rel="noopener ugc nofollow" target="_blank">查询选项</a>，包括<code class="fe nb nc nd ne b">useStarTree</code>(默认为<code class="fe nb nc nd ne b">true</code>)。</p><p id="f19d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Pinot中提供了多种<a class="ae le" href="https://docs.pinot.apache.org/basics/indexing" rel="noopener ugc nofollow" target="_blank">索引技术</a>，包括正向索引、反向索引、星形树索引、布隆过滤器和范围索引等。在不同的查询场景中各有优势。根据<a class="ae le" href="https://docs.pinot.apache.org/basics/indexing" rel="noopener ugc nofollow" target="_blank">文档</a>，默认情况下，Pinot为每一列创建一个字典编码的前向索引。</p><h2 id="61b0" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">SQL示例</h2><p id="abbc" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">这里有几个SQL查询的例子，您可以在Pinot的查询控制台中尝试:</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h2 id="0f6c" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">Pinot故障排除</h2><p id="5f97" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">如果在创建表格或查询实时数据时遇到问题，可以从查看Apache Pinot日志开始:</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h1 id="2b84" class="mq lt it bd lu mr ms mt lx mu mv mw ma jz mx ka md kc my kd mg kf mz kg mj na bi translated">使用Apache超集的实时仪表板</h1><p id="56a9" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">为了显示Apache Flink流处理作业产生的实时数据流，并通过Apache Pinot进行查询，我们可以使用<a class="ae le" href="https://superset.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache超集</a>。Superset将自己定位为一个现代数据探索和可视化平台。“超集”允许用户探索和可视化他们的数据，从简单的折线图到非常详细的地理空间图。”</p><p id="e291" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据<a class="ae le" href="https://superset.apache.org/docs/databases/installing-database-drivers" rel="noopener ugc nofollow" target="_blank">文档</a>,“<em class="lf">超集需要为每个要连接的数据存储安装一个Python DB-API数据库驱动程序和一个</em><a class="ae le" href="https://www.sqlalchemy.org/" rel="noopener ugc nofollow" target="_blank"><em class="lf">SQLAlchemy</em></a><em class="lf">方言。</em>“在Apache Pinot的例子中，我们可以使用<code class="fe nb nc nd ne b"><a class="ae le" href="https://pypi.org/project/pinotdb/" rel="noopener ugc nofollow" target="_blank">pinotdb</a></code>作为Python DB-API和SQLAlchemy方言来表示Pinot。由于现有的<a class="ae le" href="https://hub.docker.com/r/apache/superset" rel="noopener ugc nofollow" target="_blank">超集Docker容器</a>没有安装<code class="fe nb nc nd ne b"><a class="ae le" href="https://pypi.org/project/pinotdb/" rel="noopener ugc nofollow" target="_blank">pinotdb</a></code>，我用驱动程序构建并发布了一个Docker映像，并将其部署为第二个容器流堆栈的一部分。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="f3c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们需要配置超集容器实例。这些指令被记录为超集Docker映像<a class="ae le" href="https://hub.docker.com/r/apache/superset" rel="noopener ugc nofollow" target="_blank">库</a>的一部分。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="2f95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">配置完成后，我们可以登录到基于web浏览器的超集UI，该UI可在端口8088上访问。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi np"><img src="../Images/e42576d5a83535d771add2b7b53a7e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xnvvQ5K1YegvzIwzRPp5iA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">基于web浏览器的超集用户界面的主页</figcaption></figure><h2 id="5115" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">Pinot数据库连接和数据集</h2><p id="a7aa" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">接下来，为了从超集连接到Pinot，我们需要创建一个<a class="ae le" href="https://superset.apache.org/docs/databases/db-connection-ui/" rel="noopener ugc nofollow" target="_blank">数据库连接</a>和一个<a class="ae le" href="https://superset.apache.org/docs/creating-charts-dashboards/creating-your-first-dashboard" rel="noopener ugc nofollow" target="_blank">数据集</a>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/8364fecf7ccc0a17afc3db9b3920708e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fD_SjfCb7bBDuscdyWtiPQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">创建到Pinot的新数据库连接</figcaption></figure><p id="702e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SQLAlchemy URI如下所示。输入URI，测试您的连接(“测试连接”)，确保成功，然后点击“连接”。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="6548" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，创建一个引用<code class="fe nb nc nd ne b">purchasesEnriched</code>皮诺表的数据集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/c47060b4e7d5eb2947095ffd1cbcf7b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5n2kkjliIi6O7LkWnXVLw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">创建一个新的数据集，允许我们访问<code class="fe nb nc nd ne b">purchasesEnriched</code> Pinot表</figcaption></figure><p id="3479" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">修改数据集的<code class="fe nb nc nd ne b">transaction_time</code>列。检查<code class="fe nb nc nd ne b">is_temporal</code>和<code class="fe nb nc nd ne b">Default datetime</code>选项。最后，将日期时间格式定义为<code class="fe nb nc nd ne b">epoch_ms</code>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi np"><img src="../Images/e6d41c1ecfbc826eb5b62ace40173940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00FiqxHXBVbY7s3Gcclhjg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">修改数据集的<code class="fe nb nc nd ne b">transaction_time</code>列</figcaption></figure><h2 id="ff85" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">构建实时仪表板</h2><p id="8ac6" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">使用连接超集和<code class="fe nb nc nd ne b">purchasesEnriched</code> Pinot表的新数据集，我们可以构建单独的图表放在仪表板上。制作一些图表，放在您的仪表板上。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/a637bf81c931b667b70cc02c87f60222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*11C1zs4TN3c0h5Ln-Utmyg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">数据源为新数据集的图表示例</figcaption></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/0dfcb8e6e895a2f5e09fc5a5de0bc8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3pAPQdGNfa3K5jkG28R_w.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">仪表板上包含的图表列表</figcaption></figure><p id="4a33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建一个新的超集仪表板，并添加图表和其他元素，如标题、分隔线和选项卡。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nr"><img src="../Images/fa8c4cc1150cc5107a18b4c0446aadd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJTh-smKy7dzZ_3cqwzAPA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">Apache超集仪表板显示来自Apache Pinot实时表的数据</figcaption></figure><p id="5048" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将刷新间隔应用于仪表板，以连续查询Pinot并近乎实时地可视化结果。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/4a706f5034feea4e3ea9dd29ad53a2f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JoxJvhzxfThqEJC7YEU4IA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">为仪表板配置刷新间隔</figcaption></figure><h1 id="a81b" class="mq lt it bd lu mr ms mt lx mu mv mw ma jz mx ka md kc my kd mg kf mz kg mj na bi translated">结论</h1><p id="ad12" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在这个由两部分组成的系列文章中，我们介绍了流处理。我们探索了四个流行的开源流处理项目:Apache <a class="ae le" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark结构化流</a>、<a class="ae le" href="https://kafka.apache.org/documentation/streams/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka流</a>、<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Flink </a>和<a class="ae le" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Pinot </a>。接下来，我们学习了如何使用不同的流技术解决类似的流处理和流分析挑战。最后，我们看到了如何将Kafka、Flink、Pinot和Superset等技术集成起来，以创建有效的流处理管道。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="62a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本博客代表我的观点，而非我的雇主亚马逊网络服务公司(Amazon Web Services)的观点。所有产品名称、徽标和品牌都是其各自所有者的财产。除非另有说明，所有图表和插图都是作者的财产。</p></div></div>    
</body>
</html>