<html>
<head>
<title>Kubernetes — Running Multiple Container Runtimes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes —运行多个容器运行时</h1>
<blockquote>原文：<a href="https://itnext.io/kubernetes-running-multiple-container-runtimes-65220b4f9ef4?source=collection_archive---------0-----------------------#2021-08-16">https://itnext.io/kubernetes-running-multiple-container-runtimes-65220b4f9ef4?source=collection_archive---------0-----------------------#2021-08-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="30c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi ko translated"><span class="l kp kq kr bm ks kt ku kv kw di">在这篇文章中，我想向你展示如何在Kubernetes上运行多个OCI容器运行时。您将看到如何配置containerd来运行runC和Kata容器。然后我们将使用Kubernetes <code class="fe kx ky kz la b">RuntimeClass</code> API让工作负载选择不同的容器运行时。</span></p><h1 id="dcdd" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">为什么不同的容器运行时</h1><p id="53ca" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">当多个租户共享一个集群时，工作负载的异构性通常意味着不同的执行和数据信任边界。这样的集群拥有一组管理和操作集群所需的可信中央服务，同时还托管不同租户拥有的“不可信”工作负载，这种情况并不少见。虽然依赖于Linux名称空间和cgroup的通用容器化方法可能适合运行可信工作负载，但是使用基于管理程序的容器化技术的更强的工作负载隔离可能更好地减轻与支持不可信工作负载相关联的威胁模型。</p><p id="9ddc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一个例子涉及GPU工作负载，其中基于虚拟机管理程序的容器运行时可用于支持GPU直通和GPU中介直通。<a class="ae me" href="https://github.com/kata-containers/kata-containers/blob/main/docs/use-cases/using-SRIOV-and-kata.md" rel="noopener ugc nofollow" target="_blank">单根I/O虚拟化(SR-IOV) </a>和<a class="ae me" href="https://github.com/kata-containers/kata-containers/blob/main/docs/use-cases/using-SPDK-vhostuser-and-kata.md" rel="noopener ugc nofollow" target="_blank">高性能用户模式应用</a>也可以通过非传统容器运行时得到更好的服务。</p><p id="15ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Kubernetes提供了<code class="fe kx ky kz la b"><a class="ae me" href="https://kubernetes.io/docs/concepts/containers/runtime-class/" rel="noopener ugc nofollow" target="_blank">RuntimeClass</a></code> <a class="ae me" href="https://kubernetes.io/docs/concepts/containers/runtime-class/" rel="noopener ugc nofollow" target="_blank"> API </a>，允许工作负载选择最适合其需求的容器运行时。这个资源最初是在Kubernetes 1.12中作为自定义资源定义(CRD)引入的。后来在Kubernetes 1.14中，它被实现为内置的集群资源。</p><h1 id="9f4e" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">关于形容器</h1><p id="f79b" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">Kata Containers是一个开源容器运行时，它在轻量级虚拟机上运行容器工作负载。它利用硬件虚拟化技术来实施强大的工作负载隔离。基于<a class="ae me" href="https://clearlinux.org/" rel="noopener ugc nofollow" target="_blank"> Clear Linux </a>的专用最小来宾Linux内核和来宾映像运行工作负载。这种部署模型确保容器化的流程不再能够访问主机内核。它简化了主机内核上防止容器利用所需的安全策略。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/5593f2755be04fbd1a1feff3a763548d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftdrjCwUWzvUTeJNZr9Ojg.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">传统容器与形容器</figcaption></figure><p id="741b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Kata Containers是OCI兼容的，通过一个CRI兼容的垫片与containerd一起工作。它利用Linux流量控制在容器的<code class="fe kx ky kz la b">veth</code>接口和虚拟机的<code class="fe kx ky kz la b">TAP</code>接口之间重定向流量。有关Kata容器架构的更多信息，请参见其文档<a class="ae me" href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture.md" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="9eb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">至此，让我们继续设置和配置Kubernetes来使用runC和Kata容器🚢🚢🚢！</p><h1 id="3b64" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">调配Kubernetes集群</h1><p id="8c2c" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">在我的设置中，我使用<code class="fe kx ky kz la b">kubeadm</code>提供了一个Kubernetes v1.22.0集群。我的集群中使用的containerd版本是1.4.9。</p><p id="c9b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本节的剩余部分将只强调相关的安装和配置步骤。关于使用<code class="fe kx ky kz la b">kubeadm</code>供应Kubernetes的详细信息可以在Kubernetes <a class="ae me" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/" rel="noopener ugc nofollow" target="_blank">文档</a>中找到，以及关于i <a class="ae me" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd" rel="noopener ugc nofollow" target="_blank">安装容器</a>的重要信息。</p><p id="6713" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">👷<em class="mv">不需要</em> <code class="fe kx ky kz la b"><em class="mv"> docker-ce</em></code> <em class="mv">和</em> <code class="fe kx ky kz la b"><em class="mv">docker-ce-cli</em></code> <em class="mv">软件包就可以安装</em> <code class="fe kx ky kz la b"><em class="mv">containerd.io</em></code> <em class="mv">软件包。</em></p><p id="24ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的集群由3个DigitalOcean droplets组成，拥有4GB内存和2个CPU，运行Ubuntu 20.04:</p><ul class=""><li id="c3dd" class="mw mx it js b jt ju jx jy kb my kf mz kj na kn nb nc nd ne bi translated">托管Kubernetes控制平面</li><li id="1cef" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated"><code class="fe kx ky kz la b">k8s-worker</code>使用runC服务可信工作负载</li><li id="1cbe" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated"><code class="fe kx ky kz la b">k8s-worker-untrusted</code>使用runC和Kata容器来服务工作负载，不可信的工作负载被指定给Kata容器</li></ul><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/902f41d2b98be9da3aab70b404e08050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*mGapSlWCB0Gt4ksRWB51oQ.png"/></div></figure><p id="edfb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我使用<a class="ae me" href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart" rel="noopener ugc nofollow" target="_blank"> Calico </a>作为CNI插件来支持pod网络。</p><p id="1643" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在使用<code class="fe kx ky kz la b">kubeadm init</code>命令初始化控制平面之前，让我们在每个节点上的<code class="fe kx ky kz la b">/etc/containerd/config.toml</code>处修改容器的配置文件。</p><p id="bba9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🔧<em class="mv"/><code class="fe kx ky kz la b"><em class="mv">kata-deploy</em></code><em class="mv">工具是在Kubernetes上安装Kata容器的简单方法。出于演示的目的，我将在本文中手动配置containerd并安装Kata容器。</em></p><h1 id="3c8f" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">用Kata容器配置containerd</h1><p id="1cb0" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">📝<em class="mv">所有后续代码示例都需要对集群节点的直接SSH访问，以及在节点上修改容器的配置文件的权限。</em></p><p id="d61d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe kx ky kz la b">containerd config default</code>命令在所有节点上重新生成containerd的默认配置:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">重新生成containerd的默认配置</figcaption></figure><p id="9e32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在将要安装Kata容器的<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上，为容器的配置文件打补丁，如下所示:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">修补containerd的配置文件以包含kata shimv2</figcaption></figure><p id="4338" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个补丁用<code class="fe kx ky kz la b">kata</code>处理程序扩展了容器的<code class="fe kx ky kz la b">cri</code>插件。正如在<a class="ae me" href="https://kubernetes.io/docs/concepts/containers/runtime-class/#hahahugoshortcode-s3-hbhb" rel="noopener ugc nofollow" target="_blank"> Kubernetes文档</a>中所解释的，这个处理程序的名称将在后面的<code class="fe kx ky kz la b">RuntimeClass</code>资源规范中引用。</p><p id="fe14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">containerd使用<code class="fe kx ky kz la b">runtime_type</code>属性来标识与底层OCI运行时交互所需的垫片。containerd通过在句柄名称和版本前面加上前缀<code class="fe kx ky kz la b">containerd-shim</code>将<code class="fe kx ky kz la b">runtime_type</code>翻译成shim的二进制名称。比如<code class="fe kx ky kz la b">io.containerd.kata.v2</code>翻译成<code class="fe kx ky kz la b">containerd-shim-kata-v2</code>，<code class="fe kx ky kz la b">io.containerd.runc.v1</code>变成<code class="fe kx ky kz la b">containerd-shim-runc-v1</code>等等。</p><p id="9077" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe kx ky kz la b">containerd-shim-kata-v2</code>实现了<a class="ae me" href="https://github.com/containerd/containerd/blob/main/runtime/v2/README.md" rel="noopener ugc nofollow" target="_blank">容器运行时V2 </a> API。通过这个垫片，Kubernetes将能够指导卡塔推出吊舱和OCI兼容的容器。</p><p id="9857" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将<code class="fe kx ky kz la b">privileged_without_host_devices</code>属性设置为<code class="fe kx ky kz la b">true</code>会将containerd配置为不允许特权kata容器直接访问主机设备。</p><p id="a0a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">📝<em class="mv">这个补丁没有故意禁用runC，以显示一个节点能够托管多个容器运行时。</em></p><p id="4177" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">成功应用补丁后，使用<code class="fe kx ky kz la b">systemctl</code>重启containerd:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">使用systemctl重新启动containerd</figcaption></figure><h1 id="a705" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">在不受信任的节点上安装Kata容器</h1><p id="7a0e" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">使用<code class="fe kx ky kz la b">snap</code>在<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上安装Kata容器2.1.1:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">在不受信任的节点上安装Kata容器</figcaption></figure><p id="b184" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe kx ky kz la b">kata-containers.runtime</code> CLI确保<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点可以运行Kata容器:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">确保不受信任的节点可以运行Kata容器</figcaption></figure><h1 id="c29f" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">初始化Kubernetes控制平面</h1><p id="9781" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">用<code class="fe kx ky kz la b">kubeadm init</code>命令初始化<code class="fe kx ky kz la b">k8s-control-plane</code>节点上的Kubernetes控制平面:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">初始化Kubernetes控制平面</figcaption></figure><p id="2c17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<code class="fe kx ky kz la b">k8s-worker</code>和<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上，使用<code class="fe kx ky kz la b">kubeadm join</code>命令将工作者加入控制平面:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">将工人加入控制平面</figcaption></figure><p id="f165" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">确认所有节点都正常运行:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">确认所有节点都正常</figcaption></figure><p id="22af" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有后续的<code class="fe kx ky kz la b">kubectl</code>命令都使用由<code class="fe kx ky kz la b">kubeadm</code>生成的默认kubeconfig，它可以在<code class="fe kx ky kz la b">k8s-control-plane</code>节点的<code class="fe kx ky kz la b">/etc/kubernetes</code>文件夹中找到。</p><h1 id="2503" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">调度不可信的工作负载</h1><p id="d0d4" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">为了确保所有不可信的工作负载都将被调度到<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上，我们将<a class="ae me" href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/" rel="noopener ugc nofollow" target="_blank">用任意的<code class="fe kx ky kz la b">example.org/workload=untrusted</code>标签来标记</a>和<a class="ae me" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" rel="noopener ugc nofollow" target="_blank">节点:</a></p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">污染并标记k8s-worker-不可信节点</figcaption></figure><p id="0298" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">创建kata <code class="fe kx ky kz la b">RuntimeClass</code>资源:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">创建kata RuntimeClass资源</figcaption></figure><p id="c9ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">创建“不受信任的”<code class="fe kx ky kz la b">Deployment</code>资源，其中pod由一个<code class="fe kx ky kz la b">curl</code>容器和一个<code class="fe kx ky kz la b">nginx</code>容器组成:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">部署不受信任的工作负载</figcaption></figure><p id="c1f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">确认<code class="fe kx ky kz la b">nginx-untrusted</code>部署成功铺开:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">确认不受信任的工作负载已成功转出</figcaption></figure><h2 id="0865" class="nn lc it bd ld no np dn lh nq nr dp ll kb ns nt lp kf nu nv lt kj nw nx lx ny bi translated">检查QEMU流程</h2><p id="eb90" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">让我们检查一下<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上pod的QEMU过程:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">检查pod的QEMU流程</figcaption></figure><p id="b546" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">应该只有一个QEMU进程，即使pod运行2个容器。关于加载的设备和到<code class="fe kx ky kz la b">vmlinuz</code>内核的路径的信息可以在进程参数中看到。</p><p id="d0ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我的设置中，<code class="fe kx ky kz la b">vmlinuz-5.10.25.container</code>访客内核的大小约为5.2MB。相比之下，同一个droplet上的<code class="fe kx ky kz la b">vmlinuz-5.4.0-80-generic</code>主机内核大约是12MB。这种小内核使得它能够相对快速地旋转新的豆荚。</p><h2 id="5948" class="nn lc it bd ld no np dn lh nq nr dp ll kb ns nt lp kf nu nv lt kj nw nx lx ny bi translated">访问来宾虚拟机控制台</h2><p id="a45a" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated"><code class="fe kx ky kz la b">kata-containers.runtime</code> CLI有一个<code class="fe kx ky kz la b">exec</code>命令，它提供了一种通过调试控制台进入客户虚拟机的机制。</p><p id="a29b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">⚠️ <em class="mv">默认</em> <a class="ae me" href="https://clearlinux.org/" rel="noopener ugc nofollow" target="_blank"> <em class="mv">清除Linux </em> </a> <em class="mv">镜像可能不会返回一个</em> <code class="fe kx ky kz la b"><em class="mv">tty</em></code> <em class="mv">带全shell访问。参见本</em> <a class="ae me" href="https://github.com/kata-containers/kata-containers/issues/2010" rel="noopener ugc nofollow" target="_blank"> <em class="mv"> GitHub一期</em> </a> <em class="mv">。</em></p><p id="3c08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要使用此功能，请在<code class="fe kx ky kz la b">/etc/kata-runtime/configuration.toml</code>配置文件中启用kata代理的<code class="fe kx ky kz la b">debug_console_enabled </code>属性:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">启用kata代理的debug_console_enabled属性</figcaption></figure><p id="2478" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上启动<code class="fe kx ky kz la b">kata-monitor</code>进程:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">启动形监控程序</figcaption></figure><p id="e217" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后使用沙箱ID作为参数执行<code class="fe kx ky kz la b">kata-containers.runtime exec</code>命令:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">使用“kata-containers.rutime exec”命令访问来宾虚拟机控制台</figcaption></figure><p id="f3a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🤔<em class="mv">如果我们将</em> <code class="fe kx ky kz la b"><em class="mv">nginx-untrusted</em></code> <em class="mv">工作负载扩展到3个副本，您认为最终会有多少台虚拟机？我们最终会有3台虚拟机吗？或者这6个容器最终会共享同一个虚拟机吗？你认为缩放操作需要多长时间？</em></p><h1 id="ce67" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">可信和不可信工作负载之间的差异</h1><p id="7aba" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">作为最后的测试，我们将使用相同的pod规范部署类似的<code class="fe kx ky kz la b">Deployment</code>资源。该工作负载将扮演我们的“可信”工作负载的角色:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">部署可信工作负载</figcaption></figure><p id="861b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我的<code class="fe kx ky kz la b">default</code>名称空间在扩展不可信工作负载和部署可信工作负载后的样子:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">包含可信和不可信工作负载的“默认”命名空间</figcaption></figure><p id="0c8d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，所有受信任的pod都被安排在<code class="fe kx ky kz la b">k8s-worker</code>节点上运行，而不受信任的pod则在<code class="fe kx ky kz la b">k8s-worker-untrusted</code>节点上运行。</p><p id="f0f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此时，在可信和不可信工作负载之间没有任何强制的网络边界。豆荚可以自由地互相交谈。</p><p id="7eab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，我可以使用可信的<code class="fe kx ky kz la b">curl</code>来联系不可信的<code class="fe kx ky kz la b">nginx</code>:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">可信的curl可以到达不可信的nginx</figcaption></figure><p id="0d2d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我也可以使用不可信的<code class="fe kx ky kz la b">curl</code>联系可信的<code class="fe kx ky kz la b">nginx</code>:</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">不可信的curl可以到达可信的nginx</figcaption></figure><p id="ed9b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">部署<code class="fe kx ky kz la b"><a class="ae me" href="https://kubernetes.io/docs/concepts/services-networking/network-policies/" rel="noopener ugc nofollow" target="_blank">NetworkPolicy</a></code>资源来限制可信域和不可信域之间的流量的任务将留给读者来完成。</p><h1 id="8af4" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="7b1a" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">在本文中，我们使用<code class="fe kx ky kz la b">kubeadm</code>在DigitalOcean上提供了一个Kubernetes v1.22.0集群。我们指定一个节点为可信工作负载服务，而另一个节点为不可信工作负载服务。在初始化集群之前，我们手动修补containerd的配置文件，并在不受信任的节点上安装Kata容器。在实际设置中，<code class="fe kx ky kz la b"><a class="ae me" href="https://github.com/kata-containers/kata-containers/tree/main/tools/packaging/kata-deploy" rel="noopener ugc nofollow" target="_blank">kata-deploy</a></code>工具将是在Kubernetes上部署Kata容器的更好选择。</p><p id="e0fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们将可信和不可信工作负载部署到集群上。通过使用适当的<a class="ae me" href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/" rel="noopener ugc nofollow" target="_blank">污点</a>和<a class="ae me" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" rel="noopener ugc nofollow" target="_blank">标签</a>，所有不可信的工作负载都被调度到不可信的节点上运行。尽管可信和不可信工作负载由不同的容器运行时提供服务，但是它们能够相互通信。部署<code class="fe kx ky kz la b"><a class="ae me" href="https://kubernetes.io/docs/concepts/services-networking/network-policies/" rel="noopener ugc nofollow" target="_blank">NetworkPolicy</a></code>资源以加强可信域和不可信域之间的网络边界的任务留给读者来完成。</p></div></div>    
</body>
</html>