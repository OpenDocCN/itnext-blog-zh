<html>
<head>
<title>Modern storage is plenty fast. It is the APIs that are bad.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">现代存储速度非常快。坏的是API。</h1>
<blockquote>原文：<a href="https://itnext.io/modern-storage-is-plenty-fast-it-is-the-apis-that-are-bad-6a68319fbc1a?source=collection_archive---------0-----------------------#2020-11-25">https://itnext.io/modern-storage-is-plenty-fast-it-is-the-apis-that-are-bad-6a68319fbc1a?source=collection_archive---------0-----------------------#2020-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/eee55e2e7e2655d83e7f520ce9468745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXK9Vi3UbLj5vtBJ2HFavg.jpeg"/></div></div></figure><div class=""/><p id="5c24" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在过去的十年里，我几乎一直在一家相当专业的产品公司工作，构建高性能的I/O系统。我有机会见证了存储技术的快速发展。谈论存储及其发展感觉像是在向唱诗班布道。</p><p id="3e2c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">今年，我已经跳槽了。在一家拥有来自多种背景的工程师的大公司，我惊讶地发现，虽然我的每个同事都非常聪明，但他们中的大多数人对如何最好地利用现代存储技术的性能有误解，导致了次优的设计，即使他们意识到存储技术的不断进步。</p><p id="7d4f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我思考这种脱节的原因时，我意识到这种误解持续存在的很大一部分原因是，如果他们花时间用基准来验证他们的假设，数据将显示他们的假设是正确的，或者至少看起来是正确的。</p><p id="a61d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这种误解的常见例子包括:</p><ul class=""><li id="5a4f" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">嗯，在这里复制内存并执行这种昂贵的计算是没问题的，因为它为我们节省了一次I/O操作，而I/O操作的成本更高。</li><li id="732a" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">“我正在设计一个需要快速运行的系统。因此它需要在内存中”。</li><li id="2807" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">“如果我们将它分成多个文件，速度会很慢，因为它会生成随机的I/O模式。我们需要对此进行优化，以便从单个文件中进行顺序访问和读取”</li><li id="b15f" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">“直接I/O非常慢。它只适用于非常特殊的应用。如果你没有自己的缓存，你就完了”。</li></ul><p id="5c7f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lk" href="https://www.samsung.com/semiconductor/global.semi.static/Ultra-Low_Latency_with_Samsung_Z-NAND_SSD-0.pdf" rel="noopener ugc nofollow" target="_blank">然而，如果你浏览一下现代NVMe设备的规格</a>,你会看到商用设备的延迟在微秒范围内，吞吐量为几GB/s，支持几十万个随机IOPS。那么，脱节在哪里呢？</p><p id="42bc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇文章中，我将证明虽然硬件在过去十年中发生了巨大的变化，但是软件API却没有，或者至少还不够。受内存拷贝、内存分配、过于乐观的预读缓存和各种昂贵操作的困扰，传统API阻止我们充分利用现代设备。</p><p id="0eb7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在写这篇文章的过程中，我非常高兴能够提前接触到英特尔的下一代Optane设备。虽然它们在市场上还不常见，但它们无疑代表了越来越快的设备趋势的顶峰。您将在本文中看到的数字都是使用该设备获得的。</p><p id="be36" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于时间关系，我将把这篇文章的重点放在阅读上。写作有其独特的问题，也有改进的机会，这将在另一篇文章中讨论。</p><h1 id="2f1c" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">索赔</h1><p id="c4d7" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">传统的基于文件的API有三个主要问题:</p><ul class=""><li id="236a" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka jc">他们执行许多昂贵的操作，因为“I/O是昂贵的”。</strong></li></ul><p id="e2e1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当遗留API需要读取没有缓存在内存中的数据时，它们会产生一个页面错误。然后在数据准备好之后，一个中断。最后，对于传统的基于系统调用的读取，您有一个到用户缓冲区的额外副本，对于基于mmap的操作，您必须更新虚拟内存映射。</p><p id="185f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些操作中没有一个是廉价的:页面错误、中断、复制或虚拟内存映射更新。但是几年前，它们仍然比I/O本身的成本便宜100倍，这使得这种方法可以接受。随着设备延迟接近个位数微秒，情况不再如此。这些操作现在与I/O操作本身处于相同的数量级。</p><p id="0258" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个简单的计算表明，在最坏的情况下，不到一半的总繁忙成本是与设备本身的通信成本。这还不算所有的浪费，这就给我们带来了第二个问题:</p><ul class=""><li id="6f96" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka jc">读放大。</strong></li></ul><p id="d546" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">尽管有一些细节我将会一笔带过(比如文件描述符使用的内存，Linux中的各种元数据缓存)，如果现代NVMe支持许多并发操作，那么没有理由认为从许多文件中读取比从一个文件中读取更昂贵。然而<em class="mo">读取的数据总量</em>确实很重要。</p><p id="3b94" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">操作系统以<em class="mo">页面粒度</em>读取数据，这意味着它一次至少只能读取4kB。这意味着，如果您需要读取分成两个文件读取的1kB，每个文件512字节，那么您实际上是读取8kB来服务1kB，浪费了87%的读取数据。实际上，操作系统还会执行预读，默认设置为128kB，以便在以后需要剩余数据时节省时间。但是如果您从来不这样做，就像随机I/O经常发生的情况一样，那么您只是读取256kB来服务1kB，浪费了99%的空间。</p><p id="d17a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您想验证我的说法，即从多个文件读取不应该比从单个文件读取慢，您可能最终会证明自己是对的，但这只是因为读取放大大大增加了有效读取的数据量。</p><p id="dd08" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然问题在于操作系统页面缓存，那么在其他条件都相同的情况下，如果您只是用直接I/O打开一个文件，会发生什么呢？不幸的是，这也不会变得更快。但那是因为我们的第三个也是最后一个问题:</p><ul class=""><li id="0b78" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka jc">传统API没有利用并行性</strong>。</li></ul><p id="f150" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">文件被视为一个连续的字节流，数据是否在内存中对读者来说是透明的。传统的API会等到你接触到不常驻的数据时才发出I/O操作。由于预读，I/O操作可能比用户请求的要大，但仍然只有一个。</p><p id="f8b1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，尽管现代设备速度很快，但它们仍然比CPU慢。当设备等待I/O操作返回时，CPU不做任何事情。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mp"><img src="../Images/633d8a6092bb7655e72c6a2c2c01eaa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v74E8E9ick4-rpiYZ2uFKA.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">传统API缺乏并行性，导致CPU在等待I/O返回时处于空闲状态。</figcaption></figure><p id="c7c4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用多个文件是朝着正确方向迈出的一步，因为它允许更有效的并行:当一个读者在等待时，另一个读者有希望继续。但是如果你不小心，你最终只会放大前面的一个问题:</p><ul class=""><li id="edc4" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">多个文件意味着多个预读缓冲区，增加了随机I/O的浪费因素。</li><li id="5f9e" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">在基于线程轮询的API中，多个文件意味着多个线程，放大了每个I/O操作所完成的工作量。</li></ul><p id="5030" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">更不用说在很多情况下这不是你想要的:你可能没有那么多的文件。</p><h1 id="7c34" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">迈向更好的API</h1><p id="1347" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">我在过去写过大量关于<a class="ae lk" href="https://www.scylladb.com/2020/05/05/how-io_uring-and-ebpf-will-revolutionize-programming-in-linux/" rel="noopener ugc nofollow" target="_blank">摄影是多么的革命性的文章。但是作为一个相当低级的接口，它实际上只是API难题的一部分。原因如下:</a></p><ul class=""><li id="43e0" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">如果I/O使用缓冲文件，通过I/O调度的I/O仍然会遇到前面列出的大多数问题。</li><li id="9488" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">直接I/O充满了警告，作为一个原始接口，I/O甚至没有试图(也不应该)隐藏这些问题:例如，内存必须正确对齐，以及读取的位置。</li><li id="36c3" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">也是很低级很原始。为了使它有用，你需要累积I/O并分批发送。这需要一个何时做这件事的策略，以及某种形式的事件循环，这意味着它与已经为此提供了机制的框架一起工作会更好。</li></ul><p id="f7f8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了解决API问题，我设计了G <a class="ae lk" href="https://www.datadoghq.com/blog/engineering/introducing-glommio/" rel="noopener ugc nofollow" target="_blank"> lommio </a>(以前被称为Scipio)，一个直接面向I/O的每核线程Rust库。Glommio建立在io ouring的基础上，支持许多高级特性，如注册缓冲区和基于轮询(无中断)的完成，使直接I/O大放异彩。为了熟悉起见，Glommio确实支持由Linux页面缓存支持的缓冲文件，其方式类似于标准的Rust APIs(我们将在这次比较中使用它)，但是它面向的是将直接I/O引入聚光灯下。</p><p id="1854" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Glommio中有两类文件:<a class="ae lk" href="https://docs.rs/glommio/0.2.0-alpha/glommio/io/struct.DmaFile.html" rel="noopener ugc nofollow" target="_blank">随机存取文件</a>，和<a class="ae lk" href="https://docs.rs/glommio/0.2.0-alpha/glommio/io/struct.DmaStreamReader.html" rel="noopener ugc nofollow" target="_blank">流</a>。</p><p id="932a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">随机存取文件将位置作为参数，这意味着不需要保持搜索光标。但更重要的是:它们不把缓冲区作为参数。相反，它们使用io_uring预先注册的缓冲区来分配一个缓冲区并返回给用户。这意味着没有内存映射，没有拷贝到用户缓冲区——只有一个从器件到glommio缓冲区的拷贝，用户得到一个指向该缓冲区的引用计数指针。因为我们知道这是随机I/O，所以不需要读取比所请求的更多的数据。</p><figure class="mq mr ms mt gt is"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="bbe4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一方面，流假设您最终将遍历整个文件，因此它们可以使用更大的块大小和预读因子。</p><p id="3b70" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">流被设计成Rust的默认<a class="ae lk" href="https://docs.rs/futures-lite/1.11.2/futures_lite/io/trait.AsyncReadExt.html" rel="noopener ugc nofollow" target="_blank"> AsyncRead </a>最熟悉的，所以它实现了AsyncRead特性，并且仍然将数据读取到用户缓冲区。基于I/O的直接扫描的所有好处仍然存在，但是在我们的内部预读缓冲区和用户缓冲区之间有一个副本。这是对使用标准API的便利性的征税。</p><p id="43e1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您需要额外的性能，glommio在流中提供了一个<a class="ae lk" href="https://docs.rs/glommio/0.2.0-alpha/glommio/io/struct.DmaStreamReader.html#method.get_buffer_aligned" rel="noopener ugc nofollow" target="_blank"> API，它也公开了原始缓冲区，节省了额外的副本。</a></p><figure class="mq mr ms mt gt is"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="3fe0" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">测试扫描</h1><p id="9d98" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">为了演示这些API，glommio有一个<a class="ae lk" href="https://github.com/DataDog/glommio/blob/master/examples/storage.rs" rel="noopener ugc nofollow" target="_blank">示例程序</a>，它使用所有这些API(缓冲、直接I/O、随机、顺序)发出具有各种设置的I/O，并评估它们的性能。</p><p id="d481" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们从一个大小约为内存2.5倍的文件开始，简单的做法是将其作为普通缓冲文件顺序读取:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="335c" class="nf lm jb nb b gy ng nh l ni nj">Buffered I/O: Scanned 53GB in 56s, 945.14 MB/s</span></pre><p id="18c6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">考虑到这个文件不适合内存，这当然不坏，但这里的优点都是英特尔Optane的完美性能和io_uring后端。每当调度I/O时，它的有效并行度仍然为1，尽管操作系统页面大小为4kB，但预读允许我们有效地增加I/O大小。</p><p id="9ce5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">事实上，如果我们试图使用直接I/O API (4kB缓冲区，并行度为1)来模拟类似的参数，结果将会令人失望，“证实”我们的怀疑，即直接I/O确实要慢得多。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="25db" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O: Scanned 53GB in 115s, 463.23 MB/s</span></pre><p id="15d9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是正如我们所讨论的，glommio的直接I/O文件流可以接受一个显式的预读参数。如果活动glommio将在当前读取的位置之前发出I/O请求，以利用设备的并行性。</p><p id="0b41" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Glommio的预读工作方式与操作系统级预读不同:我们的目标是利用并行性，而不仅仅是增加I/O大小。glommio不是先消耗整个预读缓冲区，然后再发送一个新批次的请求，而是在缓冲区的内容完全消耗后立即发送一个新的请求，并总是试图保持固定数量的缓冲区在运行中，如下图所示。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mp"><img src="../Images/8e5fd5c95f08bcd4f4739205043699b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vnqwP1nkcOOQfHhlazRYA.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">当我们用完一个缓冲区时，另一个已经被获取。这有助于提高并行度并保持较高的并行度。</figcaption></figure><p id="94be" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如最初预期的那样，一旦我们通过设置预读因子正确地利用了并行性，直接I/O不仅与缓冲I/O成对，而且实际上要快得多。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="45e1" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O, read ahead: Scanned 53GB in 22s, 2.35 GB/s</span></pre><p id="ac53" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个版本仍然使用Rust的<a class="ae lk" href="https://docs.rs/futures-lite/1.11.2/futures_lite/io/trait.AsyncReadExt.html" rel="noopener ugc nofollow" target="_blank">asynchreadext</a>接口，该接口强制从glommio缓冲区向用户缓冲区进行额外的复制。</p><p id="ebff" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用<a class="ae lk" href="https://docs.rs/glommio/0.2.0-alpha/glommio/io/struct.DmaStreamReader.html#method.get_buffer_aligned" rel="noopener ugc nofollow" target="_blank"> get_buffer_aligned </a> API可以让您对缓冲区进行原始访问，从而避免最后一次内存复制。如果我们现在在我们的读取测试中使用它，我们将获得可观的4%的性能提升</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="e7c2" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O, glommio API: Scanned 53GB in 21s, 2.45 GB/s</span></pre><p id="89ca" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后一步是增加缓冲区的大小。由于这是一个顺序扫描，我们没有必要受到4kB缓冲区大小的限制，除非是为了与操作系统页面缓存版本进行比较。</p><p id="e330" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们在下一次测试中总结glommio和io uring在幕后发生的所有事情:</p><ul class=""><li id="b812" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">每个I/O请求的大小为512kB，</li><li id="70a9" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">它们中的许多(5个)为了平行性而保持飞行，</li><li id="2808" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">内存是预先分配和预先注册的</li><li id="4e0c" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">不会对用户缓冲区执行额外的复制</li><li id="11de" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">io_uring设置为轮询模式，这意味着没有内存拷贝、没有中断、没有上下文切换。</li></ul><p id="7f9e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">结果呢？</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="6e71" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O, glommio API, large buffer: Scanned 53GB in 7s, 7.29 GB/s</span></pre><p id="f283" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这比标准缓冲方法好7倍以上。更好的是，内存利用率从未高于我们设置的预读因子乘以缓冲区大小。在本例中，2.5MB。</p><h1 id="3912" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">随机读取</h1><p id="ed99" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">众所周知，扫描对操作系统页面缓存有害。我们如何处理随机I/O？为了测试这一点，我们将在20秒内尽可能多地读取，首先将我们自己限制在可用内存的前10%(1.65 GB)</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="68ff" class="nf lm jb nb b gy ng nh l ni nj">Buffered I/O: size span of 1.65 GB, for 20s, 693870 IOPS</span></pre><p id="5262" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于直接输入/输出:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="fe34" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O: size span of 1.65 GB, for 20s, 551547 IOPS</span></pre><p id="4a32" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">直接I/O比缓冲读取慢20%。虽然完全凭记忆阅读仍然更快——这不应该让任何人感到惊讶，但这与人们预期的灾难相去甚远。事实上，如果我们记住缓冲版本保留1.65GB的常驻内存来实现这一点，而直接I/O仅使用80kB (20个4kB缓冲区)，这甚至可能对特定类别的应用程序更为<em class="mo">有利</em>，在其他地方使用该内存可能会更好。</p><p id="c300" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如任何性能工程师都会告诉你的那样，一个好的读取基准需要读取足够的数据来命中介质。毕竟“存储慢”。因此，如果我们现在读取整个文件，我们的缓冲性能会显著下降65%</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="e25e" class="nf lm jb nb b gy ng nh l ni nj">Buffered I/O: size span of 53.69 GB, for 20s, 237858 IOPS</span></pre><p id="7b0c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">而直接I/O，正如预期的那样，具有相同的性能和相同的内存利用率，与读取的数据量无关。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="957a" class="nf lm jb nb b gy ng nh l ni nj">Direct I/O: size span of 53.69 GB, for 20s, 547479 IOPS</span></pre><p id="2afa" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果较大的扫描是我们的比较点，那么直接I/O比缓冲文件快2.3倍，而不是更慢。</p><h1 id="c95b" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="4892" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">现代NVMe设备改变了如何在有状态应用程序中最佳执行I/O的本质。这种趋势已经持续了一段时间，但迄今为止被这样一个事实掩盖了，即API，尤其是更高级别的API，还没有发展到与设备中发生的事情相匹配——以及最近的Linux内核层。有了正确的API集，直接I/O将成为新的亮点。</p><p id="9d3a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">像最新一代的英特尔Optane这样的新设备就已经达成了协议。不存在标准缓冲I/O无可争议地优于直接I/O的情况</p><p id="db3c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于扫描，定制良好的基于直接I/O的API的性能要优越得多。虽然缓冲I/O标准API对于完全适合内存的随机读取的性能提高了20%,但这是以200倍的内存利用率为代价的，这使得权衡取舍并不明确。</p><p id="3bd5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">确实需要额外性能的应用程序仍然希望缓存其中的一些结果，并且提供一种简单的方法来集成专用缓存以用于直接I/O，这是glommio正在进行的工作。</p></div></div>    
</body>
</html>