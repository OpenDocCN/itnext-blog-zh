# 如何用 plain native Node.js 解包 JSON 文件

> 原文：<https://itnext.io/how-to-untar-json-files-with-plain-native-node-js-2536565707c9?source=collection_archive---------2----------------------->

解压缩，分裂和解析 tarball 的内容，没有流，缓冲区，io 或依赖。

![](img/14f6723713c65624f66a9469822816dd.png)

[https://dribbble . com/shots/6506572-Node-js-解压-文章-封面-插图](https://dribbble.com/shots/6506572-Node-js-Decompression-Article-Cover-Artwork?utm_source=Clipboard_Shot&utm_campaign=szanata&utm_content=Node.js%20Decompression%20-%20Article%20Cover%20Artwork&utm_medium=Social_Share)

我们的故事从一些 AWS Lambda 和 S3 铲斗之间的集成开始。这个桶将接收 JSON 文件，该事件将触发一个 lambda 来处理该输入。问题？那些 JSONs 是真的 tarballs。

那交易是什么？

处理 tarballs 总是很糟糕，我讨厌必须创建流，我讨厌添加大量外部依赖来完成一个简单的任务，因为我们在一个具有受控 IO 的 Lambda 中，一个 simple 不能调用`tar`并将任务委托给操作系统。你几乎注定要使用数百个 **npm** 库中的一个，这些库最终会完成工作，但也会给你的 lambda 足迹增加 **10k** 行代码。还是你？

如果你和我一样，经常使用 AWS Lambdas，你就会知道部署一个小的源代码有多好，不仅可以使部署变得更快，还可以更容易地从 AWS 加载 web UI，以便在需要时实时编辑/调试代码。

客观地说，最紧凑的 lib to *untar* 文件会给我的 lambda 增加 5k 行代码，而我的实际代码只有不到 50 行。这是一个巨大的差异。

考虑到这一点，我激励自己实现自己的本机超紧凑解决方案，这有多难呢？

首先，我花了一些时间去理解什么是 tarball ( `.tar.gz`)文件。它实际上非常简单:将一堆文件打包成一个大文件，然后压缩成 gzip。发现这一点后，我能够追踪我的使命:

1.  解压文件。
2.  把他们分开。
3.  将它们解析为 JSON。

# 1.解压文件。

这一部分实际上非常简单，只需一行代码:

这是因为 node 已经打包了`zlib`，它可以进行压缩/解压、充气/放气等操作。简单的东西。

# 2.把他们分开

现在挑战开始了。tarball 将原始文件的内容捆绑在同一个文件中，仅由一些控制字符和原始文件的元信息分隔。

它们看起来像这样(*解压成一个字符串*):

正如你所看到的，在每个文件内容之间有许多许多控制字符和一些元信息，如用户名**、**权限**、原始**文件名**等。认识到这一点后，我只需找到一个在每个文件内容之间只重复一次的字符序列，就可以将这些文件分开。**

**经过仔细观察，我发现了`\0ustar`序列，它总是在用户名元信息之前。答对了。**

**我们只需确保在将内容拆分成数组后忽略第一个位置(因为在第一个`\0ustar`之前没有内容)。**

# **3.将它们解析为 JSON**

**现在，我们将文件的内容放在一个数组中，但是内容本身的前面和后面仍然是控制字符和元信息，我们必须在转换为 JSON 之前对它们进行修整。**

****这是该解决方案开始被定制为仅处理 JSON 文件的地方。**我们可以反过来，只检查第一次和最后一次出现的`{}`或`[]`，每个 JSON 内容总是以它们开始，而不是试图制作字符在内容前后如何呈现的模式，并创建一些可怕的正则表达式来修整它们。**

**split + trim 代码如下所示:**

**请注意。如果您的。indexOf 返回-1。**

****注意** : *为什么使用*`*.indexOf*`*`*.lastIndexOf*`*并且必须同时测试* `*{}*` *和* `*[]*` *时一个简单的 RegExp 会做同样的事情吗？* ***性能*** *。这段代码的第一个版本使用的是 RegExps，它执行得并不好，这个代码块执行起来花费了很多时间，在某些情况下甚至危及了整个过程。当我切换到普通的字符串方法时，它开始运行良好。****

***根据修剪后剩下的内容，我们只需要调用`JSON.parse`和 voilà。***

***完整的代码如下所示:***

# ***一些笔记***

***这是一个很小的代码，用来接收一个压缩的 tarball(gzip)内容，将其解压缩并解析为 JSON。然而，这并不是一个适用于所有情况的好办法，我想指出的是:***

1.  ***它处理内存中的一切，这在我的情况下不是问题，因为我知道有效负载的大小，即使我在 lambda 中，我也确信它永远不会使用所有的 RAM。但是你必须记住这一点。***
2.  ***它是原子的，所以它不处理无效的 JSONs 或其他错误。同样，对于我的场景来说，这并不重要，但也许代码需要更有弹性来处理不可靠的输入。***
3.  ***如果由于某种原因，JSON 开始/结束字符(`{,},[,]`)出现在内容之前，这个方法**将失败**。*虽然这不太可能发生，因为最容易包含这些字符的序列是文件名，它位于内容之后，因为我们的拆分方式。****

***尽情享受吧！***