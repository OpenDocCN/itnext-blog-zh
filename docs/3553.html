<html>
<head>
<title>5 patterns to make your microservice fault-tolerant</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5种模式让您的微服务具有容错能力</h1>
<blockquote>原文：<a href="https://itnext.io/5-patterns-to-make-your-microservice-fault-tolerant-f3a1c73547b3?source=collection_archive---------0-----------------------#2020-01-08">https://itnext.io/5-patterns-to-make-your-microservice-fault-tolerant-f3a1c73547b3?source=collection_archive---------0-----------------------#2020-01-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/edc04ebffaa7e07ca9c15e0911669283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79TNR1YkcKzehlGf3e_STQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">在<a class="ae kc" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kc" href="https://unsplash.com/@veverkolog?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Duan Smetana</a>拍摄的照片</figcaption></figure><p id="e1bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将介绍微服务中的容错以及如何实现它。如果你在维基百科上查找，你会发现下面的定义:</p><blockquote class="lb lc ld"><p id="c08f" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><strong class="kf ir">容错</strong>是一种使系统在其某些组件出现故障的情况下能够继续正常运行的属性。</p></blockquote><p id="4708" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对我们来说，<em class="le">一个组件</em>意味着任何东西:微服务、数据库(DB)、负载平衡器(LB)，你能想到的。我不会讨论DB/LB容错机制，因为它们是特定于供应商的，启用它们最终会设置一些属性或更改部署策略。</p><p id="5eb8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为一名软件工程师，<strong class="kf ir">应用程序是我们拥有所有权力和责任的地方</strong>，所以让我们来照顾它。以下是我将要介绍的模式列表:</p><ul class=""><li id="4765" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated">超时设定</li><li id="165b" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">重试次数</li><li id="307b" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">断路器</li><li id="a155" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">最后期限</li><li id="c5e4" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">限速器</li></ul><p id="7e29" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有些模式广为人知，你甚至怀疑它们是否值得一提，但是请坚持这篇文章——我将简要介绍基本的形式，然后<strong class="kf ir">讨论它们的缺陷以及如何克服它们。</strong></p><h1 id="9f19" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">超时设定</h1><p id="2257" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">超时是一段指定的时间，允许等待某个事件发生。如果您使用SO_TIMEOUT(也称为套接字超时或读取超时)会有一个问题，它表示任何两个连续数据包之间的超时，而不是整个响应的超时，因此更难实施SLA，特别是当响应负载很大时。<strong class="kf ir">您通常想要的是超时，它涵盖了从建立连接到响应的最后一个字节的整个交互。</strong> SLA通常用这样的超时来描述，因为它们对我们来说是人道和自然的。遗憾的是，它们不符合SO_TIMEOUT哲学。要在JVM世界中克服它，你可以使用<a class="ae kc" href="https://docs.oracle.com/en/java/javase/11/docs/api/java.net.http/java/net/http/HttpClient.html" rel="noopener ugc nofollow" target="_blank"> JDK11 </a>或<a class="ae kc" href="https://square.github.io/okhttp/" rel="noopener ugc nofollow" target="_blank"> OkHttp </a>客户端。Go在std库中也有一个机制。</p><p id="c68e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想深入研究—查看我以前的<a class="ae kc" rel="noopener ugc nofollow" target="_blank" href="/why-i-like-go-http-client-as-a-java-developer-676ea1e698b4">文章</a>。</p><h1 id="160c" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">重试次数</h1><p id="9221" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">如果您的请求失败，请稍等片刻，然后重试。基本上就是这样，重试是有意义的，因为网络可能会降级一会儿，或者GC命中您的请求到达的特定实例。现在，想象一下这样的微服务链:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/a8deb3b3d89aa7d5ccfd9d894a6f0cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLzPABNtUIos5uqcOobxWw.png"/></div></div></figure><p id="3320" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们将每次服务的总尝试次数设置为3，而服务D突然开始服务100%的错误，会发生什么？这将导致重试风暴——链中的每个服务都开始重试它们的请求，因此大大增加了总负载，<strong class="kf ir">因此B将面临3倍的负载，C — 9x和D — 27x！</strong>冗余是实现高可用性的关键原则之一，但我怀疑在这种情况下集群C和D上是否有足够的空闲容量。将总尝试次数设置为2也没有多大帮助，此外，它还会使用户体验变差。</p><p id="d60e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解决方案:</p><ul class=""><li id="8368" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated">区分可重试错误和不可重试错误。当用户没有权限或者有效负载没有正确构造时，重试请求是没有意义的。相反，<strong class="kf ir">重试请求超时或5xx是好的。</strong></li><li id="ad8c" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">采用错误预算技术，如果可重试的错误率超过阈值，当<strong class="kf ir">停止重试时，例如，如果与服务D的20%的交互导致错误，则停止重试并尝试适度降级。可以使用滚动窗口跟踪过去N秒内的错误数量。</strong></li></ul><h1 id="313f" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">断路器</h1><p id="0999" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">断路器可以解释为错误预算的更严格版本——当错误率太高时，功能将根本不会执行，并将返回回退结果(如果提供的话)。为了了解第三方是否恢复，无论如何都应该执行很小一部分请求。<strong class="kf ir">我们想要的是给第三方一个恢复的机会，不需要做任何手动工作。</strong></p><p id="fdb5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能会说，如果功能在关键路径上，启用断路器是没有意义的，但请记住，这种短暂的受控“断电”可能会防止大的不可控断电。</p><p id="e908" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然断路器和错误预算有相似的想法，但配置它们是有意义的。由于错误预算的破坏性较小，其阈值必须更小。</p><p id="7e70" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很长一段时间以来，Hystrix 都是JVM中的首选断路器实现。目前进入<a class="ae kc" href="https://github.com/Netflix/Hystrix#hystrix-status" rel="noopener ugc nofollow" target="_blank">维护模式</a>，建议改用<a class="ae kc" href="https://github.com/resilience4j/resilience4j" rel="noopener ugc nofollow" target="_blank"> resilience4j </a>。</p><h1 id="5974" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">截止日期/分布式超时</h1><p id="a707" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">我们已经在本文的第一部分讨论了超时，现在让我们看看如何使它们“分布式”。首先，重新访问相互调用的同一服务链:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/dbc356c714d7e12fe7ecce4711d7add6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_Gd5oRbDCnoRvH1kzSPtw.png"/></div></div></figure><p id="4c2f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">服务A愿意等待最多400毫秒，并且请求需要所有3个下游服务完成一些工作。假设服务B用了400 ms，现在准备调用服务c，这合理吗？不要！服务超时，不再等待结果。继续前进只会浪费资源并增加重试风暴的可能性。</p><p id="3f23" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要实现它，我们必须向请求添加额外的元数据，这将有助于理解何时中断处理是合理的。理想情况下，这应该得到所有参与者的支持，并在整个系统中传播。</p><p id="c869" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实际上，该元数据是以下之一:</p><ul class=""><li id="d488" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated"><strong class="kf ir">时间戳</strong>:服务停止等待响应的时间点。首先，网关/前端服务将截止时间设置为'<em class="le">当前时间戳+超时'。</em>接下来，任何下游服务都应该检查当前时间戳是否≥截止日期。如果答案是肯定的，那么关闭它是安全的，否则—开始处理。不幸的是，<a class="ae kc" href="https://en.wikipedia.org/wiki/Clock_skew" rel="noopener ugc nofollow" target="_blank">时钟偏移</a>有一个问题，机器可以有不同的时钟时间。如果发生这种情况，请求将被阻塞或/和立即被拒绝，从而导致停机。</li><li id="4a0d" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated"><strong class="kf ir">超时</strong>:超过服务允许等待的时间。这实现起来有点棘手。和以前一样，你尽快设定最后期限。接下来，任何下游服务应该计算它花费了多少时间，从入站超时中减去它，并传递给下一个参与者。不要忘记排队等候的时间，这一点至关重要！因此，如果服务A被允许等待400毫秒，而服务B花费了150毫秒，则在调用服务c时，它必须附加250毫秒的截止时间超时。虽然它不计算花费在线路上的时间，但截止时间只能稍后触发，而不能提前触发，因此，可能会消耗稍多的资源，但不会破坏结果。在GRPC，截止日期就是这样执行的。</li></ul><p id="4c57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后要讨论的是——当超过截止时间时，不中断呼叫链有意义吗？答案是肯定的，<strong class="kf ir">如果您的服务有足够的空闲容量，并且完成请求会使它变得更热(缓存/JIT)，那么继续处理是没问题的。</strong></p><h1 id="ff8f" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">限速器</h1><p id="1f56" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">前面讨论的模式主要解决级联故障的问题——依赖的服务在其依赖关系崩溃后崩溃，最终导致完全关闭的情况。现在，让我们来看看服务过载时的情况。有很多技术和特定领域的原因可能会发生，只要假设它发生了。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/d8988f975cb737240e621211569947cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3jL9q0luHheQs-d-bucbCQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">Joshua Hoehne 在<a class="ae kc" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="49bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个应用程序都有其未知的容量。<strong class="kf ir">这个值是动态的，依赖于多个变量</strong>——比如最近的代码变化、当前运行的CPU应用的型号、主机的繁忙程度等。</p><p id="af63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当负载超过容量时会发生什么？通常，这种恶性循环会发生:</p><ol class=""><li id="f74b" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ng lo lp lq bi translated">响应时间增长，GC占用空间增加</li><li id="c82b" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ng lo lp lq bi translated">客户端获得更多超时，甚至更多负载到达</li><li id="5195" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ng lo lp lq bi translated">转到1，但更严重</li></ol><p id="7254" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个可能发生的例子。当然，如果客户有错误的预算/断路器，第二项可能不会产生额外的负载，从而给一个机会离开这个循环。可能会发生其他事情——从LB的上游列表中删除实例可能会在load和shut邻居实例中产生更多的不平等，等等。</p><p id="687b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">救援的限制者！他们的想法是优雅地卸掉传入的负载。理想情况下，过量负载应该这样处理:</p><ol class=""><li id="3233" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ng lo lp lq bi translated"><strong class="kf ir">限制器丢弃超出容量的额外负载，从而让应用服务符合SLA的请求</strong></li><li id="8459" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ng lo lp lq bi translated">过多的负载重新分配给其他实例/群集自动扩展/群集由人工扩展</li></ol><p id="c616" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有两种类型的限制——速率和并发性，前者限制入站RPS，后者限制任何时刻处理的请求数量。</p><p id="2e6b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简单起见，我将做一个<strong class="kf ir">假设，对我们服务的所有请求在计算成本上几乎相等，并且具有相同的重要性。</strong>计算不平等源于这样一个事实，即不同的用户可能有不同数量的数据与之相关联，例如最喜欢的电视连续剧或以前的订单。通常，采用分页有助于实现请求的计算平等。</p><p id="338b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">速率限制器被更广泛地使用，但是不像并发限制那样提供强有力的保证，所以如果你想选择一个，坚持使用并发限制，原因如下。</p><p id="57a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在配置速率限制器时，我们认为我们应实施以下措施:</p><blockquote class="lb lc ld"><p id="2322" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">该服务在任何时间点每秒可以处理N个请求。</p></blockquote><p id="a94b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们实际上宣布的是:</p><blockquote class="lb lc ld"><p id="15a1" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><strong class="kf ir">假设响应时间不变，</strong>该服务在任何时间点每秒可以处理N个请求。</p></blockquote><p id="955f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为什么这句话很重要？我会用直觉‘证明’它。对于那些希望得到基于数学的证明的人来说——看看<a class="ae kc" href="https://en.wikipedia.org/wiki/Little%27s_law" rel="noopener ugc nofollow" target="_blank">利特尔定律</a>。假设速率限制为1000 RPS，响应时间为1000ms，SLA为1200ms，在给定的SLA下，我们可以轻松地在一秒钟内满足1000个请求。</p><p id="b35b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，响应时间增加了50毫秒(依赖服务开始做额外的工作)。从现在起，每秒钟服务将同时面对越来越多的请求，因为到达率大于服务率。拥有无限数量的工作线程意味着<strong class="kf ir">您将耗尽资源并崩溃，尤其是在工作线程与操作系统线程1:1映射的环境中</strong>。1000个工作人员的并发限制将如何处理它？它将可靠地提供1000/1.05 = ~950 RPS而不违反SLA，并丢弃其余的。此外，不需要重新配置来赶上！</p><p id="89e3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每当依赖性改变时，我们可以更新速率限制，但是这是非常大负担，潜在地需要在每次改变时重新配置整个生态系统。</p><p id="d49b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据如何设置限制值，它是静态或动态限制器。</p><h2 id="ed31" class="nh lx iq bd ly ni nj dn mc nk nl dp mg ko nm nn mk ks no np mo kw nq nr ms ns bi translated">静态</h2><p id="df86" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">在这种情况下，限制是手动配置的。价值可以通过定期的性能测试来评估。虽然，它不会100%准确，但为了安全，它可以被模拟。<strong class="kf ir">这种类型的限制要求在CI/CD管道周围工作，且资源利用率较低。</strong>静态限制器可以通过限制工作线程池的大小(仅限并发)、添加计数请求的入站过滤器、<a class="ae kc" href="https://docs.nginx.com/nginx/admin-guide/security-controls/controlling-access-proxied-http/" rel="noopener ugc nofollow" target="_blank"> NGINX限制功能</a>或<a class="ae kc" href="https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/cluster/circuit_breaker.proto.html" rel="noopener ugc nofollow" target="_blank"> envoy sidecar代理</a>来实现。</p><h2 id="f324" class="nh lx iq bd ly ni nj dn mc nk nl dp mg ko nm nn mk ks no np mo kw nq nr ms ns bi translated">动态的</h2><p id="93e2" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">这里，限制取决于指标，该指标会定期重新计算。<strong class="kf ir">您的服务过载和响应时间增长之间很有可能存在关联。</strong>如果是这样，指标可以是响应时间的统计函数，例如百分位数、中间值或平均值。还记得计算等式属性吗？这个特性是更精确计算的关键。</p><p id="ec4f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，定义一个谓词来回答指标是否健康。例如，p99 ≥ 500ms被视为不健康，因此应降低限值。如何增加和减少限制应由应用反馈控制算法决定，如<a class="ae kc" href="https://en.wikipedia.org/wiki/Additive_increase/multiplicative_decrease" rel="noopener ugc nofollow" target="_blank"> AIMD </a>(用于TCP协议)。下面是它的伪代码:</p><pre class="na nb nc nd gt nt nu nv nw aw nx bi"><span id="322a" class="nh lx iq nu b gy ny nz l oa ob">if healthy {<br/>    limit = limit + increase;<br/>} else {<br/>    limit = limit * decreaseRatio; // 0 &lt; decreaseRatio &lt; 1.0<br/>}</span></pre><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/f1ab4e26091ab0745491389c30af3c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*59j2XNxrJg4IElYxVHdPsg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">AIMD在行动</figcaption></figure><p id="24b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所见，限制增长缓慢，探测应用程序是否运行良好，如果发现错误行为，则急剧下降。</p><p id="9ae5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">网飞开创了动态限制的理念，并开源了他们的解决方案，这里是<a class="ae kc" href="https://github.com/Netflix/concurrency-limits" rel="noopener ugc nofollow" target="_blank">回购</a>。它实现了几个反馈算法，静态限制器的实现，GRPC集成和Java servlet集成。</p></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><p id="8a34" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哼，就这样！我希望你今天学到了新的有用的东西。我想指出的是<strong class="kf ir">这个列表并不详尽，你可能还想获得良好的可观察性</strong>，因为一些意想不到的事情可能会发生，最好了解你的应用程序目前正在发生什么。然而，实施这些将会解决你当前或潜在的大量问题。</p><h2 id="9631" class="nh lx iq bd ly ni nj dn mc nk nl dp mg ko nm nn mk ks no np mo kw nq nr ms ns bi translated">参考</h2><ul class=""><li id="29e0" class="li lj iq kf b kg mu kk mv ko ok ks ol kw om la ln lo lp lq bi translated"><a class="ae kc" href="https://landing.google.com/sre/sre-book/toc/index.html" rel="noopener ugc nofollow" target="_blank">谷歌SRE图书</a>，尤其是章节<a class="ae kc" href="https://landing.google.com/sre/sre-book/chapters/addressing-cascading-failures/" rel="noopener ugc nofollow" target="_blank">解决级联故障</a>和<a class="ae kc" href="https://landing.google.com/sre/sre-book/chapters/handling-overload/" rel="noopener ugc nofollow" target="_blank">处理过载</a></li><li id="dd5d" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated"><a class="ae kc" href="https://medium.com/@NetflixTechBlog/performance-under-load-3e6fa9a60581" rel="noopener">网飞关于动态限制的文章</a></li></ul></div></div>    
</body>
</html>