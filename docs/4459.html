<html>
<head>
<title>Machine Learning Model Serving Options</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习模型服务选项</h1>
<blockquote>原文：<a href="https://itnext.io/machine-learning-model-serving-options-1edf790d917?source=collection_archive---------0-----------------------#2020-07-05">https://itnext.io/machine-learning-model-serving-options-1edf790d917?source=collection_archive---------0-----------------------#2020-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="93f0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">快速的谷歌搜索将返回大量关于开始使用<strong class="jz iu">机器学习</strong>的文章和文献，不幸的是，大多数文献涵盖模型培训，而没有多少文章涵盖<strong class="jz iu">如何在生产中服务于ML模型</strong>，当他们这样做时，他们往往专注于单一的方法。在本文中，我将尝试向<strong class="jz iu">概述生产环境中模型推理的不同选项——考虑不同的因素</strong>,如团队规模/结构、推理模式(RPC vs流)、部署类型(云vs内部)和其他方面。</p><h1 id="f6e2" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">介绍</h1><p id="8af9" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">人工智能和机器学习是一个热门话题，越来越多的人正在进入这个有很大潜力的领域，它仍然处于早期发展阶段，我相信在未来的几十年里我们会不断听到人工智能的更多突破。</p><p id="87e8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">传统上，这是一个保留给学者的领域，他们拥有开发复杂的ML模型的数学技能，但缺乏生产这些模型所需的软件工程技能。另一方面，托管服务和其他框架在过去几年中已经出现，专注于简化ML开发；允许没有科学博士学位的软件开发人员创建ML模型。然而，模型的定制化水平和性能往往低于拥有专门的数据科学家团队时的水平。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/058579efc23ea805a6e546ae95906293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X9p5EGSdLRGbYf1D"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">ML工作流程</figcaption></figure><h1 id="48d3" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">考虑</h1><h2 id="bf52" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">团队结构</h2><p id="58ed" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">根据你的需求，你可能需要不同的团队结构。如果您不需要对您的模型进行细粒度的控制，并且使用标准的分类/回归模型，您可能更喜欢利用您现有的软件工程师进行ML，特别是在以下场景中:</p><ul class=""><li id="1b1e" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated">你用托管云ML服务比如<a class="ae nj" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> AWS SageMaker </strong> </a>或者<a class="ae nj" href="https://cloud.google.com/ai-platform/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> GCP AI平台</strong> </a>。</li><li id="49ec" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">您需要丰富您的数据管道，并且您已经使用了<a class="ae nj" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Spark </strong> </a>等工具。在这种情况下，您可以使用现有的库，如<a class="ae nj" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu">【SparkML】</strong></a>。</li></ul><p id="31c0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这种方法<strong class="jz iu">易于实施</strong>并且提供了出色的结果，但是您会受到提供商能力的限制。此外，它可能会变得昂贵。</p><p id="f5a4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">另一方面，如果你需要前沿的AI、高级的ML调优和对你的模型的完全控制(你是一家AI公司)，那么你可能希望有一个<strong class="jz iu">专门的科学团队</strong>。这种方法让您可以完全控制您的模型，并有创新的空间，因为大多数竞争对手将使用云提供商的标准工具。然而，这造成了工程和科学团队之间的孤岛，使其非常难以管理。我们稍后将讨论解决这个问题的不同方法(<em class="np">模型作为数据</em>)。</p><h2 id="d29a" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">推理类型(<a class="ae nj" href="https://www.datasciencecentral.com/profiles/blogs/model-serving-stream-processing-vs-rpc-rest-a-deep-learning" rel="noopener ugc nofollow" target="_blank">在线vs流</a>)</h2><p id="8f63" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">一个重要的考虑是你计划如何为你的模型服务。最简单的选择是在线RPC风格的代码。在这种情况下，您的模型作为服务运行(通常是<em class="np">和HTTP微服务</em>)，您向它发送请求并得到响应。在这种情况下，<strong class="jz iu">托管解决方案极大地简化了模型的部署</strong>和监控。</p><p id="c887" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">另一个，也可能是最常见的用例是<strong class="jz iu">用ML模型丰富数据管道</strong>，例如在<a class="ae nj" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> NLP </strong> </a>管道中向非结构化数据添加<em class="np">结构</em>。这可以在<strong class="jz iu">批次</strong>或<strong class="jz iu">实时</strong>中完成。对于批量，可以使用<a class="ae nj" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank"> SparkML </a>等工具。对于流，我们将回顾不同的选项，这将是我们的主要关注点，因为流处理更加复杂和有趣。尤其是因为您需要维护模型的某个状态，所以您需要使用有状态流。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nq"><img src="../Images/cf177927eb3f0ebd2bf07d355234355c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S__TlgVCqJpRkozb.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">流处理</figcaption></figure><h2 id="787a" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">托管解决方案</h2><p id="92b3" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">你在哪里提供服务？本地还是云？。如果你在<strong class="jz iu">云</strong>上运行，你有几个服务(比如<a class="ae nj" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> AWS SageMaker </strong> </a>或者<a class="ae nj" href="https://cloud.google.com/ai-platform/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> GCP人工智能平台</strong> </a>)负责模型服务方面以及监控方面，使之变得简单很多<strong class="jz iu"/>。如果您在内部运行<strong class="jz iu"/>，您将需要使用<a class="ae nj" href="https://www.seldon.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Seldon </strong> </a>等企业解决方案，或者使用<strong class="jz iu"> Spark </strong>等数据管道。然而，这需要<strong class="jz iu">更多的努力</strong>。</p><h2 id="270f" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">模型服务类型</h2><p id="0bb7" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">这一点非常重要。部署训练好的模型的最常见方法是保存为您选择的工具的二进制格式，将其包装在微服务(例如Python Flask应用程序)中，并使用它进行推理。托管解决方案简化了这一部署流程，并提供了执行canary发布和A/B测试的工具，这种方法被称为代码为的<strong class="jz iu">模型。然而，这种方法有几个<strong class="jz iu">缺点</strong>，随着模型数量的增长，微服务的数量会成倍增加，故障点、延迟等的数量也会成倍增加。这使得管理变得非常困难。</strong></p><p id="eee8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">另一个更新的方法是<strong class="jz iu">标准化model </strong>格式，以便可以使用任何编程语言以编程方式使用它，这样您就不必将其包装在微服务中。这对于延迟和错误管理是个问题的数据处理流特别有用。因为我们直接调用模型，所以我们不必担心监控、错误处理等等。这种方法被称为数据的<strong class="jz iu">模型。</strong></p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/2191cfa23d0620c67c1ec5fd0272507c.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/0*OAW7i3woxxxQ8uov.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">模型作为数据。</figcaption></figure><p id="b7f8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">现在让我们特别关注数据流和模型服务选项“模型作为代码”和“模型作为数据”。我们不会关注Spark ML等大数据ML功能，尽管我们会在用例部分回到它们。</p><h1 id="a7ec" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">作为代码的模型</h1><p id="e69c" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">这是部署模型最常见的方式，主要是因为数据科学家不是sre，所以他们使用他们的工具集(<em class="np"> Python、R、Jupyter notebooks等)。</em>)来训练模型，利用他们已有的知识，通常是Python来把模型包装在HTTP服务中。这是因为最初没有保存模型的标准。由于软件开发人员对ML一无所知，这个解决方案对他们非常有用，因为他们知道如何调用REST端点。但是<strong class="jz iu">这带来了管理所有交互的复杂性</strong>，使得维护变得非常困难。引入了托管解决方案来缓解这一问题。</p><p id="052c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">专注于模型服务的工具有<a class="ae nj" href="https://www.seldon.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">【谢顿】</strong></a><a class="ae nj" href="https://github.com/ucbrise/clipper" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu">裁剪器</strong> </a>或<a class="ae nj" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">张量流服务</strong> </a>。</p><p id="e8ce" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这种方法的优点是:</p><ul class=""><li id="b4e1" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated"><strong class="jz iu">易于</strong>开发。</li><li id="f48f" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">数据科学家不需要关心生产维护和监控，服务工程师可以管理服务</li><li id="8c6b" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated"><strong class="jz iu">可以自动化</strong>，AWS SageMaker等工具负责部署服务、创建URL、A/B测试等等。一般来说，像<strong class="jz iu"> SageMaker </strong>或<a class="ae nj" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank">T25】kube flow</a>这样的工具会照顾到从训练到得分的所有方面。</li><li id="c53a" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">另一个优点是，我们可以在应用程序中用度量和其他元数据保存模型状态。</li></ul><p id="d21d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">缺点</strong>是:</p><ul class=""><li id="eefe" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated">随着越来越多模型的加入，监控和维护模型的复杂性也在增加。</li><li id="3bc5" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">额外的<strong class="jz iu">延迟</strong>和更多影响可靠性的故障点。</li><li id="8336" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated"><strong class="jz iu">阻抗不匹配</strong>:与软件开发人员相比，数据科学家使用一套不同的工具，如R或Python。</li><li id="8259" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated"><strong class="jz iu">难以更新</strong>型号。这需要SREs使用Kubernetes的功能来完成，使用金丝雀方法推出新版本，但您会失去细粒度控制和细粒度指标，从而很难获得关于您的模型性能的准确和快速的反馈。由于模型是代码，很难更新。</li><li id="70a5" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">很难实现背压和断路器来处理网络故障。这就是为什么很难在托管集群中使用Spark或<a class="ae nj" href="https://flink.apache.org/stateful-functions.html" rel="noopener ugc nofollow" target="_blank"> Flink </a>这样的大数据，它们不能很好地处理阻塞I/O，也是为什么ML库是为这些工具开发的。</li><li id="1e60" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">另一个问题是，很难精确复制在训练阶段获得的结果，因为权重和其他元数据在生产模型中可能不完全相同。</li><li id="d034" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">由于额外的延迟和数据大小，它无法针对大数据流管道进行扩展。</li></ul><p id="d227" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下面是一个关于如何调用外部服务在数据流中进行模型推断的示例:</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="94aa" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如您所见，我们需要引入未来来处理阻塞I/O和处理故障、指数级回退重试、延迟等。因此，一个常见的模式是使用一个<strong class="jz iu">侧柜</strong>来处理所有这些逻辑:度量、重试、断路器等。在Kubernetes中，这可以使用边车容器来完成。</p><p id="8a5d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">一般来说，<strong class="jz iu">流处理管道的目标是避免阻塞I/O </strong>，模型作为代码引入了这一障碍，正因为如此，模型作为数据被引入。</p><h1 id="1bf8" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">模型作为数据</h1><p id="52e1" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">最近的一种方法是将模型标准化为数据，以便可以用任何编程语言读取。目前，<strong class="jz iu"> Tensorflow </strong>已经成为<strong class="jz iu">事实上的</strong>标准，新的<a class="ae nj" href="https://www.tensorflow.org/guide/saved_model" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> SavedModel </strong> </a>格式包含一个完整的Tensorflow程序，包括权重和计算。它不需要运行原始的模型构建代码，这使得它对于共享非常有用。</p><p id="dcad" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">有几个项目试图将模型标准化为数据，<a class="ae nj" href="http://dmg.org/pmml/v4-3/GeneralStructure.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> PMML </strong> </a>是最著名的使用XML表示数据的格式。其他格式有<a class="ae nj" href="https://en.wikipedia.org/wiki/Portable_Format_for_Analytics" rel="noopener ugc nofollow" target="_blank"> PFA </a>和ONNX。</p><p id="5537" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">正如我们之前提到的，大多数机器学习实现都是基于作为REST服务的运行模型，这可能不适合大容量数据处理或流系统的使用，这需要重新编码/启动系统以进行模型更新，例如TensorFlow或Flink。<strong class="jz iu">模型即数据非常适合大数据管道</strong>。对于在线推理，实现起来相当容易，你可以将模型存储在任何地方(S3、HDFS……)，读入内存并调用它。</p><p id="1cc0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">主要问题是我们需要保存模型状态来执行A/B测试或更新元数据。对于流处理，这意味着我们需要<strong class="jz iu">有状态流</strong>。此外，我们需要一种简单的方法来更新模型，而不干扰模型服务。为了克服这一点，一种常见的模式是使用由<strong class="jz iu"> Lightbend </strong>引入的<a class="ae nj" href="https://www.lightbend.com/blog/serve-machine-learning-models-dynamically-controlled-streams" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">动态控制流</strong> </a>。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nu"><img src="../Images/008658741188643e1701c114dd7ff569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zcArJBB8l8yIb0RDDf6cg.png"/></div></div></figure><p id="2a73" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">该解决方案为<strong class="jz iu">有状态流处理</strong>提供了在服务状态改变时动态更新状态<strong class="jz iu">的能力。主流接收数据和对模型的请求，这将丰富数据。辅助流用于接收模型更新。是的，整个模型可以序列化并通过网络发送，模型可以存储在内存中。在这种情况下，模型就是状态。或者，可以从外部来源(如S3)检索模型。</strong></p><p id="e1a3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这个解决方案可以使用有状态的解决方案来实现，例如<a class="ae nj" href="https://doc.akka.io/docs/akka/current/stream/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Akka Streams </strong> </a>，S <a class="ae nj" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> park结构化流</strong> </a>或<a class="ae nj" href="https://flink.apache.org/stateful-functions.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Flink </strong> </a>。现在让我们看一个使用Akka流和Spark流的例子。</p><h2 id="3aa9" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">阿卡溪流</h2><p id="dfa5" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><a class="ae nj" href="https://doc.akka.io/docs/akka/current/stream/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Akka Streams </strong> </a>是为流处理而建的低级库。它为构建任何类型的流处理应用程序提供了极大的灵活性。这是一个类似于<a class="ae nj" href="https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/" rel="noopener ugc nofollow" target="_blank"> Kafka Streams </a>的库，这意味着您拥有完全的控制权，但您必须管理部署，因为它不是Spark或Flink这样的托管集群。这些应用程序可以很容易地在Kubernetes上运行。有关不同流媒体选项的更多信息，请参见<a class="ae nj" href="https://www.lightbend.com/blog/akka-spark-or-kafka-selecting-the-right-streaming-engine-for-the-job" rel="noopener ugc nofollow" target="_blank">本博客</a>。<a class="ae nj" href="https://doc.akka.io/docs/alpakka/current/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Alpakka </strong> </a>可用于连接Kafka或其他信号源。</p><p id="99e9" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">主要思想是有两个Akka流，一个用于数据，另一个用于模型更新。几个模型可以链接或并行运行，您有完全的灵活性。您可以使用Akka <strong class="jz iu"> DSL </strong>来生成复杂的图形，以满足您管理模型间依赖关系的需求。<strong class="jz iu"> Actors </strong>可用于管理状态，例如，您可以为每个模型版本使用一个Actors，从而对A/B测试进行细粒度控制。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nv"><img src="../Images/674fbc76ed8c564eea6fef4593c117e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRW4s4WCuwh85GCgn8WR4g.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">服务于Akka流的模型</figcaption></figure><p id="8cdc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这个想法是使用ask模式调用一个actor，该actor将模型作为其内部状态:<em class="np"> Consumer.atMostOnceSource(..).via(ActorFlow.ask(1)(..)… </em></p><p id="d64f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然后，每个参与者将存储模型，在每个消息上，我们调用模型并返回结果，我们可以调用几个模型来丰富我们的数据管道。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="0801" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这样，我们可以在运行时更新模型，而无需重新部署任何服务。该模型可以实现为包含张量流或PMML二进制数据的类。</p><h2 id="83bf" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">火花结构化流</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nw"><img src="../Images/20a8992727732def38a5ad4b5b222a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WFU5Dk-g0GhaA4RI.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">有状态处理火花。</figcaption></figure><p id="ad2d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">动态控制流也可以在Flink和<a class="ae nj" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark结构化流</a>中实现。在Spark中，您可以使用<em class="np">联合</em>来连接数据流和模型流。然后使用<code class="fe nx ny nz oa b"><a class="ae nj" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#arbitrary-stateful-operations" rel="noopener ugc nofollow" target="_blank">mapGroupsWithState</a></code>对合并流中的数据进行评分。这种方法使用Spark <strong class="jz iu">小型批处理</strong>，这带来了额外的延迟。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="efc4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">另一种更新的方法是使用新的<a class="ae nj" href="https://databricks.com/blog/2018/03/20/low-latency-continuous-processing-mode-in-structured-streaming-in-apache-spark-2-3-0.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">连续</strong>火花流</a>，这使得<strong class="jz iu">实时模型服务</strong>。</p><p id="0118" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><a class="ae nj" href="https://www.lightbend.com/blog/managing-streaming-and-queryable-state-in-spark-akka-streams-kafka-streams-flink" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">可查询状态</strong> </a>可用于管理有状态应用程序的状态，这允许在不使用任何外部数据源的情况下访问整个流的状态，因此我们的模型及其元数据等指标可以使用<a class="ae nj" href="https://kafka.apache.org/10/documentation/streams/developer-guide/interactive-queries.html" rel="noopener ugc nofollow" target="_blank">交互查询</a>从流外部进行查询。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ob"><img src="../Images/fb3deffcee259a47e0f5aa5c87636675.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5ZOr9TVx2qpXoqIQ.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">交互式查询</figcaption></figure><h2 id="9330" class="mo kw it bd kx mp mq dn lb mr ms dp lf ki mt mu lj km mv mw ln kq mx my lr mz bi translated">模型作为数据的利与弊</h2><p id="6414" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><strong class="jz iu">的优点</strong>是:</p><ul class=""><li id="551d" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated">简化的模型管理。</li><li id="2d06" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">模型标准化。</li><li id="7939" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">低延迟。</li><li id="6fa8" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">更易于实施，有多种选择。</li><li id="3cf9" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">有助于沟通，当你有筒仓。</li></ul><p id="4f93" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">的缺点</strong>是:</p><ul class=""><li id="f0f0" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated"><strong class="jz iu">并非所有的ML工具都支持当前的标准格式</strong>。对于某些用例，您还不能使用这种方法。</li><li id="42d6" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">标准化的早期阶段。</li></ul><h1 id="83a4" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">用例</h1><p id="02ed" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">概括地说，让我们通过不同的使用案例来回顾我们的选项:</p><ul class=""><li id="4b3c" class="na nb it jz b ka kb ke kf ki nc km nd kq ne ku nf ng nh ni bi translated">你没有专门的数据科学家团队，你在云中运行你的服务，并希望建立你自己的分类/回归模型供你的服务使用:在这种情况下，使用你的云管理服务，如AWS SageMaker或GCP <a class="ae nj" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank"> Kubeflow </a>。</li><li id="1eb0" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">你需要从图像中检测文本，或者创建一个聊天框，或者翻译文本，或者一般来说，任何高级的ML服务。在这种情况下，使用托管服务；所有云提供商都提供图像识别、文本到语音、翻译、计算机视觉等等。</li><li id="e472" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">您有一个使用Spark、Flink或任何其他托管集群的现有数据管道。您希望使用众所周知的监督或非监督模型来丰富数据。您没有专门的数据科学家团队。在这种情况下，使用已经集成在平台中的<strong class="jz iu"> SparkML </strong>或<strong class="jz iu"> FlinkML </strong>，无论您是在本地运行还是在云中运行，都很容易使用。</li><li id="de2d" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">您有一个专门的数据科学家团队，您在内部运行您的服务。不需要流处理。在这种情况下，使用<a class="ae nj" href="https://www.seldon.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">谢顿</strong> </a>或任何其他模式的发球服务。</li><li id="f32b" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">您没有专门的数据科学家团队，而是在内部运行服务。你以前没有经验。在这种情况下，迁移到云或获得一个数据科学家团队！</li><li id="871e" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">你有一个专门的数据科学家团队，你需要丰富你的数据流管道，你需要节省成本，云解决方案太贵了。在这种情况下，如果可能，使用模型作为代码来使用动态流。一般来说，当你有筒仓时，<strong class="jz iu">数据模型是一个更好的选择。</strong></li><li id="368c" class="na nb it jz b ka nk ke nl ki nm km nn kq no ku nf ng nh ni bi translated">对于数据流，只要你的用例得到<a class="ae nj" href="https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language" rel="noopener ugc nofollow" target="_blank"> PMML </a>或Tensorflow的支持，尽量使用模型作为动态流的数据。如果没有，使用支持反压和重试的Akka流。</li></ul><h1 id="0986" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">结论</h1><p id="63c8" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">我们已经看到了根据您的用例部署您的ML模型的不同选项。可能的话<strong class="jz iu">尝试打破孤岛</strong>让数据科学家和工程师一起工作。<strong class="jz iu">考虑数据量和数据速度</strong>，如果低延迟是你的优先选择<strong class="jz iu">使用Akka流</strong>，如果你有大量的数据使用Spark、Flink或GCP <a class="ae nj" href="https://cloud.google.com/dataflow/" rel="noopener ugc nofollow" target="_blank">数据流</a>。如果您不能打破孤岛，模型作为数据是一个更好的选择。</p><p id="2c2e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">探索和使用您的云提供商人工智能平台</strong>，这将极大地简化您的部署。如果预算很重要，或者如果你是一家人工智能公司，并且你想完全控制你的模型，那么只实现你自己的。</p><p id="2ad4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我真心推荐<a class="ae nj" href="https://www.lightbend.com/ebooks/machine-learning-guide-architecture-stream-processing-frameworks-oreilly" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">这本书</strong> </a>出自<strong class="jz iu"> Lightbend </strong>。也检查这个关于动态流的<a class="ae nj" href="https://www.lightbend.com/blog/serve-machine-learning-models-dynamically-controlled-streams" rel="noopener ugc nofollow" target="_blank">帖子</a>。最重要的是，<strong class="jz iu">不要忽视生产你的模型服务过程</strong>的重要性，这是<strong class="jz iu">极其重要的</strong>。</p></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="05e3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae nj" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu"><em class="np">me</em></strong></a><strong class="jz iu"><em class="np"/></strong><em class="np">进行未来岗位。</em></p></div></div>    
</body>
</html>