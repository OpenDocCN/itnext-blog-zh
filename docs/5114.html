<html>
<head>
<title>Ingest data from Apache Kafka into Azure Cosmos DB Cassandra API using Kafka Connect</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kafka Connect将数据从Apache Kafka导入Azure Cosmos DB Cassandra API</h1>
<blockquote>原文：<a href="https://itnext.io/ingest-data-from-apache-kafka-into-azure-cosmos-db-cassandra-api-using-kafka-connect-11e054f82a05?source=collection_archive---------5-----------------------#2020-12-14">https://itnext.io/ingest-data-from-apache-kafka-into-azure-cosmos-db-cassandra-api-using-kafka-connect-11e054f82a05?source=collection_archive---------5-----------------------#2020-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a890" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本教程基于一个实际场景，以及一个可重用的Docker Compose设置，有助于迭代开发和实验</h2></div><p id="b929" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Azure Cosmos DB Cassandra API 是一个完全托管的云服务，兼容Cassandra查询语言(CQL)3.11 API。它没有运营开销，您可以从所有底层<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/introduction?WT.mc_id=data-11341-abhishgu#key-benefits" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB功能</a>中受益，如全球分发、自动横向扩展分区、可用性和延迟保证、静态加密、备份等。</p><p id="9140" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lc">在写这篇博客的时候，</em><a class="ae lb" href="https://devblogs.microsoft.com/cosmosdb/azure-cosmos-db-cassandra-api-serverless-now-in-preview/" rel="noopener ugc nofollow" target="_blank"><em class="lc">Azure Cosmos DB Cassandra API server less在预览模式</em> </a> <em class="lc">！</em></p><p id="b1bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您现有的Cassandra应用程序可以与<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/cassandra-introduction?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank">Azure Cosmos DB Cassandra API</a>一起工作，因为它与<a class="ae lb" href="https://cassandra.apache.org/doc/latest/getting_started/drivers.html?highlight=driver" rel="noopener ugc nofollow" target="_blank"> CQLv4兼容的驱动程序</a>一起工作(参见<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-java-v4?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank"> Java </a>、<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-dotnet-core?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank">的示例)。Net Core </a>、<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-nodejs?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank"> Node.js </a>、<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-python?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank"> Python </a>等。)但是，你还需要考虑用现有数据与其他系统集成，并将其引入Azure Cosmos DB。一个这样的系统是Apache Kafka，这是一个分布式流媒体平台。它在行业和组织中用于解决各种各样的问题，从传统的异步消息传递、网站活动跟踪、日志聚合、实时欺诈检测等等！它拥有丰富的技术生态系统，如用于流处理的<a class="ae lb" href="https://kafka.apache.org/26/documentation/streams" rel="noopener ugc nofollow" target="_blank"> Kafka Streams </a>和用于实时数据集成的<a class="ae lb" href="https://kafka.apache.org/documentation/#connect" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>。</p><p id="02a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于其<a class="ae lb" href="https://kafka.apache.org/documentation/#design" rel="noopener ugc nofollow" target="_blank">可扩展的设计</a>，Apache Kafka经常充当整个数据架构的核心组件，其他系统将数据注入其中。这些可以是点击流事件、日志、传感器数据、订单、数据库变化事件等。你说吧！因此，可以想象，Apache Kafka(主题)中有很多数据，但只有在被其他系统消费或吸收时才有用。你可以通过使用<a class="ae lb" href="https://kafka.apache.org/documentation/#api" rel="noopener ugc nofollow" target="_blank"> Kafka生产者/消费者</a>API<a class="ae lb" href="https://cwiki.apache.org/confluence/display/KAFKA/Clients" rel="noopener ugc nofollow" target="_blank">使用你选择的语言和客户端SDK</a>编写优秀的老管道代码来实现这一点。但是你可以做得更好！</p><p id="a211" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博文展示了如何使用开源解决方案(基于连接器)将Kafka的数据接收到Azure Cosmos DB Cassandra API中。它使用一个简单而实用的场景，以及一个使用Docker Compose的可重用设置来帮助迭代开发和测试。您将了解到:</p><ul class=""><li id="3bfc" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">Kafka Connect概述以及集成的详细信息</li><li id="7259" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">如何配置和使用连接器来使用Azure Cosmos DB</li><li id="9bf3" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">使用连接器将数据从单个Kafka主题写入多个表</li></ul><p id="2c39" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博客结束时，你应该有一个端到端的集成，并能够验证它。</p><p id="e93b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与这篇博文相关的代码和配置可以在这个GitHub资源库中找到—<a class="ae lb" href="https://github.com/abhirockzz/kafka-cosmosdb-cassandra" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kafka-cosmosdb-cassandra</a></p><h1 id="8943" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">你好，卡夫卡连线！</h1><p id="043f" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">Kafka Connect是一个平台，以可伸缩和可靠的方式在Apache Kafka和其他系统之间传输数据流。除了它只依赖于Kafka这一事实之外，它的伟大之处在于它提供了一套现成的连接器。这意味着您不需要编写定制的集成代码来将系统粘合在一起；没有代码，只有配置！如果现有的连接器不可用，您可以利用强大的Kafka Connect框架来构建自己的连接器。</p><p id="87aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Kafka Connect提供两大类连接器:</p><ul class=""><li id="f01e" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">源连接器:它用于从外部系统提取数据，并将其发送到Apache Kafka。</li><li id="b1b3" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">接收器连接器:它用于将Apache Kafka中的现有数据发送到外部系统。</li></ul><p id="cda6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博文中，我们将使用开源的<a class="ae lb" href="https://docs.datastax.com/en/kafka/doc/kafka/kafkaIntro.html" rel="noopener ugc nofollow" target="_blank"> DataStax Apache Kafka连接器</a>，这是一个基于Kafka Connect框架的接收连接器，用于将Kafka主题中的记录接收到一个或多个Cassandra表的行中。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="213c" class="lr ls iq bd lt lu mv lw lx ly mw ma mb jw mx jx md jz my ka mf kc mz kd mh mi bi translated">解决方案概述</h1><p id="e99f" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在高层次上，解决方案相当简单！尽管如此，图表应该是有帮助的。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi na"><img src="../Images/ab91d7741f886597dc3ef508d210fdae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CxnXIvJLO-cEr0Dg.png"/></div></div></figure><p id="20af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">样本天气数据不断生成到一个卡夫卡主题中。这由连接器获取并发送到Azure Cosmos DB，并且可以使用任何Cassandra客户端驱动程序进行查询。</p><p id="7b8f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了Azure Cosmos DB，解决方案的其余组件作为<a class="ae lb" href="https://docs.docker.com/get-started/overview/" rel="noopener ugc nofollow" target="_blank"> Docker </a>容器运行(使用<a class="ae lb" href="https://docs.docker.com/compose/reference/overview/" rel="noopener ugc nofollow" target="_blank"> Docker Compose </a>)。这包括Kafka(和Zookeeper)、Kafka Connect worker(Cassandra连接器)以及样本数据生成器(<a class="ae lb" href="https://golang.org/" rel="noopener ugc nofollow" target="_blank"> Go </a>)应用程序。话虽如此，只要所有组件都配置为根据需要相互访问和通信，这些指令将适用于任何Kafka集群和Kafka Connect workers。例如，你可以在Azure HD Insight上拥有Kafka集群，在Azure Marketplace上拥有融合云。</p><h2 id="64f5" class="nm ls iq bd lt nn no dn lx np nq dp mb ko nr ns md ks nt nu mf kw nv nw mh nx bi translated">Docker编写服务</h2><p id="3fa9" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">下面是组件及其服务定义的分类——你可以参考GitHub repo 中完整的docker-compose文件<a class="ae lb" href="https://github.com/abhirockzz/kafka-cosmosdb-cassandra/blob/master/docker-compose.yaml" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="429e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://hub.docker.com/r/debezium/kafka/" rel="noopener ugc nofollow" target="_blank"> debezium </a>图像用于运行Kafka和Zookeeper。它们只是工作，而且对于快速反馈循环、演示等迭代开发非常有用。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="6b78" class="nm ls iq nz b gy od oe l of og">zookeeper:<br/>    image: debezium/zookeeper:1.2<br/>    ports:<br/>      - 2181:2181<br/>  kafka:<br/>    image: debezium/kafka:1.2<br/>    ports:<br/>      - 9092:9092<br/>    links:<br/>      - zookeeper<br/>    depends_on:<br/>      - zookeeper<br/>    environment:<br/>      - ZOOKEEPER_CONNECT=zookeeper:2181<br/>      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092</span></pre><p id="6d3d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了作为Docker容器运行，DataStax Apache Kafka连接器构建在现有的Docker映像之上—<a class="ae lb" href="https://github.com/debezium/docker-images/tree/master/connect-base/1.2" rel="noopener ugc nofollow" target="_blank">debezium/connect-base</a>。这个图像包括Kafka及其Kafka Connect库的安装，因此添加定制连接器非常方便。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="63bf" class="nm ls iq nz b gy od oe l of og">cassandra-connector:<br/>    build:<br/>      context: ./connector<br/>    ports:<br/>      - 8083:8083<br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - BOOTSTRAP_SERVERS=kafka:9092<br/>      - GROUP_ID=cass<br/>      - CONFIG_STORAGE_TOPIC=cass_connect_configs<br/>      - OFFSET_STORAGE_TOPIC=cass_connect_offsets<br/>      - STATUS_STORAGE_TOPIC=cass_connect_statuses</span></pre><p id="a646" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://github.com/abhirockzz/kafka-cosmosdb-cassandra/blob/master/connector/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>相当紧凑。它下载连接器并将其解压缩到文件系统(插件路径)中的适当目录，以便Kafka Connect框架检测它。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="d7f1" class="nm ls iq nz b gy od oe l of og">FROM debezium/connect-base:1.2<br/>WORKDIR $KAFKA_HOME/connect<br/>RUN curl -L -O https://downloads.datastax.com/kafka/kafka-connect-cassandra-sink.tar.gz<br/>RUN tar zxf kafka-connect-cassandra-sink.tar.gz<br/>RUN rm kafka-connect-cassandra-sink.tar.gz</span></pre><p id="57a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，数据生成器服务将随机生成的(JSON)数据植入天气数据Kafka主题。可以参考<a class="ae lb" href="https://github.com/abhirockzz/kafka-cosmosdb-cassandra/blob/master/data-generator/" rel="noopener ugc nofollow" target="_blank">GitHub repo</a>中的代码和Dockerfile</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="7892" class="nm ls iq nz b gy od oe l of og">data-generator:<br/>    build:<br/>      context: ./data-generator<br/>    ports:<br/>      - 8080:8080<br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - KAFKA_BROKER=kafka:9092<br/>      - KAFKA_TOPIC=weather-data</span></pre><p id="61e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们转到实际的方面！继续之前，请确保您已准备好以下内容。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="36a1" class="lr ls iq bd lt lu mv lw lx ly mw ma mb jw mx jx md jz my ka mf kc mz kd mh mi bi translated">先决条件</h1><p id="db4f" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">最后，克隆这个GitHub repo:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="a87d" class="nm ls iq nz b gy od oe l of og">git clone <a class="ae lb" href="https://github.com/abhirockzz/kafka-cosmosdb-cassandra" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kafka-cosmosdb-cassandra</a> <br/>cd kafka-cosmos-cassandra</span></pre><p id="5397" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来的部分将指导您完成:</p><ul class=""><li id="62fc" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">设置Azure Cosmos DB帐户、Cassandra keyspace和表</li><li id="b117" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">引导集成管道</li><li id="e547" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">了解配置并启动连接器实例</li><li id="b96d" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">测试端到端的结果，并对Azure Cosmos DB表中的数据运行查询</li></ul><h2 id="2c7c" class="nm ls iq bd lt nn no dn lx np nq dp mb ko nr ns md ks nt nu mf kw nv nw mh nx bi translated">设置和配置Azure Cosmos DB</h2><p id="8a9e" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">首先创建一个<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-api-account-java?WT.mc_id=devto-blog-abhishgu#create-a-database-account" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB帐户</a>，选择<strong class="kh ir"> Cassandra API </strong>选项</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi oh"><img src="../Images/cebae19f2a7e925bc2a61843fc66423c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A4MouZbgWIN15B9k.png"/></div></div></figure><p id="fe05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Azure门户，创建Cassandra密钥空间和演示应用程序所需的表。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="0e2d" class="nm ls iq nz b gy od oe l of og">CREATE KEYSPACE weather WITH REPLICATION = {'class' : 'NetworkTopologyStrategy', 'datacenter1' : 1};<br/><br/>CREATE TABLE weather.data_by_state (station_id text, temp int, state text, ts timestamp, PRIMARY KEY (state, ts)) WITH CLUSTERING ORDER BY (ts DESC) AND cosmosdb_cell_level_timestamp=true AND cosmosdb_cell_level_timestamp_tombstones=true AND cosmosdb_cell_level_timetolive=true;<br/><br/>CREATE TABLE weather.data_by_station (station_id text, temp int, state text, ts timestamp, PRIMARY KEY (station_id, ts)) WITH CLUSTERING ORDER BY (ts DESC) AND cosmosdb_cell_level_timestamp=true AND cosmosdb_cell_level_timestamp_tombstones=true AND cosmosdb_cell_level_timetolive=true;</span></pre><p id="966a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据库部分到此为止！是时候启动其他组件了。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="3dc4" class="lr ls iq bd lt lu mv lw lx ly mw ma mb jw mx jx md jz my ka mf kc mz kd mh mi bi translated">开始集成管道</h1><p id="414f" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">因为一切都是Docker化的，所以您只需要一个命令就可以在本地引导服务— Kafka、Zookeeper、Kafka Connect worker和示例数据生成器应用程序。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="680e" class="nm ls iq nz b gy od oe l of og">docker-compose --project-name kafka-cosmos-cassandra up --build</span></pre><p id="33e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下载和启动容器可能需要一段时间:这只是一个一次性的过程。</p><p id="39d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要确认是否所有容器都已启动:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="c0fb" class="nm ls iq nz b gy od oe l of og">docker-compose -p kafka-cosmos-cassandra ps<br/><br/><br/>#output<br/><br/>                  Name                                Command             State                    Ports                  <br/>--------------------------------------------------------------------------------------------------------------------------<br/>kafka-cosmos-cassandra_cassandra-           /docker-entrypoint.sh start   Up      0.0.0.0:8083-&gt;8083/tcp, 8778/tcp,       <br/>connector_1                                                                       9092/tcp, 9779/tcp                      <br/>kafka-cosmos-cassandra_datagen_1            /app/orders-gen               Up      0.0.0.0:8080-&gt;8080/tcp                  <br/>kafka-cosmos-cassandra_kafka_1              /docker-entrypoint.sh start   Up      8778/tcp, 0.0.0.0:9092-&gt;9092/tcp,       <br/>                                                                                  9779/tcp                                <br/>kafka-cosmos-cassandra_zookeeper_1          /docker-entrypoint.sh start   Up      0.0.0.0:2181-&gt;2181/tcp, 2888/tcp,</span></pre><p id="7ab5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据生成器应用程序将开始向Kafka中的天气数据主题输入数据。你也可以做快速检查来确认。查看运行Kafka connect worker的Docker容器:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="87a9" class="nm ls iq nz b gy od oe l of og">docker exec -it kafka-cosmos-cassandra_cassandra-connector_1 bash</span></pre><p id="0032" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦您进入容器外壳，只需启动通常的Kafka控制台消费者进程，您应该会看到天气数据(JSON格式)流入。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="1839" class="nm ls iq nz b gy od oe l of og">cd ../bin<br/><br/>./kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic weather-data<br/><br/>#output<br/><br/>{"stationid":"station-7","temp":"64","state":"state-17","created":"2020-11-28T04:51:06Z"}<br/>{"stationid":"station-9","temp":"65","state":"state-1","created":"2020-11-28T04:51:09Z"}<br/>{"stationid":"station-3","temp":"60","state":"state-9","created":"2020-11-28T04:51:12Z"}<br/>{"stationid":"station-8","temp":"60","state":"state-3","created":"2020-11-28T04:51:15Z"}<br/>{"stationid":"station-5","temp":"65","state":"state-7","created":"2020-11-28T04:51:18Z"}<br/>{"stationid":"station-6","temp":"60","state":"state-4","created":"2020-11-28T04:51:21Z"}<br/>....</span></pre><h2 id="de2a" class="nm ls iq bd lt nn no dn lx np nq dp mb ko nr ns md ks nt nu mf kw nv nw mh nx bi translated">Cassandra水槽连接器设置</h2><p id="e64b" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">将下面的JSON内容复制到一个文件中(可以命名为<code class="fe oi oj ok nz b">cassandra-sink-config.json</code>)。您需要根据您的设置更新它，本节的其余部分将围绕这个主题提供指导。</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="307d" class="nm ls iq nz b gy od oe l of og">{<br/>    "name": "kafka-cosmosdb-sink",<br/>    "config": {<br/>        "connector.class": "com.datastax.oss.kafka.sink.CassandraSinkConnector",<br/>        "tasks.max": "1",<br/>        "topics": "weather-data",<br/>        "contactPoints": "&lt;cosmos db account name&gt;.cassandra.cosmos.azure.com",<br/>        "port": 10350,<br/>        "loadBalancing.localDc": "&lt;cosmos db region e.g. Southeast Asia&gt;",<br/>        "auth.username": "&lt;enter username for cosmosdb account&gt;",<br/>        "auth.password": "&lt;enter password for cosmosdb account&gt;",<br/>        "ssl.hostnameValidation": true,<br/>        "ssl.provider": "JDK",<br/>        "ssl.keystore.path": "/etc/alternatives/jre/lib/security/cacerts/",<br/>        "ssl.keystore.password": "changeit",<br/>        "datastax-java-driver.advanced.connection.init-query-timeout": 5000,<br/>        "maxConcurrentRequests": 500,<br/>        "maxNumberOfRecordsInBatch": 32,<br/>        "queryExecutionTimeout": 30,<br/>        "connectionPoolLocalSize": 4,<br/>        "topic.weather-data.weather.data_by_state.mapping": "station_id=value.stationid, temp=value.temp, state=value.state, ts=value.created",<br/>        "topic.weather-data.weather.data_by_station.mapping": "station_id=value.stationid, temp=value.temp, state=value.state, ts=value.created",<br/>        "key.converter": "org.apache.kafka.connect.storage.StringConverter",<br/>        "value.converter": "org.apache.kafka.connect.json.JsonConverter",<br/>        "value.converter.schemas.enable": false,<br/>        "offset.flush.interval.ms": 10000<br/>    }<br/>}</span></pre><p id="310c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是这些属性的摘要:</p><p id="08fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">基本连接</strong></p><ul class=""><li id="18d8" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><strong class="kh ir">联系人</strong>:输入Cosmos DB Cassandra的联系人</li><li id="8269" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir"> localDc </strong>:输入Cosmos DB账户的地区，如东南亚</li><li id="be0b" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">用户名</strong>:输入用户名</li><li id="f35f" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">密码</strong>:输入密码</li><li id="cf47" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">端口</strong>:输入端口值(这里是<code class="fe oi oj ok nz b">10350</code>，不是9042)。让它保持原样)</li></ul><p id="a6d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在Azure门户网站上访问这些信息:</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi oh"><img src="../Images/b6d91fae65571697eed53e2b3fd27d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Em9mpGWREn5f_KKj.png"/></div></div></figure><p id="38b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> SSL配置</strong></p><p id="fa85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Azure Cosmos DB通过SSL 实施<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/database-security?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank">安全连接，Kafka Connect connector也支持SSL。</a></p><ul class=""><li id="f9ed" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><strong class="kh ir">keystore . path</strong>:JDK密钥库的路径(在容器中是/etc/alternatives/JRE/lib/security/cacerts/)</li><li id="f186" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir"> keystore.password </strong> : JDK密钥库(默认)密码</li><li id="5657" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">主机名验证</strong>:我们打开节点主机名验证</li><li id="6c28" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">提供者</strong> : JDK被用作SSL提供者</li></ul><p id="b3ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">ssl.keystore.path的值不应更新，因为它指向Kafka Connect worker的Docker容器内的路径。不言而喻，这对于生产级部署是不同的，在生产级部署中，您必须更新Docker容器来添加您的证书等。</p><p id="d9d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">卡夫卡到卡珊德拉的映射</strong></p><p id="5a07" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要将数据从Kafka主题推送到Cassandra，必须通过提供Kafka主题中的记录和Cassandra表中的列之间的映射来配置连接器。连接器的一个很好的功能是，它允许您使用来自单个Kafka主题的数据写入多个Cassandra表。这在你需要Kafka主题中事件的衍生表示(表格)的场景中非常有用。</p><p id="0906" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看一下以下映射属性:</p><ul class=""><li id="a94b" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">" topic . weather-data . weather . data _ by _ state . mapping ":" station _ id = value . station id，temp=value.temp，state=value.state，ts=value.created "</li><li id="7bea" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">" topic . weather-data . weather . data _ by _ station . mapping ":" station _ id = value . station id，temp=value.temp，state=value.state，ts=value.created "</li></ul><p id="b825" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来分解一下:</p><ul class=""><li id="3557" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">键(例如<code class="fe oi oj ok nz b">weather-data.weather.data_by_state.mapping</code>)只不过是Kafka主题名称和Cassandra表(包括键空间)的组合。注意，使用单独的配置参数为两个表(<code class="fe oi oj ok nz b">data_by_state</code>和<code class="fe oi oj ok nz b">data_by_station</code>)定义映射。</li><li id="0119" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">该值是Kafka主题中事件的Cassandra列名和相应JSON属性的逗号分隔条目，例如，<code class="fe oi oj ok nz b">station_id=value.stationid</code>指的是<em class="lc"> data_by_station </em>表中的列<code class="fe oi oj ok nz b">station_id</code>，而<code class="fe oi oj ok nz b">value.stationid</code>指的是JSON有效负载中的属性<code class="fe oi oj ok nz b">stationid</code>，如下所示:</li></ul><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="2a45" class="nm ls iq nz b gy od oe l of og">{<br/>    "stationid": "station-7",<br/>    "temp": "64",<br/>    "state": "state-17",<br/>    "created": "2020-11-28T04:51:06Z"<br/>}</span></pre><p id="23d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">详情请查看<a class="ae lb" href="https://docs.datastax.com/en/kafka/doc/kafka/kafkaMapTopicTable.html" rel="noopener ugc nofollow" target="_blank">https://docs . datastax . com/en/Kafka/doc/Kafka/kafkamaptopictable . html</a></p><p id="4103" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">通用参数</strong></p><ul class=""><li id="5434" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><strong class="kh ir">转换器</strong>:我们使用字符串转换器<code class="fe oi oj ok nz b">org.apache.kafka.connect.storage.StringConverter</code></li><li id="e9a8" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">转换器</strong>:由于Kafka topics中的数据是JSON，所以我们使用<code class="fe oi oj ok nz b">org.apache.kafka.connect.json.JsonConverter</code></li><li id="12b6" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><strong class="kh ir">converter . schemas . enable</strong>:这很重要——我们的JSON负载没有与之相关联的模式(出于演示应用程序的目的)。我们需要通过将此设置为false来指示Kafka Connect不要查找模式。不这样做将导致失败。</li></ul><p id="71b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">通过Java驱动程序级配置</strong></p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="087e" class="nm ls iq nz b gy od oe l of og">datastax-java-driver.advanced.connection.init-query-timeout: 5000</span></pre><p id="83bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管连接器提供了相同的默认值，但是您可以将Java驱动程序属性作为连接器配置参数传入。Java驱动程序使用500毫秒作为<code class="fe oi oj ok nz b">init-query-timeout</code>参数的默认值(在我看来这个值很低)，因为它被用作<em class="lc">“用于作为初始化过程的一部分运行的内部查询的超时”</em>(在这里阅读更多<a class="ae lb" href="https://docs.datastax.com/en/developer/java-driver/4.2/manual/core/configuration/reference/" rel="noopener ugc nofollow" target="_blank"/>)</p><p id="7032" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这个原因，我确实遇到了一些问题，并且很高兴看到它是可调的！将它设置为5000毫秒对我来说是可行的，但是它可能可以设置得稍微低一点，它仍然可以很好地工作，例如2000毫秒</p><p id="0124" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请保持其他属性不变</p><p id="df9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于配置的更多细节，请参考<a class="ae lb" href="https://docs.datastax.com/en/kafka/doc/kafka/kafkaConfigTasksTOC.html" rel="noopener ugc nofollow" target="_blank">文档</a></p><p id="6b5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Kafka Connect REST端点安装连接器:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="9666" class="nm ls iq nz b gy od oe l of og">curl -X POST -H "Content-Type: application/json" --data @cassandra-sink-config.json <a class="ae lb" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a> </span><span id="40af" class="nm ls iq nz b gy ol oe l of og"># check status </span><span id="2a93" class="nm ls iq nz b gy ol oe l of og">curl <a class="ae lb" href="http://localhost:8080/connectors/kafka-cosmosdb-sink/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/connectors/kafka-cosmosdb-sink/status</a></span></pre><p id="5218" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果一切顺利，连接器应该开始编织它的魔法。它应该向Azure Cosmos DB认证，并开始从Kafka主题(<code class="fe oi oj ok nz b">weather-data</code>)将数据摄取到Cassandra表- <code class="fe oi oj ok nz b">weather.data_by_state</code>和<code class="fe oi oj ok nz b">weather.data_by_station</code></p><p id="f08f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，您可以查询表中的数据。前往Azure门户网站，<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/cassandra-support?WT.mc_id=data-11341-abhishgu#hosted-cql-shell-preview" rel="noopener ugc nofollow" target="_blank">为你的Azure Cosmos DB帐户打开托管的CQL Shell </a>。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi om"><img src="../Images/a43ac79f9b4e247bb0c79d93f8017e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2c1N6Dh0IjPhZ13Y.png"/></div></div></figure></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="0215" class="lr ls iq bd lt lu mv lw lx ly mw ma mb jw mx jx md jz my ka mf kc mz kd mh mi bi translated">查询Azure Cosmos DB</h1><p id="44f6" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">检查<code class="fe oi oj ok nz b">data_by_state</code>和<code class="fe oi oj ok nz b">data_by_station</code>工作台。以下是一些让您入门的示例查询:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="0e41" class="nm ls iq nz b gy od oe l of og">select * from weather.data_by_state where state = 'state-1'; select * from weather.data_by_state where state IN ('state-1', 'state-2'); select * from weather.data_by_state where state = 'state-3' and ts &gt; toTimeStamp('2020-11-26'); select * from weather.data_by_station where station_id = 'station-1'; select * from weather.data_by_station where station_id IN ('station-1', 'station-2'); select * from weather.data_by_station where station_id IN ('station-2', 'station-3') and ts &gt; toTimeStamp('2020-11-26');</span></pre><h1 id="3424" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">[重要提示:删除资源]</h1><p id="1ef4" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">要停止容器，您可以:</p><pre class="nb nc nd ne gt ny nz oa ob aw oc bi"><span id="996e" class="nm ls iq nz b gy od oe l of og">docker-compose -p kafka-cosmos-cassandra down -v</span></pre><p id="8412" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以<a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/create-cassandra-go?WT.mc_id=data-11341-abhishgu#clean-up-resources" rel="noopener ugc nofollow" target="_blank">删除keyspace/table或者Azure Cosmos DB帐户</a>。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="ade7" class="lr ls iq bd lt lu mv lw lx ly mw ma mb jw mx jx md jz my ka mf kc mz kd mh mi bi translated">包裹</h1><p id="5035" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">总之，您学习了如何使用Kafka Connect在Apache Kafka和Azure Cosmos DB之间进行实时数据集成。由于样品采用基于Docker容器的方法，您可以根据自己的独特要求轻松定制，冲洗并重复！</p><p id="3717" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文中演示的用例和数据流相对简单，但是丰富的Kafka Connect连接器生态系统允许您集成不同的系统，并将复杂的数据管道缝合在一起，而不必编写定制的集成代码。例如，要迁移/集成另一个RDBMS(通过Kafka ),您可能会使用Kafka Connect JDBC源连接器将数据库记录拉入Kafka，使用Kafka流以流的方式转换或丰富它们，将它们重新写回到Kafka主题，然后使用本文中概述的方法将数据引入Azure Cosmos DB。有很多可能性，解决方案将取决于使用案例和需求。</p><p id="2c14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">显然，您需要设置、配置和操作这些连接器。在最核心的地方，Kafka Connect集群实例只是JVM进程，本质上是无状态的(所有的状态处理都被卸载给Kafka)。因此，就整体架构和编排而言，您有很大的灵活性:例如，在Kubernetes中运行它们以实现容错和可伸缩性！</p><h2 id="a149" class="nm ls iq bd lt nn no dn lx np nq dp mb ko nr ns md ks nt nu mf kw nv nw mh nx bi translated">额外资源</h2><p id="18fe" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如果您想进一步探索，我建议您参考以下资源:</p><ul class=""><li id="81d2" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/cassandra-spark-generic?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank">集成Azure Cosmos DB Cassandra API和Apache Spark </a></li><li id="dfea" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><a class="ae lb" href="https://docs.microsoft.com/azure/cosmos-db/cassandra-migrate-cosmos-db-databricks?WT.mc_id=data-11341-abhishgu" rel="noopener ugc nofollow" target="_blank">使用Azure Databricks将数据从Cassandra迁移到Azure Cosmos DB Cassandra API帐户</a></li><li id="ff3c" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><a class="ae lb" href="https://kafka.apache.org/documentation/#connect_development" rel="noopener ugc nofollow" target="_blank">如何为Kafka Connect编写新的连接器</a></li><li id="2870" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><a class="ae lb" href="https://docs.datastax.com/en/kafka/doc/kafka/kafkaArchitecture.html" rel="noopener ugc nofollow" target="_blank">了解DataStax Apache Kafka连接器的架构</a></li><li id="677d" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">探索<a class="ae lb" href="https://debezium.io/documentation/reference/1.2/connectors/index.html" rel="noopener ugc nofollow" target="_blank"> Debezium连接器</a></li></ul><p id="d142" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lc">原载于2020年12月14日</em><a class="ae lb" href="https://devblogs.microsoft.com/cosmosdb/integrating-azure-cosmos-db-cassandra-api-with-apache-kafka-using-kafka-connect/" rel="noopener ugc nofollow" target="_blank"><em class="lc">【https://devblogs.microsoft.com】</em></a><em class="lc">。</em></p></div></div>    
</body>
</html>