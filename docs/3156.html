<html>
<head>
<title>Building a Basic Scraper with Ruby</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Ruby构建一个基本的刮刀</h1>
<blockquote>原文：<a href="https://itnext.io/building-a-basic-scraper-with-ruby-1cec071ada83?source=collection_archive---------6-----------------------#2019-10-13">https://itnext.io/building-a-basic-scraper-with-ruby-1cec071ada83?source=collection_archive---------6-----------------------#2019-10-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9464" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我喜欢网络抓取。近年来，它不仅成为了一个大产业，而且充满了乐趣。它可以帮助您使用已有的数据轻松找到有趣的见解。今天，我将构建一个非常基本的web scraper，可以搜索DuPont Registry(一个昂贵汽车、住宅和游艇的市场)；对于这个刮刀，我将重点放在汽车部分。</p><p id="08cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将使用两个相关的宝石:<a class="ae kl" href="https://rubygems.org/gems/nokogiri/versions/1.6.8" rel="noopener ugc nofollow" target="_blank"> Nokogiri </a>和<a class="ae kl" href="https://rubygems.org/gems/httparty" rel="noopener ugc nofollow" target="_blank">http party</a>。Nokogiri是一块宝石，它允许你把HTML和XML解析成Ruby对象。另一方面，HTTParty简化了将原始HTML拉入Ruby代码的过程。这两个宝石将在我们的刮刀中一起工作。</p><p id="d1ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">需要注意的是，虽然Nokogiri和HTTParty很酷，但它们更像是上面的sprinkles。用它构建程序的核心技能是定义和初始化一个类及其实例，遍历散列和数组，以及构建助手方法。</p><p id="099b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">入门</strong></p><p id="fff4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您还没有，请确保您已经安装了基本的gem，并且在代码中需要这些gem。此外，我喜欢使用byebug或pry，这样我就可以在需要时停止代码，看看发生了什么！</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="d5b5" class="kv kw iq kr b gy kx ky l kz la">require 'nokogiri'</span><span id="2afa" class="kv kw iq kr b gy lb ky l kz la">require 'httparty'</span><span id="e737" class="kv kw iq kr b gy lb ky l kz la">require 'byebug'</span><span id="c35f" class="kv kw iq kr b gy lb ky l kz la">require 'pry'</span><span id="289c" class="kv kw iq kr b gy lb ky l kz la">class Scraper<br/> #we will be adding code here shortly<br/>end</span></pre><h2 id="31a4" class="kv kw iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">初始化实例</h2><p id="6285" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">现在，让我们考虑一下我们的Scraper类。它应该有什么样的方法？这个类需要跟踪什么？</p><p id="88d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在定义如何初始化我们的新scraper之前，我们需要决定这一点。我已经考虑过这个问题，以下是我的想法:</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="1ec7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来分析一下。Scraper类的每个实例应该知道它应该查看什么样的<strong class="jp ir"> make </strong>和<strong class="jp ir"> model </strong>，以及它需要访问哪个<strong class="jp ir"> URL </strong>来找到它的数据。如果这些实例变量是可读的，那就更好了，所以我给它们都添加了一个attr_reader。</p><p id="712b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">DuPont Registry的URL路径相当简单，因此我们可以从“make”和“model”中提取模板文字来生成我们的目标URL，然后将其保存到我们的实例变量<strong class="jp ir"> @url </strong>。<em class="mb">。URL字符串末尾的sub("，"—"</em>只是一个用两个破折号替换空白的方法。</p><p id="ea4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是时候添加更多的功能了。我们需要我们的scraper实例来进行实际的刮擦。让我们开始构建一些实例方法。</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="274f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想在我们的<strong class="jp ir"> #scrape </strong>方法成为小说之前，尽早开始使用这些助手方法。<strong class="jp ir"> #parse_url </strong>方法接受一个url作为参数，调用<strong class="jp ir">http party</strong>获取原始HTML，然后<strong class="jp ir"> Nokogiri </strong>获取那个未解析的页面并……嗯……<em class="mb">解析它</em>。就像这样，我们可以把整个网页转换成一个可用的Ruby对象！然后，我们将整个对象保存到#scrape中一个名为<strong class="jp ir"> parsed_page的局部变量中。</strong>现在是设定绑定的好时机。在我们继续下一步之前，窥探一下我们实际拥有的东西。</p><p id="d230" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们继续，在我们的终端中使用bash命令<strong class="jp ir"> ruby scraper.rb </strong>运行这段代码(这里假设您在一个名为scraper.rb的文件中编码，如果您的文件有不同的名称，那么相应地进行调整)。确保您位于正确的目录中。</p><p id="9d73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，您处于(或者应该处于)窥探会话中，所以我们可以开始在终端中键入Ruby代码了。首先，让我们创建一个新的Scraper实例:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="f7e4" class="kv kw iq kr b gy kx ky l kz la">bentley = Scraper.new("bentley", "continental GT")</span></pre><p id="17c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">酷，我们有一个新的铲运机实例，它将在<a class="ae kl" href="https://www.dupontregistry.com/autos/results/bentley/continental--gt/for-sale" rel="noopener ugc nofollow" target="_blank">https://www . DuPont registry . com/autos/results/Bentley/Continental-gt/for-sale</a>上查找宾利欧陆GTs。我们可以通过在终端中键入以下内容来确认这一点:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="74bd" class="kv kw iq kr b gy kx ky l kz la">bentley.url</span><span id="ce64" class="kv kw iq kr b gy lb ky l kz la">#=&gt; "<a class="ae kl" href="https://www.dupontregistry.com/autos/results/bentley/continental--gt/for-sale" rel="noopener ugc nofollow" target="_blank">https://www.dupontregistry.com/autos/results/bentley/continental--gt/for-sale</a>"</span></pre><p id="f116" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">太好了！现在让我们言归正传。我们需要在我们的<strong class="jp ir"> bentley </strong>的Scraper实例上调用我们的#scrape方法，这样我们可以点击我们的第二个binding.pry，看看我们得到了什么:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="fff5" class="kv kw iq kr b gy kx ky l kz la">bentley.scrape</span></pre><figure class="km kn ko kp gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mc"><img src="../Images/1bf28f3348430eea5b0d1b3728383c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SiMtWIOXAUqLpMuHgmquZQ.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk translated">我们现在正在窥探#scrape方法的内部</figcaption></figure><p id="76df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一点上，我感兴趣的是到底什么是被解析的，因为有很多Ruby gem的诡计正在进行。让我们调用<strong class="jp ir"> parsed_page </strong>局部变量。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="2d57" class="kv kw iq kr b gy kx ky l kz la">pry(#&lt;Scraper&gt;)&gt; parsed_page</span></pre><p id="fa80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哇哦。好吧。那是一大堆东西。很明显它在做什么，我只是不确定该怎么处理这些。我的看起来像这样:</p><figure class="km kn ko kp gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mn"><img src="../Images/6d956f0113992c08568da43f79acd0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rr4F7AXDSkLvdtNhmD8Ymw.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk translated">Nokogiri将HTML解析成类似这样的内容</figcaption></figure><p id="e5f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您抓取的是不同的网站，这看起来可能会有所不同。</p><p id="e386" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们深入研究如何从这个庞大的对象中获取我们的数据之前，让我们来看看我想得到什么，这样我们就可以对它进行逆向工程。我想要一个类似这样的散列:</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="b4ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很好，所以我们并没有试图提取每一条数据，我们只是在寻找这五条数据:年份、品牌、型号、价格和链接。但是等等！当我们实例化scraper实例时，我们已经知道了我们的品牌和型号，所以我们实际上只需要寻找3个数据点。</p><h2 id="60e8" class="kv kw iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">处理HTML</h2><p id="784f" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">现在我们知道了我们在寻找什么，让我们浏览我们想要抓取的页面的HTML来找到我们的路径。首先，让我们看看能否找到包含所有相关汽车信息的容器。我们需要访问列表页面并打开开发者工具。</p><figure class="km kn ko kp gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mo"><img src="../Images/017804780f7ae1c53b299213bd1adf56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Y468MvSzoeRYGt6XUKZlA.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk translated">看起来每个汽车列表都存储在一个名为<strong class="bd lc">‘search results’</strong>的独立div中</figcaption></figure><p id="0224" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们将每个列表保存在一个变量中，以便以后使用。我们将使用。Nokogiri的css方法来构建这个数组。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="1c1f" class="kv kw iq kr b gy kx ky l kz la"><strong class="kr ir">cars = parsed_page.css('div.searchResults')</strong></span><span id="3817" class="kv kw iq kr b gy lb ky l kz la">#creates an array where each element is parsed HTML pertaining to a different listing</span></pre><p id="d3f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们试着找出价格。</p><figure class="km kn ko kp gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mp"><img src="../Images/5a3992780c748e7e8015649e14f9c1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i7gktF_LJnIgKwT390vSng.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk translated">价格包含在一个叫做“成本”的区间内</figcaption></figure><p id="9c52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了提取出我们需要的文本，我们将不得不摆弄它。最好在pry或byebug会话中这样做。我能够使用以下代码得出价格:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="0f36" class="kv kw iq kr b gy kx ky l kz la"><strong class="kr ir">car.css('.cost').children[1].text.sub(",","").to_i</strong></span><span id="c3e2" class="kv kw iq kr b gy lb ky l kz la">#looks in an instance of car for the <em class="mb">cost</em> div<br/>#looks in its children at an index of 1 (this is where it lives)<br/>#converts it to text<br/>#gets rid of the comma <br/>#converts the string into an integer</span></pre><p id="bb0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们知道了价格，现在让我们知道年份。同样，我们需要使用开发人员工具来查找包含汽车年份的字符串。在我的例子中，这是一个看起来像“2017 Bentley Continental GT V8 S”的字符串，所以我决定只窃取前4个字符并将其转换为整数:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="ee52" class="kv kw iq kr b gy kx ky l kz la"><strong class="kr ir">car.css('a').children[0].text[0..4].strip.to_i</strong></span><span id="e296" class="kv kw iq kr b gy lb ky l kz la">#looks in an instance of car for the <em class="mb">&lt;a&gt; tag<br/></em>#looks in its children at an index of 0 (this is where it lives)<br/>#converts to text<br/>#takes the first 4 characters (ie "2017")<br/>#strips any whitespace if it exists<br/>#converts to integer</span></pre><p id="d91a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后但同样重要的是，让我们获得汽车页面的链接。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="4679" class="kv kw iq kr b gy kx ky l kz la"><strong class="kr ir">car.css('a').attr('href').value</strong></span><span id="64d6" class="kv kw iq kr b gy lb ky l kz la">#looks in an instance of car for the <em class="mb">&lt;a&gt; tag<br/>#gets the attribute of &lt;href&gt;<br/>#pulls out is value (as a string)</em></span></pre><p id="7e41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们已经想好了所有JQuery风格的东西。继续读下去，你会看到这些是如何在助手方法<strong class="jp ir"> create_car_hash </strong>中实现的。</p><h2 id="f88c" class="kv kw iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">完成刮刀</h2><p id="b1e1" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">从这里，很容易完成我们的铲运机。让我们设置我们的助手方法，这样我们的#scrape方法将拥有它所需要的一切。</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="4bd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我最终制作了4个不同的助手方法:</p><ol class=""><li id="d5a4" class="mq mr iq jp b jq jr ju jv jy ms kc mt kg mu kk mv mw mx my bi translated"><strong class="jp ir"> create_car_hash </strong>根据我们需要的值创建一个散列</li><li id="4a88" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated"><strong class="jp ir"> get_all_page_urls </strong>果然如其名！将所有URL收集到一个数组中，这将允许我们考虑分页</li><li id="6814" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">get_number_of_pages 非常简单——这也将帮助我们处理分页</li><li id="bed6" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated"><strong class="jp ir"> build_full_cars </strong>给出了第2页及以后的汽车散列数组</li></ol><p id="da55" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们用#scrape方法把它们放在一起，这样我们就可以得到我们想要的东西了。最后，我的代码是这样的:</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="f3c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分别为第一页和其余页面构建散列可能看起来有点奇怪(见第32行)，您可能会合并这一点，但是第一页的URL有一点不同，并且对于设置初始数据很重要。</p><p id="4f54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们快速运行一下，确保它按照我们的要求运行。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="455c" class="kv kw iq kr b gy kx ky l kz la">ruby scraper.rb<br/>bentley = Scraper.new("bentley", "continental gt")<br/>bentley.scrape</span></pre><p id="286a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的产量很大！我不得不把它截短一点。这是我得到的:</p><figure class="km kn ko kp gt ly"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="c80b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们打电话。长度，我们确实得到了120，这与我们的列表数相匹配。完美！</p><p id="567d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还想在其中加入许多方法，让它变得有用。例如，我们可以创建一个方法，返回当前列出的最便宜的Bentley的链接，或者创建一个计算平均要价的方法。你甚至可以美化一下这段代码，因为它远非完美。然而，在这篇文章变成<em class="mb">战争与和平</em>之前，我今天就到此为止了！这里有一个<a class="ae kl" href="https://github.com/alexfarmer91/DuPont-Registry-Scraper" rel="noopener ugc nofollow" target="_blank">到GitHub库</a>的链接，如果你想用它来启发你自己的网页抓取器。</p></div></div>    
</body>
</html>