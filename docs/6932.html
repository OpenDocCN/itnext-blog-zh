<html>
<head>
<title>Creating a Single Neuron Model(Perceptron) from Scratch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python从头开始创建单个神经元模型(感知器)</h1>
<blockquote>原文：<a href="https://itnext.io/creating-a-single-neuron-model-perceptron-5731aaf36a54?source=collection_archive---------0-----------------------#2022-04-17">https://itnext.io/creating-a-single-neuron-model-perceptron-5731aaf36a54?source=collection_archive---------0-----------------------#2022-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4d7f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从零开始理解深度学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b96e2038501a09d4edb88ae652c96589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1AZS_oqiOFD5k-spVFerQ.jpeg"/></div></div></figure><p id="5936" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可能以前使用过或听说过神经网络，今天在这篇博客中，我们将从头开始创建一个单神经元模型或感知器，它也可以被称为逻辑回归，一种用于分类数据的分类算法。所有代码都可以在<em class="lo"> perceptron.ipynb </em>笔记本内的这个<a class="ae ln" href="https://github.com/akil-ahmed3/understanding_deep_learning.git" rel="noopener ugc nofollow" target="_blank"> GitHub链接</a>中找到，数据集可以在<a class="ae ln" href="https://drive.google.com/drive/folders/1OTmte5WhL97YrDHYsb7JSv_7E55JZeYG?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="ab4d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以让我们创造我们可爱的小感知器</p><p id="0ade" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们需要准备好所需格式的数据，它只能使用矢量格式的数据或一维数据，但我们的图像形状是(32，32，3)，其中前两个是图像的高度和宽度，3是RGB通道。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><ul class=""><li id="abff" class="lr ls iq kt b ku kv kx ky la lt le lu li lv lm lw lx ly lz bi translated">首先，在上面的代码块中，我们导入所需的模块</li><li id="1d7f" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后，我们从本地驱动器加载数据，并以4:1的比例分割数据。</li><li id="0a24" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后，我们正在将我们的图像数据从多维矩阵格式重塑为矢量格式。</li><li id="a858" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">最后，我们正在标准化我们的数据集，使像素值保持在0到1之间。</li></ul><p id="22ac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，一旦我们的数据准备就绪，让我们了解我们的模型的架构，你可以在下面的图片中看到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mf"><img src="../Images/2172d98a6e59e82eae8e31fcc1ba78be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JsIwmKP0twSljfw2KVYyYQ.png"/></div></div></figure><p id="8df8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们有向量格式的数据(X ),它将与我们的权重向量(W)加上偏差(b)进行点积，在下面的等式中(I)表示第I个元素<em class="lo"> X </em>或<em class="lo"> Z，</em>和Z是<em class="lo"> W </em>、<em class="lo"> X </em>和<em class="lo"> b </em>的结果的向量。</p><p id="bcc2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是否意味着Z是我们感知机的结果。嗯，没那么快！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/4ac7158618f165041df574e25b5d26f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*nMreNzt-HpANtJ4hhjbN5Q.png"/></div></figure><p id="803e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">值为<em class="lo"> Z </em>矢量没有任何上限或下限，我们需要一个介于0和1之间的值，因此我们将使用sigmoid函数，该函数将获取<em class="lo"> Z </em>的值，并将它们带入0和1之间，这表示为<em class="lo">一个</em>矢量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/77fe8ff0502fe7376a9f4bb6f17ff434.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*XleyR6BewZljf1T-FDXXlQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/6062f8634124f71d923b1aa4ac2f3973.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*a2e-ozEcNCm_s0trFzf-DA.jpeg"/></div></figure><p id="05b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以现在，你可能会问我们如何决定W和b的值？嗯，我们正在将<em class="lo"> W </em>的向量元素的所有值初始化为0.0，将<em class="lo"> b </em>初始化为标量值0.0。</p><p id="19e1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">整个过程到目前为止被称为前向传播，这里是所有步骤的代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><ul class=""><li id="6241" class="lr ls iq kt b ku kv kx ky la lt le lu li lv lm lw lx ly lz bi translated">首先，我们定义一个函数<em class="lo"> initialize_with_zeros </em>，它将dimension作为一个参数，并将返回<em class="lo"> W </em> vector和<em class="lo"> b </em>，记住偏置项(b)是一个标量值。</li><li id="ea60" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后，我们正在定义<em class="lo"> sigmoid </em>函数。</li><li id="edcd" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">最后，<em class="lo"> forward_propagation </em>函数会给我们<em class="lo">一个值从0到1的</em>向量。</li></ul></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="5929" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，一旦我们完成了正向传播步骤，我们必须返回并更新<em class="lo"> W </em>和<em class="lo"> b </em>的值，以便它可以正确区分这两个类。为此，有一个叫做<em class="lo">成本函数(J) </em>的东西，它给出了预测的成本，这意味着预测值与实际值有多远。因此，为了进行计算，我们必须找出每个单独预测的成本，这里的<em class="lo"> y后缀(i) </em>是实际值，而<em class="lo"> a后缀(i) </em>是用数据预测的<em class="lo">值。请参考这个<a class="ae ln" href="https://www.youtube.com/watch?v=k_S5fnKjO-4" rel="noopener ugc nofollow" target="_blank">链接</a>详细了解成本函数，以及这个表达式是怎么来的。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/3729010737bfd2cc3994f9232e36e508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*UFaAWbUhIOElokqG8dCACw.png"/></div></figure><p id="10a7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对数据集中的所有值求和。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8656071099b49228164411677bd1a5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*MUHBWQKS29ZZTVJBV3wPxA.png"/></div></figure><p id="617e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">取平均值，其中<em class="lo"> m </em>是当前训练数据的数量。这是成本函数，我们要尽可能的最小化这个成本函数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/5571017242a287257ce5be82cca2256e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qq1DZs2C6cHsczm1-eINbA.png"/></div></div></figure><p id="46dd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了最小化成本函数或<em class="lo"> J </em>，我们必须找到<em class="lo"> J </em>相对于<em class="lo"> W </em>和<em class="lo"> b、</em>的导数，这意味着<em class="lo"> W </em>和<em class="lo"> b </em>区分两个类别所需的变化量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/662cb7fc2fffccabc576fe5f2bcee6b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gWLtyvTLJ6Hl5ZWOiP441g.jpeg"/></div></div></figure><p id="cef5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以下面给出<em class="lo"> W(dw) </em>和<em class="lo"> b(db) </em> w.r.t <em class="lo"> J </em>的导数，<em class="lo"> dw </em>和<em class="lo"> db </em>称为<em class="lo"> J </em>的梯度。如果你想了解它是如何进入画面的，那么参考这个<a class="ae ln" href="https://www.youtube.com/watch?v=yXcQ4B-YSjQ" rel="noopener ugc nofollow" target="_blank">视频</a>。从<em class="lo">正向传播</em>到现在为止的所有步骤都称为<em class="lo">反向传播</em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/b5ab1920d5fde8b5d26ba6a81f78feaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*IuA8PYfKG_Yw-KGWI7IhHg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/d1f92ec1ffaee7a8ff2437c9d3738dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*h7tbVCl17ID_nv0dAfhysg.png"/></div></figure><p id="a216" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们看看到目前为止的代码。我们去掉了forward_propagation函数，将其与向后传播代码合并，姑且称之为<em class="lo"> propagate </em>函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><ul class=""><li id="1f96" class="lr ls iq kt b ku kv kx ky la lt le lu li lv lm lw lx ly lz bi translated">我们之前已经解释到第12行，现在首先，我们根据之前提到的表达式计算<em class="lo">成本</em>。</li><li id="7cab" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后，我们计算<em class="lo">成本的梯度，其中</em>是<em class="lo"> dw </em>和<em class="lo"> db </em></li><li id="834f" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">最后，返回梯度和成本。</li></ul></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="2dd7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，在接下来的步骤中，我们必须迭代地降低成本函数，为此，我们必须在每次迭代中非常缓慢地减去<em class="lo"> W(dw) </em>和<em class="lo"> b(db) </em>的导数，但是<em class="lo"> dw </em>和<em class="lo"> db </em>的值非常大，由于过冲，直接减去它们的值将不起作用，作为一种解决方案，我们将<em class="lo"> dw </em>和<em class="lo"> db </em>乘以一个非常小的数，称为<em class="lo">这里<em class="lo"> l </em>是学习率，“:=”是赋值运算符。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/a95a747f6ff1f2e765236bc4ca3cb944.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*oOC2yvpk6BpxJ5gYQSoEhQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6314f10b0fdc3ea9e07bfc0dee3963e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*VPRz83sSH8o-IlxbmWm4fg.png"/></div></figure><p id="abc3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">W和b值的这种逐渐变化称为<em class="lo">梯度下降。</em>下图中，足球表示<em class="lo"> W </em>和<em class="lo"> b </em>的值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/a563d899580c94cf8020280ab5b23fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*NGlsxled6JLG1lIF9vfA2w.gif"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk translated"><a class="ae ln" href="https://laptrinhx.com/implement-gradient-descent-in-python-841608606/" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure><p id="e76b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们来理解梯度下降代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><ul class=""><li id="9259" class="lr ls iq kt b ku kv kx ky la lt le lu li lv lm lw lx ly lz bi translated">在函数中，我们传递w(权重)、b(偏差)、X(训练集)、Y(训练集的实际值)、num_iteration(迭代次数)和learning_rate(相同)。我们在第一个代码块中创建的训练和测试集。</li><li id="454b" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">从上面创建的传播函数中，它得到<em class="lo"> dw </em>、<em class="lo"> db </em>和<em class="lo">成本</em>。</li><li id="8cae" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后我们正在根据我们之前的解释更新<em class="lo"> w </em>和<em class="lo"> b </em>。在下一次迭代中，<em class="lo"> w </em>和<em class="lo"> b </em>的值将是新值。</li><li id="dd28" class="lr ls iq kt b ku ma kx mb la mc le md li me lm lw lx ly lz bi translated">然后我们打印每100次迭代的成本，并返回<em class="lo"> w </em>和<em class="lo"> b </em>。请理解，虽然<em class="lo"> w </em>是小写字母，但它是一个矢量，b是标量。</li></ul><p id="af19" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们现在处于最后阶段，让我们首先创建一个<em class="lo">预测</em>函数<em class="lo"> </em>，它将预测(显然)我们的数据点的类别，您可以在这里看到，如果sigmoid函数的结果值小于0.5，则它将被视为0，否则为1。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="7598" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们把现在所有的函数组装起来，创建<em class="lo">模型</em>函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="d571" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这段代码非常简单明了，用零初始化<em class="lo"> w </em>和<em class="lo"> b </em>的值，然后在梯度下降后，我们打印训练和测试集中的精度。</p><p id="cf22" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看我们可爱的小模特表现如何。运行下面给出的代码。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="ba50" class="ni nj iq ne b gy nk nl l nm nn">logistic_regression_model = model(train_set_x, y_train, test_set_x, y_test, num_iterations=2000, learning_rate=0.001)`</span></pre><p id="3223" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是运行它后可能得到的结果。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="33b5" class="ni nj iq ne b gy nk nl l nm nn">Cost after iteration 0: 0.693147 <br/>Cost after iteration 100: 0.679755 <br/>Cost after iteration 200: 0.673041 <br/>Cost after iteration 300: 0.668556 <br/>Cost after iteration 400: 0.665001 <br/>Cost after iteration 500: 0.661952 <br/>Cost after iteration 600: 0.659240 <br/>Cost after iteration 700: 0.656784 <br/>Cost after iteration 800: 0.654535 <br/>Cost after iteration 900: 0.652458 <br/>Cost after iteration 1000: 0.650527 <br/>Cost after iteration 1100: 0.648720 <br/>Cost after iteration 1200: 0.647020 <br/>Cost after iteration 1300: 0.645414 <br/>Cost after iteration 1400: 0.643889 <br/>Cost after iteration 1500: 0.642436 <br/>Cost after iteration 1600: 0.641046 <br/>Cost after iteration 1700: 0.639713 <br/>Cost after iteration 1800: 0.638430 <br/>Cost after iteration 1900: 0.637192 <br/>train accuracy: 63.25 % <br/>test accuracy: 58.5 %</span></pre><p id="d249" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们在测试集上的准确率是58.5%，这比随机猜测(50%)要好，但显然没有达到标准。所以，现在让我们想想我们可以改变什么来使它变得更好，我们可以使用不同的激活函数，不同的学习速率可以训练它进行更多或更少的迭代。请尝试不同的想法，看看你是否能改变结果。在本系列的第二篇文章中，我们已经从头开始创建了一个神经网络模型</p><p id="9a6d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">信用:【https://www.coursera.org/specializations/deep-learning T2】</p></div></div>    
</body>
</html>