<html>
<head>
<title>Kafka Transaction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡夫卡交易</h1>
<blockquote>原文：<a href="https://itnext.io/kafka-transaction-56f022af1b0c?source=collection_archive---------2-----------------------#2019-09-20">https://itnext.io/kafka-transaction-56f022af1b0c?source=collection_archive---------2-----------------------#2019-09-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ad5f834f066f53a0b80cd2f47f4cfd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e5nLc3otV9DT0zCn"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">安妮·斯普拉特在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="995f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据我的经验，在大多数情况下，使用Kafka处理至少一次或最多一次消息事件就足够了。</p><p id="bdfa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在卡夫卡那里实现事务性处理并不容易，因为它不是为事务性而生的，我想。</p><p id="09d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，让我们看看为什么很难在使用Kafka Streams的应用程序中获得完整的事务处理，Kafka Streams可以在您的流应用程序中进行复杂的处理。</p><p id="b074" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">kafka streams应用程序可以包含许多消费-流程-生产的处理周期。使用Kafka Streams应用程序，您可以多次遇到以下情况:</p><ul class=""><li id="0297" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">如果您在应用程序中使用Kafka Streams，可能会有很多类似于<code class="fe lk ll lm ln b">map(), through(), transform(), flatMap(), etc</code>的函数调用，其中会发生重新划分，也就是说，带有中间主题的新主题将使用新主题关键字创建。</li><li id="17d7" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated">如果您的kafka streams应用程序是有状态的，本地状态将被异步同步到changelog主题。</li><li id="f8cf" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated">如果在kafka streams应用程序的处理过程中，您必须将处理结果保存到外部数据库，那么您也必须考虑将偏移量保存到同一个外部数据库。</li></ul><p id="0f69" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如在上面的情况中所看到的，可能有许多消费、处理、生产过程，有许多不同的数据存储，如kafka、本地存储和外部数据库，其中所有的事务都必须以原子的方式提交。但是在kafka streams应用程序中，很难以原子方式实现整个事务提交。</p><p id="cdf0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相反，它应该被划分为个人消费-加工-生产循环。</p><p id="3d9c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我将向您展示如何在Kafka中进行生产者端事务和消费者端事务，以实现一次性处理:</p><ul class=""><li id="4b0d" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">在生产者端事务中，kafka生产者使用kafka事务api发送带有事务配置的avro消息。</li><li id="3a80" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated">在消费者端事务中，kafka消费者消费来自主题的avro消息，处理它们，将处理后的结果保存到外部数据库，偏移也保存到相同的外部数据库，最后所有数据库事务将以原子方式提交。</li></ul><p id="22a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文的完整代码可以在我的github repo中找到:</p><div class="lt lu gp gr lv lw"><a href="https://github.com/mykidong/kafka-transaction-example" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd ir gy z fp mb fr fs mc fu fw ip bi translated">my kidong/Kafka-交易-示例</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">github.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk jw lw"/></div></div></a></div><h1 id="052b" class="ml mm iq bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">交易型卡夫卡制片人</h1><p id="e01c" class="pw-post-body-paragraph kd ke iq kf b kg nj ki kj kk nk km kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">我们先来讨论卡夫卡中的生产者端交易。</p><p id="e3bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以设置生成器的以下事务属性:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="7576" class="nw mm iq ln b gy nx ny l nz oa">        // transaction properties.<br/>        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, transactionalId); // unique transactional id.<br/>        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);<br/>        props.put(ProducerConfig.ACKS_CONFIG, "all");<br/>        props.put(ProducerConfig.RETRIES_CONFIG, 3);<br/>       props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 1);<br/>        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 600000);</span></pre><ul class=""><li id="2d92" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ProducerConfig.TRANSACTIONAL_ID_CONFIG</code>必须是单个kafka生产者的唯一交易id。</li><li id="833c" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG</code>一定是<code class="fe lk ll lm ln b">true</code>。</li><li id="33e7" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ProducerConfig.ACKS_CONFIG</code>是<code class="fe lk ll lm ln b">all</code>，即所有的领导者和追随者经纪人都向日志提交了消息。</li><li id="1c58" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ProducerConfig.RETRIES_CONFIG</code>应大于1的尝试请求多次失败请求。</li><li id="24cf" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code>为1，表示将保证有序的顺序。</li></ul><p id="f406" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看kafka producer以事务方式发送的消息:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="d4d4" class="nw mm iq ln b gy nx ny l nz oa"><em class="ob">// construct producer.<br/></em>KafkaProducer&lt;UserKey, Events&gt; producer = <strong class="ln ir">new </strong>KafkaProducer&lt;&gt;(props);<br/><br/><em class="ob">// initiate transaction.<br/></em>producer.initTransactions();<br/><em class="ob">log</em>.info(<strong class="ln ir">"tx init..."</strong>);<br/><strong class="ln ir">try </strong>{<br/>    <em class="ob">// begin transaction.<br/>    </em>producer.beginTransaction();<br/>    <em class="ob">log</em>.info(<strong class="ln ir">"tx begun..."</strong>);<br/><br/>    <strong class="ln ir">for</strong>(<strong class="ln ir">int </strong>i = 0; i &lt; 20; i++) {<br/>        Events events = <strong class="ln ir">new </strong>Events();<br/>        events.setCustomerId(<strong class="ln ir">"customer-id-" </strong>+ (i % 5));<br/>        events.setOrderInfo(<strong class="ln ir">"some order info " </strong>+ <strong class="ln ir">new </strong>Date().toString() + <strong class="ln ir">"-" </strong>+ i);<br/><br/>        Date date = <strong class="ln ir">new </strong>Date();<br/>        events.setEventTime(date.getTime());<br/><br/><br/>        UserKey key = <strong class="ln ir">new </strong>UserKey(events.getCustomerId().toString(), date);<br/><br/><br/>        <em class="ob">// send messages.<br/>        </em>Future&lt;RecordMetadata&gt; response = producer.send(<strong class="ln ir">new </strong>ProducerRecord&lt;UserKey, Events&gt;(topic, key, events));<br/>        <em class="ob">log</em>.info(<strong class="ln ir">"message sent ... " </strong>+ <strong class="ln ir">new </strong>Date().toString() + <strong class="ln ir">"-" </strong>+ i);<br/><br/>        RecordMetadata recordMetadata = response.get();<br/>        <em class="ob">log</em>.info(<strong class="ln ir">"response - topic [{}], partition [{}], offset [{}]"</strong>, Arrays.<em class="ob">asList</em>(recordMetadata.topic(), recordMetadata.partition(), recordMetadata.offset()).toArray());<br/>    }<br/><br/>    <em class="ob">// commit transaction.<br/>    </em>producer.commitTransaction();<br/>    <em class="ob">log</em>.info(<strong class="ln ir">"tx committed..."</strong>);<br/><br/>} <strong class="ln ir">catch </strong>(KafkaException e) {<br/>    <em class="ob">// For all other exceptions, just abort the transaction and try again.<br/>    </em>producer.abortTransaction();<br/>}<br/><br/><em class="ob">// close producer.<br/></em>producer.close();</span></pre><ul class=""><li id="8afb" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">在发送消息之前，必须初始化Kafka producer事务:<code class="fe lk ll lm ln b">producer.initTransactions()</code></li><li id="ec8d" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated">发送消息后，提交事务:<code class="fe lk ll lm ln b">producer.commitTransaction()</code></li><li id="0e22" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated">如果出现异常，中止交易:<code class="fe lk ll lm ln b">producer.abortTransaction()</code></li></ul><h1 id="a933" class="ml mm iq bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">交易型卡夫卡消费者</h1><p id="261d" class="pw-post-body-paragraph kd ke iq kf b kg nj ki kj kk nk km kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">现在，让我们看看消费者端的交易。</p><p id="6042" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的场景中，您必须消费、处理消息，并将处理后的结果保存到外部数据库。同时，偏移量也必须保存到相同的外部数据库中。</p><p id="a36b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在开始使用消息之前，让我们看看db表<code class="fe lk ll lm ln b">offset</code>模式，它可以在上面的git repo中找到:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="990d" class="nw mm iq ln b gy nx ny l nz oa">CREATE TABLE `offset` (<br/>    `group_id` VARCHAR(255),<br/>   `topic` VARCHAR(255),<br/>   `partition` INT,<br/>   `offset` BIGINT,<br/>   PRIMARY KEY (`group_id`, `topic`, `partition`)<br/>);</span></pre><p id="6f3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是<code class="fe lk ll lm ln b">offset</code>表，将为消费者组的单个主题分区保存和检索偏移量。</p><p id="ceea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要以事务方式使用消息，可以为使用者设置以下配置:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="a4b7" class="nw mm iq ln b gy nx ny l nz oa">        // transaction properties.<br/>        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, "read_committed");<br/>        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");<br/>        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");</span></pre><ul class=""><li id="55f9" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ConsumerConfig.ISOLATION_LEVEL_CONFIG</code>必须是<code class="fe lk ll lm ln b">read_committed</code>，这意味着只有提交的消息才会被消费者消费。<code class="fe lk ll lm ln b">ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG</code>必须是<code class="fe lk ll lm ln b">false</code>，这意味着消费者将手动控制偏移提交。</li><li id="b44c" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><code class="fe lk ll lm ln b">ConsumerConfig.AUTO_OFFSET_RESET_CONFIG</code>应为<code class="fe lk ll lm ln b">earliest</code>，表示如果指定的消费者组id的消费者所消费的分区没有offset commit，则消费者将从分区中的第一个offset开始消费消息。</li></ul><p id="aa8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，kafka消费者将使用这些交易配置来消费消息:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="14e4" class="nw mm iq ln b gy nx ny l nz oa"><strong class="ln ir">try </strong>{<br/>    <em class="ob">// consumer subscribe with consumer rebalance listener.<br/>    </em><strong class="ln ir">consumer</strong>.subscribe(Arrays.<em class="ob">asList</em>(<strong class="ln ir">topic</strong>), <strong class="ln ir">new </strong>TransactionalConsumerRebalanceListener(<strong class="ln ir">this</strong>));<br/>    <strong class="ln ir">consumer</strong>.poll(0);<br/><br/>    <em class="ob">// When the consumer first starts, after we subscribed to topics, we call poll()<br/>    // once to make sure we join a consumer group and get assigned partitions and<br/>    // then we immediately seek() to the correct offset in the partitions we are assigned<br/>    // to. Keep in mind that seek() only updates the position we are consuming from,<br/>    // so the next poll() will fetch the right messages.<br/>    </em><strong class="ln ir">for </strong>(TopicPartition topicPartition : <strong class="ln ir">this</strong>.<strong class="ln ir">consumer</strong>.assignment()) {<br/>        <strong class="ln ir">long </strong>offset = getOffsetFromDB(<strong class="ln ir">groupId</strong>, topicPartition);<br/>        <strong class="ln ir">consumer</strong>.seek(topicPartition, offset);<br/>        <em class="ob">log</em>.info(<strong class="ln ir">"consumer seek to the offset [{}] with groupId [{}], topic [{}] and parition [{}]"</strong>, Arrays.<em class="ob">asList</em>(offset, <strong class="ln ir">groupId</strong>, topicPartition.topic(), topicPartition.partition()).toArray());<br/>    }<br/><br/><br/>    <strong class="ln ir">while </strong>(<strong class="ln ir">true</strong>) {<br/>        <em class="ob">// if wakeupCalled flag set to true, throw WakeupException to exit, before that flushing message by producer<br/>        // and offsets committed by consumer will occur.<br/>        </em><strong class="ln ir">if </strong>(<strong class="ln ir">this</strong>.<strong class="ln ir">wakeupCalled</strong>) {<br/>            <strong class="ln ir">throw new </strong>WakeupException();<br/>        }<br/><br/>        ConsumerRecords&lt;String, Events&gt; records = <strong class="ln ir">consumer</strong>.poll(100);<br/>        <strong class="ln ir">if</strong>(!records.isEmpty()) {<br/>            <strong class="ln ir">for </strong>(ConsumerRecord&lt;String, Events&gt; record : records) {<br/>                String key = record.key();<br/>                Events events = record.value();<br/><br/>                <em class="ob">log</em>.info(<strong class="ln ir">"key: [" </strong>+ key + <strong class="ln ir">"], events: [" </strong>+ events.toString() + <strong class="ln ir">"], topic: [" </strong>+ record.topic() + <strong class="ln ir">"], partition: [" </strong>+ record.partition() + <strong class="ln ir">"], offset: [" </strong>+ record.offset() + <strong class="ln ir">"]"</strong>);<br/><br/>                <em class="ob">// process events.<br/>                </em>processEvents(events);<br/><br/>                <em class="ob">// an action involved in this db transaction.<br/><br/>                // NOTE: if consumers run with difference group id, avoid saving duplicated events to db.<br/>                </em>saveEventsToDB(events);<br/><br/>                <em class="ob">// another action involved in this db transaction.<br/>                </em>saveOffsetsToDB(<strong class="ln ir">groupId</strong>, record.topic(), record.partition(), record.offset());<br/>            }<br/><br/>            commitDBTransaction();<br/>        }<br/>    }<br/><br/>} <strong class="ln ir">catch </strong>(WakeupException e) {<br/><br/>} <strong class="ln ir">finally </strong>{<br/>    commitDBTransaction();<br/>    <strong class="ln ir">this</strong>.<strong class="ln ir">consumer</strong>.close();<br/>}</span></pre><p id="ae6a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">消费者将使用消费者重新平衡监听器订阅主题中的消息:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="53b2" class="nw mm iq ln b gy nx ny l nz oa"><strong class="ln ir">consumer</strong>.subscribe(Arrays.<em class="ob">asList</em>(<strong class="ln ir">topic</strong>), <strong class="ln ir">new </strong>TransactionalConsumerRebalanceListener(<strong class="ln ir">this</strong>));</span></pre><p id="5174" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<code class="fe lk ll lm ln b">TransactionalConsumerRebalanceListener</code>消费者重新平衡监听器中，数据库事务将在重新平衡开始之前提交，在消费者被分配到特定分区后，消费者将从数据库中寻找偏移量:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="d15d" class="nw mm iq ln b gy nx ny l nz oa"><strong class="ln ir">public class </strong>TransactionalConsumerRebalanceListener&lt;K, V&gt; <strong class="ln ir">implements </strong>ConsumerRebalanceListener {<br/><br/>    <strong class="ln ir">private static </strong>Logger <em class="ob">log </em>= LoggerFactory.<em class="ob">getLogger</em>(TransactionalConsumerRebalanceListener.<strong class="ln ir">class</strong>);<br/><br/>    <strong class="ln ir">private </strong>AbstractConsumerHandler&lt;K, V&gt; <strong class="ln ir">consumeHandler</strong>;<br/><br/>    <strong class="ln ir">public </strong>TransactionalConsumerRebalanceListener(AbstractConsumerHandler&lt;K, V&gt; consumeHandler)<br/>    {<br/>        <strong class="ln ir">this</strong>.<strong class="ln ir">consumeHandler </strong>= consumeHandler;<br/>    }<br/><br/>    @Override<br/>    <strong class="ln ir">public void </strong>onPartitionsRevoked(Collection&lt;TopicPartition&gt; collection) {<br/>        <em class="ob">// commit db transaction for saving records and offsets to db.<br/>        </em><strong class="ln ir">this</strong>.<strong class="ln ir">consumeHandler</strong>.commitDBTransaction();<br/>    }<br/><br/>    @Override<br/>    <strong class="ln ir">public void </strong>onPartitionsAssigned(Collection&lt;TopicPartition&gt; topicPartitions) {<br/>        <strong class="ln ir">for</strong>(TopicPartition topicPartition : topicPartitions)<br/>        {<br/>            <em class="ob">// get offset from db and let consumer seek to this offset.<br/>            </em>String groupId = <strong class="ln ir">this</strong>.<strong class="ln ir">consumeHandler</strong>.<strong class="ln ir">groupId</strong>;<br/>            <strong class="ln ir">long </strong>offset = <strong class="ln ir">this</strong>.<strong class="ln ir">consumeHandler</strong>.getOffsetFromDB(groupId, topicPartition);<br/>            <strong class="ln ir">this</strong>.<strong class="ln ir">consumeHandler</strong>.getConsumer().seek(topicPartition, offset);<br/><br/>            <em class="ob">log</em>.info(<strong class="ln ir">"in rebalance listener, consumer seek to the offset [{}] with groupId [{}], topic [{}] and parition [{}]"</strong>, Arrays.<em class="ob">asList</em>(offset, groupId, topicPartition.topic(), topicPartition.partition()).toArray());<br/>        }<br/>    }<br/>}</span></pre><p id="2542" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当使用者重新启动时，使用者将从数据库中查找分区的最后更新的偏移量:</p><pre class="no np nq nr gt ns ln nt nu aw nv bi"><span id="da9d" class="nw mm iq ln b gy nx ny l nz oa"><strong class="ln ir">long </strong>offset = getOffsetFromDB(<strong class="ln ir">groupId</strong>, topicPartition);<br/><strong class="ln ir">consumer</strong>.seek(topicPartition, offset);</span></pre><p id="7763" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看一下<code class="fe lk ll lm ln b">saveEventsToDB()</code>和<code class="fe lk ll lm ln b">saveOffsetsToDB()</code>，在这里处理的结果和偏置将被保存到同一个外部数据库。最后，所有数据库事务都将通过<code class="fe lk ll lm ln b">commitDBTransaction()</code>提交。</p></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><p id="2ef8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Kafka中，只进行一次处理并不容易，但是正如本文中提到的，您应该分别考虑生产者端和消费者端的事务，并尝试实现事务处理。</p><p id="a016" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以从我的github repo中查看以下wiki页面，了解运行本文中代码的详细信息:</p><ul class=""><li id="09c8" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated"><a class="ae kc" href="https://github.com/mykidong/kafka-transaction-example/wiki/Run-Transactional-Kafka-Producer-and-Consumers" rel="noopener ugc nofollow" target="_blank">https://github . com/mykidong/Kafka-transaction-example/wiki/Run-Transactional-Kafka-Producer-and-Consumers</a></li><li id="b0f1" class="lb lc iq kf b kg lo kk lp ko lq ks lr kw ls la lg lh li lj bi translated"><a class="ae kc" href="https://github.com/mykidong/kafka-transaction-example/wiki/Scenario" rel="noopener ugc nofollow" target="_blank">https://github . com/mykidong/Kafka-transaction-example/wiki/Scenario</a></li></ul></div></div>    
</body>
</html>