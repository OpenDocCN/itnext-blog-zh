<html>
<head>
<title>Graphics Processors (GPUs) Under the Hood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">引擎下的图形处理器(GPU)</h1>
<blockquote>原文：<a href="https://itnext.io/graphics-processors-gpus-under-the-hood-4522dbec777d?source=collection_archive---------1-----------------------#2022-03-27">https://itnext.io/graphics-processors-gpus-under-the-hood-4522dbec777d?source=collection_archive---------1-----------------------#2022-03-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a6c9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于CPU如何工作的常见问题和误解的解答。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/15772089d4f9588ffaf85baa16fabaa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T-4gdbY8OHubiD7GIRK49g.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">用于高性能计算和机器学习任务的Nvidia Hopper H100</figcaption></figure><p id="88cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于我一直在深入研究现代GPU的内部工作方式，我不得不与自己对它们如何工作的误解作斗争。这个故事试图回答我和其他人在尝试使用CUDA等框架进行GPU编程时遇到的许多问题。</p><p id="bea1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我不会过多地关注编程的实际方面，而是更多地关注对底层硬件如何工作的理解。</p><h1 id="4d10" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">线、经线、线块和网格</h1><p id="a5e0" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">当你试图用CUDA解决一个问题时，你试图把你的问题分成更小的部分，以适应你的图形硬件的处理能力。假设你有一百万个元素要处理。你想对他们做什么并不重要。也许它们是你想要平方或去掉平方根的数字。</p><p id="eb18" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以将问题划分成线程块。在当前架构上，这些线程最多可以包含1024个线程。使用978个线程块，我们可以处理978 × 1024 = 1，001，472个元素。比我们需要的多一点，但是976个块只处理999，424个元素。所有这些线程块一起形成了我们所说的网格。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mr"><img src="../Images/ac5213aed9fd98874a41915bf973e3de.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2tN8_5worg5K61q2ksWVlQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">将线程组织成不同维度的块</figcaption></figure><p id="d53e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，您已经了解了基础知识，但是对于所有线程块、经线、线程和GPU核心如何协同工作还有许多误解。</p><h2 id="65da" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">一个GPU线程和CPU线程一样吗？</h2><p id="eee9" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">我的第一印象是它们根本不一样，但经过更仔细的研究，我得出结论，GPU线程实际上与CPU线程有许多相似之处。什么是常规编程中的线程？</p><p id="6188" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在常规编程中，多个线程可以执行同一个程序。它们各自在同一个程序中跟踪自己的位置。换句话说，每个线程都有一个持久的状态，这意味着当你恢复一个线程时，它可以从先前挂起的地方恢复。</p><p id="e805" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这同样适用于GPU线程。每个GPU线程都有一个关联的状态，例如:</p><ul class=""><li id="d4ce" class="ne nf it la b lb lc le lf lh ng ll nh lp ni lt nj nk nl nm bi translated">程序计数器—指向线程当前正在执行的指令的位置。</li><li id="2b65" class="ne nf it la b lb nn le no lh np ll nq lp nr lt nj nk nl nm bi translated">线程索引——x、y和z位置，有助于识别线程负责处理哪个数组元素。</li><li id="0052" class="ne nf it la b lb nn le no lh np ll nq lp nr lt nj nk nl nm bi translated">用于执行算术运算的寄存器。</li></ul><p id="ba19" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当CPU上的线程调度器调度线程时，它读取存储的线程状态，并将CPU寄存器和程序计数器设置为为该线程存储的值。</p><p id="4aea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当CUDA线程被调度时，类似的事情发生在GPU核心中。</p><h2 id="3d78" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">GPU线程和CPU线程有什么不同？</h2><p id="0abe" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">一个CPU线程可以完全独立于其他线程运行。对于GPU线程来说，情况并非如此。GPU线程总是在warp环境中执行。经线是32根线的集合。</p><p id="913d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">warp将在它包含的所有线程中并行执行一条指令。对于所有执行的线程，它必须是相同的指令。因此，只有具有相同程序计数器的线程才会并行运行。假设我们在曲速中有A，B，C，D和E线。如果A、B、C在指令4，D、E在指令6，那么所有线程不能同时运行。相反，C和D将被禁用，指令4开始运行。接下来，A、B、C被禁用，指令6开始运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mr"><img src="../Images/632decf5077b8191528156610a1cf70c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xbARsSQK1WbIc0dRd54bvw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">扭曲是如何在GPU核心中调度的</figcaption></figure><h2 id="2633" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">如何将线指定给经线？</h2><p id="7375" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">根据线的ID将线指定给扭曲。所以ID为0，1，…，31的线程将被分配给第一个经线。ID为32，33，…，64的线程将被分配给第二个经线，依此类推。</p><p id="af18" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线程的索引和它的线程ID以一种直接的方式相互关联:对于一维块，它们是相同的；对于二维块，其为:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3247" class="ms lv it nt b gy nx ny l nz oa">threadID = threadIdx.x + threadIdx.y * blockIdx.x</span></pre><p id="09b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于大小为的三维块，线程ID为:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="656b" class="ms lv it nt b gy nx ny l nz oa">threadID = threadIdx.x + threadIdx.y * blockIdx.x <br/>                       + threadIdx.z * blockIdx.x * blockIdx.y</span></pre><p id="6006" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可能认为这是将一维数组视为二维或三维数组的方式。</p><h2 id="f4f4" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">为什么分配给GPU核心的线程比它能够并行执行的线程多？</h2><p id="d698" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">通常不可能在一个时钟周期内读取32个线程的数据。因此，依赖于从存储器读取的数据的指令将会停止。这使得CPU内核未得到充分利用。通过分配比可以并行处理的线程更多的线程，我们可以在一些线程等待输入时在GPU核心上运行其他线程。这种方法提高了硬件资源的利用率。</p><h1 id="64e6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">环</h1><p id="416f" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">关于GPU核心如何处理循环有很多困惑。</p><h2 id="65c3" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">GPU可以执行for循环吗？</h2><p id="56b6" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">考虑一个简单的加法函数，它将两个长度为<code class="fe ob oc od nt b">n</code>的数组相加。常规的CPU代码会有一个显式的for循环。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="cbf5" class="ms lv it nt b gy nx ny l nz oa">void<br/>vadd(int n, float *xs, float *ys) {<br/>    for (int i=0; i&lt;n; i++)<br/>        ys[i] = xs[i] + ys[i];<br/>}</span></pre><p id="5728" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们重新编写这个代码来使用CUDA，它将看起来像这样:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="d2ee" class="ms lv it nt b gy nx ny l nz oa">_global_void <br/>gpu_vadd(int n, float *xs, float *ys) {<br/>    int i = blockIdx.x * blockDim.x + threadIdx.x;<br/>    if (i &lt; n) <br/>        y[i] = xs[i] + ys[i]; <br/>}</span></pre><p id="581a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以看到for循环消失了。这是因为这是将被并行应用于所有元素<code class="fe ob oc od nt b">xs</code>和<code class="fe ob oc od nt b">ys</code>的内核函数。这是通过设置对<code class="fe ob oc od nt b">gpu_vadd</code>函数的调用来实现的，这样它可以跨所有数组元素工作:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="1b0b" class="ms lv it nt b gy nx ny l nz oa">int blocksize = 256<br/>int nblocks = (n + blocksize-1) / blocksize;<br/>gpu_vadd&lt;&lt;&lt;nblocks, blocksize&gt;&gt;&gt;(n, xs, ys);</span></pre><p id="7e91" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个例子给人一种错误的印象，你根本不应该在CUDA中使用for循环，或者你甚至不能这样做。然而，GPU可以在内核中执行循环，如<a class="ae oe" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="noopener ugc nofollow" target="_blank"> Nvidia CUDA文档</a>中的矩阵乘法示例所示。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="029a" class="ms lv it nt b gy nx ny l nz oa">typedef struct {<br/>    int width;<br/>    int height;<br/>    float* elements;<br/>} Matrix;<br/><br/>// Matrix multiplication kernel called by MatMul()<br/>__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C)<br/>{<br/>    // Each thread computes one element of C<br/>    // by accumulating results into Cvalue<br/>    float Cvalue = 0;<br/>    int row = blockIdx.y * blockDim.y + threadIdx.y;<br/>    int col = blockIdx.x * blockDim.x + threadIdx.x;<br/>    for (int e = 0; e &lt; A.width; ++e)<br/>        Cvalue += A.elements[row * A.width + e]<br/>                * B.elements[e * B.width + col];<br/>    C.elements[row * C.width + col] = Cvalue;<br/>}</span></pre><p id="0f70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这种情况下，for循环遍历矩阵<code class="fe ob oc od nt b">A</code>的行中的所有值和矩阵<code class="fe ob oc od nt b">B</code>的列中的所有值。这是因为矩阵乘法是通过取矩阵<code class="fe ob oc od nt b">A</code>中的行向量和矩阵<code class="fe ob oc od nt b">B</code>中的列向量之间的点积来完成的。</p><p id="57e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阅读更多:<a class="ae oe" href="https://erik-engheim.medium.com/why-does-matrix-multiplication-work-the-way-it-does-7a8ed9739254" rel="noopener">为什么矩阵乘法是这样工作的？</a></p><p id="c024" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Julia编程语言非常擅长交互地做这件事。下面是对一些行进行点积的演示:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="f685" class="ms lv it nt b gy nx ny l nz oa">julia&gt; using LinearAlgebra<br/><br/>julia&gt; B = [1 4; 2 5; 3 6]<br/>3×2 Matrix{Int64}:<br/> 1  4<br/> 2  5<br/> 3  6<br/><br/>julia&gt; A = [3 2 1; 4 5 2]<br/>2×3 Matrix{Int64}:<br/> 3  2  1<br/> 4  5  2<br/><br/>julia&gt; A*B<br/>2×2 Matrix{Int64}:<br/> 10  28<br/> 20  53<br/><br/># Dot product to calculate values for first row <br/>julia&gt; [3, 2, 1] ⋅ [1, 2, 3]<br/>10<br/><br/>julia&gt; [3, 2, 1] ⋅  [4, 5, 6]<br/>28</span></pre><p id="e1d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图说明了矩阵乘法的工作原理。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mr"><img src="../Images/714f5d624b2378c36806be87ef76a87f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*BidALukai1Qeam4JyUkSXw.png"/></div></figure><p id="9f5a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么要展示所有这些关于矩阵乘法的细节？我只想让你明白，输出中的每个值都需要访问整个矩阵的行和列。这就是循环的作用。我们实际上是在并行地循环几行和几列，因为内核程序将并行执行几个线程。在将结果写入内存中的正确位置之前，每个线程都有独立的寄存器来存储中间结果。</p><p id="0a62" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">内存写入不能独立完成，必须捆绑在一起。内存是以32字节为单位进行读写的，因此只要输入或输出内存地址位于连续的内存位置，就可以在一个周期内完成这些读/写操作。否则你需要多个周期。GPU核心包含独立的<em class="of"> SIMD通道</em>用于运行每个线程。下图显示了两个这样的通道，允许两个线程并行运行。</p><p id="110a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它旨在说明每个通道如何使用自己的LSU(加载/存储单元)独立生成读/写地址。然而，不可能并行执行多个存储器访问。因此，我们需要依次执行。例外情况是同一32字节块内的内存地址。这就是为什么我们可以将内存访问合并到单个读/写指令中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mr"><img src="../Images/064c8e18155bbd9f789c923818777285.png" data-original-src="https://miro.medium.com/v2/format:webp/1*64dNvhcZByK3tDYlLNEqQw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">GPU中的每个SIMD通道如何访问内存</figcaption></figure><h2 id="1d68" class="ms lv it bd lw mt mu dn ma mv mw dp me lh mx my mg ll mz na mi lp nb nc mk nd bi translated">何时使用和不使用循环</h2><p id="a442" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">所以你可以在内核中使用一个循环，但你并不总是必须这样做？我怎么知道什么时候用什么？</p><p id="30d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理想情况下，您应该避免循环，并尽可能多地在并行线程中运行。有时这是不可能的。假设您正在处理一百万个元素。当您启动内核时，您可以设置一百万个线程来处理这些元素，但是如果每个元素都需要访问相邻的元素呢？也许是高斯平滑滤波器，卷积或者只是矩阵乘法。</p><p id="9f2c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">设置用于访问数据的线程是不切实际的，这需要一些编程逻辑来确定位置。</p><p id="e0be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为什么有时循环是一个完美可行的解决方案。循环不一定会导致性能下降。</p><p id="78eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您的硬件可以同时并行处理最多512个线程，那么每个线程执行4次迭代的for循环与调度2048 (512 × 4)个线程在显卡上运行没有任何区别。</p><p id="c2a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您只是读取输入数据中的每个内存位置一次，则不需要循环。</p><h1 id="5a92" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">内存访问和使用</h1><p id="b459" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">如果同一块内存将被多次访问，那么在本地内存中存储一个副本是值得的，因为它可以被更快地访问。</p><p id="bf00" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么访问本地内存更快？全局内存必须在多个GPU核心之间共享。因此，任何访问都会导致多个GPU核心竞争使用数据和地址总线。</p><p id="9d60" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他GPU核心无法访问每个GPU核心的本地内存。因此，不存在对共享资源的争用来减缓存储器访问。</p><p id="6136" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">访问速度也更快，因为用于本地内存访问的L1缓存在物理上更靠近每个内核。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mr"><img src="../Images/a9003cfb1cd23f125f4cf4b08f2eec20.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nhPOvBVIveoD8MiAWB2VGw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">同一块上的线程可以共享内存。</figcaption></figure><p id="e695" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在对CUDA编程时，你可以使用<code class="fe ob oc od nt b">__shared__</code>关键字来表示一些静态分配的内存将代表GPU核心的本地内存，而不是全局内存(所有核心共享的内存)。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="2e52" class="ms lv it nt b gy nx ny l nz oa">__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C) <br/>{<br/>    // some code...<br/>        __shared__ float As[16][16];<br/>    __shared__ float Bs[16][16];<br/> // more code ...<br/>}</span></pre><p id="9152" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个例子中，我们为矩阵<code class="fe ob oc od nt b">A</code>的子集分配了256个浮点值，为矩阵<code class="fe ob oc od nt b">B</code>的子集分配了另外256个浮点值。您可以在<a class="ae oe" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory" rel="noopener ugc nofollow" target="_blank"> CUDA工具包文档</a>中了解更多关于使用共享内存的细节。</p><h1 id="df4d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">GPU汇编代码是什么样子的？</h1><p id="5948" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">GPU的硬件不像主处理器那样保持稳定的指令集架构。通常图形驱动程序会给出一个你想要执行的内核的高级表示。然后内核负责将这个高级代码编译成机器代码。</p><p id="987c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">GPU的指令集在每一代之间会有很大的变化。保持二进制兼容性对个人电脑来说非常重要，但并不那么重要。</p><p id="2779" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，你仍然可以得到关于汇编代码的信息，但这主要是为了阅读。你不会自己写的。下面是一些代码的例子。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3e47" class="ms lv it nt b gy nx ny l nz oa">; Uniform Integer Multiplication<br/>IMAD.MOV.U32 R6, RZ, RZ, c[0x0][0x170]<br/><br/>MOV R7, c[0x0][0x174] ; Move from memory to register<br/>IADD3 R9, R2, R5, RZ  ; Uniform integer addition<br/>STG.E.SYS [R6], R9    ; Store to global memory</span></pre><p id="6791" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">操作通常在名为<code class="fe ob oc od nt b">R0</code>、<code class="fe ob oc od nt b">R1</code>的寄存器上完成，...<code class="fe ob oc od nt b">R32</code>(不确定他们有多少寄存器)。</p><h1 id="b760" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">资源</h1><p id="85d0" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">来自Nvidia和其他公司的一些有用的资源。</p><ul class=""><li id="7b72" class="ne nf it la b lb lc le lf lh ng ll nh lp ni lt nj nk nl nm bi translated"><a class="ae oe" href="https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf" rel="noopener ugc nofollow" target="_blank"> CUDA基础知识</a></li><li id="a100" class="ne nf it la b lb nn le no lh np ll nq lp nr lt nj nk nl nm bi translated"><a class="ae oe" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="noopener ugc nofollow" target="_blank"> CUDA矩阵乘法示例</a></li><li id="fd2f" class="ne nf it la b lb nn le no lh np ll nq lp nr lt nj nk nl nm bi translated"><a class="ae oe" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="noopener ugc nofollow" target="_blank"> CUDA C++编程指南</a> —伟大的Nvidia指南，详细介绍了内存层次结构(每个线程、块和网格的内存)以及如何将事物分为线程和块。</li><li id="1af7" class="ne nf it la b lb nn le no lh np ll nq lp nr lt nj nk nl nm bi translated"><a class="ae oe" href="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html#instruction-set-ref" rel="noopener ugc nofollow" target="_blank"> CUDA二进制实用程序</a> —通过查看CUDA的汇编器/反汇编器来解释GPU汇编代码。</li></ul></div></div>    
</body>
</html>