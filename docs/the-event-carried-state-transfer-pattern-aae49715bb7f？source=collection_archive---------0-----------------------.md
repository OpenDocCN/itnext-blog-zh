# 事件承载状态转移模式

> 原文：<https://itnext.io/the-event-carried-state-transfer-pattern-aae49715bb7f?source=collection_archive---------0----------------------->

## 了解事件承载状态转移模式如何帮助您构建强大的事件驱动系统，以及您需要注意哪些陷阱。

![](img/9981464d4d59ad13c50ac515d951ae07.png)

基特·苏曼在 [Unsplash](https://unsplash.com/s/photos/empire-state-building?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

在“事件驱动架构工程师指南”系列的第三篇博客[中，我讨论了最常用的事件驱动软件设计模式，即事件通知模式。让我们探索另一种可供使用的模式，事件承载的状态转移模式。在这篇博客中，我解释了这种模式的特征，它如何影响事件的设计，以及预期的挑战。最后，我将给出一个很好的技巧，介绍如何使用实际的生产数据量和吞吐量开始体验事件承载的状态转移模式。](https://medium.com/geekculture/the-event-notification-pattern-a62d48519107)

# 事件承载状态转移模式的特征

顾名思义，事件携带状态转移模式的主要特征是事件包含状态，这与通知事件完全不同，通知事件只包含一个标识符来从生产者那里检索状态。客户下订单的有状态事件可能如下所示(使用 [cloudevents.io](https://cloudevents.io/) 标准建模):

在事件中包含状态消除了使用者回调生产者以检索状态的需要。相反，消费者通过存储他们消费的事件的状态来构建状态的私有副本。

一个例子是计费微服务，它侦听 customerAddressUpdate 事件以保持最新的地址可用，从而建议用户将其作为新订单的默认计费地址。当用户更改他们的地址时，客户微服务会更新其自身的状态，这将被视为“事实的来源”，然后产生有状态的 customerAddressUpdate 事件，该事件使其他微服务(如 billing)能够更新其私有的状态副本。

拥有所有可用于处理后续事件的状态的消费者消除了在事件消费时回调生产者的需要，使得这种模式非常适合具有高吞吐量、健壮性和可用性需求的工作负载。

在事件中包含状态会带来新的挑战，如状态管理和复制、更具挑战性的事件设计、处理重复处理和事件流设计中的顺序。让我们来讨论这些挑战和可用的设计方案。

# 状态管理和复制

当消费者使用有状态事件来更新他们的私有状态副本时，与“真实的来源”相比，数据“滞后”的时间确实很短。这意味着系统最终是一致的，而不是强一致性。最终一致性是理论上的保证，即如果没有对数据进行新的更新，整个系统中对该数据的所有读取将最终返回最后更新的值。

牺牲强一致性在分布式系统中并不少见，因为它们必须平衡一致性、可用性和分区容差。按照[上限定理](https://en.wikipedia.org/wiki/CAP_theorem)不可能同时拥有这三者，在设计可扩展系统时，分区容差和可用性通常是优先考虑的。

最终的一致性并不特定于微服务、事件或事件承载的状态转移模式。集群存储解决方案本身就是分布式系统，因此也在一致性保证级别上做出选择。[例如，Cassandra](http://cassandra.apache.org/doc/latest/cassandra/architecture/guarantees.html) 最终是一致的，许多其他产品都有微调一致性行为的配置。然而，当使用像 Cassandra 这样的第三方解决方案时，我们有一种奢侈的感觉，即处理最终一致性挑战的大部分复杂性都被抽象在作者创建的经过战斗考验的解决方案后面，这些解决方案要么“开箱即用”，要么只需要最少的配置来微调特定的用例。从概念上理解正在发生的事情仍然很重要，但是已经为我们做了很多。

当使用事件携带的状态转移模式时，在你和最终一致性的变化无常的现实之间没有任何障碍。

有一个普遍的真理，所有可能失败的事情都会失败，这不是“如果”的问题，而是“什么时候”的问题。如果一个消费者失败了，并且在设计中没有考虑到这一点，状态副本可能会永久地分离。

幸运的是，有一些策略可以通过健壮的事件流处理失败，包括重试和重新处理。请看来自[汇合](https://www.confluent.io/blog/error-handling-patterns-in-kafka/)和[优步](https://eng.uber.com/reliable-reprocessing/)关于如何为阿帕奇卡夫卡实现 reties 的一些例子。虽然其他代理的实现会有所不同，但一般概念应该同样适用。

除了最终的一致性之外，当引入需要历史状态的新微服务时，假设所有微服务都应该具有它们需要的可用状态会带来额外的复杂性。有三种可能的情况来处理这个问题:

*   重新使用可用的持久化有状态事件流
*   从“真相来源”微服务进行数据迁移
*   消费者随着时间的推移建立状态的过渡期

一些事件代理，比如 Apache Kafka，支持可配置的事件保持期。这意味着所有的历史事件都可以“重演”。对于新引入的服务来说，这是快速建立状态的好方法。

还可以从“真实来源”微服务执行数据迁移。该方法应基于数据集大小、准确性、可重复性和转换要求等属性。我发现这个空间非常有趣的一个概念是 [merkle trees](http://distributeddatastore.blogspot.com/2013/07/cassandra-using-merkle-trees-to-detect.html) 。Cassandra 和 Dynamo 依靠它们来比较集群节点之间的状态，并非常有效地纠正网络中的不一致。

在新的微服务中构建状态的最终解决方案是一个过渡场景，在该场景中，使用者通过使用有状态事件开始构建状态，但是在缺少状态的情况下，可以选择调用该状态的其他服务，就像使用事件通知模式一样。这种方法的最大缺点是微服务之间的运行时依赖性被临时重新引入，直到新的微服务被“赶上”。

总之，不要低估在高可用性环境和大规模环境中跨微服务维护一致状态的复杂性。做好准备，因为如果它能失败，它就会失败，问题是什么时候。

# 活动设计

当使用事件通知模式时，事件非常小。它们只包含对状态的引用，并附有有用的元数据。这也意味着他们的设计是稳定的，因为回调接口经常随着系统的发展和特性的增加而改变。对于有状态事件，就像事件状态转移一样，在设计过程中需要做出更多的权衡。不仅如此，它还意味着不断地调整事件的设计以适应变化的环境和(非)功能需求。

说起来容易做起来难，尤其是对于更复杂的系统。在 Martin Fowler 关于[进化设计](https://martinfowler.com/articles/designDead.html)的文章中有一句话，他说优秀设计的核心技能之一是知道如何使用代码、图表和最重要的:对话，将设计传达给需要理解它的人。来自领域驱动设计的实践，如[有界上下文](https://martinfowler.com/bliki/BoundedContext.html)、[集合](https://martinfowler.com/bliki/DDD_Aggregate.html)、[上下文映射](https://www.infoq.com/articles/ddd-contextmapping/)和[事件风暴](https://techbeacon.com/app-dev-testing/introduction-event-storming-easy-way-achieve-domain-driven-design)，虽然不是强制性的，但在设计过程和设计交流中非常有帮助。对于下一节，理解有界上下文和[无处不在的语言](https://martinfowler.com/bliki/UbiquitousLanguage.html)的基本概念是有帮助的。

## 不同类型的事件

在我们讨论如何确定有状态事件的范围之前，区分域事件和集成事件很重要。域事件是在域中发生的与同一有界上下文中的其他微服务相关的事情。域事件可以是单个业务事务执行的一部分。集成事件是发生的与系统中其他有界上下文相关的事情，通常在业务事务成功完成时发生。

这种区别很重要，因为随着系统的发展，事件不断地适应新的需求，而集成事件往往更难适应，因为它们形成了跨边界的上下文联系。不同的有界上下文通常由不同的团队实现和维护。跨团队的变更需要更多的计划和协调，因为团队往往有他们自己的目标、优先级和路线图。

此外，更有可能在细节层面上产生误解，因为[无处不在的语言](https://martinfowler.com/bliki/UbiquitousLanguage.html)不能保证在两种情况下都是一致的。“客户”这个看似简单的概念对不同的人可能有不同的含义。对营销部门来说，某人可能在注册时就被视为客户，而对风险部门来说，只有在所有“了解你的客户”合规检查完成后，才被视为客户。

除非在设计过程中发现这些差异，否则成本会很高。这是因为我们的交付过程、自动化测试和交互都是针对团队内部发生的事情以及在相同的受限环境下工作的团队而优化的。关注与更广泛的系统的集成通常在以后发挥作用，这意味着 bug 在返工方面有更大的影响。

因此，确保设计过程适合事件类型，并使用上下文映射和事件存储等技术来促进正确的对话。

## 如何确定有状态事件的范围

有状态事件的一个关键决策是确定事件中包含的状态的范围。在许多出版物中，包含任何状态的事件被称为 fat 事件。这将使所有利用事件携带状态转移模式的事件成为 fat 事件。包括我在内的一些作者区分了 delta 事件和 fat 事件。增量事件只包含发生变化的属性，所以只是足够的细节，仅此而已。

我认为包含冗余信息的事件是一个胖事件，其目的是减少消费者必须收听的不同事件的数量。例如，在订单事件中包含客户的姓名，这样配送服务就不必单独构建客户状态来触发关于订单配送状态的个性化电子邮件。

delta 事件的好处是它们是一个小的、集中的契约，表达了它们的意图。清晰的意图是一个干净且可维护的实现的一个经常被低估的特征。小事件也会阻止耦合，因为它们在设计时没有考虑到特定的消费者需求。相对于 fat 事件，这是一个很大的优势，fat 事件通常包括针对特定消费者的附加状态。随着消费者随着时间的推移来来去去，通常会变得不清楚哪个消费者使用什么状态，这使得在使用 fat 事件时更难更改生产者。此外，随着时间的推移，fat 事件可能会变成臃肿的事件，因为越来越多的状态被包含进来以支持额外的功能。

delta 事件也有一些挑战，因为它们需要消费者基于几个小事件构建状态，并进行查找以将事物彼此关联起来。这增加了消费者的复杂性，并且基于消费的事件数量，创建了一种更间接的耦合形式，因为消费者对生产者的业务流程有更高的认识。最后一个缺点是性能。事件处理期间的状态构建和检索会限制性能潜力并增加操作成本。

因此，虽然两者都有其优点和缺点，但对我来说，它是“delta 事件，除非…”这意味着我将 delta 事件作为起点。它们清晰的意图和表现力是非常有价值的，它避免了臃肿的事件陷阱。

总之，由于更多的考虑，状态给事件设计带来了急剧的复杂性增加。一般来说，对 fat 事件要非常小心，不要随意地为特定消费者的事件添加额外的状态。通过检查选项和权衡，考虑决定的不可逆转性，在设计中遵守纪律，以优先考虑将可用时间花在哪里。

# 重复处理

与事件设计相关的挑战是一回事，设计事件流引入了额外的挑战，表现为可能发生的重复处理和无序处理。先说重复处理。

默认情况下，许多事件代理提供至少一次处理，这意味着如果代理没有收到成功使用事件的确认，代理将重新发送事件。虽然这确保了事件得到处理，但也意味着如果处理失败后来自消费者的确认，这可能会发生多次。

这里的防御措施是将事件设计成幂等的。幂等性意味着一个事件可以应用多次而不会改变结果。

假设您有 itemQuantityIncreased 事件。如果你简单地把它设计成“数量增加一”，那么多次应用该事件会导致不同的结果。相反，通过将其建模为“将数量设置为 5”，您可以多次应用该事件，结果总是 5。

使事件幂等并不总是可能的。一些代理提供检测和忽略重复交付的功能。总是阅读小字。这种保证通常有一个有限的时间跨度。这对于大多数情况来说可能是好的，但对于您正在设计的产品来说可能不是。也可以手动实现重复检测，方法是保存哈希或最近处理的事件的键的缓存，或者使用序列号来检测和忽略重复。因为这种检测需要状态，所以如果您使用[竞争消费者](https://medium.com/event-driven-utopia/competing-consumers-pattern-explained-b338d54eff2b)实例，您可以使用本地状态存储的分区消费或中央状态存储。这对性能和可伸缩性有很大影响。

总之，有多种方法来处理重复处理，将事件建模为幂等的是最简单和最可靠的，所以尽可能利用它。

# 事件流中的顺序

既然我们已经介绍了事件设计和重复处理，那么让我们来讨论无序处理及其对设计事件流的影响。

当我们谈到排序时，重要的是要认识到有多种级别的排序，全局排序和部分排序。很少有用例需要对所有事件进行全局排序，但是部分排序通常是相关的。

如果单个客户的事件排序正确，则对所有客户的事件排序是不相关的。这种排序是必要的，因为它们都是相互关联的，以不正确的顺序处理它们会导致问题。

保证端到端的部分订购需要查看链中的每个环节。对于大多数使用 FIFO(先进先出)事件平台的事件流，使用客户 id 作为分区键进行分区消费。如果这些概念不为人所知，我在[之前的博客](https://medium.com/swlh/the-6-things-you-need-to-know-about-event-driven-architectures-38e11fdcb5a)中已经有所涉及。根据具有相同分区键的事件的预期频率，也可以看看消费者端。如果事件是批量生成的，这可能会破坏排序。这里有一个例子，如果设置不正确的话，[阿帕奇卡夫卡](https://blog.softwaremill.com/does-kafka-really-guarantee-the-order-of-messages-3ca849fd19d2)中的生产者配置是如何影响订购的。

对于需要重试以确保正确处理消息的事件流，部分排序可能会变得更加困难。如果设计不当，这些备选的不愉快流程可能会破坏有序的处理。这里有一个在 [Apache Kafka](https://www.confluent.io/blog/error-handling-patterns-in-kafka/) 中保持订单保证的错误处理的例子。

这只是考虑快乐流。在现实生活中，事情会失败。因此，通常有一种类似重试的机制，将事件写入不同的队列主题，并由重试应用程序处理。这些流也倾向于破坏顺序保证，除非生成器被专门构建为不管底层错误是否被解决，都将后续相关事件发送到重试。

正如我们之前所了解的，使用事件携带的状态转移模式，消费者可以利用事件来构建状态，这是他们执行由不同事件发起的业务任务所需要的。由于仅在队列/分区级别提供保证，这可能会引入消耗开销。

我们用一个例子来解释这个。我们负责一个大型电子商务系统中的运输微服务。我们的范围很简单，我们的消费者监听两个事件:customerShippingAddressEntered 和 orderPlaced。很明显，我们有一个灵活的最先进的订购流程，因此客户可以在订购流程中来回切换，并根据他们的需要进行更改。这意味着客户可以更改他们的送货地址，我们可以将多个客户的送货地址归入一个订单。由于错误发货的订单和愤怒的客户对业务没有好处，我们最好在 orderPlaced 事件之前处理这些 customerShippingAddressEntered 事件…那么，我们如何确保这种情况发生呢？

一般来说，当您有一个支持 FIFO 和分区消费的代理时，有三种方法可以实现这一点。在这些选项中，我将使用单词 queue，因为这是在代理级别上用户定义的事件流分段的最广为人知的术语。请注意，并非所有解决方案都提供这一级别的订购保证。阅读您计划使用的经纪人的文档，并详细了解订购的工作原理。

现在，继续接近:

*   第一种方法是将整个事件流发布到单个队列，并让所有需要与订单相关的事件的微服务使用订单 ID 作为分区键的部分消费模式来消费该队列。虽然这是一个简单的设置，但是如果消费者只对事件的一个子集感兴趣，就会有(相当大的)消耗开销。我们的 shipping 微服务必须使用属于订单的所有事件，而它只关心 customerShippingAddressEntered 和 orderPlaced 事件。
*   第二种方法是使用订单 ID 作为分区键，创建具有分区消费模式的不同队列。例如，订单和发货队列。拥有不同的队列消除了以前方法的消耗开销。由于没有跨队列的订单保证，侦听 customerShippingAddressEntered 事件的发货队列和 orderPlaced 事件的订单队列可能会破坏排序。一个简单的解决方案是为订单和运输队列都生成 orderPlaced 事件，这样运输微服务只需要从运输队列中消费。如果 orderPlaced 中的状态保持最小，并且不针对特定的消费者进行调整，那么这种方法就不会产生耦合。然而，生产者不再像在酒吧/餐馆那样完全不了解消费者。这也可以被认为是一种耦合形式。
*   第三种也是最后一种方法是将整个事件流发布到一个队列中，使用一个部分消费模式，订单 ID 作为分区键，就像第一种方法一样。然而，现在不是不同的微服务使用该事件流，而是由流程编排器使用。然后，该协调器可以在适当的时候向微服务(如 shipping)发送适当的命令。这也消除了消费者的开销，并且不需要生成多个队列的订单。虽然与有序处理无关，但允许集中流逻辑、更细粒度的基于时间的错误处理场景和 SLA 监控。orchestrators 的主要挑战是它们是潜在的单点故障，并且它们在设计中需要更多的规则，因为它们容易受到复杂性的影响，因为所处理的业务可能覆盖多个有限的上下文。

虽然可能性很小，但还有两种情况值得一提，即处理 FIFO 和分区消耗不可用的情况，以及如何处理全局排序要求。

虽然 FIFO 和分区消费在大多数流行的事件代理和大型云供应商中普遍可用，但在没有的情况下，有序处理仍然是可能的。这需要订单 ID 和事件顺序编号等关键字的组合来指示订单。考虑这是一个后备场景，因为它确实意味着消费者必须消费流中的所有事件，如果没有部分消费，当使用竞争消费者实例时，您要么被限制运行单个消费者实例，要么被限制运行中央状态存储。这对性能和可伸缩性有很大影响。

当存在全局排序需求时，最常见的方法是使用某种缓冲层实现，并在那里实现排序机制。一个常见的想法或倾向是使用时间戳形式的物理时间进行排序。虽然可能，但我不建议在分布式系统中依赖物理时间，因为物理时钟在系统网络中永远不会完全同步。相反，看看逻辑时钟，如 Lamport 时钟或向量时钟。马丁·克莱普曼对此做了非常好的解释。虽然我自己没有在生产中实现过这些，但在订购时，它们是分布式系统领域中一个众所周知的概念。

总之，处理事件流中的顺序可能很有挑战性。虽然有很多机制可以支持，但端到端地正确实现它需要很好地理解事件流过的链中的每个环节。

# 受控实验

读完这篇博客后，希望我已经能够准确地表达出使用事件携带状态转移模式会带来什么样的挑战。在没有经验的情况下，我不建议对生产工作负载使用这种模式。

在这篇博客的开头，我暗示了一个很好的技巧，关于如何使用实际的生产数据量和吞吐量开始获得事件承载状态转移模式的经验。因为我们都听说过概念验证或技术高峰，以便在完全投入之前获得宝贵的经验。他们很棒，但他们也是一个神奇的小数据量的土地，在相当可控和可预测的环境中。

这样做的问题是，当你决定将某样东西投入生产时，现实世界会给你一巴掌。很难。那么，当峰值和产量之间的差距过大时，我们该如何缩小这一差距呢？

事件及其灵活的异步特性的一个独特而酷的好处是，通过引入分流，可以在生产中进行受控实验。分流是一个来自河流三角洲的术语，特指河流的一个分支，在离开后不再回到主流。您可以使用事件轻松构建这样的河流分支。最重要的是，通过使用不同的队列和消费者等，这样的事件流被设计为与主生产流完全分离。这个流程可以从小规模开始，尝试一两个微服务，然后随着时间的推移而扩展。

因此，如果您有一个发布通知事件的现有微服务，那么发布一个额外的有状态事件，就像您在只使用事件携带的状态转移时所做的那样。到不同的队列或主题。

现在启动一个单独的消费者，监听那些事件并与它建立状态。了解最终一致性、重复处理和无序处理等挑战是否以及如何出现在实际生产数据量和吞吐量中。

由于分流流与生产流完全分离，因此如果遇到状态管理或其他方面的任何不可预见的问题，也不会出现大的恐慌，因为这不是影响用户的生产问题。进去，调查，抹掉过去，重新开始。直到你确信你有一个坚如磐石的实现。如果对查看生产数据有隐私方面的顾虑，请确保在进行任何后续处理之前，第一个分流消费者对原始事件中的敏感数据项使用假名。以这种方式试验事件承载的状态转移模式是相对安全的，并且比通常使用的童话般的隔离概念验证环境更现实。

这是对“事件驱动架构工程师指南”博客系列相当重要的补充。敬请期待下一期。到那时候，祝你牛逼一天，编码快乐！