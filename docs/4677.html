<html>
<head>
<title>Tutorial: Data ingestion from Kafka to Azure Data Explorer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:从Kafka到Azure Data Explorer的数据摄取</h1>
<blockquote>原文：<a href="https://itnext.io/tutorial-data-ingestion-from-kafka-to-azure-data-explorer-d1886e24f054?source=collection_archive---------3-----------------------#2020-08-21">https://itnext.io/tutorial-data-ingestion-from-kafka-to-azure-data-explorer-d1886e24f054?source=collection_archive---------3-----------------------#2020-08-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fb9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇博客将涵盖使用<a class="ae kl" href="https://kafka.apache.org/documentation/#connect" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>从<a class="ae kl" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Kafka </a>到<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/data-explorer-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Data Explorer </a> (Kusto)的数据摄取。</p><p id="854e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Azure Data Explorer是一种快速、可扩展的数据探索服务，允许您收集、存储和分析来自任何不同来源的大量数据，如网站、应用程序、物联网设备等。Kafka Connect platform允许您以可伸缩和可靠的方式在Apache Kafka和外部系统之间传输数据。用于Azure Data Explorer的Kafka Connect Sink连接器允许您将Kafka主题中的数据移动到Azure Data Explorer表中，您可以稍后查询和分析这些表。</p><blockquote class="km kn ko"><p id="963c" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated"><em class="iq">下面是本博客的GitHub repo—</em><a class="ae kl" href="https://github.com/abhirockzz/kafka-kusto-ingestion-tutorial" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://GitHub . com/abhirockzz/Kafka-kusto-ingestion-tutorial</em></a></p></blockquote><p id="fa94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的目标是快速开始<em class="kp"/>，所以我们将保持事情的简单性，并将所有事情归档！这包括Kafka、Zookeeper、Kafka Connect worker和事件生成器应用程序——在<a class="ae kl" href="https://github.com/abhirockzz/kafka-kusto-ingestion-tutorial/blob/master/docker-compose.yaml" rel="noopener ugc nofollow" target="_blank"> docker-compose.yaml </a>中定义</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi kt"><img src="../Images/990f8939cc3eb485613ef441468674e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*VesuZTU4iDvlr4bm.jpg"/></div></figure><p id="66a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，您将:</p><ul class=""><li id="ee8e" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">获得单个组件的概述</li><li id="ffa0" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">配置和设置Azure数据浏览器并安装连接器</li><li id="1fcf" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">运行端到端演示</li></ul></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="cc29" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">先决条件</h1><ul class=""><li id="dd99" class="lb lc iq jp b jq mu ju mv jy mw kc mx kg my kk lg lh li lj bi translated">你需要一个<a class="ae kl" href="https://docs.microsoft.com/azure/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">微软Azure账户</a>。也许试试免费的？</li><li id="84a1" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">安装<a class="ae kl" href="https://docs.microsoft.com/cli/azure/install-azure-cli?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>如果你还没有的话(应该很快！)或者直接从你的浏览器使用<a class="ae kl" href="https://azure.microsoft.com/features/cloud-shell/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure云壳</a>。</li><li id="4d03" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated"><a class="ae kl" href="https://docs.docker.com/get-docker/" rel="noopener ugc nofollow" target="_blank">对接器</a>和<a class="ae kl" href="https://docs.docker.com/compose/install" rel="noopener ugc nofollow" target="_blank">对接器组成</a>安装</li></ul></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="4dc8" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">概观</h1><p id="bfc4" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">如前所述，所有组件都在<code class="fe nc nd ne nf b">docker-compose.yaml</code>文件中定义。让我们一点一点地检查一下:</p><p id="2b44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卡夫卡和动物园管理员的部分非常简单——使用<a class="ae kl" href="https://hub.docker.com/r/debezium/kafka/" rel="noopener ugc nofollow" target="_blank"> debezium </a>图片</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="320b" class="nk lx iq nf b gy nl nm l nn no">zookeeper:<br/>    image: debezium/zookeeper:1.2<br/>    ports:<br/>      - 2181:2181<br/>kafka:<br/>    image: debezium/kafka:1.2<br/>    ports:<br/>      - 9092:9092<br/>    links:<br/>      - zookeeper<br/>    depends_on:<br/>      - zookeeper<br/>    environment:<br/>      - ZOOKEEPER_CONNECT=zookeeper:2181<br/>      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092</span></pre><p id="17ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nc nd ne nf b">events-producer</code>服务是一个<a class="ae kl" href="https://github.com/abhirockzz/kafka-kusto-ingestion-tutorial/tree/master/storm-events-producer" rel="noopener ugc nofollow" target="_blank">简单应用程序</a>,它向Kafka主题发送风暴事件数据。Storm Events data是Azure Data Explorer文档中使用的一个典型示例(例如，<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-sample-data?WT.mc_id=medium-blog-abhishgu#ingest-data" rel="noopener ugc nofollow" target="_blank"> check this Quickstart </a>和<a class="ae kl" href="https://kustosamplefiles.blob.core.windows.net/samplefiles/StormEvents.csv?st=2018-08-31T22%3A02%3A25Z&amp;se=2020-09-01T22%3A02%3A00Z&amp;sp=r&amp;sv=2018-03-28&amp;sr=b&amp;sig=LQIbomcKI8Ooz425hWtjeq6d61uEaq21UVX7YrM61N4%3D" rel="noopener ugc nofollow" target="_blank"> the complete CSV file </a>)。producer应用程序使用原始CSV，但只包括选定的字段(如开始和结束时间、状态、来源等。)而不是整行(超过20列)。以下是示例数据:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="3909" class="nk lx iq nf b gy nl nm l nn no">2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23357,WISCONSIN,Winter Storm,COOP Observer<br/>2007-01-01 00:00:00.0000000,2007-01-01 06:00:00.0000000,9488,NEW YORK,Winter Weather,Department of Highways<br/>2007-01-01 00:00:00.0000000,2007-01-01 06:00:00.0000000,9487,NEW YORK,Winter Weather,Department of Highways<br/>...</span></pre><p id="bee0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Docker Compose中的服务组件是这样定义的:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="23e0" class="nk lx iq nf b gy nl nm l nn no"><strong class="nf ir">events-producer:</strong><br/>    build:<br/>      <strong class="nf ir">context: ./storm-events-producer</strong><br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - KAFKA_BOOTSTRAP_SERVER=kafka:9092<br/>      - KAFKA_TOPIC=storm-events<br/>      - <strong class="nf ir">SOURCE_FILE=StormEvents.csv</strong></span></pre><p id="d038" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接收器连接器是许多奇迹发生的地方！让我们来探索一下:</p><h2 id="8eca" class="nk lx iq bd ly np nq dn mc nr ns dp mg jy nt nu mk kc nv nw mo kg nx ny ms nz bi translated">用于Azure数据浏览器的Kafka接收器连接器</h2><p id="5d98" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">以下是docker编写文件中的<code class="fe nc nd ne nf b">kusto-connect</code>服务:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="0a26" class="nk lx iq nf b gy nl nm l nn no"><strong class="nf ir">kusto-connect:</strong><br/>    build:<br/>      <strong class="nf ir">context: ./connector</strong><br/>    ports:<br/>      - 8083:8083<br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - BOOTSTRAP_SERVERS=kafka:9092<br/>      - GROUP_ID=adx<br/>      - CONFIG_STORAGE_TOPIC=my_connect_configs<br/>      - OFFSET_STORAGE_TOPIC=my_connect_offsets<br/>      - STATUS_STORAGE_TOPIC=my_connect_statuses</span></pre><p id="d341" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">容器是从一个<code class="fe nc nd ne nf b">Dockerfile</code>构建的——这使得您可以更容易地在本地运行它，而不是从外部Docker注册表中获取它</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="182c" class="nk lx iq nf b gy nl nm l nn no">FROM debezium/connect:1.2</span><span id="daf1" class="nk lx iq nf b gy oa nm l nn no">WORKDIR $KAFKA_HOME/connect</span><span id="50cd" class="nk lx iq nf b gy oa nm l nn no">ARG KUSTO_KAFKA_SINK_VERSION</span><span id="9964" class="nk lx iq nf b gy oa nm l nn no">RUN curl -L -O <a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto/releases/download/v$KUSTO_KAFKA_SINK_VERSION/kafka-sink-azure-kusto-$KUSTO_KAFKA_SINK_VERSION-jar-with-dependencies.jar" rel="noopener ugc nofollow" target="_blank">https://github.com/Azure/kafka-sink-azure-kusto/releases/download/v$KUSTO_KAFKA_SINK_VERSION/kafka-sink-azure-kusto-$KUSTO_KAFKA_SINK_VERSION-jar-with-dependencies.jar</a></span></pre><p id="aca9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它基于<a class="ae kl" href="https://hub.docker.com/r/debezium/connect/" rel="noopener ugc nofollow" target="_blank"> Debezium Kafka Connect </a>图像之上。只需下载Kusto连接器JAR ( <a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto/releases/tag/v1.0.1" rel="noopener ugc nofollow" target="_blank">版本1.0.1 </a>在撰写本文时)并将其放在Kafka Connect插件目录中。就是这样！</p><p id="5514" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接收器连接器配置文件如下所示:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="6d4d" class="nk lx iq nf b gy nl nm l nn no">{<br/>    "name": "storm",<br/>    "config": {<br/>        "connector.class": "com.microsoft.azure.kusto.kafka.connect.sink.KustoSinkConnector",<br/>        "flush.size.bytes": 10000,<br/>        "flush.interval.ms": 50000,<br/>        "tasks.max": 1,<br/>        "topics": "storm-events",<br/>        "kusto.tables.topics.mapping": "[{'topic': 'storm-events','db': '&lt;enter database name&gt;', 'table': 'Storms','format': 'csv', 'mapping':'Storms_CSV_Mapping'}]",<br/>        "aad.auth.authority": "&lt;enter tenant ID&gt;",<br/>        "aad.auth.appid": "&lt;enter application ID&gt;",<br/>        "aad.auth.appkey": "&lt;enter client secret&gt;",<br/>        "kusto.url": "https://ingest-&lt;name of cluster&gt;.&lt;region&gt;.kusto.windows.net",<br/>        "key.converter": "org.apache.kafka.connect.storage.StringConverter",<br/>        "value.converter": "org.apache.kafka.connect.storage.StringConverter"<br/>    }<br/>}</span></pre><p id="d638" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Azure Data Explorer中将数据加载/导入到表中的过程被称为摄取。这也是连接器的工作方式。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi ob"><img src="../Images/a8d5723fc44921873a368f5853816b2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gzSl-njfjwvGD1IO.png"/></div></div><figcaption class="og oh gj gh gi oi oj bd b be z dk translated"><a class="ae kl" href="https://docs.microsoft.com/en-us/azure/data-explorer/ingest-data-overview" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/data-explorer/ingest-data-overview</a></figcaption></figure><p id="1496" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在幕后，它使用了用于Azure Data Explorer的<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/kusto/api/java/kusto-java-client-library?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Java SDK中的以下模块</a></p><ul class=""><li id="572a" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated"><code class="fe nc nd ne nf b">data</code>:连接，发布(控制)命令，查询数据</li><li id="d428" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated"><code class="fe nc nd ne nf b">ingest</code>:摄取数据</li></ul><p id="66d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">编写时，连接器支持的数据格式有:<code class="fe nc nd ne nf b">csv</code>、<code class="fe nc nd ne nf b">json</code>、<code class="fe nc nd ne nf b">txt</code>、<code class="fe nc nd ne nf b">avro</code>、<code class="fe nc nd ne nf b">apacheAvro</code>、<code class="fe nc nd ne nf b">tsv</code>、<code class="fe nc nd ne nf b">scsv</code>、<code class="fe nc nd ne nf b">sohsv</code>、<code class="fe nc nd ne nf b">psv</code>。Kafka主题中的数据被写到磁盘上的文件中。然后，基于以下连接器配置，这些文件被发送到Azure Data Explorer当文件到达<code class="fe nc nd ne nf b">flush.size.bytes</code> <strong class="jp ir">或</strong>时，<code class="fe nc nd ne nf b">flush.interval.ms</code>间隔已过。</p><blockquote class="km kn ko"><p id="7607" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated"><em class="iq">上述机制的唯一例外是作为字节数组</em>处理的 <code class="fe nc nd ne nf b"><em class="iq">avro</em></code> <em class="iq">和</em> <code class="fe nc nd ne nf b"><em class="iq">apacheAvro</em></code> <em class="iq">数据类型</em></p></blockquote><p id="b375" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过“发送到Azure Data Explorer”，我真正的意思是文件被排队等待接收(使用<a class="ae kl" href="https://github.com/Azure/azure-kusto-java/blob/35d682a89b6b76be5196d73ad10a52fd47ef9ad5/ingest/src/main/java/com/microsoft/azure/kusto/ingest/IngestClient.java#L31" rel="noopener ugc nofollow" target="_blank">ingest client . ingestfromfile</a>)</p><p id="28ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，到目前为止有很多理论…</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="6399" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">..我们来试试吧！</h1><p id="ed5c" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">克隆此回购:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="abc0" class="nk lx iq nf b gy nl nm l nn no">git clone <a class="ae kl" href="https://github.com/abhirockzz/kafka-kusto-ingestion-tutorial" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kafka-kusto-ingestion-tutorial</a></span><span id="169b" class="nk lx iq nf b gy oa nm l nn no">cd kafka-kusto-ingestion-tutorial</span></pre><p id="1b73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用Azure Portal 、<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-cli?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>或任何客户端SDK(如<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-python?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Python </a>)开始创建Azure Data Explorer集群和数据库<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-portal?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="3b91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完成后，创建一个表(<code class="fe nc nd ne nf b">Storms</code>)和相应的映射(<code class="fe nc nd ne nf b">Storms_CSV_Mapping</code>):</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="0964" class="nk lx iq nf b gy nl nm l nn no">.create table Storms (StartTime: datetime, EndTime: datetime, EventId: int, State: string, EventType: string, Source: string)</span><span id="9736" class="nk lx iq nf b gy oa nm l nn no">.create table Storms ingestion csv mapping 'Storms_CSV_Mapping' '[{"Name":"StartTime","datatype":"datetime","Ordinal":0}, {"Name":"EndTime","datatype":"datetime","Ordinal":1},{"Name":"EventId","datatype":"int","Ordinal":2},{"Name":"State","datatype":"string","Ordinal":3},{"Name":"EventType","datatype":"string","Ordinal":4},{"Name":"Source","datatype":"string","Ordinal":5}]'</span></pre><h2 id="5dc9" class="nk lx iq bd ly np nq dn mc nr ns dp mg jy nt nu mk kc nv nw mo kg nx ny ms nz bi translated">启动容器并安装连接器</h2><p id="365f" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">在安装连接器之前，我们需要创建一个服务主体，以便连接器进行身份验证并连接到Azure Data Explorer服务。</p><p id="64a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<a class="ae kl" href="https://docs.microsoft.com/cli/azure/ad/sp?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-ad-sp-create-for-rbac" rel="noopener ugc nofollow" target="_blank"> az ad sp create-for-rbac </a>命令:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="745f" class="nk lx iq nf b gy nl nm l nn no">az ad sp create-for-rbac -n "kusto-sp"</span></pre><p id="01b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您将得到一个JSON响应——请记下<code class="fe nc nd ne nf b">appId</code>、<code class="fe nc nd ne nf b">password</code>和<code class="fe nc nd ne nf b">tenant</code>,因为您将在后续步骤中使用它们</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="6a2c" class="nk lx iq nf b gy nl nm l nn no">{<br/>  "appId": "fe7280c7-5705-4789-b17f-71a472340429",<br/>  "displayName": "kusto-sp",<br/>  "name": "http://kusto-sp",<br/>  "password": "29c719dd-f2b3-46de-b71c-4004fb6116ee",<br/>  "tenant": "42f988bf-86f1-42af-91ab-2d7cd011db42"<br/>}</span></pre><p id="f456" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">启动容器:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="97c0" class="nk lx iq nf b gy nl nm l nn no">docker-compose up</span></pre><p id="0d96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生产者应用程序将开始向<code class="fe nc nd ne nf b">storm-events</code>主题发送事件。您应该会看到类似于以下内容的日志:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="4743" class="nk lx iq nf b gy nl nm l nn no">....<br/>events-producer_1  | sent message to partition 0 offset 0<br/>events-producer_1  | event  2007-01-01 00:00:00.0000000,2007-01-01 00:00:00.0000000,13208,NORTH CAROLINA,Thunderstorm Wind,Public<br/>events-producer_1  | <br/>events-producer_1  | sent message to partition 0 offset 1<br/>events-producer_1  | event  2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23358,WISCONSIN,Winter Storm,COOP Observer<br/>events-producer_1  | <br/>events-producer_1  | sent message to partition 0 offset 2<br/>events-producer_1  | event  2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23357,WISCONSIN,Winter Storm,COOP Observer<br/>events-producer_1  | <br/>events-producer_1  | sent message to partition 0 offset 3<br/>events-producer_1  | event  2007-01-01 00:00:00.0000000,2007-01-01 06:00:00.0000000,9494,NEW YORK,Winter Weather,Department of Highways<br/>events-producer_1  | <br/>events-producer_1  | sent message to partition 0 offset 4<br/>events-producer_1  | 2020/08/20 16:51:35 event  2007-01-01 00:00:00.0000000,2007-01-01 06:00:00.0000000,9488,NEW YORK,Winter Weather,Department of Highways<br/>....</span></pre><p id="102f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在可以安装接收器连接器来消费这些事件，并将它们接收到Azure Data Explorer中</p><p id="1e0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">替换<code class="fe nc nd ne nf b">adx-sink-config.json</code>中下列属性的值:<code class="fe nc nd ne nf b">aad.auth.authority</code>、<code class="fe nc nd ne nf b">aad.auth.appid</code>、<code class="fe nc nd ne nf b">aad.auth.appkey</code>、<code class="fe nc nd ne nf b">kusto.tables.topics.mapping</code>(数据库名称)和<code class="fe nc nd ne nf b">kusto.url</code></p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="94f3" class="nk lx iq nf b gy nl nm l nn no">{<br/>    "name": "storm",<br/>    "config": {<br/>        "connector.class": "com.microsoft.azure.kusto.kafka.connect.sink.KustoSinkConnector",<br/>        "flush.size.bytes": 10000,<br/>        "flush.interval.ms": 50000,<br/>        "tasks.max": 1,<br/>        "topics": "storm-events",<br/>        "kusto.tables.topics.mapping": "[{'topic': 'storm-events',<strong class="nf ir">'db': '&lt;enter database name&gt;</strong>', 'table': 'Storms','format': 'csv', 'mapping':'Storms_CSV_Mapping'}]",<br/>        <strong class="nf ir">"aad.auth.authority": "&lt;enter tenant ID&gt;"</strong>,<br/>        <strong class="nf ir">"aad.auth.appid": "&lt;enter application ID&gt;</strong>",<br/>        "<strong class="nf ir">aad.auth.appkey": "&lt;enter client secret&gt;</strong>",<br/>        <strong class="nf ir">"kusto.url": "https://ingest-&lt;name of cluster&gt;.&lt;region&gt;.kusto.windows.net"</strong>,<br/>        "key.converter": "org.apache.kafka.connect.storage.StringConverter",<br/>        "value.converter": "org.apache.kafka.connect.storage.StringConverter"<br/>    }<br/>}</span></pre><p id="c15c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在不同的终端中，记录连接器服务日志:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="c551" class="nk lx iq nf b gy nl nm l nn no">docker-compose logs -f | grep kusto-connect</span></pre><p id="f0bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">安装连接器:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="e312" class="nk lx iq nf b gy nl nm l nn no">curl -X POST -H "Content-Type: application/json" --data @adx-sink-config.json http://localhost:8083/connectors</span><span id="59b5" class="nk lx iq nf b gy oa nm l nn no">//check status<br/>curl <a class="ae kl" href="http://localhost:8083/connectors/storm/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors/storm/status</a></span></pre><p id="6c8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">连接器应该弹起动作。同时，在另一个终端中，您应该会看到类似于以下内容的日志:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="01d1" class="nk lx iq nf b gy nl nm l nn no">kusto-connect_1    | INFO   ||  Refreshing Ingestion Resources   [com.microsoft.azure.kusto.ingest.ResourceManager]</span><span id="16a3" class="nk lx iq nf b gy oa nm l nn no">kusto-connect_1    | INFO   ||  Kusto ingestion: file (/tmp/kusto-sink-connector-0a8a9fa2-9e4b-414d-bae1-5d01f3969522/kafka_storm-events_0_0.csv.gz) of size (9192) at current offset (93)   [com.microsoft.azure.kusto.kafka.connect.sink.TopicPartitionWriter]</span><span id="9634" class="nk lx iq nf b gy oa nm l nn no">kusto-connect_1    | INFO   ||  WorkerSinkTask{id=storm-0} Committing offsets asynchronously using sequence number 1: {storm-events-0=OffsetAndMetadata{offset=94, leaderEpoch=null, metadata=''}}   [org.apache.kafka.connect.runtime.WorkerSinkTask]<br/>ct.runtime.WorkerSinkTask]</span><span id="581b" class="nk lx iq nf b gy oa nm l nn no">kusto-connect_1    | INFO   ||  Kusto ingestion: file (/tmp/kusto-sink-connector-0a8a9fa2-9e4b-414d-bae1-5d01f3969522/kafka_storm-events_0_94.csv.gz) of size (1864) at current offset (111)   [com.microsoft.azure.kusto.kafka.connect.sink.TopicPartitionWriter]</span><span id="c723" class="nk lx iq nf b gy oa nm l nn no">kusto-connect_1    | INFO   ||  WorkerSinkTask{id=storm-0} Committing offsets asynchronously using sequence number 2: {storm-events-0=OffsetAndMetadata{offset=112, leaderEpoch=null, metadata=''}}   [org.apache.kafka.connect.runtime.WorkerSinkTask]<br/>....</span></pre><p id="7992" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">等待一段时间，直到数据在<code class="fe nc nd ne nf b">Storms</code>表中结束。要进行确认，请检查行数并确认摄取过程中没有失败:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="7cb9" class="nk lx iq nf b gy nl nm l nn no">Storms | count</span><span id="b7aa" class="nk lx iq nf b gy oa nm l nn no">. show ingestion failures</span></pre><p id="c68f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦有了一些数据，尝试几个查询。要查看所有记录:</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="1c7e" class="nk lx iq nf b gy nl nm l nn no">Storms</span></pre><p id="1d70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe nc nd ne nf b">where</code>和<code class="fe nc nd ne nf b">project</code>过滤特定数据</p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="0bd1" class="nk lx iq nf b gy nl nm l nn no">Storms<br/>| where EventType == 'Drought' and State == 'TEXAS'<br/>| project StartTime, EndTime, Source, EventId</span></pre><p id="8b90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe nc nd ne nf b"><a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries?WT.mc_id=medium-blog-abhishgu#summarize" rel="noopener ugc nofollow" target="_blank">summarize</a></code> <a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries?WT.mc_id=medium-blog-abhishgu#summarize" rel="noopener ugc nofollow" target="_blank">运算符</a></p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="c6ab" class="nk lx iq nf b gy nl nm l nn no">Storms<br/>| summarize event_count=count() by State<br/>| where event_count &gt; 10<br/>| project State, event_count<br/>| render columnchart</span></pre><p id="07a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您应该会看到类似如下的图表:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi ok"><img src="../Images/a4d1aa80adb740968660858685000cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*h5wimZTddnkIkVxF.png"/></div></div></figure><p id="7d92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些只是几个例子。深入研究<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/kusto/query/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Kusto查询语言文档</a>或探索关于<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-json-formats?tabs=kusto-query-language&amp;WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">如何使用<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries?WT.mc_id=medium-blog-abhishgu#scalar-operators" rel="noopener ugc nofollow" target="_blank">标量操作符</a>、<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/kusto/query/tutorial?pivots=azuredataexplorer&amp;WT.mc_id=medium-blog-abhishgu#timecharts" rel="noopener ugc nofollow" target="_blank">时间表</a>等将JSON格式的样本数据摄取到Azure Data Explorer </a>中的教程。</p><blockquote class="km kn ko"><p id="56a3" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated"><em class="iq">如果您想从头开始，只需停止容器(</em> <code class="fe nc nd ne nf b"><em class="iq">docker-compose down -v</em></code> <em class="iq">)、删除(</em> <code class="fe nc nd ne nf b"><em class="iq">drop table Storms</em></code> <em class="iq">)并重新创建</em> <code class="fe nc nd ne nf b"><em class="iq">Storms</em></code> <em class="iq">表(以及映射)并重新启动容器(</em> <code class="fe nc nd ne nf b"><em class="iq">docker-compose up</em></code> <em class="iq"> ) </em></p></blockquote><h2 id="983f" class="nk lx iq bd ly np nq dn mc nr ns dp mg jy nt nu mk kc nv nw mo kg nx ny ms nz bi translated">打扫</h2><p id="21f2" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">要删除Azure Data Explorer集群/数据库，请使用<a class="ae kl" href="https://docs.microsoft.com/cli/azure/kusto/cluster?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-kusto-cluster-delete" rel="noopener ugc nofollow" target="_blank"> az集群删除</a>或<a class="ae kl" href="https://docs.microsoft.com/cli/azure/kusto/database?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-kusto-database-delete" rel="noopener ugc nofollow" target="_blank"> az kusto数据库删除</a></p><pre class="ku kv kw kx gt ng nf nh ni aw nj bi"><span id="78fd" class="nk lx iq nf b gy nl nm l nn no">az kusto cluster delete -n &lt;cluster name&gt; -g &lt;resource group name&gt;</span><span id="3988" class="nk lx iq nf b gy oa nm l nn no">az kusto database delete -n &lt;database name&gt; --cluster-name &lt;cluster name&gt; -g &lt;resource group name&gt;</span></pre></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="4806" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">这是一个总结！</h1><p id="d898" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">我希望这有助于您开始使用Kafka Connect sink连接器构建从Kafka到Azure Data Explorer的数据接收管道。这不是将数据摄取到Azure Data Explorer的唯一方式(当然！).欢迎您浏览文档并探索其他技术，如<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-one-click?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">一键摄取</a>，使用<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-event-grid-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">事件网格</a>，<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-iot-hub-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">物联网中心</a>等等！</p><p id="6781" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下次再见，愉快的探索！</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ol om l"/></div></figure></div></div>    
</body>
</html>