<html>
<head>
<title>Up and Running with Keras: Deep Learning Digit Classification using CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras的启动和运行:使用CNN的深度学习数字分类</h1>
<blockquote>原文：<a href="https://itnext.io/up-and-running-with-keras-deep-learning-digit-classification-using-cnn-804777073e43?source=collection_archive---------3-----------------------#2018-11-24">https://itnext.io/up-and-running-with-keras-deep-learning-digit-classification-using-cnn-804777073e43?source=collection_archive---------3-----------------------#2018-11-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9caf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如<a class="ae kl" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>文档所说——“Keras是一种高级神经网络API，用Python编写，能够在<a class="ae kl" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>、<a class="ae kl" href="https://github.com/Microsoft/cntk" rel="noopener ugc nofollow" target="_blank"> CNTK </a>或<a class="ae kl" href="https://github.com/Theano/Theano" rel="noopener ugc nofollow" target="_blank"> Theano </a>之上运行。”我们将使用Tensorflow作为后端。为此，您需要安装Keras和Tensorflow库。</p><p id="cb0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有关完整的安装说明和将Tensorflow配置为Keras后端的信息，请点击此处的链接—<a class="ae kl" href="https://keras.io/#installation" rel="noopener ugc nofollow" target="_blank">https://keras.io/#installation</a>和此处—<a class="ae kl" href="https://www.pyimagesearch.com/2016/11/14/installing-keras-with-tensorflow-backend/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2016/11/14/installing-Keras-with-tensor flow-back end/</a></p><p id="c26b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，可以使用GPU来训练深度学习模型，但这超出了本文的范围。感兴趣的读者可以在这里找到用GPU设置Tensorflow的说明——<a class="ae kl" href="https://keras.rstudio.com/reference/install_keras.html" rel="noopener ugc nofollow" target="_blank">https://keras.rstudio.com/reference/install_keras.html</a></p><p id="e1b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将开发一个简单的CNN(卷积神经网络),也称为<em class="km"> convent </em>,将大小为28x28像素的灰度图像中的数字0-9分类为10个类别(0到9)。这是一个多类分类问题，我们将尝试使用深度学习算法CNN(卷积神经网络)来解决，准确率在99%以上。</p><p id="1888" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">加载数据集</strong>:</p><p id="4dc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们将使用下面的代码从keras数据集加载著名的MNIST数据集</p><blockquote class="kn ko kp"><p id="a5f8" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">从keras.datasets导入mnist</p><p id="0c21" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">(train_images，train_labels)，(test_images，test_labels) = mnist.load_data()</p></blockquote><p id="b68a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，数据集被加载并分成训练和测试图像以及相应的标签。MNIST有70，000个数据样本，其中60，000个是训练数据，10，000个是测试数据。我们可以检查数据的形状如下—</p><blockquote class="kn ko kp"><p id="c9e7" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">火车_图像.形状</p></blockquote><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="ab5a" class="lc ld iq ky b gy le lf l lg lh">(60000, 28, 28)</span></pre><p id="e463" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和</p><blockquote class="kn ko kp"><p id="b54f" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">测试_图像.形状</p></blockquote><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="af1a" class="lc ld iq ky b gy le lf l lg lh">(10000, 28, 28)</span></pre><p id="feb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备模型</strong>:</p><p id="5686" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们用下面的代码准备我们的CNN模型(也被称为<em class="km">修道院</em>)</p><blockquote class="kn ko kp"><p id="2009" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">从keras导入模型<br/>从keras导入层</p><p id="1f25" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated"><strong class="jp ir"> def make_classifier(优化器):</strong> <br/> model = models。<br/> <br/>()【层层相续。Conv2D(filters=32，kernel_size=(3，3)，activation='relu '，padding='same '，input_shape=(28，28，1))) <br/> model.add(layers。MaxPooling2D(pool_size=(2，2))<br/><br/>model . add(layers。Conv2D(filters=64，kernel_size=(3，3)，activation='relu '，padding = ' same ')<br/>model . add(layers。MaxPooling2D(pool_size=(2，2))) <br/> <br/> model.add(layers。Conv2D(filters=64，kernel_size=(3，3)，activation='relu '，padding = ' same ')<br/>model . add(layers。<br/>)<br/>(图层展平())。Dense(64，activation = ' relu ')<br/>model . add(图层。Dense(10，激活='softmax '))</p><p id="406c" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">model . compile(optimizer = ' optimizer '，<br/>loss = ' category _ cross entropy '，<br/> metrics=['accuracy'])</p><p id="fbc0" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated"><strong class="jp ir">返回模型</strong></p></blockquote><p id="fb88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型/网络基本上是Conv2D、MaxPooling2D和密集层的堆栈。我们将在这里讨论模型配置超参数，但是解释CNN如何工作超出了本文的范围。对此，我建议在这里过一遍好看的文章——<em class="km">卷积神经网络的直观解释(</em><a class="ae kl" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank"><em class="km">https://ujjwalkarn . me/2016/08/11/Intuitive-explain-conv nets/</em></a><em class="km">)</em></p><p id="0f5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，修道院的输入形状是——(图像_高度，图像_宽度，图像_通道)。在我们的例子中，因为图像是灰度的，所以image _ channels = 1(0到255之间的值)。我们将用输入形状(28，28，1)训练网络。我们已经在Covn2D层中使用了<em class="km"> padding = "same" </em>，以便在学习特征映射时不会丢失Conv2D层上的任何维度。一个3×3矩阵被用作“<em class="km"> kernel_size </em>”来学习具有32个滤波器的特征图，这些滤波器通过Conv2D的第一个后期的卷积来计算。此外，我们还使用了'<em class="km"> relu </em>'激活功能。</p><p id="2bfa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还使用了MaxPooling2D层。最大池包括从输入要素地图中提取窗口并输出每个通道的最大值。我们使用2x2的窗口大小。</p><p id="4034" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的网络也由一系列的两个致密层组成。第二层(也是最后一层)是10路'<em class="km"> softmax' </em>层，这意味着它将返回10个概率得分的数组。每个分数将是当前数字图像属于我们的10个数字类之一的概率。</p><p id="52f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们使用了—</p><p id="10b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">—优化器:rmsprop(作为参数传递)</p><p id="ffb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">—损失函数:分类交叉熵</p><p id="5733" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">—指标:准确性</p><p id="7dcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">形状转换:</strong></p><p id="7abf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的训练和测试图像存储在uint8类型的shape (60000，28，28)数组中，其值在[0，255]区间内。根据模型的要求，我们将它转换成一个形状为(60000，28，28，1)的float32数组，其值介于0和1之间。</p><blockquote class="kn ko kp"><p id="9a7d" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">train _ images = train _ images . shape((60000，28，28，1))<br/>train _ images = train _ images . as type(' float 32 ')/255</p><p id="ce71" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">test _ images = test _ images . shape((10000，28，28，1))<br/>test _ images = test _ images . as type(' float 32 ')/255</p></blockquote><p id="0c52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">分类编码:</strong></p><p id="9b69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还在标签上应用分类编码。分类交叉熵(我们的损失函数)期望标签遵循分类编码。</p><blockquote class="kn ko kp"><p id="eb75" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">从keras.utils导入到_ categorical</p><p id="981c" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">train _ labels = to _ categorial(train _ labels)<br/>test _ labels = to _ categorial(test _ labels)</p></blockquote><p id="257d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">车型总结</strong>:</p><p id="429c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们准备模型并打印模型摘要，如下所示—</p><blockquote class="kn ko kp"><p id="88cd" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">model = make _ classifier(' rms prop ')<br/>model . summary()</p></blockquote><figure class="kt ku kv kw gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi li"><img src="../Images/df4223a079eef605e4e0710a621db233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9h9GxDcPK2EoZY1LfotJRA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk translated"><strong class="bd lu">图</strong>:模型总结</figcaption></figure><p id="d473" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，每个maxpooling将输入维度减少了一半，而没有损失任何维度，因为我们在out模型中使用了<strong class="jp ir">填充</strong>。</p><p id="ea09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">列车型号</strong>:</p><p id="0b24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们训练我们的模型如下—</p><blockquote class="kn ko kp"><p id="20b4" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">history = model.fit(train_images，train_labels，epochs=10，batch_size=200)</p></blockquote><figure class="kt ku kv kw gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lv"><img src="../Images/de9ff6aaee9c528c77251bca081ab885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkzos1WW6BbRpLUwJqB18Q.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk translated"><strong class="bd lu">图</strong>:模型训练</figcaption></figure><p id="d0e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">损失与精度图:</strong></p><p id="d4f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们用下面的代码绘制了模型训练历史的损失与准确性的关系图</p><blockquote class="kn ko kp"><p id="2886" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">将matplotlib.pyplot作为plt导入</p><p id="c1d4" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">history _ dict = history . history<br/>loss _ values = history _ dict[' loss ']<br/>ACC _ values = history _ dict[' ACC ']</p><p id="805e" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">历元=范围(1，len(acc_values) + 1)</p><p id="8b6c" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">plt.plot(epochs，loss_values，' bo '，label = ' Training Loss ')<br/>PLT . plot(Epochs，acc_values，' b '，label = ' Training Accuracy ')<br/>PLT . title(' Training Loss vs Accuracy ')<br/>PLT . xlabel(' Epochs ')<br/>PLT . ylabel(' Loss/Accuracy ')<br/>PLT . legend()<br/>PLT . show()</p></blockquote><p id="0e9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">情节看起来如下—</p><figure class="kt ku kv kw gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lw"><img src="../Images/7cb46c9f7bdf0a02acfb07de86ade43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nz2Mo_h8CoHKJ7si3qvEXA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk translated"><strong class="bd lu">图</strong>:训练损失与精度图</figcaption></figure><p id="7048" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，每个时期的损耗都在下降，而精度却在提高。</p><p id="a81f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">车型评价</strong>:</p><p id="6849" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们在测试数据上评估了我们的模型，我们发现测试准确率为99.27%，测试损失为0.03166。</p><blockquote class="kn ko kp"><p id="61e3" class="jn jo km jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">test_loss，test _ ACC = model . evaluate(test _ images，test_labels)</p></blockquote><p id="3e52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">批量正常化和剔除:</strong></p><p id="7c58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">批量规范化和剔除是用于增加规范化和减少过度拟合的技术。然而，本文作者并没有发现在这个例子中使用这些技术有什么好处。</p><p id="da3a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完整的源代码可以从Jupyter笔记本这里获得—<a class="ae kl" href="https://github.com/imeraj/MachineLearning/blob/master/DeepLearnPython/MNIST_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/imeraj/machine learning/blob/master/DeepLearnPython/MNIST _分类器. ipynb </a></p><p id="0c2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献:</strong></p><p id="4940" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1]用Python进行深度学习:<a class="ae kl" href="https://www.manning.com/books/deep-learning-with-python" rel="noopener ugc nofollow" target="_blank">https://www.manning.com/books/deep-learning-with-python</a></p><p id="a819" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我不是机器学习/深度学习方面的专家，但我希望这篇文章能帮助一些读者。如果你喜欢这篇文章，请关注我这里或者上 <a class="ae kl" href="https://twitter.com/meraj_enigma" rel="noopener ugc nofollow" target="_blank"> <em class="km">推特</em> </a> <em class="km">别忘了鼓掌；)</em></p></div></div>    
</body>
</html>