<html>
<head>
<title>Predicting Credit Risk by using PySpark ML and Docker Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PySpark ML和Docker Part-1预测信用风险</h1>
<blockquote>原文：<a href="https://itnext.io/predicting-credit-risk-by-using-pyspark-ml-and-docker-part-1-eef141a50a7e?source=collection_archive---------3-----------------------#2020-01-08">https://itnext.io/predicting-credit-risk-by-using-pyspark-ml-and-docker-part-1-eef141a50a7e?source=collection_archive---------3-----------------------#2020-01-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4f56" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">分析关于信用风险的数据集</strong></p><p id="8912" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">信用风险可以解释为由于借款人未能偿还贷款或履行合同义务而造成损失的可能性。基本上，它意味着贷款人可能收不到所欠本金和利息的风险。更高的风险意味着更高的成本，这使得这个话题对许多人来说很重要。在本文中，我们将分析一个关于申请人贷款状态的数据集，并通过不同的机器学习算法对新的申请进行预测。</p><p id="0d94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用Spark在本地分析数据集。我们使用Spark的原因是它促进了可伸缩性，并且提供了简单的集成。Spark不是在一台机器上处理数据，而是使数据从业者能够以更好的规模交互式地处理他们的机器学习问题。</p><p id="c12a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">机器学习是一种通过分析数据来自动建立分析模型的方法。在本文中，我们将使用PySpark的二进制分类算法进行预测。首先，将使用数据对算法进行训练，这种训练将作为新预测的参考。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/013ea4c180aa72184eb3c6de451cef47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPjclY_VKpM2Io4YHyNm8w.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated"><a class="ae lb" href="https://unsplash.com/@kasiape?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Katarzyna Pe </a>在<a class="ae lb" href="https://unsplash.com/s/photos/machine--learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="7d9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">阿帕奇火花</strong></p><p id="4e6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark是最重要的大数据技术之一，它为各种情况提供了分布式数据处理引擎。Spark包括用于流处理、SQL、图形计算以及机器学习的库。它能够在Java、Scala、Python和r上编写应用程序。Apache Spark在批处理和流数据方面都具有高性能，是处理大数据机器学习的最重要因素之一。在Spark中，您可以将数据分割成分区，然后在集群中的所有节点上并行处理这些分区。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/a79be74d579565e4d7f94fb24dd49c27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*T-kyLoNm-67rjKUJkr8_pQ.jpeg"/></div></figure><p id="e5c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文将首先在本地分析一个数据集，然后在其上实现二进制分类算法。为了实现我们的算法，我们将通过Docker使用Jupyter Notebook。</p><p id="fe55" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">什么是机器学习？</strong></p><p id="aa36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">机器学习是人工智能的一个应用。它基本上可以定义为使系统自动学习并从经验中改进。它是教会机器自己学习的科学。学习过程从训练数据开始，以便深入观察，然后根据我们提供的模式在未来做出更好的决策。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/e6622709099730cfcb52efa7b94df0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*1PdbIKomc9z5iI1YNabQGg.jpeg"/></div></figure><p id="0388" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们提到的，Spark是大数据领域的重要参与者，Spark MLlib提供了快速的机器学习能力。</p><h1 id="e37e" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">项目设置</h1><p id="c486" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">为了访问Jupyter笔记本，我们将使用下面的<code class="fe mh mi mj mk b">docker-compose.yml</code>文件:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">docker-compose.yml</figcaption></figure><p id="933d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个<code class="fe mh mi mj mk b">.yml</code>文件将使我们能够访问Jupyter笔记本。首先，我们应该打开终端，然后在<code class="fe mh mi mj mk b">docker-compose.yml</code>文件的同一个文件夹中输入<code class="fe mh mi mj mk b">$docker-compose up</code>(你可以通过<a class="ae lb" href="https://docs.docker.com/compose/install/" rel="noopener ugc nofollow" target="_blank">https://docs.docker.com/compose/install/</a>安装<code class="fe mh mi mj mk b">docker-compose</code></p><p id="d5f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以通过<code class="fe mh mi mj mk b">$docker ps</code>在终端中查看您正在运行的docker容器。这将向您显示正在运行的容器列表。在本教程中，我们有容器图像<code class="fe mh mi mj mk b">.jupyter/all-spark-notebook:latest</code>和它的<code class="fe mh mi mj mk b">CONTAINER ID</code>，我们输入终端<code class="fe mh mi mj mk b">$docker logs CONTAINER_ID</code>:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/2e75c49f400353c9b0271a83f48d426f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNSVKUAqfS-usphBAtvB-w.png"/></div></div></figure><p id="015e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，您可以找到通过浏览器访问Jupyter笔记本的令牌。从那时起，您就可以访问Jupyter Notebook并创建一个Python项目。</p><h1 id="4930" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">导入数据</h1><p id="d641" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">对于二元分类模型，我们将使用一个关于信用风险的数据集。它包括几个输入，输出将预测是否有资格获得贷款。为了导入数据，我们将使用<code class="fe mh mi mj mk b">PySpark</code>。</p><p id="8ed8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们开始火花会议:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">火花会议</figcaption></figure><p id="744c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建SparkSession后，我们就可以读取本地数据了:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="e46f" class="ms lf iq mk b gy mt mu l mv mw"># reading data via Spark</span><span id="1171" class="ms lf iq mk b gy mx mu l mv mw">df = spark.read.csv(“./DataFolder/*.csv”, inferSchema = True, header = True, sep=”,”)</span></pre><p id="ab04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，我们将两个单独的<code class="fe mh mi mj mk b">.csv</code>文件放到一个文件夹中，并将它们集成在一起(这些文件必须具有相同的模式和参数类型)。Spark会自动检测它，并将它伪装成一个文件。如果您分析单个文件，给出文件的路径就足够了。为了通过Jupyter Notebook演示该模式，我们键入:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="4cbf" class="ms lf iq mk b gy mt mu l mv mw">df.printSchema()</span></pre><p id="c904" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是我们数据集的模式:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="6e88" class="ms lf iq mk b gy mt mu l mv mw">root<br/> |-- Loan_ID: string (nullable = true)<br/> |-- Gender: string (nullable = true)<br/> |-- Married: string (nullable = true)<br/> |-- Dependents: string (nullable = true)<br/> |-- Education: string (nullable = true)<br/> |-- Self_Employed: string (nullable = true)<br/> |-- ApplicantIncome: integer (nullable = true)<br/> |-- CoapplicantIncome: double (nullable = true)<br/> |-- LoanAmount: integer (nullable = true)<br/> |-- Loan_Amount_Term: integer (nullable = true)<br/> |-- Credit_History: integer (nullable = true)<br/> |-- Property_Area: string (nullable = true)<br/> |-- Loan_Status: string (nullable = true)</span></pre><p id="29b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在此级别，输入变量是Loan_ID、性别、已婚、受抚养人、教育、自营职业、申请人收入、共同申请人收入、贷款金额、贷款金额期限、信用历史、财产面积。</p><p id="cdf1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出变量是Loan_Status。输出将代表我们的预测变量。</p><h1 id="9362" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">为机器学习准备好数据</h1><p id="2caa" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">在我们的数据集中，有一些变量有二进制或三个不同的值。例如，让我们考虑一下<code class="fe mh mi mj mk b">Property Area</code>。为了显示<code class="fe mh mi mj mk b">Property Area</code>的不同值:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="b96a" class="ms lf iq mk b gy mt mu l mv mw">df.select(“Property_Area”).distinct().show()</span></pre><p id="b4ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出是:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="3813" class="ms lf iq mk b gy mt mu l mv mw">+-------------+<br/>|Property_Area|<br/>+-------------+<br/>|        Urban|<br/>|    Semiurban|<br/>|        Rural|<br/>+-------------+</span></pre><p id="1994" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们更喜欢将这些值保存为字符串类型，这对我们的机器学习模型来说是很昂贵的。为了提高我们预测的性能，我们通过从<code class="fe mh mi mj mk b">Property_Area</code>产生三个不同的整数类型属性来更好地修改这个列。</p><p id="56d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具有二进制值的其他属性稍后也会被修改:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="c597" class="ms lf iq mk b gy mt mu l mv mw">df = df.withColumn(‘Married’, when(col(‘Married’)==’No’, 0).otherwise(1))</span><span id="7fca" class="ms lf iq mk b gy mx mu l mv mw">df = df.withColumn(‘Education’, when(col(‘Education’)==’Not Graduate’, 0).otherwise(1))</span><span id="29bf" class="ms lf iq mk b gy mx mu l mv mw">df = df.withColumn(‘Self_Employed’, when(col(‘Self_Employed’)==’No’, 0).otherwise(1))</span><span id="6e3f" class="ms lf iq mk b gy mx mu l mv mw">df = df.withColumn('Married', when(col('Married')=='No', 0).otherwise(1))</span><span id="9694" class="ms lf iq mk b gy mx mu l mv mw">df = df.withColumn('Education', when(col('Education')=='Not Graduate', 0).otherwise(1))</span><span id="5a08" class="ms lf iq mk b gy mx mu l mv mw">df = df.withColumn('Self_Employed', when(col('Self_Employed')=='No', 0).otherwise(1))</span></pre><p id="d2e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经过这些修改后，我们有了具有新模式的新数据框架:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="e064" class="ms lf iq mk b gy mt mu l mv mw">root<br/> |-- Loan_ID: string (nullable = true)<br/> |-- Gender: string (nullable = true)<br/> |-- Married: integer (nullable = false)<br/> |-- Dependents: string (nullable = true)<br/> |-- Education: integer (nullable = false)<br/> |-- Self_Employed: integer (nullable = false)<br/> |-- ApplicantIncome: integer (nullable = true)<br/> |-- CoapplicantIncome: double (nullable = true)<br/> |-- LoanAmount: integer (nullable = true)<br/> |-- Loan_Amount_Term: integer (nullable = true)<br/> |-- Credit_History: integer (nullable = true)<br/> |-- Property_Area: string (nullable = true)<br/> |-- Loan_Status: string (nullable = true)<br/> |-- Urban: integer (nullable = false)<br/> |-- Semiurban: integer (nullable = false)<br/> |-- Rural: integer (nullable = false)</span></pre><p id="8178" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们已经用三个新属性修改了<code class="fe mh mi mj mk b">Property Area</code>，所以它必须被删除。而<code class="fe mh mi mj mk b">Loan_ID</code>是所有客户的唯一属性，在预测中没有作用。对于性能，也应删除:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="7fd3" class="ms lf iq mk b gy mt mu l mv mw">drop_list = [‘Loan_ID’, ‘Property_Area’]</span><span id="93a3" class="ms lf iq mk b gy mx mu l mv mw">df = df.select([column for column in df.columns if column not in drop_list])</span></pre><p id="911b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在实现预测之前，我们最好做的另一个修改是对<code class="fe mh mi mj mk b">Dependents</code>进行类型转换。我们首先通过<code class="fe mh mi mj mk b">df.select("Dependents").distinct().show()</code>检查<code class="fe mh mi mj mk b">Dependents</code>的不同值:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="3f0e" class="ms lf iq mk b gy mt mu l mv mw">+----------+<br/>|Dependents|<br/>+----------+<br/>|         1|<br/>|         3|<br/>|         2|<br/>|         0|<br/>+----------+</span></pre><p id="3d63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如你所观察到的，虽然它有整数值，但它的类型是字符串。为了更好地预测，我们将把它转换为整数，并创建一个新的数据帧<code class="fe mh mi mj mk b">df</code>:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="cbcf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们有适当的数据来实现机器学习算法。为了对数据进行统计概述，我们收集数字特征，然后以统计方式对其进行描述:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="c47d" class="ms lf iq mk b gy mt mu l mv mw">import pandas as pd</span><span id="ceb4" class="ms lf iq mk b gy mx mu l mv mw">## gather numerical features</span><span id="16b0" class="ms lf iq mk b gy mx mu l mv mw">numerical_features = [t[0] for t in df.dtypes if t[1] == ‘int’ or t[1]==’double’]<br/>df_numeric = df.select(numerical_features).describe().toPandas().transpose()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi my"><img src="../Images/f0b2233186ac65dadbd8d683799b01c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4flWCkYJOWDyOWymbUxy4w.png"/></div></div></figure><p id="a9d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，作为一种统计操作，我们可以生成一个相关矩阵，它可以帮助我们理解特征之间的关系:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/01506fd6cfc66c4690febb45cc8ed5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zl4Js_-gMiW-2kCWvUlJIQ.png"/></div></div></figure><p id="3c54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">处理数据</strong></p><p id="0afe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Spark ML中，预测中使用的所有特性都应该是整数类型，或者应该转换为整数类型。现在，我们的数据框架中既有字符串形式的分类特征，也有整数形式的数字特征。分类特征首先将由<code class="fe mh mi mj mk b">StringIndexer</code>编码，然后通过一键编码，它们将可用于期望连续特征的算法，如逻辑回归。在此转换之前，让我们定义分类和数字特征:</p><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="0584" class="ms lf iq mk b gy mt mu l mv mw"># detect categorical columns:</span><span id="6670" class="ms lf iq mk b gy mx mu l mv mw">categorical_cols = [item[0] for item in df.dtypes if item[1].startswith(‘string’)][:1]</span><span id="8431" class="ms lf iq mk b gy mx mu l mv mw"># detect numerical columns:</span><span id="f88b" class="ms lf iq mk b gy mx mu l mv mw">numerical_cols = [item[0] for item in df.dtypes if item[1].startswith(‘int’) | item[1].startswith(‘double’)]</span></pre><p id="fc07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还没有准备好实现我们的机器学习算法。检测数据集中的缺失值是机器学习项目中的另一个重要任务。价值观缺失也可以看作是现实生活的凌乱。缺失值通常有几个原因，如数据输入过程中的人为错误、传感器读数不正确、数据处理流程中的软件错误等。</p><p id="2f38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将向我们显示哪个要素有多少缺失值:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="be2c" class="ms lf iq mk b gy mt mu l mv mw">[('Gender', 24),<br/> ('Dependents', 76),<br/> ('LoanAmount', 27),<br/> ('Loan_Amount_Term', 20),<br/> ('Credit_History', 79)]</span></pre><p id="224b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们用数据集中每个要素的模式和平均值替换缺失值。</p><p id="d686" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的脚本列出了缺失值的分类列和数字列:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="km kn ko kp gt mo mk mp mq aw mr bi"><span id="9a87" class="ms lf iq mk b gy mt mu l mv mw">cateogrical columns_miss: ['Gender']<br/>numerical columns_miss: ['Dependents', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']</span></pre><p id="5016" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们用每列的众数和平均值来填充这些缺失值:</p><p id="a537" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">使数据可用于机器学习</strong></p><p id="86a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此时，我们的数据集中没有缺失值。正如前面提到的，我们将用<code class="fe mh mi mj mk b">StringIndexer</code>和<code class="fe mh mi mj mk b">OneHotEncoderEstimator</code>来索引分类列。当<code class="fe mh mi mj mk b">StringIndexer</code>正在为每个分类特征分配索引时，<code class="fe mh mi mj mk b">StringIndexer</code>正在将分类列转换为独热编码向量。之后，我们通过转换特征的<code class="fe mh mi mj mk b">VectorAssembler</code>将所有的特征列放入一个向量中。这个过程可以定义为构建机器学习管道的阶段:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="8f42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您也可以在<a class="ae lb" href="https://docs.databricks.com/applications/machine-learning/mllib/binary-classification-mllib-pipelines.html" rel="noopener ugc nofollow" target="_blank"> Databricks </a>网站上访问该脚本。</p><p id="e617" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong></p><p id="d7d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文的第一部分中，我们转换了可用于机器学习算法的信用风险数据集，并对特征进行了分类。这些预处理过程被可视化以具有更好的概观。我们现在正在进行我们的项目。在下一部分中，我们将在PySpark中实现一个端到端的分类模型。</p><p id="d9a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><div class="na nb gp gr nc nd"><a href="https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">如何在Apache Spark 2.0中使用SparkSession</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">在Databricks中尝试这种笔记本通常，会话是两个或多个实体之间的交互。在计算机中…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">databricks.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr kv nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://spark.apache.org/docs/latest/ml-features" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">提取、转换和选择特征</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">本节介绍处理要素的算法，大致分为以下几组:提取:提取…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">spark.apache.org</p></div></div><div class="nm l"><div class="ns l no np nq nm nr kv nd"/></div></div></a></div></div></div>    
</body>
</html>