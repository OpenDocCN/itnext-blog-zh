<html>
<head>
<title>K8s Monitor Pod CPU and memory usage with Prometheus</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K8s使用Prometheus监控Pod CPU和内存使用情况</h1>
<blockquote>原文：<a href="https://itnext.io/k8s-monitor-pod-cpu-and-memory-usage-with-prometheus-28eec6d84729?source=collection_archive---------0-----------------------#2020-02-10">https://itnext.io/k8s-monitor-pod-cpu-and-memory-usage-with-prometheus-28eec6d84729?source=collection_archive---------0-----------------------#2020-02-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a74a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">找出你的Kubernetes豆荚实际使用多少资源，并可视化CPU节流。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/65bfb8941771971d31e302c76001f3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNnj2TkOM_PzXpQpPb0V3Q.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/photos/WEQbe2jBg40" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/WEQbe2jBg40</a></figcaption></figure><h2 id="88c2" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">部件</h2><ol class=""><li id="8c8c" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated">手动监控pod资源(本文)</li><li id="6979" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" href="https://medium.com/@wuestkamp/k8s-vertical-pod-autoscaling-fd9e602cbf81?source=friends_link&amp;sk=df7289cb35bcfdfa7f191546e6d555b6" rel="noopener">通过垂直pod自动缩放自动设置Pod资源</a></li></ol><h2 id="7f69" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">有关系的</h2><ol class=""><li id="f449" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated"><a class="ae ky" href="https://codeburst.io/practical-guide-to-kubernetes-scaling-1-pods-5a7ed08f4e8b?source=friends_link&amp;sk=22602bf9789af6112fa53e9d20c05ed0" rel="noopener" target="_blank">Kubernetes卧式容器自动缩放实用指南</a></li><li id="9257" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" href="https://codeburst.io/practical-guide-to-kubernetes-node-scaling-5a7fc3499a56?source=friends_link&amp;sk=ac4e04e5bc9a21197871ecdc8ccec911" rel="noopener" target="_blank">Kubernetes节点自动缩放实用指南</a></li></ol><h1 id="684e" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">我们在这里做什么？</h1><p id="eed7" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">我们将逐步完成监控Kubernetes pod使用多少资源(CPU或内存)的必要步骤。因此，我们来看看:</p><ul class=""><li id="0c16" class="lv lw it lx b ly nn ma no li np lm nq lq nr mf ns mh mi mj bi translated">CPU请求/限制/实际使用/节流</li><li id="2b32" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf ns mh mi mj bi translated">内存请求/限制/实际使用/终止</li></ul><p id="0f47" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">我们使用metrics-server、Grafana和Prometheus来完成这项工作。</p><h1 id="edfa" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">资源请求和限制</h1><h2 id="3d9f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">这些是什么？</h2><p id="dfed" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated"><a class="ae ky" href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-resource-requests-and-limits" rel="noopener ugc nofollow" target="_blank">这篇很棒的博文和视频</a>会让你了解最新情况。</p><h2 id="d5b1" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">我们为什么需要这些？</h2><p id="ff45" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">当您创建一个新的应用程序或将现有的应用程序迁移到Kubernetes时，您可能不知道它需要多少资源。尽管Kubernetes在每个pod(更准确地说是每个pod中的每个容器)都定义了资源限制和请求的情况下工作得最好。这控制节点上的pod调度。</p><p id="b671" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated"><strong class="lx iu">定义请求+限制将更有效地利用集群内的所有可用资源。</strong></p><h1 id="d29c" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">不需要的CPU节流错误</h1><p id="f959" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">设置任何CPU限制都会导致不必要的CPU节流，即使使用率没有达到其限制。阅读更多关于我的文章<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/kubernetes-resource-management-in-production-d5382c904ed1?source=friends_link&amp;sk=0c1dd3cb89f524f9d495a196a2cbb44b"> Kubernetes生产中的资源管理</a>。</p><h1 id="4c35" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">测试报告/应用程序</h1><p id="e5b2" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">您可以使用这个repo:<a class="ae ky" href="https://github.com/wuestkamp/k8s-example-resource-monitoring" rel="noopener ugc nofollow" target="_blank">https://github . com/wuestkamp/k8s-example-resource-monitoring</a></p><h2 id="fedf" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">图像</h2><p id="22b1" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">该应用程序由一个使用映像<code class="fe nw nx ny nz b">gcr.io/kubernetes-e2e-test-images/resource-consumer:1.5</code>的简单部署组成。它提供了一个HTTP端点，可以接收使用资源的命令:</p><pre class="kj kk kl km gt oa nz ob oc aw od bi"><span id="c57d" class="kz la it nz b gy oe of l og oh">curl --data "millicores=400&amp;durationSec=600" 10.12.0.11:8080/ConsumeCPU</span><span id="c779" class="kz la it nz b gy oi of l og oh">curl --data "megabytes=300&amp;durationSec=600" 10.12.0.11:8080/ConsumeMem</span></pre><p id="309d" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">这允许我们在一个正在运行的pod中操纵CPU和内存的使用(更多<a class="ae ky" href="https://github.com/kubernetes/kubernetes/tree/d52ecd5f70cdf5f13f919bab56cf08cd556a2e26/test/images/resource-consumer" rel="noopener ugc nofollow" target="_blank">在这里</a>)。</p><h2 id="716e" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">查看Grafana仪表板</h2><p id="65ce" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">测试应用程序附带安装和配置的Grafana+Prometheus。还有一个显示CPU和内存数据的仪表板(<code class="fe nw nx ny nz b">i/grafana/dashboard.json</code>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/2eb3887a9aecf5a26662501366880bba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpw98U_d-T3zBjSEuGCLug.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">测试应用中包含的仪表板</figcaption></figure><h1 id="ad2d" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">Kubernetes 1.16更改了指标</h1><blockquote class="ok ol om"><p id="582d" class="na nb on lx b ly nn ju nc ma no jx nd oo nt nf ng op nu ni nj oq nv nl nm mf im bi translated">移除cadvisor公制标签<code class="fe nw nx ny nz b">pod_name</code>和<code class="fe nw nx ny nz b">container_name</code>以符合仪器指南。任何匹配<code class="fe nw nx ny nz b">pod_name</code>和<code class="fe nw nx ny nz b">container_name</code>标签的Prometheus查询(例如cadvisor或kubelet probe metrics)必须更新为使用<code class="fe nw nx ny nz b">pod</code>和<code class="fe nw nx ny nz b">container</code>。(<a class="ae ky" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.16.md#removed-metrics" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></blockquote><p id="41bc" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">如果你使用的是Kubernetes 1.16及以上版本，你必须使用<strong class="lx iu"> pod </strong>而不是<strong class="lx iu"> pod_name </strong>和<strong class="lx iu"> container </strong>而不是<strong class="lx iu"> container_name </strong>。</p><h1 id="f929" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">中央处理器</h1><p id="2326" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">我们使用以下Prometheus查询:</p><pre class="kj kk kl km gt oa nz ob oc aw od bi"><span id="88d8" class="kz la it nz b gy oe of l og oh"># metrics are for k8s till 1.15<br/># for &gt;=1.16 use <em class="on">pod</em> instead of <em class="on">pod_name</em> and <em class="on">container</em> instead <em class="on">container_name</em></span><span id="2bb0" class="kz la it nz b gy oi of l og oh"># container usage<br/>rate(<strong class="nz iu">container_cpu_usage_seconds_total</strong>{pod=~"compute-.*", image!="", container_name!="POD"}[5m])<br/><br/># container requests<br/>avg(<strong class="nz iu">kube_pod_container_resource_requests_cpu_cores</strong>{pod=~"compute-.*"})<br/><br/># container limits<br/>avg(<strong class="nz iu">kube_pod_container_resource_limits_cpu_cores</strong>{pod=~"compute-.*"})<br/><br/># throttling<br/>rate(<strong class="nz iu">container_cpu_cfs_throttled_seconds_total</strong>{pod=~"compute-.*", container_name!="POD", image!=""}[5m])</span></pre><p id="8dec" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">关于单位(<a class="ae ky" href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container" rel="noopener ugc nofollow" target="_blank">更</a>):</p><ul class=""><li id="d2dd" class="lv lw it lx b ly nn ma no li np lm nq lq nr mf ns mh mi mj bi translated">500米= 500百万芯= 0.5芯</li><li id="9a74" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf ns mh mi mj bi translated">500米= 500毫cpu = 0.5 cpu</li></ul><h2 id="7470" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">没有使用</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/46c7f03d3af61c594fb21fdfd30a3c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jmXbLfY-9mSmx7G26dwLSw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod不使用任何CPU</figcaption></figure><p id="2b3b" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">上图显示了500米(绿色)的pod请求和700米(黄色)的限制。它还显示pod当前没有使用任何CPU(蓝色)，因此没有任何东西受到限制(红色)。</p><h2 id="34aa" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在极限范围内使用</h2><p id="6846" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">我们现在将pod的CPU使用率提高到600m:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/f15138b52c029d1cb6f6674f6e0f4d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HGvL-JK3HvuwcW6R4HRscg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod能够使用600毫升，没有节流</figcaption></figure><p id="f9a2" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">上图显示CPU使用率(蓝色)上升到600m。我们低于定义的限制(黄色)，因此看不到节流(红色)。</p><h2 id="3e15" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">超出限制的使用</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/7b151f87990978a323f767f5aa6f6fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cg9tWTc2sldjmBi4NyspUQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod尝试使用1个CPU，但受到限制</figcaption></figure><p id="bef5" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">上图显示pod的容器现在试图使用1000米(蓝色)，但这被限制为700米(黄色)。由于限制，我们看到节流正在进行(红色)。pod使用700m，节流300m，加起来就是它试图使用的1000m。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/138885dea350ee54e1e20219a899bf95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hej6ViTuLb1yr7qCaVUjg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod CPU使用率降至5亿</figcaption></figure><p id="bc51" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">如果我们将pod的CPU使用率降低到500m(蓝色)，与请求值(绿色)相同，我们会看到throttling(红色)再次降低到0。</p><p id="73e8" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated"><strong class="lx iu">我们希望避免CPU节流以获得最佳效率。</strong></p><h1 id="533e" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">记忆</h1><p id="3644" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">我们使用以下Prometheus查询:</p><pre class="kj kk kl km gt oa nz ob oc aw od bi"><span id="190c" class="kz la it nz b gy oe of l og oh"># metrics are for k8s till 1.15<br/># for &gt;=1.16 use <em class="on">pod</em> instead of <em class="on">pod_name</em> and <em class="on">container</em> instead <em class="on">container_name</em></span><span id="974e" class="kz la it nz b gy oi of l og oh"># container usage<br/><strong class="nz iu">container_memory_working_set_bytes</strong>{pod_name=~"compute-.*", image!="", container_name!="POD"}<br/><br/># container requests<br/>avg(<strong class="nz iu">kube_pod_container_resource_requests_memory_bytes</strong>{pod=~"compute-.*"})<br/><br/># container limits<br/>avg(<strong class="nz iu">kube_pod_container_resource_limits_memory_bytes</strong>{pod=~"compute-.*"})</span></pre><h2 id="19c0" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">没有使用</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/82a207018d361d20300dbe404aadebe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NDBPxJAOcDsrZ97S0ra6Kw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod不分配任何内存</figcaption></figure><p id="086e" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">在上图中，我们看到pod请求(绿色)250英里，限制(黄色)500英里，使用(蓝色)0内存。</p><h2 id="9f98" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在极限范围内使用</h2><p id="efff" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">我们现在将内存使用量提高到低于定义限制的值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/0e3a6cff47c4ea82b51d0463f6ffa9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ex1AM5cADrPF0Vq2uz_Vw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">400Mi的内存使用量</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/65218f312e5b788961552cea119b2e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3BNYA3xQXmmiL3PRrFklQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">内存使用量高达480毫升</figcaption></figure><h2 id="6397" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">超出限制的使用</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/3ad27073a4c1ffd0c7560eabd78b811e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1laDkFu0bEKs6n1iWEtZBg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pod尝试分配550英里</figcaption></figure><p id="21b8" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">当试图分配比设置的限制更多的内存时，Kubernetes会终止导致这种情况的进程(信号9)。如果容器作为入口点运行该进程，容器将重新启动。在上图中，主进程没有被终止，而只是一个子进程。因此，我们没有看到容器重启，但是内存使用下降到0。</p><p id="98a9" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">这导致一个警告事件(<code class="fe nw nx ny nz b">kubectl get events</code>):</p><pre class="kj kk kl km gt oa nz ob oc aw od bi"><span id="2434" class="kz la it nz b gy oe of l og oh">default     22s         Warning   OOMKilling   node/gke-resources-test-default-pool-6cad87bd-bgf4   Memory cgroup out of memory: Kill process 134119 (stress) score 1962 or sacrifice child</span><span id="ac2c" class="kz la it nz b gy oi of l og oh">Killed process 134119 (stress) total-vm:519288kB, anon-rss:508260kB, file-rss:268kB, shmem-rss:0kB</span></pre><p id="4c36" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">要将这些k8s事件导入Prometheus/Grafana，例如设置Prometheus警报，可以使用<a class="ae ky" href="https://github.com/caicloud/event_exporter" rel="noopener ugc nofollow" target="_blank"> event_exporter </a>。</p><h1 id="7991" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">阅读更多</h1><p id="1a4b" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated"><a class="ae ky" href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/" rel="noopener ugc nofollow" target="_blank">https://kubernetes . io/docs/tasks/configure-pod-container/assign-memory-resource</a></p><p id="e264" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated"><a class="ae ky" href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/" rel="noopener ugc nofollow" target="_blank">https://kubernetes . io/docs/tasks/configure-pod-container/assign-CPU-resource</a></p><h1 id="d06a" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">下一步是什么？</h1><p id="f5ed" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">接下来，我将深入了解垂直扩展pod资源的概念，它如何与Kubernetes一起工作，以及如何使用Grafana+Prometheus来可视化它。</p><p id="7c80" class="pw-post-body-paragraph na nb it lx b ly nn ju nc ma no jx nd li nt nf ng lm nu ni nj lq nv nl nm mf im bi translated">最后，我想让集群根据应用程序的需求自动调整请求和限制会很棒。至少在可能的范围内。</p><h1 id="54a7" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">成为Kubernetes认证</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://killer.sh"><div class="gh gi ox"><img src="../Images/cf3901a56841fcb55f9e4e17b9f07672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Kbj17_6VncUuoBqNsAzzg.png"/></div></a><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://killer.sh" rel="noopener ugc nofollow" target="_blank"> https://killer.sh </a></figcaption></figure></div></div>    
</body>
</html>