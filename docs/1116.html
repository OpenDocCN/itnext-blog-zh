<html>
<head>
<title>Basics of Text Analysis &amp; Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本分析和可视化基础</h1>
<blockquote>原文：<a href="https://itnext.io/basics-of-text-analysis-visualization-1978de48af47?source=collection_archive---------0-----------------------#2018-07-24">https://itnext.io/basics-of-text-analysis-visualization-1978de48af47?source=collection_archive---------0-----------------------#2018-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/52512e8fb9222cc602af98f3d971424f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XPIHXKkCfXS0B-CHd80FTw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">由前2000个GitHub存储库的READMEs组成的二元标记云</figcaption></figure><blockquote class="kc"><p id="fcb7" class="kd ke iq bd kf kg kh ki kj kk kl km dk translated">好的软件是平易近人的、一致的、自我解释的、可教人的，并且是为人类服务的——<a class="ae kn" href="https://medium.com/@mbostock/what-makes-software-good-943557f8a488" rel="noopener"><strong class="ak">迈克·博斯托克</strong> </a></p></blockquote><p id="6c05" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk km ij bi translated">作为一名UX工程师，我为用户考虑了很多。当编写软件时，用户的需求是最重要的。然而，我经常使用、贡献和编写开源软件。<strong class="kq ir">开源项目在设计时也需要考虑到他们的用户、<em class="ll">其他开发者</em>。</strong></p><p id="5413" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">先前，我讨论了一个旨在调查软件工程师描述他们工作的方式的项目。目标是通过理解如何描述好的软件来理解是什么造就了好的软件。我对“好”的定义是评价很高或者盯着看。</p><p id="793e" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">我搜集了GitHub上前2000个知识库的阅读材料，并可视化了出现频率最高的单词。虽然我不是数据科学家，但我经常分析和可视化数据集，并希望分享这个项目的结果和发现。</p><p id="d980" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">关于初始结果和上下文，请参见<a class="ae kn" href="https://medium.com/@tbarrasso/open-source-words-part-2-ce1077305a32" rel="noopener">开源单词</a> <a class="ae kn" href="https://medium.com/@tbarrasso/open-source-words-part-1-72f059c2730" rel="noopener"> — </a> <a class="ae kn" href="https://medium.com/@tbarrasso/open-source-words-part-2-ce1077305a32" rel="noopener">第3部分</a></p><p id="a928" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">有关提取和清理的更多信息，请参见<a class="ae kn" href="https://medium.com/@tbarrasso/open-source-words-part-1-72f059c2730" rel="noopener">开源单词—第1部分</a></p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="77d9" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">标签云</h1><p id="36ad" class="pw-post-body-paragraph ko kp iq kq b kr mw kt ku kv mx kx ky kz my lb lc ld mz lf lg lh na lj lk km ij bi translated">最简单和最常见的文本可视化形式是<a class="ae kn" href="https://en.wikipedia.org/wiki/Tag_cloud" rel="noopener ugc nofollow" target="_blank">标签(或单词)云</a>。它们描绘了根据标签频率、分类或重要性在空间中排列的不同大小、颜色和位置的<strong class="kq ir">标签</strong>。</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/38245f8dc7ac3197007389806b204d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y68Prz3fN4CGJS4l4DpXEg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来自2000个GitHub知识库的READMEs的Word cloud</figcaption></figure><p id="401a" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">在这个简单的例子中，颜色和位置是任意的，但是字体大小根据词频而变化。因为即使计数也很复杂，更具体地说，这些单词的大小根据<strong class="kq ir">总词频</strong>而非唯一词频(每个文档计数一次)而变化。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="292a" class="nl lz iq nh b gy nm nn l no np">import ntlk</span><span id="3afc" class="nl lz iq nh b gy nq nn l no np">unique_frequencies = dict()<br/>total_frequencies = dict()</span><span id="f168" class="nl lz iq nh b gy nq nn l no np">for readme in reasmes:<br/>    words = nltk.word_tokenize(readme)<br/>    fdist = nltk.FreqDist(words)<br/>    for word, freq in fdist.most_common(50):<br/>        total_frequencies[word] += freq # total count<br/>        unique_frequencies[word] += 1 # unique count</span></pre><p id="0182" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">这是一个统计数据集中单词的总频率和唯一频率的示例。Tim Strehle有一个更加全面的例子，包括大小写规范化、标记化、词性标注，以及删除T2停用词、标点符号等。在分析之前，这种类型的清理通常是必要的。</p><h1 id="71d1" class="ly lz iq bd ma mb nr md me mf ns mh mi mj nt ml mm mn nu mp mq mr nv mt mu mv bi translated">搭配云</h1><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/3a85d7c732ce6d0950390478aa3f9714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fN1O6IVU_71GBmCBrSKCBg.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kn" href="http://www.wordle.net/" rel="noopener ugc nofollow" target="_blank"> Wordle </a>来自<a class="ae kn" href="https://quickshout.blogspot.com/2011/11/on-surface-of-it-just-word-looks-just.html" rel="noopener ugc nofollow" target="_blank"> Nik的QuickShout </a>的双字母云</figcaption></figure><p id="59a8" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">搭配云是标签云的另一种变体，它将经常搭配的特定单词可视化(发现它们紧挨着彼此)。它们属于N元问题的一般类别，最常见的例子是二元问题(两个)和三元问题(三个)。</p><p id="e3d5" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">n元语法在基因组学中有许多应用，并用于语法校正和文本压缩的算法中。上面的英雄图像是README数据集中最常见的单词对的双字母组合。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="8940" class="nl lz iq nh b gy nm nn l no np">import nltk<br/>from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures</span><span id="1c98" class="nl lz iq nh b gy nq nn l no np">bi_dict = dict()<br/>bg_measures = BigramAssocMeasures()</span><span id="b1ea" class="nl lz iq nh b gy nq nn l no np">for readme in readmes:<br/>    words = nltk.word_tokenize(readme)<br/>    bi_finder = BigramCollocationFinder.from_words(words)<br/>    bi_collocs = bi_finder.nbest(bg_measures.likelihood_ratio, 10)</span><span id="9f51" class="nl lz iq nh b gy nq nn l no np">    for colloc in bi_collocs:<br/>        bi_dict[colloc] += 1</span></pre><p id="f44b" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">上面是一个使用<a class="ae kn" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk </a>(自然语言工具包)将文本数据集处理成二元语法的例子。</p><h1 id="4f44" class="ly lz iq bd ma mb nr md me mf ns mh mi mj nt ml mm mn nu mp mq mr nv mt mu mv bi translated">情感分析</h1><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nx"><img src="../Images/b24d2b7fcaebce94e01bc74cced3c7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Hm14HbhXyIZ3y9p76WCFw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kn" href="https://github.com/cjhutto/vaderSentiment" rel="noopener ugc nofollow" target="_blank"> VADER情感分析</a>，来自2000个阅读量的句子的复合得分分布；1为正，-1为负</figcaption></figure><p id="30be" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">情感分析是基于作者对主题的态度对文本进行计算分类的过程。在评论线程等社交媒体上，这对于了解用户对产品的评价是正面的、负面的还是中性的非常有用。它广泛适用于机器学习分类算法，并且在使用相关数据集进行训练时效果最佳。</p><p id="d9eb" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">出于学习的目的，我使用了VADER情感分析，因为它与nltk打包在一起。“VADER”是一个词汇和基于规则的情绪分析工具，专门针对社交媒体中表达的情绪以下是在Python中使用VADER的示例:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="72e7" class="nl lz iq nh b gy nm nn l no np">import nltk<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer</span><span id="aeba" class="nl lz iq nh b gy nq nn l no np">sid = SentimentIntensityAnalyzer()<br/>sentiment_summary = dict()</span><span id="472f" class="nl lz iq nh b gy nq nn l no np">for readme in readmes:<br/>    sentences = nltk.tokenize.sent_tokenize(readme)<br/>    for sentence in sentences:<br/>        sentiment_score = sid.polarity_scores(sentence)</span><span id="d970" class="nl lz iq nh b gy nq nn l no np">        if sentiment_score["compound"] == 0.0:<br/>            sentiment_summary["neutral"] += 1<br/>        elif sentiment_score["compound"] &gt; 0.0:<br/>            sentiment_summary["positive"] += 1<br/>        else:<br/>            sentiment_summary["negative"] += 1</span></pre><p id="a26a" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">在上图中，将近2，000个READMEs被标记为超过120，000个句子，综合得分为0.143。一种解释可能是，<strong class="kq ir">平均来说，开发人员积极地谈论他们的库和项目。</strong>然而，将近一半的复合得分是中性的，这表明开发者在写作时没有归因于情感。</p><p id="4f33" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">值得注意的是，这些结果远非结论性的，特别是在缺乏相关训练集和依赖社交媒体语料库的情况下。这只是为了说明的目的。虽然我不认为这个分析是正确的，但我确实觉得它很有趣。这是一个带有强烈否定句(<code class="fe ny nz oa nh b">compound &lt; -0.95</code>)的例句:</p><blockquote class="ob oc od"><p id="ad22" class="ko kp ll kq b kr lm kt ku kv ln kx ky oe lo lb lc of lp lf lg og lq lj lk km ij bi translated">如果问题仍未解决，请参阅常见问题指南:屏蔽无法安装:卷曲错误权限被拒绝错误校验和不匹配错误来源不存在错误参数数量错误未列出原因卸载错误地将屏蔽报告为未安装错误:未知命令:屏蔽错误我的问题未列出请求屏蔽请求将自动关闭。</p></blockquote><p id="55c0" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">我的假设是，像<em class="ll">失败、</em>和<em class="ll">错误</em>这样的词负责将这个例子归类为强烈否定。</p><p id="d7fe" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">更多信息，请参见<a class="ae kn" href="https://medium.com/@sharonwoo/sentiment-analysis-with-nltk-422e0f794b8" rel="noopener">NLTK/VADER的情感分析</a></p><h1 id="080a" class="ly lz iq bd ma mb nr md me mf ns mh mi mj nt ml mm mn nu mp mq mr nv mt mu mv bi translated">其他分析</h1><p id="8b38" class="pw-post-body-paragraph ko kp iq kq b kr mw kt ku kv mx kx ky kz my lb lc ld mz lf lg lh na lj lk km ij bi translated">本文没有涉及<a class="ae kn" href="https://en.wikipedia.org/wiki/Topic_model" rel="noopener ugc nofollow" target="_blank">主题建模</a>、<a class="ae kn" href="https://machinelearningmastery.com/gentle-introduction-text-summarization/" rel="noopener ugc nofollow" target="_blank">总结</a>、<a class="ae kn" href="https://medium.com/@acrosson/extract-subject-matter-of-documents-using-nlp-e284c1c61824" rel="noopener">主题识别</a>、<a class="ae kn" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank">词干提取</a>、<a class="ae kn" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank">实体识别</a>等诸多主题。</p><p id="1bdb" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">无论是使用这个README数据集，还是其他数据集，我都打算继续探索数据科学和可视化的其他领域。随着我的学习，我会在<a class="ae kn" href="https://medium.com/@tbarrasso" rel="noopener">媒体</a>上分享我的过程和结果，以及在<a class="ae kn" href="https://github.com/Tombarr" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上分享数据和源代码。</p><p id="7642" class="pw-post-body-paragraph ko kp iq kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk km ij bi translated">对于自然语言处理方法、可视化和示例的全面概述，我推荐以下资源:</p><ul class=""><li id="7982" class="oh oi iq kq b kr lm kv ln kz oj ld ok lh ol km om on oo op bi translated"><a class="ae kn" href="https://doc.lagout.org/Others/Data%20Mining/Text%20Mining%20and%20Visualization_%20Case%20Studies%20using%20Open-Source%20Tools%20%5BHofmann%20%26%20Chisholm%202015-12-18%5D.pdf" rel="noopener ugc nofollow" target="_blank">文本挖掘和可视化</a></li><li id="54eb" class="oh oi iq kq b kr oq kv or kz os ld ot lh ou km om on oo op bi translated"><a class="ae kn" href="https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/" rel="noopener ugc nofollow" target="_blank">理解终极指南&amp;实现自然语言处理</a></li><li id="052f" class="oh oi iq kq b kr oq kv or kz os ld ot lh ou km om on oo op bi translated"><a class="ae kn" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">维基百科:自然语言处理</a></li></ul></div></div>    
</body>
</html>