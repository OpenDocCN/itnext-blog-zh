<html>
<head>
<title>Running Spark Jobs on Amazon EMR with Apache Airflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Airflow在Amazon EMR上运行Spark作业</h1>
<blockquote>原文：<a href="https://itnext.io/running-spark-jobs-on-amazon-emr-with-apache-airflow-2e16647fea0c?source=collection_archive---------1-----------------------#2020-12-22">https://itnext.io/running-spark-jobs-on-amazon-emr-with-apache-airflow-2e16647fea0c?source=collection_archive---------1-----------------------#2020-12-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="df23" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在AWS上使用新的Amazon Managed Workflows for Apache air flow(亚马逊MWAA)服务</h2></div><h1 id="a342" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="e024" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本系列的第一篇文章中，我们探索了几种使用AWS服务在Amazon EMR上运行PySpark应用程序的方法，包括AWS CloudFormation、AWS Step函数和用于Python的AWS SDK。这个系列的第二篇文章将使用最近宣布的<a class="ae lw" href="https://aws.amazon.com/managed-workflows-for-apache-airflow/" rel="noopener ugc nofollow" target="_blank">亚马逊管理的Apache Airflow </a>(亚马逊MWAA)服务来检查在亚马逊EMR上运行的Spark作业。</p><h2 id="41a6" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated"><strong class="ak">亚马逊EMR </strong></h2><p id="3aff" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">据<a class="ae lw" href="https://aws.amazon.com/emr" rel="noopener ugc nofollow" target="_blank"> AWS </a>介绍，Amazon Elastic MapReduce(Amazon EMR)是一个基于云的大数据平台，使用常见的开源工具处理大量数据，如<a class="ae lw" href="https://aws.amazon.com/emr/features/spark/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>、<a class="ae lw" href="https://aws.amazon.com/emr/features/hive/" rel="noopener ugc nofollow" target="_blank"> Hive </a>、<a class="ae lw" href="https://aws.amazon.com/emr/features/hbase/" rel="noopener ugc nofollow" target="_blank"> HBase </a>、<a class="ae lw" href="https://aws.amazon.com/blogs/big-data/use-apache-flink-on-amazon-emr/" rel="noopener ugc nofollow" target="_blank"> Flink </a>、<a class="ae lw" href="https://aws.amazon.com/emr/features/hudi/" rel="noopener ugc nofollow" target="_blank">胡迪</a>和<a class="ae lw" href="https://zeppelin.apache.org/" rel="noopener ugc nofollow" target="_blank"> Zeppelin </a>、<a class="ae lw" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter </a>和<a class="ae lw" href="https://aws.amazon.com/emr/features/presto/" rel="noopener ugc nofollow" target="_blank">prest使用Amazon EMR，数据分析师、工程师和科学家可以自由地探索、处理和可视化数据。EMR负责调配、配置和调整底层计算集群，使您能够专注于运行分析。</a></p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/20c8ad4d56ed33b8937036d9f06d1538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-d1KZWCCB8gqj_KIjNKQlQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Amazon EMR控制台的集群摘要选项卡</figcaption></figure><p id="bfe9" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">用户与EMR的交互方式多种多样，这取决于他们的具体需求。例如，您可以创建一个瞬态EMR集群，使用Spark、Hive或Presto执行一系列数据分析作业，并在作业完成后立即终止集群。您只需为集群启动和运行的时间付费。或者，对于时间关键型工作负载或持续的高容量作业，您可以选择创建一个或多个持久的、<a class="ae lw" href="https://aws.amazon.com/about-aws/whats-new/2019/05/amazon-emr-now-supports-multiple-master-nodes-to-enable-high-availability-for-hbase-clusters/" rel="noopener ugc nofollow" target="_blank">高可用性的</a> EMR集群。这些集群<a class="ae lw" href="https://aws.amazon.com/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/" rel="noopener ugc nofollow" target="_blank">自动水平扩展</a>计算资源，包括使用<a class="ae lw" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html" rel="noopener ugc nofollow" target="_blank"> EC2 Spot实例</a>，以满足处理需求，最大限度地提高性能和成本效益。</p><p id="9fa2" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">AWS目前提供5.x和6.x版本的亚马逊EMR。Amazon EMR的每个主要和次要版本都提供了近25个不同的流行开源大数据应用程序的增量版本供选择，Amazon EMR将在创建集群时安装和配置这些应用程序。最新的<a class="ae lw" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html" rel="noopener ugc nofollow" target="_blank">亚马逊EMR版本</a>是亚马逊EMR版本6.2.0和亚马逊EMR版本5.32.0。</p><h2 id="7266" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">亚马逊管理的Apache Airflow工作流(MWAA)</h2><p id="cd7e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae lw" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Airflow </a>是一个流行的开源平台，旨在调度和监控工作流。根据<a class="ae lw" href="https://en.wikipedia.org/wiki/Apache_Airflow" rel="noopener ugc nofollow" target="_blank">维基百科</a>的说法，Airbnb于2014年创建了Airflow，以管理该公司日益复杂的工作流程。项目从一开始就做开源，成为2016年<a class="ae lw" href="https://incubator.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache孵化器</a>项目，2019年顶级Apache软件基金会项目(TLP)。</p><p id="7b7f" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">许多组织使用Amazon EC2或Amazon EKS等计算服务在AWS上构建、管理和维护Apache Airflow。亚马逊最近宣布<a class="ae lw" href="https://aws.amazon.com/managed-workflows-for-apache-airflow/" rel="noopener ugc nofollow" target="_blank">亚马逊管理阿帕奇气流</a>(亚马逊MWAA)的工作流程。随着亚马逊MWAA<a class="ae lw" href="https://aws.amazon.com/blogs/aws/introducing-amazon-managed-workflows-for-apache-airflow-mwaa/" rel="noopener ugc nofollow" target="_blank">于2020年11月发布</a>，AWS客户现在可以专注于开发工作流自动化，而将气流管理留给AWS。亚马逊MWAA可以作为<a class="ae lw" href="https://aws.amazon.com/step-functions/" rel="noopener ugc nofollow" target="_blank"> AWS步骤函数</a>的替代品，用于AWS上的工作流自动化。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/fbd6fe3fdc5f51c0cd9b52ae0c81e4c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wtA_PN9NKQboamT6rFFmA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache气流用户界面</figcaption></figure><p id="cb0c" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">Apache <a class="ae lw" href="http://airflow.apache.org/blog/airflow-two-point-oh-is-here/" rel="noopener ugc nofollow" target="_blank">最近宣布</a>2020年12月17日发布气流2.0.0。气流最新的1.x版本是1.10.14，发布于2020年12月12日。然而，在这篇文章发表时，亚马逊MWAA正在运行2020年8月25日发布的<a class="ae lw" href="https://github.com/apache/airflow/releases/tag/1.10.12" rel="noopener ugc nofollow" target="_blank"> Airflow 1.10.12 </a>。确保在为亚马逊MWAA开发工作流时，使用正确的<a class="ae lw" href="https://airflow.apache.org/docs/apache-airflow/1.10.12/" rel="noopener ugc nofollow" target="_blank"> Apache Airflow 1.10.12文档</a>。</p><p id="9ea5" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">亚马逊MWAA服务可以使用AWS管理控制台，以及使用最新版本的<a class="ae lw" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/mwaa.html" rel="noopener ugc nofollow" target="_blank"> AWS SDK </a>和<a class="ae lw" href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/mwaa/index.html" rel="noopener ugc nofollow" target="_blank"> AWS CLI </a>的<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-actions-resources.html" rel="noopener ugc nofollow" target="_blank">亚马逊MWAA API </a>获得。</p><p id="9b00" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">Airflow有一种机制，允许您扩展其功能并与其他系统集成。鉴于其集成能力，Airflow对AWS有广泛的支持，包括亚马逊EMR、亚马逊S3、AWS Batch、亚马逊RedShift、亚马逊DynamoDB、AWS Lambda、亚马逊Kinesis和亚马逊SageMaker。除了对亚马逊S3的支持，大多数AWS集成可以在气流代码库的<a class="ae lw" href="https://github.com/apache/airflow/tree/master/airflow/contrib" rel="noopener ugc nofollow" target="_blank">贡献</a>部分的<a class="ae lw" href="https://github.com/apache/airflow/tree/master/airflow/contrib/hooks" rel="noopener ugc nofollow" target="_blank">钩子</a>、<a class="ae lw" href="https://github.com/apache/airflow/tree/master/airflow/contrib/secrets" rel="noopener ugc nofollow" target="_blank">秘密</a>、<a class="ae lw" href="https://github.com/apache/airflow/tree/master/airflow/contrib/sensors" rel="noopener ugc nofollow" target="_blank">传感器</a>和<a class="ae lw" href="https://github.com/apache/airflow/tree/master/airflow/contrib/sensors" rel="noopener ugc nofollow" target="_blank">操作符</a>中找到。</p><h1 id="185e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">入门指南</h1><h2 id="7241" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">源代码</h2><p id="1ec8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用这个<code class="fe ne nf ng nh b">git clone</code>命令，下载这篇文章的<a class="ae lw" href="https://github.com/garystafford/aws-airflow-demo" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>到你的本地环境。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="a739" class="lx kj it nh b gy nm nn l no np">git clone --branch main --single-branch --depth 1 --no-tags \<br/>    https://github.com/garystafford/aws-airflow-demo.git</span></pre><h2 id="6d1d" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">初步步骤</h2><p id="5fcc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这篇文章假设读者已经完成了前一篇文章中的演示，<a class="ae lw" href="https://medium.com/swlh/running-pyspark-applications-on-amazon-emr-e536b7a865ca" rel="noopener">在Amazon EMR方法上运行PySpark应用程序，以便与Amazon Elastic MapReduce上的PySpark进行交互</a>。这篇文章将重用许多上一篇文章的AWS资源，包括EMR VPC、子网、安全组、AWS粘合数据目录、亚马逊S3桶、EMR角色、EC2密钥对、AWS系统管理器参数存储参数、PySpark应用程序和Kaggle数据集。</p><h2 id="a487" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">配置亚马逊MWAA</h2><p id="09d2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">创建新的MWAA环境最简单的方法是通过AWS管理控制台。我强烈建议您在继续之前查看一下亚马逊MWAA的<a class="ae lw" href="https://aws.amazon.com/managed-workflows-for-apache-airflow/pricing/" rel="noopener ugc nofollow" target="_blank">定价</a>。即使在空闲时，这项服务的运营成本也可能非常高，最小的环境级别每月可能高达数百美元。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/46ac50cbdc4209a83d6b993d1f6cbb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSsYrpGSX_UFy-jc0SB1HQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="3cc8" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">使用控制台，创建一个新的亚马逊MWAA环境。亚马逊MWAA界面将引导你完成创建过程。注意现在的‘气流版本’，<code class="fe ne nf ng nh b">1.10.12</code>。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/e5261b993e1f1f0f55368230feec9214.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hJVxmAoglwW_EQZhturhA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="7199" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">亚马逊MWAA需要一个亚马逊S3桶来存储气流资产。创建一个新的亚马逊S3桶。根据<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-s3-bucket.html" rel="noopener ugc nofollow" target="_blank">文档</a>，桶必须以前缀<code class="fe ne nf ng nh b">airflow-</code>开始。您还必须在Bucket上启用<a class="ae lw" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html" rel="noopener ugc nofollow" target="_blank"> Bucket版本控制</a>。在bucket中指定一个<code class="fe ne nf ng nh b">dags</code>文件夹来存储气流的<a class="ae lw" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts.html#core-ideas" rel="noopener ugc nofollow" target="_blank">有向无环图</a> (DAG)。将接下来的两个选项留空，因为我们没有额外的Airflow插件或额外的Python包需要安装。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/a9ea6f1dfc47898bbf20e22f9af87283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-aRgk_LmDFQy-yh2ClSNA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="5619" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">借助亚马逊MWAA，您的数据在默认情况下是安全的，因为工作负载运行在他们自己的亚马逊虚拟私有云(亚马逊VPC)内。作为MWAA环境创建过程的一部分，您可以选择让AWS创建一个MWAA·VPC云形成堆栈。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/2389855af59e881b3833a82b2f06689a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8JUGKOAbEFu_ZtcfnArMg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="e62d" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">在本演示中，选择让MWAA创建一个新的VPC和相关的网络资源。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/b47f8b2be16a079bff59755455193df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vHMl_2McOx-ZvH_rMZ65sQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">AWS CloudFormation创建堆栈控制台</figcaption></figure><p id="90a8" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">MWAA CloudFormation堆栈包含大约22个AWS资源，包括一个VPC、一对公共和私有子网、路由表、一个互联网网关、两个NAT网关和相关的弹性IP(EIP)。更多细节见<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-create.html" rel="noopener ugc nofollow" target="_blank"> MWAA文档</a>。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/70de5324f62d3117a9ad415df1fd8c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtpqtEP1lor_ToLpBv4LNQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">AWS CloudFormation创建堆栈控制台</figcaption></figure><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/a7caf5e5bc6d1da7f63f1c4f6adc5fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lSFW40J43PBZ241nP-f_jQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="e10f" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">作为亚马逊MWAA网络配置的一部分，您必须决定您希望对Airflow的web访问是公开的还是私有的。网络配置的详细信息可在<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-create.html" rel="noopener ugc nofollow" target="_blank"> MWAA文档</a>中找到。对于这个演示，我选择公共web服务器访问，但是为了更高的安全性，建议选择私有。使用公共选项时，AWS仍然需要IAM身份验证来登录AWS管理控制台，以便访问Airflow UI。</p><p id="9103" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">您必须选择一个现有的VPC安全组，或者让MWAA创建一个新的组。在本演示中，选择让MWAA为您创建一个安全组。</p><p id="cd9c" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">最后，根据您的需求规模，为气流选择适当大小的环境类别。对于这个演示来说，<code class="fe ne nf ng nh b">mw1.small</code>类就足够了。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/1dfc0e4a83b2b640a1759961330966c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mA3Gz_pCALLG-y3L2D5hvQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><p id="74ad" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">最后，对于权限，您必须选择一个现有的Airflow执行服务角色或创建一个新角色。在本演示中，创建一个新的气流服务角色。我们稍后将添加额外的权限。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/3d0708eb15d606426000198088e3d373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1FmVZ5idQ_nZYKpN9QW-w.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境创建流程</figcaption></figure><h2 id="52b8" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">气流执行角色</h2><p id="980a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">作为本次演示的一部分，我们将使用气流在EMR上运行Spark作业(EMR步骤)。为了允许气流与EMR交互，我们必须增加新的气流执行角色的默认权限。其他权限包括允许新的气流角色使用<code class="fe ne nf ng nh b">iam:PassRole</code>承担EMR角色。对于这个演示，我们将包括两个默认的EMR服务和作业流角色，<code class="fe ne nf ng nh b">EMR_DefaultRole</code>和<code class="fe ne nf ng nh b">EMR_EC2_DefaultRole</code>。我们还将包括在<a class="ae lw" href="https://medium.com/swlh/running-pyspark-applications-on-amazon-emr-e536b7a865ca" rel="noopener">上一篇文章</a>、<code class="fe ne nf ng nh b">EMR_DemoRole</code>和<code class="fe ne nf ng nh b">EMR_EC2_DemoRole</code>中创建的相应自定义EMR角色。对于本演示，气流服务角色还需要三个特定的EMR权限，如下所示。在这篇文章的后面，Airflow还将从S3读取文件，这需要<code class="fe ne nf ng nh b">s3:GetObject</code>的许可。</p><p id="a44d" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">通过导入项目的JSON文件<code class="fe ne nf ng nh b">iam_policy/airflow_emr_policy.json</code>创建一个新策略，并将这个新策略附加到Airflow服务角色。确保用您自己的帐户ID更新文件中的AWS帐户ID。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">气流EMR IAM策略</figcaption></figure><p id="71f2" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">由MWAA创建的气流服务角色如下所示，并附有新策略。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/a8d808c119dd1e337a95fe81d31a5aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELbMCz4Zgcb-Uvgt77fPPA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">附加了新策略的气流执行服务角色</figcaption></figure><h2 id="ccc5" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">最终建筑</h2><p id="5aa3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">下面是帖子演示的最终高层架构。该图以红色显示了DAG运行请求的大致路由。该图包括一个可选的<a class="ae lw" href="https://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html" rel="noopener ugc nofollow" target="_blank"> S3网关VPC端点</a>，在帖子中没有详细说明，但建议用于额外的安全性。据<a class="ae lw" href="https://docs.aws.amazon.com/vpc/latest/userguide/endpoint-services-overview.html" rel="noopener ugc nofollow" target="_blank"> AWS </a>称，VPC端点使您能够将您的VPC私下连接到受支持的AWS服务和由AWS PrivateLink支持的VPC端点服务，而无需互联网网关。在这种情况下，MWAA VPC和亚马逊S3之间的私人连接。还可以创建一个<a class="ae lw" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/interface-vpc-endpoint.html" rel="noopener ugc nofollow" target="_blank"> EMR接口VPC端点</a>来安全地将流量从MWAA直接路由到EMR，而不是通过互联网连接。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ns"><img src="../Images/af3c9599b5480aa51b6be4f692686f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I-gGoXjVk4BaW3WxDVdJJg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">演示亚马逊MWAA和亚马逊EMR架构</figcaption></figure><h2 id="b580" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">亚马逊MWAA环境</h2><p id="8a23" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">新的MWAA环境将包括到气流UI的链接。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/75448148f9990178057ed0fbe4657976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0L3T1r5Gpksien0BUOQ6ZA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">亚马逊MWAA环境控制台</figcaption></figure><h2 id="d74d" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">气流UI</h2><p id="964c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用提供的链接，您应该能够使用web浏览器访问Airflow UI。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/5a901004f11d124edb623c4bfbd319f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BwGmPipesUCHPhAYpadiNg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache气流用户界面</figcaption></figure><h1 id="7fec" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">我们的第一只狗</h1><p id="200d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">亚马逊MWAA文档包括一个<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/samples-emr.html" rel="noopener ugc nofollow" target="_blank">示例DAG </a>，它包含Spark自带的几个示例程序SparkPi<a class="ae lw" href="https://spark.apache.org/docs/latest/#running-the-examples-and-shell" rel="noopener ugc nofollow" target="_blank">中的一个。我已经创建了一个类似的DAG，包含在GitHub项目中，<code class="fe ne nf ng nh b">dags/emr_steps_demo.py</code>。DAG将创建一个最小规模的单节点EMR群集，没有核心或任务节点。然后DAG将使用该集群向Spark提交<code class="fe ne nf ng nh b">calculate_pi</code>作业。一旦作业完成，DAG将终止EMR群集。</a></p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">火花Pi气流DAG</figcaption></figure><p id="547e" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">上传DAG到气流S3桶的<code class="fe ne nf ng nh b">dags</code>目录。在下面的AWS CLI命令中替换您的气流S3桶名称，然后从项目的根目录运行它。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="adb1" class="lx kj it nh b gy nm nn l no np">aws s3 cp dags/spark_pi_example.py \<br/>    s3://<strong class="nh iu"><em class="nt">&lt;your_airflow_bucket_name&gt;</em></strong>/dags/</span></pre><p id="6442" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">DAG，<code class="fe ne nf ng nh b">spark_pi_example</code>，应该会自动出现在气流UI中。单击“Trigger DAG”创建新的EMR集群并启动Spark作业。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/9213868f9dadd742bcce10aab1e87ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IFpH8u_nNQTPdBJ6S4CfaA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow用户界面的DAGs选项卡</figcaption></figure><p id="3e95" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">DAG没有可选的配置作为JSON输入。选择“Trigger”提交作业，如下所示。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/e6a64f71385bab47dd6865905affd22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZmQ9TbFDWXxxO4jeH4IBg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow用户界面的触发器DAG页面</figcaption></figure><p id="dc7f" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">DAG应该成功完成所有三个<a class="ae lw" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts.html#core-ideas" rel="noopener ugc nofollow" target="_blank">任务</a>，如下面DAG的“图表视图”选项卡所示。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/4db537dc21a5214f65ddb64d8b800a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RKOoN0GvkdgFDjvi0-Lmeg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow UI的DAG图形视图</figcaption></figure><p id="33cf" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">切换到EMR控制台，您应该看到正在创建单节点EMR集群。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/1958469fcc7fbb20b0c6cfae6e2d0f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*coq8_5kbAqmyc5GzWLr1FA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Amazon EMR控制台的摘要选项卡</figcaption></figure><p id="2521" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">在“Steps”选项卡上，您应该看到“calculate _ pi”Spark作业已经提交，正在等待集群准备运行。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/5e89db8081b84c1aa18b52eb70152b58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJMwajirZLRoqAH63QaVqg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Amazon EMR控制台的步骤选项卡</figcaption></figure><h2 id="aae5" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">以编程方式触发Dag</h2><p id="c001" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">亚马逊MWAA服务可以使用AWS管理控制台，以及使用最新版本的<a class="ae lw" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/mwaa.html" rel="noopener ugc nofollow" target="_blank"> AWS SDK </a>和<a class="ae lw" href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/mwaa/index.html" rel="noopener ugc nofollow" target="_blank"> AWS CLI </a>的<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-actions-resources.html" rel="noopener ugc nofollow" target="_blank">亚马逊MWAA API </a>获得。为了自动运行DAG，我们可以使用AWS CLI并通过Apache Airflow服务器上的端点调用Airflow CLI。<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/access-airflow-ui.html" rel="noopener ugc nofollow" target="_blank">亚马逊MWAA文档</a>和<a class="ae lw" href="https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html#dags" rel="noopener ugc nofollow" target="_blank"> Airflow的CLI文档</a>解释了如何操作。</p><p id="91ee" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">下面是一个使用Airflow的<code class="fe ne nf ng nh b">trigger_dag</code> CLI命令以编程方式触发<code class="fe ne nf ng nh b">spark_pi_example</code> DAG的示例。您需要用自己的Airflow Web服务器的主机名替换<code class="fe ne nf ng nh b">WEB_SERVER_HOSTNAME</code>变量。<code class="fe ne nf ng nh b">ENVIROMENT_NAME</code>变量假设<code class="fe ne nf ng nh b">jq</code>只返回一个MWAA环境。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">使用AWS CLI触发DAG</figcaption></figure><h1 id="0527" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">气流分析作业</h1><p id="6882" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们将向EMR提交一个实际的分析作业。如果你还记得<a class="ae lw" href="https://medium.com/swlh/running-pyspark-applications-on-amazon-emr-e536b7a865ca" rel="noopener">之前的帖子</a>，我们有四个不同的分析PySpark应用程序，它们对三个Kaggle数据集进行分析。对于下一个DAG，我们将运行一个执行<code class="fe ne nf ng nh b">bakery_sales_ssm.py</code> PySpark应用程序的Spark作业。该作业应该已经存在于<code class="fe ne nf ng nh b">processed</code>数据S3存储桶中。</p><p id="d84d" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">DAG<code class="fe ne nf ng nh b">dags/bakery_sales.py</code>创建一个EMR集群，该集群与使用<a class="ae lw" href="https://medium.com/swlh/running-pyspark-applications-on-amazon-emr-e536b7a865ca" rel="noopener">上一篇文章</a>中的<a class="ae lw" href="https://github.com/garystafford/emr-demo/blob/main/run_job_flow.py" rel="noopener ugc nofollow" target="_blank"> run_job_flow.py </a> Python脚本创建的EMR集群相同。使用AWS步进功能时可用的所有EMR配置选项均可用于EMR的Airflow的<code class="fe ne nf ng nh b">airflow.contrib.operators</code>和<code class="fe ne nf ng nh b">airflow.contrib.sensors</code>包。</p><p id="29e8" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">Airflow利用了<a class="ae lw" href="https://jinja.palletsprojects.com/" rel="noopener ugc nofollow" target="_blank"> Jinja模板</a>，并为管道作者提供了一组内置参数和宏。面包店销售DAG包含11个Jinja模板变量。通过将JSON文件导入“管理”⇨的“变量”选项卡，将在气流用户界面中配置七个变量。这些模板变量在DAG中以<code class="fe ne nf ng nh b">var.value</code>为前缀。其他三个变量将作为DAG运行配置作为JSON blob传递，类似于前面的DAG示例。这些模板变量以<code class="fe ne nf ng nh b">dag_run.conf</code>为前缀。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">面包店销售气流图</figcaption></figure><h2 id="5b3f" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">将变量导入气流用户界面</h2><p id="9d12" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">要导入所需的变量，首先，更改项目的<code class="fe ne nf ng nh b">airflow_variables/admin_variables.json</code>文件中的值。您需要更新<code class="fe ne nf ng nh b">bootstrap_bucket</code>、<code class="fe ne nf ng nh b">emr_ec2_key_pair</code>、<code class="fe ne nf ng nh b">logs_bucket</code>和<code class="fe ne nf ng nh b">work_bucket</code>的值。三个S3桶应该都存在于<a class="ae lw" href="https://medium.com/swlh/running-pyspark-applications-on-amazon-emr-e536b7a865ca" rel="noopener">之前的帖子</a>中。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">面包店销售DAG变量</figcaption></figure><p id="e122" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">接下来，从Airflow UI的“管理”⇨“变量”选项卡导入变量文件。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/d18cdb498ff6dc1ad513989a58e8a531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vZzlJ18gHnkHovAdaFDKuA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow用户界面的管理&gt;变量选项卡</figcaption></figure><p id="5c19" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">将DAG<code class="fe ne nf ng nh b">dags/bakery_sales.py</code>上传到气流S3桶，类似于第一个DAG。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="2485" class="lx kj it nh b gy nm nn l no np">aws s3 cp dags/bakery_sales.py \<br/>    s3://<strong class="nh iu"><em class="nt">&lt;your_airflow_bucket_name&gt;</em></strong>/dags/</span></pre><p id="3f9f" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">第二个DAG，<code class="fe ne nf ng nh b">bakery_sales</code>，应该会自动出现在气流UI中。单击“Trigger DAG”创建新的EMR集群并启动Spark作业。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/949e4f790a5e701198bc9d03efa67086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SO_3sDc-IRT12z0IeRvk6w.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow用户界面的DAGs选项卡</figcaption></figure><p id="2974" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">在“触发DAG”界面中输入三个必需的参数，用于传递DAG运行配置，然后选择“触发”。JSON blob的示例可以在项目<code class="fe ne nf ng nh b">airflow_variables/dag_run_config.json</code>中找到。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="6334" class="lx kj it nh b gy nm nn l no np">{<br/>    "airflow_email": "<a class="ae lw" href="mailto:airflow@example.com" rel="noopener ugc nofollow" target="_blank">airflow@example.com</a>",<br/>    "email_on_failure": false,<br/>    "email_on_retry": false<br/>}</span></pre><p id="42b8" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">这只是为了演示的目的。要收发电子邮件，您需要<a class="ae lw" href="https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html" rel="noopener ugc nofollow" target="_blank">配置气流</a>。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/1f25b6729a2907a06985fcd00d70370b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h_3vAbQKDq4o_k3QJu-60w.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow UI的触发DAG屏幕</figcaption></figure><p id="604d" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">切换到EMR控制台，您应该在“步骤”选项卡中看到“面包店销售”Spark作业。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/b2feacf40253349b9ba58735e8fba884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PMDrF4p0TMgzoo1S3qNRog.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Amazon EMR控制台的步骤选项卡</figcaption></figure><h1 id="8ce4" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">多步DAG</h1><p id="ef88" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们的最后一个示例中，我们将使用单个DAG并行运行四个Spark作业。Spark作业参数(<code class="fe ne nf ng nh b">EmrAddStepsOperator</code> <code class="fe ne nf ng nh b">steps</code>参数)将从位于亚马逊S3的外部JSON文件中加载，而不是像前面两个DAG示例那样在DAG中定义。此外，EMR集群规范(<code class="fe ne nf ng nh b">EmrCreateJobFlowOperator</code> <code class="fe ne nf ng nh b">job_flow_overrides</code>参数)也将从外部JSON文件中加载。使用这种方法，我们将EMR集群细节和Spark作业细节从DAG中分离出来。DataOps或DevOps工程师可能将EMR集群规范作为代码进行管理，而数据分析师则分别管理Spark作业参数。第三个团队可能管理DAG本身。</p><p id="dc07" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">我们仍然在JSON文件中维护变量。DAG会将基于JSON文件的配置作为JSON blobs读入任务，然后在DAG被触发时，用在Airflow中定义的变量值或作为参数的输入替换DAG中的Jinja模板变量(表达式)。</p><p id="6818" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">下面我们看到了四个Spark <code class="fe ne nf ng nh b">submit-job</code>作业定义中的两个(<code class="fe ne nf ng nh b">steps</code>)的片段，它们已经被移动到一个单独的JSON文件中，<code class="fe ne nf ng nh b">emr_steps/emr_steps.json</code>。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Spark作业定义JSON文件</figcaption></figure><p id="6fac" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">下面是EMR集群规范(<code class="fe ne nf ng nh b">job_flow_overrides)</code>)，它们已经被移到一个单独的JSON文件中，<code class="fe ne nf ng nh b">job_flow_overrides/job_flow_overrides.json</code>。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Spark作业覆盖JSON文件</figcaption></figure><p id="727f" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">解耦配置将DAG从200多行代码减少到不到75行。请注意下面DAG的第56行和第63行。参数现在引用函数<code class="fe ne nf ng nh b">get_objects(key, bucket_name)</code>，而不是引用局部对象变量，该函数加载JSON。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">多级气流DAG</figcaption></figure><p id="fd67" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">这一次，我们需要上传三个文件到S3，DAG到气流S3桶，和两个JSON文件到EMR工作S3桶。更改bucket名称以匹配您的环境，然后运行如下所示的三个AWS CLI命令。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="b4c1" class="lx kj it nh b gy nm nn l no np">aws s3 cp emr_steps/emr_steps.json \<br/>    s3://<strong class="nh iu">emr-demo-work-</strong><strong class="nh iu">123412341234</strong><strong class="nh iu">-us-east-1</strong>/emr_steps/</span><span id="6908" class="lx kj it nh b gy nu nn l no np">aws s3 cp job_flow_overrides/job_flow_overrides.json \<br/>    s3://<strong class="nh iu">emr-demo-work-</strong><strong class="nh iu">123412341234</strong><strong class="nh iu">-us-east-1</strong>/job_flow_overrides/</span><span id="655d" class="lx kj it nh b gy nu nn l no np">aws s3 cp dags/multiple_steps.py \<br/>    s3://<strong class="nh iu">airflow-</strong><strong class="nh iu">123412341234</strong><strong class="nh iu">-us-east-1</strong>/dags/</span></pre><p id="c976" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">第二个DAG，<code class="fe ne nf ng nh b">multiple_steps</code>，应该会自动出现在气流UI中。单击“Trigger DAG”创建新的EMR集群并启动Spark作业。“触发DAG”界面中所需的三个输入参数与之前的<code class="fe ne nf ng nh b">bakery_sales</code> DAG相同。JSON blob示例可以在项目中的<code class="fe ne nf ng nh b">airflow_variables/dag_run_conf.json</code>处找到。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/3a2a9a95004cfd2cd73f96ac0412f643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgW7594ktv8jmuYNqC--Yg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Apache Airflow用户界面的DAGs选项卡</figcaption></figure><p id="6550" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">下面我们看到EMR集群已经完成了四个Spark任务(EMR步骤),并且已经自动终止。请注意，所有四个作业都是在完全相同的时间启动的。如果您还记得上一篇文章，这是可能的，因为我们将“并发”级别预设为5。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/07290f53a7126c0fb89c2c9d0a02f76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8Le--h0Gso5fhaR7GpyWg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">Amazon EMR控制台的步骤选项卡显示了并行运行的四个步骤</figcaption></figure><h2 id="93ed" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">使用CLI以编程方式触发Dag</h2><p id="dde5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">与前面的示例类似，下面我们可以使用Airflow的<code class="fe ne nf ng nh b">trigger_dag</code> CLI命令以编程方式触发<code class="fe ne nf ng nh b">multiple_steps</code> DAG。注意添加了名为<code class="fe ne nf ng nh b">—-conf</code>的参数，它将包含三个键/值对的配置作为JSON blob传递给trigger命令。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk translated">使用AWS CLI触发DAG</figcaption></figure><h2 id="3f74" class="lx kj it bd kk ly lz dn ko ma mb dp ks lj mc md ku ln me mf kw lr mg mh ky mi bi translated">使用AWS SDK触发</h2><p id="9fad" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">也可以使用AWS SDK触发气流Dag。例如，对于Python的<code class="fe ne nf ng nh b">boto3</code>,我们可以使用类似下面的脚本来远程触发DAG。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h1 id="f316" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">清理</h1><p id="c8fa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">一旦您完成了MWAA环境，一定要尽快删除它，以节省额外的成本。此外，删除<code class="fe ne nf ng nh b">MWAA-VPC</code>云形成堆栈。与两个NAT网关一样，这些资源也将继续产生额外的成本。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="ffe5" class="lx kj it nh b gy nm nn l no np">aws mwaa delete-environment --name <strong class="nh iu"><em class="nt">&lt;your_mwaa_environment_name&gt;</em></strong></span><span id="577b" class="lx kj it nh b gy nu nn l no np">aws cloudformation delete-stack --stack-name MWAA-VPC</span></pre><h1 id="8ef4" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="4e17" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本系列的第二篇文章中，我们探索了如何使用最新发布的Amazon Managed Workflows for Apache air flow(Amazon MWAA)在Amazon Elastic MapReduce(Amazon EMR)上运行PySpark应用程序。在未来的帖子中，我们将探索Jupyter和Zeppelin笔记本在EMR上用于数据科学、科学计算和机器学习的用途。</p><p id="6fa9" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">如果你有兴趣了解更多关于配置亚马逊MWAA和气流的信息，请看我最近的帖子<a class="ae lw" rel="noopener ugc nofollow" target="_blank" href="/amazon-managed-workflows-for-apache-airflow-configuration-77db7fd633c5">亚马逊管理的Apache气流工作流——配置:了解亚马逊MWAA的配置选项</a>。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="839b" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">这篇博客代表我自己的观点，而不是我的雇主亚马逊网络服务公司的观点。所有产品名称、徽标和品牌都是其各自所有者的财产。</p></div></div>    
</body>
</html>