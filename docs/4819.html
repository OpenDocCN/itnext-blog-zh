<html>
<head>
<title>Data Ingestion into Azure Data Explorer using Kafka Connect on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kubernetes上的Kafka Connect将数据摄取到Azure Data Explorer中</h1>
<blockquote>原文：<a href="https://itnext.io/data-ingestion-into-azure-data-explorer-using-kafka-connect-3b59e8b648b7?source=collection_archive---------2-----------------------#2020-09-26">https://itnext.io/data-ingestion-into-azure-data-explorer-using-kafka-connect-3b59e8b648b7?source=collection_archive---------2-----------------------#2020-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0501" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我们将回顾如何使用开源的<a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto" rel="noopener ugc nofollow" target="_blank">Kafka Connect Sink connector for Azure Data Explorer</a>将数据摄取到<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Data Explorer </a>中，Kafka Connect Sink connector在Kubernetes上使用Strimzi运行。<a class="ae kl" href="https://kafka.apache.org/documentation/#connect" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>是一个使用源和接收器连接器在Apache Kafka和其他系统之间可扩展和可靠地传输数据的工具，Strimzi提供了一种运行Kafka集群和Kafka Connect workers的“Kubernetes-native”方式。</p><p id="75e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Azure Data Explorer是一种快速、可扩展的数据探索服务，允许您收集、存储和分析来自任何不同来源的大量数据，如网站、应用程序、物联网设备等。它有一个丰富的连接器生态系统，支持摄取到Azure Data Explorer中，如这里详述的<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"/>。受支持的数据源之一是Apache Kafka，sink connector允许您将Kafka主题中的数据移动到Azure Data Explorer表中，您可以稍后查询和分析这些表。最棒的是，您可以通过配置以可扩展和容错的方式做到这一点！</p><p id="3514" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是这篇博文中描述的场景的概述:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/a73b68484b51215a79b613f306f94cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tvcY7XdiQLU96s1w.jpg"/></div></div></figure><p id="39c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Azure Data Explorer Kafka连接器从已配置的Kafka主题中提取数据，并对接收流程(成批)进行排队，最终将数据写入Azure Data Explorer中的表。在幕后，连接器利用了用于Azure Data Explorer的<a class="ae kl" href="https://github.com/Azure/azure-kusto-java" rel="noopener ugc nofollow" target="_blank">Java SDK</a>。</p><blockquote class="ky kz la"><p id="0979" class="jn jo lb jp b jq jr js jt ju jv jw jx lc jz ka kb ld kd ke kf le kh ki kj kk ij bi translated"><em class="iq">这篇博文的资源在GitHub </em> 上有 <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi" rel="noopener ugc nofollow" target="_blank"> <em class="iq"/></a></p></blockquote></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="1524" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">先决条件</h1><p id="74a1" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">你将需要一个Azure账号以及Azure CLI 或Azure云壳。</p><p id="9dc2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一些在Azure上设置Azure Data Explorer集群和托管Kubernetes服务的快速指南。我建议将下面的服务作为一个单独的Azure资源组<a class="ae kl" href="https://docs.microsoft.com/azure/azure-resource-manager/management/overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">的一部分来安装，这样可以很容易地管理这些服务</a></p><h2 id="cf1f" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">Azure数据浏览器</h2><p id="7cfc" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">您可以使用Azure Portal 、<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-cli?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>或任何客户端SDK(如<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-python?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Python </a>)来设置Azure Data Explorer集群和数据库<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-portal?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">。完成后，使用下面的查询创建一个表(名为<code class="fe nb nc nd ne b">Storms</code>)和相应的映射(名为<code class="fe nb nc nd ne b">Storms_CSV_Mapping</code>):</a></p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="24f4" class="mp ln iq ne b gy nj nk l nl nm">.create table Storms (StartTime: datetime, EndTime: datetime, EventId: int, State: string, EventType: string, Source: string)</span><span id="756d" class="mp ln iq ne b gy nn nk l nl nm">.create table Storms ingestion csv mapping 'Storms_CSV_Mapping' '[{"Name":"StartTime","datatype":"datetime","Ordinal":0}, {"Name":"EndTime","datatype":"datetime","Ordinal":1},{"Name":"EventId","datatype":"int","Ordinal":2},{"Name":"State","datatype":"string","Ordinal":3},{"Name":"EventType","datatype":"string","Ordinal":4},{"Name":"Source","datatype":"string","Ordinal":5}]'</span></pre><h2 id="a296" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">Azure Kubernetes服务(可选)</h2><p id="4460" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">我使用过Azure Kubernetes服务，但是这篇博文中的说明应该也适用于其他选项(比如在你的笔记本电脑上安装一个本地的T2集群)。您可以使用<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>、<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure portal </a>或<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-rm-template?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> ARM模板</a>来设置AKS集群</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="9b95" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">基础安装</h1><p id="6a3f" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">首先安装Strimzi操作符，并使用它在Kubernetes上启动一个单节点Kafka集群。使用<code class="fe nb nc nd ne b">Helm</code>安装Strimzi非常简单:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="def3" class="mp ln iq ne b gy nj nk l nl nm">helm repo add strimzi https://strimzi.io/charts/<br/>helm install strimzi-kafka strimzi/strimzi-kafka-operator</span></pre><p id="e5dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要确认成功安装:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="940f" class="mp ln iq ne b gy nj nk l nl nm">kubectl get pods -l=name=strimzi-cluster-operator</span></pre><p id="748b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您应该会看到集群操作员<code class="fe nb nc nd ne b">Pod</code>处于<code class="fe nb nc nd ne b">Running</code>状态</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="b115" class="mp ln iq ne b gy nj nk l nl nm">NAME                                        READY   STATUS    RESTARTS   AGE<br/>strimzi-cluster-operator-5c66f679d5-69rgk   1/1     Running   0          43s</span></pre><p id="3293" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要部署单节点kafka集群(以及Zookeeper):</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="8b70" class="mp ln iq ne b gy nj nk l nl nm">kubectl apply -f <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/kafka.yaml" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/kafka.yaml</a></span></pre><p id="f2e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">等待群集启动:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="63da" class="mp ln iq ne b gy nj nk l nl nm">kubectl get pod my-kafka-cluster-kafka-0 -w</span></pre><p id="8738" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka Pod应转换到<code class="fe nb nc nd ne b">Running</code>状态，两个容器都应处于<code class="fe nb nc nd ne b">READY</code>状态</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="d00c" class="mp ln iq ne b gy nj nk l nl nm">NAME                       READY   STATUS    RESTARTS   AGE<br/>my-kafka-cluster-kafka-0   2/2     Running   0          1m</span></pre><h2 id="ea22" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">Kafka连接集群设置</h2><p id="4cc6" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">Kafka Connect的Strimzi容器映像包括两个内置的文件连接器— <code class="fe nb nc nd ne b">FileStreamSourceConnector</code>和<code class="fe nb nc nd ne b">FileStreamSinkConnector</code>。出于本博客的目的，在Docker Hub 上提供了一个定制的Docker映像，该映像以<a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto/releases/tag/v1.0.1" rel="noopener ugc nofollow" target="_blank">Azure Data Explorer connector</a>(版本<code class="fe nb nc nd ne b">1.0.1</code>)为种子，并在<code class="fe nb nc nd ne b">KafkaConnect</code>资源定义(<code class="fe nb nc nd ne b">image: abhirockzz/adx-connector-strimzi:1.0.1</code>)中引用:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="3f2e" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: kafka.strimzi.io/v1beta1<br/>kind: KafkaConnect<br/>metadata:<br/>  name: my-connect-cluster<br/>spec:<br/>  image: abhirockzz/adx-connector-strimzi:1.0.1<br/>  version: 2.4.0<br/>....</span></pre><p id="6d95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您想要构建自己的Docker映像，请使用<a class="ae kl" href="https://hub.docker.com/r/strimzi/kafka" rel="noopener ugc nofollow" target="_blank"> Strimzi Kafka Docker映像</a>作为基础，并将Azure Data Explorer连接器JAR top添加到插件路径中。首先下载连接器JAR文件:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="8ab9" class="mp ln iq ne b gy nj nk l nl nm">export KUSTO_KAFKA_SINK_VERSION=1.0.1<br/>mkdir connector &amp;&amp; cd connector</span><span id="d3a4" class="mp ln iq ne b gy nn nk l nl nm">curl -L -O <a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto/releases/download/v$KUSTO_KAFKA_SINK_VERSION/kafka-sink-azure-kusto-$KUSTO_KAFKA_SINK_VERSION-jar-with-dependencies.jar" rel="noopener ugc nofollow" target="_blank">https://github.com/Azure/kafka-sink-azure-kusto/releases/download/v$KUSTO_KAFKA_SINK_VERSION/kafka-sink-azure-kusto-$KUSTO_KAFKA_SINK_VERSION-jar-with-dependencies.jar</a></span></pre><p id="4986" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，您可以使用这个<code class="fe nb nc nd ne b">Dockerfile</code>来构建Docker映像:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="9937" class="mp ln iq ne b gy nj nk l nl nm">FROM strimzi/kafka:0.19.0-kafka-2.4.0<br/>USER root:root<br/>COPY ./connector/ /opt/kafka/plugins/<br/>RUN ls -lrt /opt/kafka/plugins/<br/>USER 1001</span></pre><blockquote class="ky kz la"><p id="cd89" class="jn jo lb jp b jq jr js jt ju jv jw jx lc jz ka kb ld kd ke kf le kh ki kj kk ij bi translated"><em class="iq">这个技巧已经在</em> <a class="ae kl" href="https://strimzi.io/docs/operators/master/deploying.html#creating-new-image-from-base-str" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> Strimzi文档</em> </a>中有所说明</p></blockquote><h2 id="ff9b" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">证明</h2><p id="56e8" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">在安装连接器之前，我们需要创建一个<a class="ae kl" href="https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure服务主体</a>，以便连接器验证并连接到Azure Data Explorer服务。您可以使用<a class="ae kl" href="https://docs.microsoft.com/cli/azure/ad/sp?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> az ad sp create-for-rbac </a>命令:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="809a" class="mp ln iq ne b gy nj nk l nl nm">az ad sp create-for-rbac -n "kusto-sp"</span></pre><p id="0a59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您将得到如下JSON响应——请记下<code class="fe nb nc nd ne b">appId</code>、<code class="fe nb nc nd ne b">password</code>和<code class="fe nb nc nd ne b">tenant</code>,因为您将在后续步骤中使用它们</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="2134" class="mp ln iq ne b gy nj nk l nl nm">{<br/>  "appId": "fe7280c7-5705-4789-b17f-71a472340429",<br/>  "displayName": "kusto-sp",<br/>  "name": "http://kusto-sp",<br/>  "password": "29c719dd-f2b3-46de-b71c-4004fb6116ee",<br/>  "tenant": "42f988bf-86f1-42af-91ab-2d7cd011db42"<br/>}</span></pre><p id="f67f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">向您的数据库添加权限</strong></p><p id="9505" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为刚刚创建的服务主体提供适当的角色。要分配<code class="fe nb nc nd ne b">admin</code>角色，<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/manage-database-permissions?WT.mc_id=medium-blog-abhishgu#manage-permissions-in-the-azure-portal" rel="noopener ugc nofollow" target="_blank">请遵循本指南</a>来使用Azure门户或在您的数据浏览器集群中使用以下命令</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="449e" class="mp ln iq ne b gy nj nk l nl nm">.add database &lt;database name&gt; admins  ('aadapp=&lt;service principal AppID&gt;;&lt;service principal TenantID&gt;') 'AAD App'</span></pre><p id="2d92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将auth相关的配置作为<a class="ae kl" href="https://kubernetes.io/docs/concepts/configuration/secret/" rel="noopener ugc nofollow" target="_blank"> Kubernetes Secret </a>的种子—稍后您将看到这个<code class="fe nb nc nd ne b">Secret</code>在哪里被引用。</p><p id="522c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用下面的内容创建一个名为<code class="fe nb nc nd ne b">adx-auth.yaml</code>的文件。</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="668e" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: v1<br/>kind: Secret<br/>metadata:<br/>  name: adx-auth<br/>type: Opaque<br/>stringData:<br/>  adx-auth.properties: |-<br/>    kustoURL: &lt;replace ADX Ingest URL&gt;<br/>    tenantID: &lt;enter service principal tenant ID&gt;<br/>    appID: &lt;enter service principal app ID&gt;<br/>    password: &lt;enter service principal tenant password&gt;</span></pre><p id="d580" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">替换以下内容的值:</p><ul class=""><li id="2aa2" class="no np iq jp b jq jr ju jv jy nq kc nr kg ns kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">kustoURL</code> : Azure Data Explorer摄取URL，例如<code class="fe nb nc nd ne b">https://ingest-[cluster name].[region].kusto.windows.net</code></li><li id="fba8" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">tenantID</code> -服务主租户ID</li><li id="6faa" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">appID</code> -服务委托申请ID</li><li id="8725" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">password</code> -服务主体密码</li></ul></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="c44a" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">安装Kafka Connect</h1><p id="6180" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">创建<code class="fe nb nc nd ne b">Secret</code>并启动Kafka集群创建:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="de30" class="mp ln iq ne b gy nj nk l nl nm">kubectl apply -f adx-auth.yaml</span><span id="4452" class="mp ln iq ne b gy nn nk l nl nm">kubectl apply -f <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/kafka-connect.yaml" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/kafka-connect.yaml</a></span></pre><p id="9b44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当您等待Kafka Connect集群启动时，请看一下这个<code class="fe nb nc nd ne b">KafkaConnect</code>集群资源定义的片段。注意<code class="fe nb nc nd ne b">externalConfiguration</code>属性，它指向我们刚刚创建的秘密。它作为<a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/volumes/" rel="noopener ugc nofollow" target="_blank">卷</a>加载到Kafka Connect <code class="fe nb nc nd ne b">Pod</code>中，Kafka<a class="ae kl" href="https://kafka.apache.org/26/javadoc/org/apache/kafka/common/config/provider/FileConfigProvider.html" rel="noopener ugc nofollow" target="_blank">FileConfigProvider</a>用于访问它们。</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="7b8a" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: kafka.strimzi.io/v1beta1<br/>kind: KafkaConnect<br/>metadata:<br/>  name: my-connect-cluster<br/>spec:<br/>  image: abhirockzz/adx-connector-strimzi:1.0.1<br/>  config:<br/>    ...<br/>    config.providers: file<br/>    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider<br/>  externalConfiguration:<br/>    volumes:<br/>      - name: adx-auth-config<br/>        secret:<br/>          secretName: adx-auth</span></pre><p id="1673" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要检查Kafka Connect集群状态:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="aa32" class="mp ln iq ne b gy nj nk l nl nm">kubectl get pod -l=strimzi.io/cluster=my-connect-cluster -w</span></pre><p id="a5cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">等待Kafka Connect Pod转换到<code class="fe nb nc nd ne b">Running</code>状态。</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="5489" class="mp ln iq ne b gy nj nk l nl nm">NAME                                          READY   STATUS    RESTARTS   AGE<br/>my-connect-cluster-connect-5bf9db5d9f-9ttg4   1/1     Running   0          1m</span></pre><h2 id="e155" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">创建主题并安装连接器</h2><p id="033a" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">您可以使用<a class="ae kl" href="https://strimzi.io/docs/operators/master/using.html#using-the-topic-operator-str" rel="noopener ugc nofollow" target="_blank"> Strimzi实体操作符</a>来创建<code class="fe nb nc nd ne b">storm-events</code>主题。下面是<code class="fe nb nc nd ne b">Topic</code>的定义:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="d935" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: kafka.strimzi.io/v1beta1<br/>kind: KafkaTopic<br/>metadata:<br/>  name: storm-events<br/>  labels:<br/>    strimzi.io/cluster: my-kafka-cluster<br/>spec:<br/>  partitions: 3<br/>  replicas: 1</span></pre><p id="bf5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要创建:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="b8aa" class="mp ln iq ne b gy nj nk l nl nm">kubectl apply -f <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/topic.yaml" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/topic.yaml</a></span></pre><p id="c5c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe nb nc nd ne b">kubectl get kafkatopic</code>查看您刚刚创建的主题以及内部Kafka主题</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="741a" class="mp ln iq ne b gy nj nk l nl nm">NAME                                                          PARTITIONS   REPLICATION FACTOR<br/>consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a   50           1<br/>storm-events                                                  3            1<br/>strimzi-connect-cluster-configs                               1            1<br/>strimzi-connect-cluster-offsets                               25           1<br/>strimzi-connect-cluster-status                                5            1</span></pre><p id="fb56" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是连接器(<code class="fe nb nc nd ne b">KafkaConnector</code>)定义的片段——这只是一种为您想要安装的连接器捕获配置和元数据的方法。</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="c3e7" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: kafka.strimzi.io/v1alpha1<br/>kind: KafkaConnector<br/>metadata:<br/>  name: adx-sink-connector<br/>  labels:<br/>    strimzi.io/cluster: my-connect-cluster<br/>spec:<br/>  class: com.microsoft.azure.kusto.kafka.connect.sink.KustoSinkConnector<br/>  tasksMax: 3<br/>  config:<br/>    topics: storm-events<br/>    flush.size.bytes: 10000<br/>    flush.interval.ms: 50000<br/>    kusto.tables.topics.mapping: "[{'topic': 'storm-events','db': '[REPLACE DATABASE NAME]', 'table': 'Storms','format': 'csv', 'mapping':'Storms_CSV_Mapping'}]"<br/>    kusto.url: ${file:/opt/kafka/external-configuration/adx-auth-config/adx-auth.properties:kustoURL}<br/>    aad.auth.authority: ${file:/opt/kafka/external-configuration/adx-auth-config/adx-auth.properties:tenantID}<br/>    aad.auth.appid: ${file:/opt/kafka/external-configuration/adx-auth-config/adx-auth.properties:appID}<br/>    aad.auth.appkey: ${file:/opt/kafka/external-configuration/adx-auth-config/adx-auth.properties:password}<br/>    key.converter: "org.apache.kafka.connect.storage.StringConverter"<br/>    value.converter: "org.apache.kafka.connect.storage.StringConverter"</span></pre><blockquote class="ky kz la"><p id="0215" class="jn jo lb jp b jq jr js jt ju jv jw jx lc jz ka kb ld kd ke kf le kh ki kj kk ij bi translated"><em class="iq"/><code class="fe nb nc nd ne b"><em class="iq">flush.size.bytes</em></code><em class="iq">和</em> <code class="fe nb nc nd ne b"><em class="iq">flush.interval.ms</em></code> <em class="iq">属性协同工作，作为批处理的性能旋钮。请参考</em> <a class="ae kl" href="https://github.com/Azure/kafka-sink-azure-kusto/blob/master/README.md#5-sink-properties" rel="noopener ugc nofollow" target="_blank"> <em class="iq">连接器GitHub repo </em> </a> <em class="iq">了解这些和其他配置参数</em>的详细信息</p></blockquote><p id="38d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意单个属性(来自<code class="fe nb nc nd ne b">Secret</code>)实际上是如何被引用的。例如，为了引用服务主体应用程序ID，我们使用了:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="6c81" class="mp ln iq ne b gy nj nk l nl nm">aad.auth.appid: ${file:/opt/kafka/external-configuration/adx-auth-config/adx-auth.properties:appID}</span></pre><ul class=""><li id="b65c" class="no np iq jp b jq jr ju jv jy nq kc nr kg ns kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">/opt/kafka/external-configuration</code>是容器内部的固定路径</li><li id="04f4" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">adx-auth-config</code>是<code class="fe nb nc nd ne b">KafkaConnect</code>定义中的卷名</li><li id="fb3a" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">adx-auth.properties</code>是在<code class="fe nb nc nd ne b">Secret</code>中定义的文件名</li><li id="d851" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><code class="fe nb nc nd ne b">appID</code>是钥匙的名称</li></ul><blockquote class="ky kz la"><p id="56dd" class="jn jo lb jp b jq jr js jt ju jv jw jx lc jz ka kb ld kd ke kf le kh ki kj kk ij bi translated"><em class="iq">直接属性名已用于定义非敏感连接器配置(如</em> <code class="fe nb nc nd ne b"><em class="iq">topics: storm-events</em></code> <em class="iq">)。或者，可以将这些封装在一个</em> <code class="fe nb nc nd ne b"><em class="iq">ConfigMap</em></code> <em class="iq">中，将它们加载为一个</em> <code class="fe nb nc nd ne b"><em class="iq">Volume</em></code> <em class="iq">并引用它们(就像敏感属性使用一个</em> <code class="fe nb nc nd ne b"><em class="iq">Secret</em></code> <em class="iq">)。</em></p></blockquote><p id="afab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将上述<code class="fe nb nc nd ne b">KafkaConnector</code>的定义复制到本地文件<code class="fe nb nc nd ne b">adx-connect-config.yaml</code>。确保在<code class="fe nb nc nd ne b">kusto.tables.topics.mapping</code>属性中替换正确的数据库名称。要创建:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="ab53" class="mp ln iq ne b gy nj nk l nl nm">kubectl apply -f adx-connect-config.yaml</span></pre><p id="35ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">检查kafka连接日志<code class="fe nb nc nd ne b">kubectl logs -l=strimzi.io/cluster=my-connect-cluster</code>。如果一切正常，您应该会看到类似如下的日志:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="0c28" class="mp ln iq ne b gy nj nk l nl nm">....<br/>INFO [Consumer clientId=connector-consumer-adx-sink-connector-1, groupId=connect-adx-sink-connector] Resetting offset for partition storm-events-1 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState) [task-thread-adx-sink-connector-1]</span><span id="8ef5" class="mp ln iq ne b gy nn nk l nl nm">INFO [Consumer clientId=connector-consumer-adx-sink-connector-2, groupId=connect-adx-sink-connector] Resetting offset for partition storm-events-2 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState) [task-thread-adx-sink-connector-2]</span></pre></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="fd71" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">数据摄取正在进行</h1><p id="04c7" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">那么，我们一切都准备好了。我们只需要将事件发送到Kafka主题，这样我们就可以看到连接器的运行，并将数据接收到Azure Data Explorer中。</p><p id="9550" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以使用这个方便的事件生成器应用程序(在<a class="ae kl" href="https://hub.docker.com/r/abhirockzz/adx-event-producer" rel="noopener ugc nofollow" target="_blank"> Docker Hub </a>中可用)并将它部署到您的Kubernetes集群中—<code class="fe nb nc nd ne b">Dockerfile</code>在<a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/storm-events-producer/Dockerfile" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中可用，以防您想要引用它。</p><p id="72b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kubernetes <code class="fe nb nc nd ne b">Deployment</code>片段:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="a2a1" class="mp ln iq ne b gy nj nk l nl nm">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: adx-event-producer<br/>spec:<br/>  replicas: 1<br/>  ....<br/>    spec:<br/>      containers:<br/>        - name: adx-event-producer<br/>          image: abhirockzz/adx-event-producer<br/>          imagePullPolicy: Always<br/>          env:<br/>            - name: KAFKA_BOOTSTRAP_SERVER<br/>              value: my-kafka-cluster-kafka-bootstrap:9092<br/>            - name: KAFKA_TOPIC<br/>              value: storm-events<br/>            - name: SOURCE_FILE<br/>              value: StormEvents.csv</span></pre><p id="ac87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要部署生产者应用程序:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="6433" class="mp ln iq ne b gy nj nk l nl nm">kubectl apply -f <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/producer.yaml" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/kusto-kafka-connect-strimzi/raw/master/deploy/producer.yaml</a></span></pre><p id="a633" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">应用程序从<a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/blob/master/storm-events-producer/StormEvents.csv" rel="noopener ugc nofollow" target="_blank"> StormEvents.csv文件</a>中提取记录，并将它们发送到Kafka主题。每个事件都是一个CSV记录，代表风暴发生数据(开始和结束时间、状态、类型等)。)，例如:<code class="fe nb nc nd ne b">2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23357,WISCONSIN,Winter Storm,COOP Observer</code>。</p><blockquote class="ky kz la"><p id="c8c2" class="jn jo lb jp b jq jr js jt ju jv jw jx lc jz ka kb ld kd ke kf le kh ki kj kk ij bi translated"><em class="iq">生产者应用</em> <a class="ae kl" href="https://github.com/abhirockzz/kusto-kafka-connect-strimzi/blob/master/storm-events-producer/main.go#L65" rel="noopener ugc nofollow" target="_blank"> <em class="iq">等待3秒</em> </a> <em class="iq">之间对卡夫卡进行后续的生产操作。这是有意的，以便您可以监视Kafka Connect日志并了解正在发生的事情。</em> <code class="fe nb nc nd ne b"><em class="iq">StormEvents.csv</em></code> <em class="iq">文件包含超过50，000条记录，因此可能需要一段时间才能将它们全部批处理并获取到Azure Data Explorer </em></p></blockquote><p id="4f61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以使用<code class="fe nb nc nd ne b">kubectl logs -f -l app=adx-event-producer</code>跟踪应用程序日志。如果一切正常，您应该会看到类似这样的内容:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="0d3e" class="mp ln iq ne b gy nj nk l nl nm">...<br/>sent message to partition 0 offset 0<br/>event  2007-01-01 00:00:00.0000000,2007-01-01 00:00:00.0000000,13208,NORTH CAROLINA,Thunderstorm Wind,Public</span><span id="c94b" class="mp ln iq ne b gy nn nk l nl nm">sent message to partition 0 offset 1<br/>event  2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23358,WISCONSIN,Winter Storm,COOP Observer</span><span id="3991" class="mp ln iq ne b gy nn nk l nl nm">sent message to partition 0 offset 2<br/>event  2007-01-01 00:00:00.0000000,2007-01-01 05:00:00.0000000,23357,WISCONSIN,Winter Storm,COOP Observer</span></pre><p id="c358" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nb nc nd ne b">storm-events</code>主题现在将开始获取事件，这些事件将被接收器连接器拾取。如果您要跟踪连接器日志:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="a63e" class="mp ln iq ne b gy nj nk l nl nm">kubectl logs -f -l strimzi.io/cluster=my-connect-cluster</span></pre><p id="ad3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">…您应该会看到类似以下内容的日志:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="f043" class="mp ln iq ne b gy nj nk l nl nm">....<br/>INFO Kusto ingestion: file (/tmp/kusto-sink-connector-17d03941-f8ca-498e-bc52-68ced036dc69/kafka_storm-events_0_0.csv.gz) of size (1722) at current offset (16) (com.microsoft.azure.kusto.kafka.connect.sink.TopicPartitionWriter) [Timer-6]</span><span id="c106" class="mp ln iq ne b gy nn nk l nl nm">INFO WorkerSinkTask{id=adx-sink-connector-0} Committing offsets asynchronously using sequence number 17: {storm-events-0=OffsetAndMetadata{offset=17, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask) [task-thread-adx-sink-connector-0]</span><span id="e956" class="mp ln iq ne b gy nn nk l nl nm">INFO Kusto ingestion: file (/tmp/kusto-sink-connector-17d03941-f8ca-498e-bc52-68ced036dc69/kafka_storm-events_0_17.csv.gz) of size (1666) at current offset (33) (com.microsoft.azure.kusto.kafka.connect.sink.TopicPartitionWriter) [Timer-7]<br/>....</span></pre><h2 id="eea2" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">查询Azure数据浏览器</h2><p id="b362" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">等待一段时间，直到数据在<code class="fe nb nc nd ne b">Storms</code>表中结束。要进行确认，请检查行数并确认摄取过程中没有失败:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="957f" class="mp ln iq ne b gy nj nk l nl nm">Storms | count</span><span id="4ac2" class="mp ln iq ne b gy nn nk l nl nm">. show ingestion failures</span></pre><p id="be85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦有了一些数据，尝试几个查询。要查看所有记录:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="fa03" class="mp ln iq ne b gy nj nk l nl nm">Storms</span></pre><p id="791d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe nb nc nd ne b">where</code>和<code class="fe nb nc nd ne b">project</code>过滤特定数据</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="0324" class="mp ln iq ne b gy nj nk l nl nm">Storms<br/>| where EventType == 'Drought' and State == 'TEXAS'<br/>| project StartTime, EndTime, Source, EventId</span></pre><p id="53ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe nb nc nd ne b"><a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries?WT.mc_id=medium-blog-abhishgu#summarize" rel="noopener ugc nofollow" target="_blank">summarize</a></code> <a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries?WT.mc_id=medium-blog-abhishgu#summarize" rel="noopener ugc nofollow" target="_blank">运算符</a></p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="38f3" class="mp ln iq ne b gy nj nk l nl nm">Storms<br/>| summarize event_count=count() by State<br/>| where event_count &gt; 10<br/>| project State, event_count<br/>| render columnchart</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oc"><img src="../Images/ad8158609e6998f43476d5bd52678303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6vuF_QE4qqnUmeDR.png"/></div></div></figure><p id="cecb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些只是几个例子。请看看<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/kusto/query/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Kusto查询语言文档</a>或者探索关于如何使用<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/write-queries#scalar-operators" rel="noopener ugc nofollow" target="_blank">标量操作符</a>、<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/kusto/query/tutorial?pivots=azuredataexplorer&amp;WT.mc_id=medium-blog-abhishgu#timecharts" rel="noopener ugc nofollow" target="_blank">时间表</a>等将JSON格式的样本数据摄取到Azure Data Explorer中的教程。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="a35a" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">清理资源</h1><p id="390d" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">要删除连接器和/或Kafka集群:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="d4e8" class="mp ln iq ne b gy nj nk l nl nm">kubectl delete kafkaconnect/my-connect-cluster<br/>kubectl delete kafka/my-kafka-cluster</span></pre><p id="d19e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要删除AKS和Azure Data Explorer集群，只需删除资源组:</p><pre class="kn ko kp kq gt nf ne ng nh aw ni bi"><span id="9407" class="mp ln iq ne b gy nj nk l nl nm">az group delete --name &lt;AZURE_RESOURCE_GROUP&gt; --yes --no-wait</span></pre><h1 id="17eb" class="lm ln iq bd lo lp od lr ls lt oe lv lw lx of lz ma mb og md me mf oh mh mi mj bi translated">结论</h1><p id="cbdd" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">这就是这篇博文的全部内容，希望你觉得有用！请注意，这是<em class="lb">而不是</em>将数据导入Azure Data Explorer的唯一方式。欢迎您参考文档并探索其他技术，如<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-one-click?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">一键摄取</a>，使用<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-event-grid-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">事件网格</a>，<a class="ae kl" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-iot-hub-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">物联网中心</a>等。</p><p id="6cac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请考虑探索以下主题作为额外的学习资源:</p><h2 id="87a1" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">资源</h2><ul class=""><li id="de47" class="no np iq jp b jq mk ju ml jy oi kc oj kg ok kk nt nu nv nw bi translated"><a class="ae kl" href="https://strimzi.io/docs/latest/#proc-configuring-kafka-connect-deployment-configuration-kafka-connect" rel="noopener ugc nofollow" target="_blank">使用Strimzi配置Kafka Connect集群</a></li><li id="603a" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated">Strimzi <a class="ae kl" href="https://strimzi.io/docs/latest/#type-KafkaConnect-reference" rel="noopener ugc nofollow" target="_blank"> KafkaConnect模式参考</a></li><li id="5839" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated">Strimzi <a class="ae kl" href="https://strimzi.io/docs/latest/#type-KafkaConnector-reference" rel="noopener ugc nofollow" target="_blank"> KafkaConnector模式参考</a></li><li id="f977" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><a class="ae kl" href="https://techcommunity.microsoft.com/t5/azure-data-explorer/just-enough-azure-data-explorer-for-architects/ba-p/1636234" rel="noopener ugc nofollow" target="_blank">刚刚够云架构师使用的Azure Data Explorer】</a></li><li id="7fe2" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><a class="ae kl" href="https://techcommunity.microsoft.com/t5/azure-data-explorer/azure-data-explorer-kafka-connector-new-features-with-version-1/ba-p/1637143" rel="noopener ugc nofollow" target="_blank">Azure Data Explorer connector 1 . x的新特性</a></li><li id="7f85" class="no np iq jp b jq nx ju ny jy nz kc oa kg ob kk nt nu nv nw bi translated"><a class="ae kl" href="https://docs.microsoft.com/en-us/azure/data-explorer/kql-quick-reference" rel="noopener ugc nofollow" target="_blank">库斯托查询语言</a></li></ul></div></div>    
</body>
</html>