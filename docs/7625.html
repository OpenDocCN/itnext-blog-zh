<html>
<head>
<title>Kubernetes — II: Deploying applications on dedicated nodes using terraform &amp; terragrunt</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes — II:使用terraform &amp; terragrunt在专用节点上部署应用程序</h1>
<blockquote>原文：<a href="https://itnext.io/kubernetes-ii-deploying-applications-on-dedicated-nodes-using-terraform-terragrunt-9fef9ea96d8d?source=collection_archive---------0-----------------------#2022-11-29">https://itnext.io/kubernetes-ii-deploying-applications-on-dedicated-nodes-using-terraform-terragrunt-9fef9ea96d8d?source=collection_archive---------0-----------------------#2022-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/326d40bf4401453aeeb9ac90ae160e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JLniprC-2MPZ8doVDXkuKA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来源:<a class="ae jd" href="https://www.macstadium.com/blog/how-to-k8s-getting-started-with-helm-charts" rel="noopener ugc nofollow" target="_blank"> macstadium </a></figcaption></figure><div class=""/><p id="e28c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本系列的第一部分中，我们介绍了Kubernetes集群的不同架构模式，并使用terraform &amp; terragrunt在EKS上创建了一个多节点Kubernetes集群。在第二部分中，我们将探索如何使用terraform &amp; terragrunt在Kubernetes上确定性地部署应用程序生命周期管理的舵图。</p><div class="ip iq gp gr ir lb"><a rel="noopener  ugc nofollow" target="_blank" href="/kubernetes-i-multi-node-deployment-using-terraform-and-terragrunt-30c40a1238e8"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">Kubernetes — I:使用terraform和terragrunt的多节点部署</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">本文讨论了Kubernetes的不同部署架构，以及如何使用…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">itnext.io</p></div></div><div class="lk l"><div class="ll l lm ln lo lk lp ix lb"/></div></div></a></div></div><div class="ab cl lq lr hu ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ij ik il im in"><p id="88b9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Operations applications，简称OpsApps，是我们在Kubernetes上调度的包，用于为我们的应用程序运行建立基础。这些软件包增强了应用程序的功能，并允许用户充分利用提供给他们的服务。这样的包被安装在Kubernetes上，使用一个流行的和广泛使用的包管理器，称为Helm，这些包被称为Helm Charts(Helm上的包以一种特殊的格式打包，称为<em class="lx"> charts </em> ，一个Kubernetes资源的集合)。</p><div class="ip iq gp gr ir lb"><a href="https://helm.sh/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">舵</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">Helm是查找、共享和使用为Kubernetes构建的软件的最佳方式。Helm帮助您管理Kubernetes…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">helm.sh</p></div></div><div class="lk l"><div class="ly l lm ln lo lk lp ix lb"/></div></div></a></div><p id="a880" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Helm使得在Kubernetes上部署应用程序包变得很容易。您可以为任何应用程序创建helm部署；可以把它看作是部署在Kubernetes上的应用程序打包工具。这些包通常带有一个庞大的配置列表，通常采用名为values.yaml的yaml文件的形式。该文件为您的OpsApps提供了一个确定性的部署环境，因为该文件在其配置被应用后被签入git。在这篇文章的最后，我们将会看到如何使用terraform自动部署舵图。</p><p id="b5ee" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Helm charts为运行在Kubernetes上的面向微服务的架构提供了坚实、高效的功能结构基础。这些图表中最值得注意的是<code class="fe lz ma mb mc b">ingress-nginx</code>、<code class="fe lz ma mb mc b">hashicorp vault</code>、<code class="fe lz ma mb mc b">cert-manager</code>、<code class="fe lz ma mb mc b">rabbitmq</code>和<code class="fe lz ma mb mc b">linkerd</code>等等。每个图表都专注于其特定的功能，并允许应用程序开发人员专注于开发其应用程序的业务逻辑，而不是创建大规模运行的支持基础架构。</p><p id="ddbb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来理解一下<a class="ae jd" href="https://kubernetes.github.io/ingress-nginx" rel="noopener ugc nofollow" target="_blank"> ingress-nginx </a>图表的例子。Kubernetes中的控制器至少跟踪一种资源类型，并确保<a class="ae jd" href="https://kubernetes.io/docs/concepts/architecture/controller" rel="noopener ugc nofollow" target="_blank">使集群更接近期望的状态</a>。一个<a class="ae jd" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" rel="noopener ugc nofollow" target="_blank">入口控制器</a>，比如ingress-nginx，从Kubernetes集群外部公开http和https路由，并充当集群内请求数据的服务的负载平衡器。使用这个掌舵图，开发人员可以利用服务的负载管理、公共端点的TLS/SSL终止以及有限的缓存服务，而不必自己设置所有这些服务。</p><div class="ip iq gp gr ir lb"><a href="https://kubernetes.github.io/ingress-nginx/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">欢迎- NGINX入口控制器</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">这是入口NGINX控制器的文档。它是围绕Kubernetes入口资源构建的，使用了…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">kubernetes.github.io</p></div></div></div></a></div><div class="ip iq gp gr ir lb"><a href="https://kubernetes.io/docs/concepts/architecture/controller/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">控制器</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">在机器人和自动化中，控制回路是调节系统状态的非终止回路。这里有一个…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">kubernetes.io</p></div></div><div class="lk l"><div class="md l lm ln lo lk lp ix lb"/></div></div></a></div><p id="373a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以使用cli工具在Kubernetes集群上配置Helm chart，该工具指向<code class="fe lz ma mb mc b">.kubeconfig</code>文件夹的<code class="fe lz ma mb mc b">kubeconfig</code>中的<a class="ae jd" href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/" rel="noopener ugc nofollow" target="_blank">当前上下文</a>。这是最易于使用的方法，但对于在多个集群或生产集群上应用更改，这可能并不完美。维护人员需要跟踪进入他们的Kubernetes集群的不同舵图的配置，以及比较他们想要引入系统的任何新变化。这就是terraform &amp; terragrunt出现的原因。在Hashicorp 的<a class="ae jd" href="https://registry.terraform.io/providers/hashicorp/helm/latest/docs" rel="noopener ugc nofollow" target="_blank"> Helm provider的帮助下，用户可以对其集群进行确定性的、可重复的更改。唯一的要求是下载舵图表的值文件，以正确配置和应用图表。这将解决问题的前半部分；在Kubernetes集群上安装OpsApps，但是我们仍然需要弄清楚如何在专用于这些OpsApps的节点组上调度这些应用程序。这是因为这些是操作关键型应用程序，需要专门访问资源，如CPU、RAM、磁盘空间等。</a></p><div class="ip iq gp gr ir lb"><a href="https://registry.terraform.io/providers/hashicorp/helm/latest/docs" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">地形注册表</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">编辑描述</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">registry.terraform.io</p></div></div></div></a></div><p id="0128" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不同Kubernetes节点组上应用程序执行的这种分离是由内置工具管理的，如NodeSelector、Taints &amp; Tolerations和Node Affinity &amp; Anti-Affinity机制。这些技术使OpsApps应用程序单元连接到特定的节点，并排斥该节点组中的其他应用程序。这是通过创建标签并将它们附加到节点和应用程序上来实现的，这些标签帮助Kubernetes识别哪些应用程序将被调度到哪些节点上。让我们简单看看这些机制是如何让Kubernetes实现这一点的。</p><ul class=""><li id="2353" class="me mf jg kf b kg kh kk kl ko mg ks mh kw mi la mj mk ml mm bi translated">NodeSelector: Node Selector的工作方式非常类似于Node Affinity，不同之处在于它直接匹配在节点创建期间定义的节点标签。</li><li id="7f74" class="me mf jg kf b kg mn kk mo ko mp ks mq kw mr la mj mk ml mm bi translated">节点亲和性和反亲和性:节点亲和性和反亲和性允许您高度定制pod调度的规则和逻辑。它比NodeSelector更具表达性，允许在符合特定规则或约束的节点上调度pod。</li><li id="b144" class="me mf jg kf b kg mn kk mo ko mp ks mq kw mr la mj mk ml mm bi translated">污染和容忍:<em class="lx">节点亲和性</em>是Pods的一个属性，它将Pods吸引到一组节点上(作为一种偏好或硬性要求)。<em class="lx">污点</em>则相反；这是节点的属性，允许一个节点击退一组豆荚。容忍适用于pod，并允许(但不要求)pod调度到具有匹配污点的节点上。</li></ul><div class="ip iq gp gr ir lb"><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">将窗格分配给节点</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">您可以约束一个Pod，使它被限制在特定的节点上运行，或者更喜欢在特定的节点上运行…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">kubernetes.io</p></div></div><div class="lk l"><div class="ms l lm ln lo lk lp ix lb"/></div></div></a></div><p id="decc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从我在Kubernetes系列的第一篇文章上离开的地方继续，我将向Kubernetes集群添加三个舵图，并在各自的OpsApps节点组上调度它们。我采取了另一种策略，通过利用terraform中模块的力量，重构了代码，使其简洁、易于理解。为了创建eks集群、节点组和eks的IRSA，我使用了来自<a class="ae jd" href="https://github.com/antonbabenko" rel="noopener ugc nofollow" target="_blank"> Anton Babenko </a>的terragrunt-aws-eks模块。IRSA，即服务帐户的IAM角色，是AWS的一项功能，它允许您通过组合<a class="ae jd" href="https://openid.net/connect/" rel="noopener ugc nofollow" target="_blank"> OpenID Connect </a> (OIDC)身份提供者和Kubernetes服务帐户注释，在pod级别使用IAM角色。</p><div class="ip iq gp gr ir lb"><a href="https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">服务帐户的IAM角色</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">了解pods中的应用程序如何访问AWS服务。</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">docs.aws.amazon.com</p></div></div><div class="lk l"><div class="mt l lm ln lo lk lp ix lb"/></div></div></a></div><div class="ip iq gp gr ir lb"><a href="https://github.com/terraform-aws-modules/terraform-aws-eks" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">GitHub-terra form-AWS-modules/terra form-AWS-eks:terra form模块创建弹性Kubernetes…</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">创建AWS EKS (Kubernetes)资源的Terraform模块请注意，我们努力提供全面的…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">github.com</p></div></div><div class="lk l"><div class="mu l lm ln lo lk lp ix lb"/></div></div></a></div><p id="2ffa" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从使用这个模块创建一个eks集群开始。</p><pre class="mv mw mx my gt mz mc na bn nb nc bi"><span id="47ba" class="nd ne jg mc b be nf ng l nh ni">################################################################################<br/># Supporting Resources<br/>################################################################################<br/><br/>resource "aws_kms_key" "eks" {<br/>  description             = var.aws_kms_key.description<br/>  deletion_window_in_days = var.aws_kms_key.deletion_window_in_days<br/>  enable_key_rotation     = var.aws_kms_key.enable_key_rotation<br/>  tags                    = var.aws_kms_key.tags<br/>}<br/><br/>resource "aws_security_group" "additional_security_group" {<br/>  name_prefix = var.aws_security_group.name_prefix<br/>  vpc_id      = var.aws_security_group.vpc_id<br/><br/>  dynamic "ingress" {<br/>    for_each = var.aws_security_group.ingresses<br/>    content {<br/>      from_port   = ingress.value.from_port<br/>      to_port     = ingress.value.to_port<br/>      protocol    = ingress.value.protocol<br/>      cidr_blocks = ingress.value.cidr_blocks<br/>    }<br/>  }<br/>  tags = var.aws_security_group.tags<br/>}<br/><br/>################################################################################<br/># Supporting Resources<br/>################################################################################<br/><br/><br/>################################################################################<br/># EKS Module<br/>################################################################################<br/><br/>module "eks" {<br/>  source  = "terraform-aws-modules/eks/aws"<br/>  version = "18.30.3"<br/><br/>  cluster_name                    = var.aws_eks_cluster.cluster_name<br/>  cluster_version                 = var.aws_eks_cluster.cluster_version<br/>  cluster_endpoint_private_access = var.aws_eks_cluster.cluster_endpoint_private_access<br/>  cluster_endpoint_public_access  = var.aws_eks_cluster.cluster_endpoint_public_access<br/><br/>  cluster_addons = {<br/>    coredns = {<br/>      resolve_conflicts = "OVERWRITE"<br/>    }<br/>    kube-proxy = {}<br/>    # vpc-cni = {<br/>    #   resolve_conflicts        = "OVERWRITE"<br/>    #   service_account_role_arn = module.vpc_cni_irsa.iam_role_arn<br/>    # }<br/>  }<br/><br/>  cluster_encryption_config = [{<br/>    provider_key_arn = aws_kms_key.eks.arn<br/>    resources        = ["secrets"]<br/>  }]<br/><br/>  vpc_id     = var.aws_eks_cluster.vpc_id<br/>  subnet_ids = var.aws_eks_cluster.subnets<br/><br/>  # Extend cluster security group rules<br/>  cluster_security_group_additional_rules = var.aws_eks_cluster.cluster_security_group_additional_rules<br/><br/>  # Extend node-to-node security group rules<br/>  node_security_group_additional_rules = var.aws_eks_cluster.node_security_group_additional_rules<br/><br/>  # eks_managed_node_group_defaults = {<br/>  #   iam_role_attach_cni_policy = true<br/>  # }<br/><br/>  eks_managed_node_groups = var.aws_eks_cluster.eks_managed_node_groups<br/><br/>  tags = var.aws_eks_cluster.tags<br/>}<br/><br/>################################################################################<br/># EKS Module<br/>################################################################################<br/><br/>module "vpc_cni_irsa" {<br/>  source  = "terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks"<br/>  version = "~&gt; 4.12"<br/><br/>  role_name_prefix      = var.vpc_cni_irsa.role_name_prefix<br/>  attach_vpc_cni_policy = var.vpc_cni_irsa.attach_vpc_cni_policy<br/>  vpc_cni_enable_ipv4   = var.vpc_cni_irsa.vpc_cni_enable_ipv4<br/><br/>  oidc_providers = {<br/>    main = {<br/>      provider_arn               = module.eks.oidc_provider_arn<br/>      namespace_service_accounts = ["kube-system:aws-node"]<br/>    }<br/>  }<br/><br/>  tags = var.aws_eks_cluster.tags<br/>}</span></pre><p id="669d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些设备各自的地形地貌配置如下。注意<code class="fe lz ma mb mc b">eks_managed_node_groups</code>块中的标签和污点。</p><pre class="mv mw mx my gt mz mc na bn nb nc bi"><span id="4c9d" class="nd ne jg mc b be nf ng l nh ni">inputs = {<br/>  aws_kms_key = {<br/>    description             = "EKS Secret Encryption Key"<br/>    deletion_window_in_days = 7<br/>    enable_key_rotation     = true<br/>    tags                    = local.tags<br/>  }<br/><br/>  aws_security_group = {<br/>    name_prefix = "eks-cluster-additional-sg"<br/>    vpc_id      = dependency.vpc.outputs.vpc_id<br/>    ingresses = [{<br/>      from_port = 22<br/>      to_port   = 22<br/>      protocol  = "tcp"<br/>      cidr_blocks = [<br/>        "10.0.0.0/8",<br/>        "172.16.0.0/12",<br/>        "192.168.0.0/16",<br/>      ]<br/>    }]<br/>    tags = local.tags<br/>  }<br/><br/>  aws_eks_cluster = {<br/>    cluster_name                    = "eks-cluster"<br/>    cluster_version                 = "1.24"<br/>    cluster_endpoint_private_access = true<br/>    cluster_endpoint_public_access  = true<br/>    vpc_id                          = dependency.vpc.outputs.vpc_id<br/>    subnets                         = dependency.vpc.outputs.vpc_public_subnets_ids<br/>    cluster_security_group_additional_rules = {<br/>      egress_nodes_ephemeral_ports_tcp = {<br/>        description                = "To node 1025-65535"<br/>        protocol                   = "tcp"<br/>        from_port                  = 1025<br/>        to_port                    = 65535<br/>        type                       = "egress"<br/>        source_node_security_group = true<br/>      }<br/>    }<br/>    node_security_group_additional_rules = {<br/>      ingress_self_all = {<br/>        description = "Node to node all ports/protocols"<br/>        protocol    = "-1"<br/>        from_port   = 0<br/>        to_port     = 0<br/>        type        = "ingress"<br/>        self        = true<br/>      }<br/>      egress_all = {<br/>        description      = "Node all egress"<br/>        protocol         = "-1"<br/>        from_port        = 0<br/>        to_port          = 0<br/>        type             = "egress"<br/>        cidr_blocks      = ["0.0.0.0/0"]<br/>        ipv6_cidr_blocks = ["::/0"]<br/>      }<br/>    }<br/>    eks_managed_node_groups = {<br/>      default_node_group_1 = {<br/>        create_launch_template = false<br/>        launch_template_name   = ""<br/><br/>        disk_size = 50<br/><br/>        min_size     = 1<br/>        max_size     = 7<br/>        desired_size = 1<br/><br/>        capacity_type        = "SPOT"<br/>        force_update_version = true<br/>        instance_types       = ["t3.small"]<br/>        taints               = []<br/>      }<br/>      default_node_group_2 = {<br/>        create_launch_template = false<br/>        launch_template_name   = ""<br/><br/>        disk_size = 50<br/><br/>        min_size     = 1<br/>        max_size     = 7<br/>        desired_size = 1<br/><br/>        capacity_type        = "SPOT"<br/>        force_update_version = true<br/>        instance_types       = ["t3.small"]<br/><br/>        labels = {<br/>          NodeTypeClass = "appops"<br/>        }<br/><br/>        taints = [{<br/>          key    = "dedicated"<br/>          value  = "appops"<br/>          effect = "NO_SCHEDULE"<br/>          }<br/>        ]<br/>      }<br/>    }<br/>    tags = local.tags<br/>  }<br/>  vpc_cni_irsa = {<br/>    role_name_prefix      = "VPC-CNI-IRSA"<br/>    attach_vpc_cni_policy = true<br/>    vpc_cni_enable_ipv4   = true<br/>    tags                  = local.tags<br/>  }<br/>}</span></pre><p id="2558" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为舵释放创建一个模块，因为它将被多次重复使用</p><pre class="mv mw mx my gt mz mc na bn nb nc bi"><span id="254d" class="nd ne jg mc b be nf ng l nh ni">resource "helm_release" "helm_chart" {<br/>  name             = var.helm_chart.name<br/>  namespace        = var.helm_chart.namespace<br/>  create_namespace = var.helm_chart.create_namespace<br/>  repository       = var.helm_chart.repository<br/>  chart            = var.helm_chart.chart<br/>  version          = var.helm_chart.chart_version<br/>  cleanup_on_fail  = true<br/>  values           = [var.helm_chart.values]<br/><br/>  dynamic "set" {<br/>    for_each = var.helm_chart.set<br/>    content {<br/>      name  = set.value.name<br/>      value = set.value.value<br/>      type  = set.value.type<br/>    }<br/>  }<br/>}</span></pre><p id="1fea" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Helm charts的values.yaml中的NodeSelector中添加标签，并相应地设置节点关联。我一直想在set function中添加复杂的层次类型，但是在terragrunt非常有限的支持下，这似乎是一个不可能的任务。我决定更好地直接更新这个任务的值文件。</p><pre class="mv mw mx my gt mz mc na bn nb nc bi"><span id="1646" class="nd ne jg mc b be nf ng l nh ni"># Note the labels and taints in the eks_managed_node_groups block<br/>labels = {<br/>  NodeTypeClass = "appops"<br/>}<br/><br/>taints = [{<br/>  key    = "dedicated"<br/>  value  = "appops"<br/>  effect = "NO_SCHEDULE"<br/>  }<br/>]</span></pre><p id="a08e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们配置的节点标签和污点，我们的舵图将具有以下配置:</p><pre class="mv mw mx my gt mz mc na bn nb nc bi"><span id="b830" class="nd ne jg mc b be nf ng l nh ni"># node selector<br/>nodeSelector:<br/>  kubernetes.io/os: linux<br/>  NodeTypeClass: appops<br/><br/><br/>## <br/># tolerations<br/>tolerations:<br/>  - key: "dedicated"<br/>    operator: "Equal"<br/>    value: "appops"<br/>    effect: "NoSchedule"<br/><br/>##<br/># node affinity<br/>affinity:<br/>  nodeAffinity:<br/>    requiredDuringSchedulingIgnoredDuringExecution:<br/>      nodeSelectorTerms:<br/>        - matchExpressions:<br/>            - key: NodeTypeClass<br/>              operator: In<br/>              values:<br/>                - appops</span></pre><p id="79c7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用terragrunt最好的一点是，你可以在根目录下执行<code class="fe lz ma mb mc b">terragrunt run-all apply</code>,然后去喝咖啡，等你回来的时候，所有的基础设施都已经部署好了。</p><figure class="mv mw mx my gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/dba82418c631abd826d52b332832dd55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMfBoU7FFyOE-e2qiETwBA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">尤里卡，所有的豆荚都是健康的！注意所有的opsapps、ingress-nginx和cert-manager是如何在同一个节点上调度的。</figcaption></figure><p id="b475" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我可以看到我的<code class="fe lz ma mb mc b">OpsApps</code>pod在各自的节点上被调度。但是我真的很想看到自动缩放的效果，所以我将节点的实例类型从<code class="fe lz ma mb mc b">t3.small</code>设置为<code class="fe lz ma mb mc b">t3.micro</code>。当我使用该配置再次创建集群时，我可以看到创建了节点，但是pod遇到了以下错误</p><figure class="mv mw mx my gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/b16da127d9af68f038a9eba2029fd5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pp2g-u8JtQAF-tax_ysHMw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">计划失败— 5分钟—默认计划程序0/3个节点可用:1个单元太多，1个节点有不可容忍的污点{ node . kubernetes . io/not-ready:}，1个节点有不可容忍的污点{ node . kubernetes . io/unschedulable:}，1个节点不可计划，2个节点与单元的节点关联/选择器不匹配。抢占:0/3个节点可用:1未找到传入pod的抢占受害者，2抢占对计划没有帮助。</figcaption></figure><p id="7194" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我遵循了书中的所有技巧，但看起来我肯定错过了一些东西，因为我的节点没有像预期的那样自动缩放。就在那时，我发现我设法只创建了节点组，但需要从群集内部向控制平面发出信号，表明容量需求不匹配，需要更多资源来满足这一需求。我们已经创建了<code class="fe lz ma mb mc b">Autoscaling Group</code>作为集群创建的一部分，我们只需要安装一个自动调整集群大小的组件；这个组件是<a class="ae jd" href="https://github.com/kubernetes/autoscaler" rel="noopener ugc nofollow" target="_blank">集群自动缩放器</a>。伟大的一部分是，它可以作为一个舵图表，我只需要使用相同的舵释放组件，我已经创建了。</p><div class="ip iq gp gr ir lb"><a href="https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">集群-自动缩放- EKS最佳实践指南</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">Kubernetes集群自动缩放器是一个流行的集群自动缩放解决方案，由SIG自动缩放维护。这是…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">aws.github.io</p></div></div><div class="lk l"><div class="nl l lm ln lo lk lp ix lb"/></div></div></a></div><div class="ip iq gp gr ir lb"><a href="https://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">自动缩放</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">自动缩放是一种自动缩放资源以满足不断变化的需求的功能。这是一个主要的…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">docs.aws.amazon.com</p></div></div></div></a></div><p id="287e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦完成，让我们应用这些变化，看看我们的掌舵图表是否在我们各自的节点上被安排。</p><figure class="mv mw mx my gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/b0797d50f450685eac93337c12c37662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NIV-9OXE6Yh_vFVuBQ12GQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">这次更多的节点。它显示我们的节点确实是由t3.micro类型的实例创建的</figcaption></figure><figure class="mv mw mx my gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/d78352a942927d202f1a4d49a1e092f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qASbOTdk647T96KTKNXsfg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">EKS集群的潜行峰值验证了这一点。</figcaption></figure><p id="e000" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lx"> PS。如果你觉得这篇文章有用的话，我真的很感激在github repo上打一颗星并分享这篇文章，因为它允许我在未来创建更多相关的内容。</em></p><div class="ip iq gp gr ir lb"><a href="https://github.com/aliabbasjaffri/multinode-terraform-terragrunt" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">GitHub-aliabbasjaffri/multi node-terraform-terra grunt:多节点terra form代码库…</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">在AWS云上使用terragrunt的多节点terraform代码存储库我使用terraform和terragrunt是为了…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">github.com</p></div></div><div class="lk l"><div class="no l lm ln lo lk lp ix lb"/></div></div></a></div></div></div>    
</body>
</html>