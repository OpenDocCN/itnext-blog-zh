<html>
<head>
<title>Build a data pipeline using MongoDB and Kafka Connect on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kubernetes上的MongoDB和Kafka Connect构建数据管道</h1>
<blockquote>原文：<a href="https://itnext.io/tutorial-data-pipeline-using-mongodb-and-kafka-connect-on-kubernetes-39ce92227736?source=collection_archive---------1-----------------------#2020-07-01">https://itnext.io/tutorial-data-pipeline-using-mongodb-and-kafka-connect-on-kubernetes-39ce92227736?source=collection_archive---------1-----------------------#2020-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="25bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Kubernetes上的Kafka Connect，简单的方法！，我已经在<code class="fe km kn ko kp b">Kubernetes</code>上使用<code class="fe km kn ko kp b"><a class="ae kl" href="http://strimzi.io/" rel="noopener ugc nofollow" target="_blank">Strimzi</a></code>以及文件源和接收器连接器演示了<code class="fe km kn ko kp b"><a class="ae kl" href="https://kafka.apache.org/documentation/#connect" rel="noopener ugc nofollow" target="_blank">Kafka Connect</a></code>。这篇博客将展示如何使用MongoDB和Kafka以及<a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/" rel="noopener ugc nofollow" target="_blank"> MongoDB Kafka连接器</a>构建一个简单的数据管道，这些连接器将通过<code class="fe km kn ko kp b">Strimzi</code>部署在Kubernetes上。</p><p id="1b0d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将使用以下Azure服务:</p><blockquote class="kq kr ks"><p id="e076" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">请注意，这些组件之间没有硬性依赖关系，该解决方案也应该与替代方案一起使用</em></p></blockquote><ul class=""><li id="c629" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">Apache Kafka的Azure事件中心</a>(任何其他Kafka集群都应该工作正常)</li><li id="28bc" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/aks/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Kubernetes服务</a>(随意使用<code class="fe km kn ko kp b">minikube</code>、<code class="fe km kn ko kp b">kind</code>等。)</li><li id="b962" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/cosmos-db/introduction?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB </a>作为MongoDB数据库，感谢<a class="ae kl" href="https://docs.microsoft.com/azure/cosmos-db/mongodb-introduction?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB为MongoDB </a>提供的API</li></ul><p id="6714" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，Kafka Connect组件被部署到Kubernetes，但它也适用于任何Kafka Connect部署</p><p id="1516" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">包括什么？</p><ul class=""><li id="6b61" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">MongoDB Kafka连接器和Strimzi概述</li><li id="69ed" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">Azure特定(可选)— Azure事件中心、Azure Cosmos DB和Azure Kubernetes服务</li><li id="e27b" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">设置和操作源和接收器连接器</li><li id="4e01" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">测试端到端场景</li></ul><blockquote class="kq kr ks"><p id="c1b0" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">GitHub</em>上的 <a class="ae kl" href="https://github.com/abhirockzz/mongodb-kafkaconnect-kubernetes" rel="noopener ugc nofollow" target="_blank"> <em class="iq">都有</em></a></p></blockquote></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="de50" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">概观</h1><p id="1abf" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">以下是不同组件的概述:</p><figure class="mw mx my mz gt na gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6472defa25af8d3bc11d4cf37a24f45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*T4lVqAtkdC0WjCtu.png"/></div></figure><blockquote class="kq kr ks"><p id="ac79" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">我用了一个人为的/简单的例子来关注管道和移动部件</p></blockquote><h2 id="1b90" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">MongoDB Kafka连接器</h2><p id="8ebe" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">MongoDB Kafka Connect集成提供了两个连接器:源和接收器</p><ul class=""><li id="ce61" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">源连接器:它从一个<code class="fe km kn ko kp b">MongoDB</code>集合(充当一个<code class="fe km kn ko kp b">source</code>)中提取数据，并将它们写入Kafka主题</li><li id="4d56" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">Sink connector:它用于处理Kafka主题中的数据，将它们保存到另一个MongoDB集合中(这相当于一个<code class="fe km kn ko kp b">sink</code>)</li></ul><blockquote class="kq kr ks"><p id="55b7" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">这些连接器也可以单独使用，但是在这篇博客中，我们将一起使用它们来拼接端到端解决方案</em></p></blockquote><h2 id="7e38" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated"><code class="fe km kn ko kp b">Strimzi</code>概述</h2><p id="08c9" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated"><code class="fe km kn ko kp b">Strimzi</code>通过为在Kubernetes上运行Kafka提供容器映像和操作符，简化了在Kubernetes集群中运行Apache Kafka的过程。它是 <code class="fe km kn ko kp b"><a class="ae kl" href="https://strimzi.io/blog/2019/09/06/cncf/" rel="noopener ugc nofollow" target="_blank">Cloud Native Computing Foundation</a></code>的<a class="ae kl" href="https://strimzi.io/blog/2019/09/06/cncf/" rel="noopener ugc nofollow" target="_blank">部分，作为<code class="fe km kn ko kp b"><a class="ae kl" href="https://www.cncf.io/sandbox-projects/" rel="noopener ugc nofollow" target="_blank">Sandbox</a></code> </a><a class="ae kl" href="https://www.cncf.io/sandbox-projects/" rel="noopener ugc nofollow" target="_blank">项目</a>(撰写时)</p><p id="2e61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是这个项目的基础。这些操作人员具有专业的操作知识，能够有效地管理Kafka。运营商简化了以下过程:部署和运行Kafka集群和组件，配置和保护对Kafka的访问，升级和管理Kafka，甚至负责管理主题和用户。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="7bc8" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">先决条件</h1><p id="7552" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated"><code class="fe km kn ko kp b">kubectl</code>-<a class="ae kl" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" rel="noopener ugc nofollow" target="_blank">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p><p id="7802" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你选择使用Azure Event Hubs、Azure Kubernetes服务或Azure Cosmos DB，你将需要一个<a class="ae kl" href="https://docs.microsoft.com/azure/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">微软Azure账户</a>。去报名参加一个免费的吧！</p><p id="d40c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">Azure CLI</code>或<code class="fe km kn ko kp b">Azure Cloud Shell</code> -如果你还没有安装<a class="ae kl" href="https://docs.microsoft.com/cli/azure/install-azure-cli?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>，你可以选择安装它(应该很快！)或者直接从浏览器使用<a class="ae kl" href="https://azure.microsoft.com/features/cloud-shell/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure云壳</a>。</p><h2 id="0253" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">舵</h2><p id="fa27" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">我将使用<code class="fe km kn ko kp b">Helm</code>安装<code class="fe km kn ko kp b">Strimzi</code>。这里是安装【https://helm.sh/docs/intro/install/】<a class="ae kl" href="https://helm.sh/docs/intro/install/" rel="noopener ugc nofollow" target="_blank"><code class="fe km kn ko kp b">Helm</code>本身的文档</a></p><blockquote class="kq kr ks"><p id="d891" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">您也可以使用</em> <code class="fe km kn ko kp b"><em class="iq">YAML</em></code> <em class="iq">文件直接安装</em> <code class="fe km kn ko kp b"><em class="iq">Strimzi</em></code> <em class="iq">。点击这里查看快速入门指南-</em><a class="ae kl" href="https://strimzi.io/docs/quickstart/latest/#proc-install-product-str" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://strim zi . io/docs/quick start/latest/# proc-install-product-str</em></a></p></blockquote><p id="533e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从设置所需的Azure服务开始(如果您没有使用Azure，请跳过这一部分，但请确保您有Kafka集群的详细信息，即代理URL和身份验证凭据，如果适用)</p><blockquote class="kq kr ks"><p id="e184" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">我建议将以下服务作为单个</em> <a class="ae kl" href="https://docs.microsoft.com/azure/azure-resource-manager/management/overview?WT.mc_id=medium-blog-abhishgu#resource-groups" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> Azure资源组</em> </a> <em class="iq">的一部分安装，这样可以很容易地清理这些服务</em></p></blockquote><h2 id="3932" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">天蓝色宇宙数据库</h2><p id="b611" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">您需要创建一个启用了MongoDB API支持的Azure Cosmos DB帐户以及一个数据库和集合。按照以下步骤使用Azure门户设置Azure Cosmos DB:</p><ul class=""><li id="7174" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/cosmos-db/create-mongodb-java?WT.mc_id=medium-blog-abhishgu#create-a-database-account" rel="noopener ugc nofollow" target="_blank">创建Azure Cosmos DB帐户</a></li><li id="2792" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/cosmos-db/create-mongodb-java?WT.mc_id=medium-blog-abhishgu#add-a-collection" rel="noopener ugc nofollow" target="_blank">添加数据库和集合</a>并获取连接字符串</li></ul><blockquote class="kq kr ks"><p id="50ab" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">了解更多关于如何在Azure Cosmos DB </em> 中使用数据库、容器和项目的信息</p></blockquote><p id="aef5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想使用Azure CLI或云Shell，下面是你需要执行的命令序列:</p><p id="9086" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/cli/azure/cosmosdb?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-cosmosdb-create" rel="noopener ugc nofollow" target="_blank">创建Azure Cosmos DB帐户</a>(注意<code class="fe km kn ko kp b">--kind MongoDB</code>)</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="5d71" class="nd lt iq kp b gy nt nu l nv nw">az cosmosdb create --resource-group &lt;RESOURCE_GROUP&gt; --name &lt;COSMOS_DB_NAME&gt; --kind MongoDB</span></pre><p id="bb9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/cli/azure/cosmosdb/mongodb/database?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-cosmosdb-mongodb-database-create" rel="noopener ugc nofollow" target="_blank">创建数据库</a></p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="1a80" class="nd lt iq kp b gy nt nu l nv nw">az cosmosdb mongodb database create --account-name &lt;COSMOS_DB_ACCOUN&gt; --name &lt;COSMOS_DB_NAME&gt; --resource-group &lt;RESOURCE_GROUP&gt;</span></pre><p id="7658" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，<a class="ae kl" href="https://docs.microsoft.com/cli/azure/cosmosdb/mongodb/collection?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu#az-cosmosdb-mongodb-collection-create" rel="noopener ugc nofollow" target="_blank">在数据库中创建一个集合</a></p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="dee0" class="nd lt iq kp b gy nt nu l nv nw">az cosmosdb mongo collection create --account-name &lt;COSMOS_DB_ACCOUNT&gt; --database-name &lt;COSMOS_DB_NAME&gt; --name &lt;COSMOS_COLLECTION_NAME&gt; --resource-group-name &lt;RESOURCE_GROUP&gt; --shard &lt;SHARDING_KEY_PATH&gt;</span></pre><p id="fa39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">获取连接字符串并保存它。你以后会用到它</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="66c1" class="nd lt iq kp b gy nt nu l nv nw">az cosmosdb list-connection-strings --name &lt;COSMOS_DB_ACCOUNT&gt; --resource-group &lt;RESOURCE_GROUP&gt; -o tsv --query connectionStrings[0].connectionString</span></pre><p id="c0ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用一些数据作为集合的种子。有很多方法可以做到这一点。出于本教程的目的，我推荐快速简单的方法，例如:</p><ul class=""><li id="814c" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">Azure门户中可用的<code class="fe km kn ko kp b">Data Explorer</code>选项卡(当您创建Azure Cosmos DB帐户时)</li><li id="8b31" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/cosmos-db/data-explorer?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Cosmos DB explorer </a>(一个独立的基于网络的界面)</li><li id="f2c2" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae kl" href="https://devblogs.microsoft.com/cosmosdb/preview-native-mongo-shell/" rel="noopener ugc nofollow" target="_blank">原生Mongo shell </a>(通过Azure门户中的数据浏览器选项卡)</li></ul><blockquote class="kq kr ks"><p id="2852" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">稍后，当我们部署源连接器时，我们将仔细检查这些(现有的)项目/记录是否被连接器拾取并发送到Kafka </em></p></blockquote><h2 id="ecd8" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">Azure活动中心</h2><p id="35e4" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-about?%5BWT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Event Hubs </a>是一个数据流平台和事件摄取服务<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">，它还提供了一个Kafka端点</a>，现有的基于Kafka的应用程序可以使用它作为运行自己的Kafka集群的替代方案。Event Hubs支持Apache Kafka protocol 1.0和更高版本，并与Kafka生态系统中现有的Kafka客户端应用程序和其他工具一起工作，包括<code class="fe km kn ko kp b">Kafka Connect</code>(在本博客中演示过)<code class="fe km kn ko kp b">MirrorMaker</code>等。</p><p id="9eb4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要设置Azure Event Hubs集群，您可以从各种选项中进行选择，包括<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-create?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">Azure门户</a>、<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-quickstart-cli?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>、<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-quickstart-powershell?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure PowerShell </a>或<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-resource-manager-namespace-event-hub?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">ARM模板</a>。一旦设置完成，您将需要连接字符串(将在后续步骤中使用)用于<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/authenticate-shared-access-signature?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">认证到事件中心</a> — <a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-get-connection-string?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">使用本指南</a>完成此步骤。</p><p id="321d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请确保您还创建了一个事件中心(与Kafka主题相同),作为我们的Kafka Connect连接器的目标(在后续部分中有详细描述)</p><h2 id="ea79" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">蓝色库伯内特服务</h2><p id="2848" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Kubernetes服务(AKS) </a>让在Azure中部署托管的Kubernetes集群变得简单。它通过将大部分责任转移给Azure，降低了管理Kubernetes的复杂性和运营开销。以下是如何使用<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>、<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure portal </a>或<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-rm-template?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> ARM模板</a>设置AKS集群的示例</p><p id="f834" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们继续讨论Kubernetes组件:</p><blockquote class="kq kr ks"><p id="35d8" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">请注意，我重复使用了</em> <a class="ae kl" href="https://dev.to/azure/kafka-connect-on-kubernetes-the-easy-way-2co9" rel="noopener ugc nofollow" target="_blank"> <em class="iq">之前博文</em> </a> <em class="iq">中的部分内容(毕竟安装是一样的！)，但同时尽量保持简短，避免重复。对于已经省略的部分，例如解释Kafka Connect的</em> <code class="fe km kn ko kp b"><em class="iq">Strimzi</em></code> <em class="iq">组件规格等。，我想请你看看那个博客</em></p></blockquote></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="54ec" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">基础安装</h1><p id="c138" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">首先，我们将安装<code class="fe km kn ko kp b">Strimzi</code>和Kafka Connect，然后是MongoDB连接器</p><h2 id="e616" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">安装Strimzi</h2><p id="8e01" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">使用<code class="fe km kn ko kp b">Helm</code>安装Strimzi非常简单:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="a188" class="nd lt iq kp b gy nt nu l nv nw">//add helm chart repo for Strimzi<br/>helm repo add strimzi https://strimzi.io/charts/</span><span id="770f" class="nd lt iq kp b gy nx nu l nv nw">//install it! (I have used strimzi-kafka as the release name)<br/>helm install strimzi-kafka strimzi/strimzi-kafka-operator</span></pre><p id="fd48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将安装<code class="fe km kn ko kp b">Strimzi</code>操作符(它只是一个<code class="fe km kn ko kp b">Deployment</code>)、定制资源定义和其他Kubernetes组件，如<code class="fe km kn ko kp b">Cluster Roles</code>、<code class="fe km kn ko kp b">Cluster Role Bindings</code>和<code class="fe km kn ko kp b">Service Accounts</code></p><p id="a34c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更多详情，请点击此链接</p><p id="1b25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确认Strimzi操作器已经被部署，检查它的<code class="fe km kn ko kp b">Pod</code>(它应该在一段时间后转换到<code class="fe km kn ko kp b">Running</code>状态)</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="028a" class="nd lt iq kp b gy nt nu l nv nw">kubectl get pods -l=name=strimzi-cluster-operator</span><span id="a2a6" class="nd lt iq kp b gy nx nu l nv nw">NAME                                        READY   STATUS    RESTARTS   AGE<br/>strimzi-cluster-operator-5c66f679d5-69rgk   1/1     Running   0          43s</span></pre><p id="570e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了“大脑”(Strimzi操作符)，让我们使用它吧！</p><h2 id="3c59" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">卡夫卡连接</h2><p id="ed1c" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">在部署Kafka Connect之前，我们需要创建一些helper Kubernetes组件。</p><p id="3436" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">克隆<a class="ae kl" href="https://github.com/abhirockzz/mongodb-kafkaconnect-kubernetes" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a></p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="484b" class="nd lt iq kp b gy nt nu l nv nw">git clone <a class="ae kl" href="https://github.com/abhirockzz/mongodb-kafkaconnect-kubernetes" rel="noopener ugc nofollow" target="_blank">https://github.com/abhirockzz/mongodb-kafkaconnect-kubernetes</a></span><span id="5391" class="nd lt iq kp b gy nx nu l nv nw">cd mongodb-kafkaconnect-kubernetes</span></pre><p id="8513" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka Connect将需要引用现有的Kafka集群(在本例中是Azure Event Hubs)。我们可以将集群的认证信息存储为一个<a class="ae kl" href="https://kubernetes.io/docs/concepts/configuration/secret/" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a> <code class="fe km kn ko kp b"><a class="ae kl" href="https://kubernetes.io/docs/concepts/configuration/secret/" rel="noopener ugc nofollow" target="_blank">Secret</a></code>，稍后可以在Kafka Connect定义中使用。</p><p id="7ded" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更新<code class="fe km kn ko kp b">eventhubs-secret.yaml</code>文件以包含Azure事件中心的凭证。在<code class="fe km kn ko kp b">eventhubspassword</code>属性中输入连接字符串。</p><p id="f5f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="3ba3" class="nd lt iq kp b gy nt nu l nv nw">apiVersion: v1<br/>kind: Secret<br/>metadata:<br/>  name: eventhubssecret<br/>type: Opaque<br/>stringData:<br/>  eventhubsuser: $ConnectionString<br/>  eventhubspassword: Endpoint=sb://&lt;eventhubs-namespace&gt;.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=&lt;access-key&gt;</span></pre><blockquote class="kq kr ks"><p id="3bed" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">保持</em> <code class="fe km kn ko kp b"><em class="iq">eventhubsuser: $ConnectionString</em></code> <em class="iq">不变</em></p></blockquote><p id="8e16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">打造<code class="fe km kn ko kp b">Secret</code>:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="d7e8" class="nd lt iq kp b gy nt nu l nv nw">kubectl apply -f deploy/eventhubs-secret.yaml</span></pre><p id="64a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是卡夫卡连接斯特里姆齐的定义:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="7ced" class="nd lt iq kp b gy nt nu l nv nw">apiVersion: kafka.strimzi.io/v1beta1<br/>kind: KafkaConnect<br/>metadata:<br/>  name: my-connect-cluster<br/>  annotations:<br/>    strimzi.io/use-connector-resources: "true"<br/>spec:<br/>  image: abhirockzz/strimzi-kafkaconnect-mongodb:latest<br/>  version: 2.4.0<br/>  replicas: 1<br/>  bootstrapServers: [EVENT_HUBS_NAMESPACE.servicebus.windows.net]:9093<br/>  config:<br/>    group.id: strimzi-connect-cluster<br/>    offset.storage.topic: mongo-connect-cluster-offsets<br/>    config.storage.topic: mongo-connect-cluster-configs<br/>    status.storage.topic: mongo-connect-cluster-status<br/>  authentication:<br/>    type: plain<br/>    username: $ConnectionString<br/>    passwordSecret:<br/>      secretName: eventhubssecret<br/>      password: eventhubspassword<br/>  tls:<br/>    trustedCertificates: []</span></pre><p id="60b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经使用了一个定制的Docker映像来打包MongoDB Kafka连接器。它以施特林齐·卡夫卡的形象为(<code class="fe km kn ko kp b">strimzi/kafka</code>)基础</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="1614" class="nd lt iq kp b gy nt nu l nv nw">image: abhirockzz/strimzi-kafkaconnect-mongodb:latest</span></pre><blockquote class="kq kr ks"><p id="bd2a" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">详情请查看</em><a class="ae kl" href="https://strimzi.io/docs/latest/#creating-new-image-from-base-str" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://strim zi . io/docs/latest/# creating-new-image-from-base-str</em></a></p></blockquote><p id="8852" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里是<code class="fe km kn ko kp b">Dockerfile</code>——您可以调整它，使用不同的，上传到任何Docker注册表，并在Kafka Connect清单中引用它</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="5091" class="nd lt iq kp b gy nt nu l nv nw">FROM strimzi/kafka:0.17.0-kafka-2.4.0<br/>USER root:root<br/>COPY ./connectors/ /opt/kafka/plugins/<br/>USER 1001</span></pre><p id="983d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们几乎已经准备好创建Kafka Connect实例了。在此之前，确保用Azure Event Hubs端点的属性更新<code class="fe km kn ko kp b">bootstrapServers</code>属性</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="5aea" class="nd lt iq kp b gy nt nu l nv nw">spec:<br/>  version: 2.4.0<br/>  replicas: 1<br/>  bootstrapServers: &lt;replace-with-eventhubs-namespace&gt;.servicebus.windows.net:9093</span></pre><p id="def2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要创建Kafka Connect实例，请执行以下操作:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="946b" class="nd lt iq kp b gy nt nu l nv nw">kubectl apply -f deploy/kafka-connect.yaml</span></pre><p id="9c39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要确认:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="38bd" class="nd lt iq kp b gy nt nu l nv nw">kubectl get kafkaconnects</span><span id="827f" class="nd lt iq kp b gy nx nu l nv nw">NAME                 DESIRED REPLICAS<br/>my-connect-cluster   1</span></pre><p id="cfe2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将创建一个<code class="fe km kn ko kp b">Deployment</code>和一个相应的<code class="fe km kn ko kp b">Pod</code></p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="1a32" class="nd lt iq kp b gy nt nu l nv nw">kubectl get pod -l=strimzi.io/cluster=my-connect-cluster</span><span id="1a3f" class="nd lt iq kp b gy nx nu l nv nw">NAME                                          READY   STATUS    RESTARTS   AGE<br/>my-connect-cluster-connect-5bf9db5d9f-9ttg4   1/1     Running   0          1h</span></pre><p id="7e43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您在Kubernetes拥有Kafka Connect集群！使用<code class="fe km kn ko kp b">kubectl logs &lt;pod name&gt;</code>检查日志</p><blockquote class="kq kr ks"><p id="f16a" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">检查Azure Event Hubs——在Azure门户中，打开您的Azure Event Hubs名称空间，然后单击Event Hubs选项卡，您应该会看到Kafka Connect(内部)主题</em></p></blockquote><figure class="mw mx my mz gt na gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi ny"><img src="../Images/f92de7e210eca18556487e7cbed2eac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I1ePgJhqqGjtyCb2.png"/></div></div></figure></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="44d7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">MongoDB Kafka连接器</h1><h2 id="9747" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">源连接器</h2><p id="26cc" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">我们现在将设置源连接器。定义如下:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="ad5a" class="nd lt iq kp b gy nt nu l nv nw">apiVersion: kafka.strimzi.io/v1alpha1<br/>kind: KafkaConnector<br/>metadata:<br/>  name: mongodb-source-connector<br/>  labels:<br/>    strimzi.io/cluster: my-connect-cluster<br/>spec:<br/>  class: com.mongodb.kafka.connect.MongoSourceConnector<br/>  tasksMax: 2<br/>  config:<br/>    connection.uri: [AZURE_COSMOSDB_CONNECTION_STRING]<br/>    topic.prefix: mongo<br/>    database: [MONGODB_DATABASE_NAME]<br/>    collection: [MONGODB_COLLECTION_NAME]<br/>    copy.existing: true<br/>    key.converter": org.apache.kafka.connect.json.JsonConverter<br/>    key.converter.schemas.enable: false<br/>    value.converter: org.apache.kafka.connect.json.JsonConverter<br/>    value.converter.schemas.enable: false<br/>    publish.full.document.only: true<br/>    pipeline: &gt;<br/>      [{"$match":{"operationType":{"$in":["insert","update","replace"]}}},{"$project":{"_id":1,"fullDocument":1,"ns":1,"documentKey":1}}]</span></pre><p id="d713" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用标签来指代我们刚刚设置的kafka集群</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="4df0" class="nd lt iq kp b gy nt nu l nv nw">metadata:<br/>  name: mongodb-source-connector<br/>  labels:<br/>    strimzi.io/cluster: my-connect-cluster</span></pre><p id="cd3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<code class="fe km kn ko kp b">config</code>部分，我们输入连接器配置，包括MongoDB连接字符串、数据库和集合名称，以及我们是否想要复制现有数据等。<code class="fe km kn ko kp b">topic.prefix</code>属性被添加到数据库&amp;集合名称中，以生成Kafka主题的名称来发布数据。例如，如果数据库和集合名称分别为<code class="fe km kn ko kp b">test_db</code>、<code class="fe km kn ko kp b">test_coll</code>，那么卡夫卡主题名称将为<code class="fe km kn ko kp b">mongo.test_db.test_coll</code>。此外，<code class="fe km kn ko kp b">publish.full.document.only</code>被设置为<code class="fe km kn ko kp b">true</code>——这意味着，只有受到影响(创建、更新、替换)的文档将被发布到Kafka，而不是整个变更流文档(包含许多其他信息)</p><blockquote class="kq kr ks"><p id="1bf1" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">详见文档:</em><a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/kafka-source/#source-connector-configuration-properties" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://docs . MongoDB . com/Kafka-connector/current/Kafka-source/# source-connector-configuration-properties</em></a></p></blockquote><p id="af2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除此之外，我想强调一下<code class="fe km kn ko kp b">pipeline</code>属性:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="51eb" class="nd lt iq kp b gy nt nu l nv nw">pipeline: &gt;<br/>      [{"$match":{"operationType":{"$in":["insert","update","replace"]}}},{"$project":{"_id":1,"fullDocument":1,"ns":1,"documentKey":1}}]</span></pre><p id="9d1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是<code class="fe km kn ko kp b">JSON</code>(嵌入在<code class="fe km kn ko kp b">YAML</code>中)..多开心啊！)定义了一个自定义管道。在Azure Cosmos DB的MongoDB API的情况下，由于变更流特性中的约束(在编写本文时)，这是强制性的。有关详细信息，请参考[Azure Cosmos DB文档]中的这一部分</p><p id="d38a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在部署连接器之前，让我们做最后一件事。为了确认我们的源连接器设置确实在工作，我们需要关注事件中心中的Kafka主题</p><blockquote class="kq kr ks"><p id="553d" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">既然我们已经为连接器指定了</em> <code class="fe km kn ko kp b"><em class="iq">copy.existing: true</em></code> <em class="iq"> config，那么集合中现有的条目应该被发送到Kafka主题。</em></p></blockquote><p id="16f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有许多方法可以做到这一点。这个文档包含了很多有用的链接，包括，<code class="fe km kn ko kp b"><a class="ae kl" href="https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/quickstart/kafkacat" rel="noopener ugc nofollow" target="_blank">kafkacat</a></code>，<a class="ae kl" href="https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/quickstart/kafka-cli" rel="noopener ugc nofollow" target="_blank"> Kafka CLI </a>等。</p><blockquote class="kq kr ks"><p id="36b9" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">我会用</em>T12】</p></blockquote><p id="87ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在mac上安装<code class="fe km kn ko kp b">kafkacat</code>-<a class="ae kl" href="https://github.com/edenhill/kafkacat#install" rel="noopener ugc nofollow" target="_blank">https://github.com/edenhill/kafkacat#install</a>例如<code class="fe km kn ko kp b">brew install kafkacat</code>。替换<code class="fe km kn ko kp b">kafkacat.conf</code>文件中的属性(在<code class="fe km kn ko kp b">GitHub</code> repo中)</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="b8e7" class="nd lt iq kp b gy nt nu l nv nw">metadata.broker.list=[EVENTHUBS_NAMESPACE].servicebus.windows.net:9093<br/>security.protocol=SASL_SSL<br/>sasl.mechanisms=PLAIN<br/>sasl.username=$ConnectionString<br/>sasl.password=Endpoint=sb://[EVENTHUBS_NAMESPACE].servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=[EVENTHUBS_ACCESS_KEY]</span></pre><p id="28c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">导出环境变量</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="4ef3" class="nd lt iq kp b gy nt nu l nv nw">export KAFKACAT_CONFIG=kafkacat.conf<br/>export BROKER=[EVENTHUBS_NAMESPACE].servicebus.windows.net:9093<br/>export TOPIC=[KAFKA_TOPIC e.g. mongo.test_db.test_coll]</span></pre><p id="59d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据以下连接器配置属性，<code class="fe km kn ko kp b">TOPIC</code>的值遵循模板:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="5216" class="nd lt iq kp b gy nt nu l nv nw">&lt;topic.prefix&gt;.&lt;database&gt;.&lt;collection&gt;</span></pre><p id="8263" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">…并调用<code class="fe km kn ko kp b">kafkacat</code>:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="8195" class="nd lt iq kp b gy nt nu l nv nw">kafkacat -b $BROKER -t $TOPIC -o beginning</span></pre><p id="e556" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在连接器清单文件中，更新Azure Cosmos DB连接字符串、MongoDB数据库的名称以及集合</p><p id="1de9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="8139" class="nd lt iq kp b gy nt nu l nv nw">...<br/>  connection.uri: mongodb://&lt;COSMOSDB_ACCOUNT_NAME&gt;:&lt;COSMOSDB_PRIMARY_KEY&gt;@&lt;COSMOSDB_ACCOUNT_NAME&gt;.mongo.cosmos.azure.com:10255/?ssl=true&amp;replicaSet=globaldb&amp;maxIdleTimeMS=120000&amp;appName=@&lt;COSMOSDB_ACCOUNT_NAME&gt;@<br/>  topic.prefix: mongo<br/>  database: my_source_db<br/>  collection: my_source_coll<br/>...</span></pre><p id="245b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，你都准备好了。从不同的终端部署连接器</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="a405" class="nd lt iq kp b gy nt nu l nv nw">kubectl apply -f deploy/mongodb-source-connector.yaml</span></pre><p id="b50f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要进行确认，只需列出连接器:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="18c0" class="nd lt iq kp b gy nt nu l nv nw">kubectl get kafkaconnectors</span><span id="91aa" class="nd lt iq kp b gy nx nu l nv nw">NAME                  AGE<br/>mongodb-source-connector  70s</span></pre><p id="406f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">连接器应该旋转起来，开始编织它的魔法。如果您想反思Kafka Connect日志:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="fc39" class="nd lt iq kp b gy nt nu l nv nw">kubectl logs -f $(kubectl get pod -l=strimzi.io/cluster=my-connect-cluster -o jsonpath='{.items[0].metadata.name}')</span></pre><p id="cbdb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">按照说明，如果您已经在源MongoDB集合中创建了项目，请检查<code class="fe km kn ko kp b">kafkacat</code>终端——您应该看到Kafka主题记录弹出。继续向MongoDB集合添加一些项目，并确认您可以在<code class="fe km kn ko kp b">kafkacat</code>消费者终端中看到它们</p><blockquote class="kq kr ks"><p id="70f1" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">恢复功能:连接器能够从特定时间点继续处理。</em> <a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/kafka-source/#change-stream-event-document-format" rel="noopener ugc nofollow" target="_blank"> <em class="iq">根据连接器文档</em> </a> <em class="iq"> — </em>“顶层_id字段用作恢复令牌，用于从特定时间点开始变更流。”</p></blockquote><h2 id="0840" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">接收器连接器</h2><p id="5d17" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">我们有设置的前半部分，使用它我们可以将MongoDB操作细节发布到Kafka主题。让我们完成另一半，它将转换Kafka主题中的数据，并将其存储在目标MongoDB集合中。为此，我们将使用接收器连接器——下面是它的定义</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="075f" class="nd lt iq kp b gy nt nu l nv nw">apiVersion: kafka.strimzi.io/v1alpha1<br/>kind: KafkaConnector<br/>metadata:<br/>  name: mongodb-sink-connector<br/>  labels:<br/>    strimzi.io/cluster: my-connect-cluster<br/>spec:<br/>  class: com.mongodb.kafka.connect.MongoSinkConnector<br/>  tasksMax: 2<br/>  config:<br/>    topics: [EVENTHUBS_TOPIC_NAME]<br/>    connection.uri: [AZURE_COSMOSDB_CONNECTION_STRING]<br/>    database: [MONGODB_DATABASE_NAME]<br/>    collection: [MONGODB_COLLECTION_NAME]<br/>    post.processor.chain: com.mongodb.kafka.connect.sink.processor.DocumentIdAdder,com.mongodb.kafka.connect.sink.processor.KafkaMetaAdder<br/>    key.converter: org.apache.kafka.connect.json.JsonConverter<br/>    key.converter.schemas.enable: false<br/>    value.converter: org.apache.kafka.connect.json.JsonConverter<br/>    value.converter.schemas.enable: false</span></pre><p id="2eb5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<code class="fe km kn ko kp b">config</code>部分中，我们需要指定源Kafka主题(使用<code class="fe km kn ko kp b">topics</code>)——这与源连接器写入记录的Kafka主题相同。<code class="fe km kn ko kp b">database</code>和<code class="fe km kn ko kp b">collection</code>应分别填入目标数据库和集合的名称。注意,<code class="fe km kn ko kp b">post.processor.chain</code>属性包含<code class="fe km kn ko kp b">com.mongodb.kafka.connect.sink.processor.KafkaMetaAdder</code>——这将自动向MongoDB文档添加一个属性(<code class="fe km kn ko kp b">topic-partition-offset</code>),并捕获Kafka主题、分区和偏移值</p><p id="8914" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，<code class="fe km kn ko kp b">"topic-partition-offset" : "mongo.test_db1.test_coll1-0-74",</code>其中<code class="fe km kn ko kp b">mongo.test_db1.test_coll1</code>是主题名，<code class="fe km kn ko kp b">0</code>是分区，<code class="fe km kn ko kp b">74</code>是偏移量</p><p id="41c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在创建接收器连接器之前，用MongoDB连接字符串、源Kafka主题的名称以及接收器数据库和集合更新清单</p><p id="b1af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="afd0" class="nd lt iq kp b gy nt nu l nv nw">...<br/>  config:<br/>    topics: mongo.my_source_db.my_source_coll<br/>    connection.uri: mongodb://&lt;COSMOSDB_ACCOUNT_NAME&gt;:&lt;COSMOSDB_PRIMARY_KEY&gt;@&lt;COSMOSDB_ACCOUNT_NAME&gt;.mongo.cosmos.azure.com:10255/?ssl=true&amp;replicaSet=globaldb&amp;maxIdleTimeMS=120000&amp;appName=@&lt;COSMOSDB_ACCOUNT_NAME&gt;@<br/>    database: my_sink_db<br/>    collection: my_sink_coll<br/>...</span></pre><p id="23b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在可以部署连接器了:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="2b8b" class="nd lt iq kp b gy nt nu l nv nw">kubectl apply -f deploy/mongodb-sink-connector.yaml</span></pre><p id="bf18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要进行确认，只需列出连接器:</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="4765" class="nd lt iq kp b gy nt nu l nv nw">kubectl get kafkaconnectors</span><span id="4e51" class="nd lt iq kp b gy nx nu l nv nw">NAME                  AGE<br/>mongodb-source-connector  70s<br/>mongodb-sink-connector  70s</span></pre><p id="1fe2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，连接器将Kafka主题中的现有记录(如果有的话)复制到sink集合中。如果您最初在source Azure Cosmos DB集合中创建了项目，它们应该已经被复制到Kafka topic(通过source connector ),并随后通过sink connector持久化到sink Azure Cosmos DB集合——要确认这一点，请使用前面提到的任何方法查询Azure Cosmos DB</p><p id="5fdf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一个示例记录(注意<code class="fe km kn ko kp b">topic-partition-offset</code>属性)</p><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="6657" class="nd lt iq kp b gy nt nu l nv nw">{<br/>    "_id" : ObjectId("5eb937e5a68a237befb2bd44"),<br/>    "name" : "foo72",<br/>    "email" : "foo72@bar.com",<br/>    "status" : "online",<br/>    "topic-partition-offset" : "mongo.test_db1.test_coll1-0-74",<br/>    "CREATE_TIME" : 1589196724357<br/>}</span></pre><blockquote class="kq kr ks"><p id="2a38" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">您可以继续试验该设置。添加、更新和删除源MongoDB集合中的项目，并查看结果… </em></p></blockquote></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="6859" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">打扫</h1><p id="f9a6" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">一旦您完成了对应用程序的探索，您就可以删除这些资源。如果你把Azure服务(AKS，Event Hubs，Cosmos DB)放在同一个资源组下，执行一个命令很容易。</p><blockquote class="kq kr ks"><p id="ee7a" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">请注意，这将删除组中的所有资源，包括您作为教程的一部分创建的资源，以及如果您使用已经存在的</em>资源组时可能拥有的任何其他服务实例</p></blockquote><pre class="mw mx my mz gt np kp nq nr aw ns bi"><span id="df64" class="nd lt iq kp b gy nt nu l nv nw">az group delete --name $AZURE_RESOURCE_GROUP_NAME</span></pre></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="f4c4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">结论</h1><p id="12ea" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">如前所述，这是一个简化的示例，有助于关注不同的组件和移动部分，例如Kafka、Kubernetes、MongoDB、Kafka Connect等。我演示了一个用例，其中记录在最终存储到sink集合之前被修改，但是连接器提供了许多其他选项，所有这些选项都是基于配置的，不需要额外的代码(尽管也有集成挂钩)。一些例子包括，在源连接器中使用<a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/kafka-source/#custom-pipeline-example" rel="noopener ugc nofollow" target="_blank">定制管道</a>，在接收连接器中使用<a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/kafka-sink-postprocessors/#post-processing-of-documents" rel="noopener ugc nofollow" target="_blank">后处理器</a>等。</p><h2 id="8c13" class="nd lt iq bd lu ne nf dn ly ng nh dp mc jy ni nj mg kc nk nl mk kg nm nn mo no bi translated">资源</h2><p id="84c4" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">这个博客到此为止。一如既往，敬请期待更多！</p><p id="75ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将给你们留下一些资源:</p><ul class=""><li id="3c00" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">MongoDB Kafka连接器文档—<a class="ae kl" href="https://docs.mongodb.com/kafka-connector/current/" rel="noopener ugc nofollow" target="_blank">https://docs.mongodb.com/kafka-connector/current/</a></li><li id="81be" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">MongoDB Kafka连接器GitHub repo—<a class="ae kl" href="https://github.com/mongodb/mongo-kafka" rel="noopener ugc nofollow" target="_blank">https://github.com/mongodb/mongo-kafka</a></li><li id="6c93" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">斯特里姆齐文档—【https://strimzi.io/docs/latest/ T2】</li><li id="832d" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">卡夫卡连线—【https://kafka.apache.org/documentation/#connect T4】</li></ul></div></div>    
</body>
</html>