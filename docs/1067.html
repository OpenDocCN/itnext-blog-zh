<html>
<head>
<title>Realtime JavaScript Face Tracking and Face Recognition using face-api.js’ MTCNN Face Detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用face-api.js的MTCNN人脸检测器进行实时JavaScript人脸跟踪和人脸识别</h1>
<blockquote>原文：<a href="https://itnext.io/realtime-javascript-face-tracking-and-face-recognition-using-face-api-js-mtcnn-face-detector-d924dd8b5740?source=collection_archive---------0-----------------------#2018-07-16">https://itnext.io/realtime-javascript-face-tracking-and-face-recognition-using-face-api-js-mtcnn-face-detector-d924dd8b5740?source=collection_archive---------0-----------------------#2018-07-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0237" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">介绍用于人脸检测的face-api.js' MTCNN和tensorflow.js的5点人脸标志</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/4291303dc06c6685e811fe4ff60684f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*PYKxRC7HCmv9ZwmuyF-auw.gif"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk translated">永远不要相信劣质的GIF！自己试试吧！</figcaption></figure><p id="f9fb" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你现在正在阅读这篇文章，很可能你已经读过我的介绍文章(<a class="ae lo" rel="noopener ugc nofollow" target="_blank" href="/face-api-js-javascript-api-for-face-recognition-in-the-browser-with-tensorflow-js-bcc2a6c4cf07"> <strong class="ku ir"> face-api.js —用tensorflow.js </strong> </a>在浏览器中进行人脸识别的JavaScript API)或者之前玩过<a class="ae lo" href="https://github.com/justadudewhohacks/face-api.js" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir"> face-api.js </strong> </a>。如果你还没有听说过face-api.js，我强烈推荐你先去读一下介绍文章，看看回购！如果您想先玩一些例子，请查看<a class="ae lo" href="https://justadudewhohacks.github.io/face-api.js/" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir">演示页面</strong> </a> <strong class="ku ir">！</strong></p><p id="69a1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">和往常一样，本文中有一个代码示例在等着您。我们将破解一个小应用程序，它将在浏览器中从<strong class="ku ir">网络摄像头</strong> <strong class="ku ir">图像</strong>中执行<strong class="ku ir">实时人脸检测</strong>和<strong class="ku ir">人脸识别</strong>，请继续关注我！</p><h1 id="fdaf" class="lp lq iq bd kr lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">使用face-api.js进行人脸检测</h1><p id="2b91" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">到目前为止，face-api.js单独实现了一个基于<strong class="ku ir"> SSD Mobilenet v1 </strong>的CNN进行人脸检测。虽然这是一个非常准确的人脸检测器，但SSD不像其他架构那样快(就推理时间而言)，并且它可能无法通过这个人脸检测器实现实时，除非你/你的webapp的用户在他们的机器中内置了一个不错的GPU。</p><p id="5389" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">事实证明，你并不总是需要那么高的准确度，有时你宁愿用高准确度来换取更快的人脸检测器。</p><p id="eab4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这就是<strong class="ku ir"> MTCNN </strong>发挥作用的地方，现在可以在face-api.js中获得！MTCNN是一个更加轻量级的人脸检测器。在下文中，我将指出它与固态硬盘Mobilenet v1的区别:</p><h2 id="d2fe" class="ml lq iq bd kr mm mn dn lu mo mp dp ly lb mq mr ma lf ms mt mc lj mu mv me mw bi translated"><strong class="ak">优点:</strong></h2><ul class=""><li id="872b" class="mx my iq ku b kv mg ky mh lb mz lf na lj nb ln nc nd ne nf bi translated">推断时间更短(<strong class="ku ir">检测速度更快</strong>)</li><li id="2e02" class="mx my iq ku b kv ng ky nh lb ni lf nj lj nk ln nc nd ne nf bi translated">同时检测<strong class="ku ir"> 5个人脸标志点</strong>(免费获得人脸对齐)</li><li id="171d" class="mx my iq ku b kv ng ky nh lb ni lf nj lj nk ln nc nd ne nf bi translated">更小的型号尺寸:与大约6MB(量化SSD Mobilenet v1重量)相比，只有大约2MB</li><li id="60c9" class="mx my iq ku b kv ng ky nh lb ni lf nj lj nk ln nc nd ne nf bi translated"><strong class="ku ir">可配置:</strong>您可以调整一些参数来提高性能，以满足您的特定需求</li></ul><h2 id="923a" class="ml lq iq bd kr mm mn dn lu mo mp dp ly lb mq mr ma lf ms mt mc lj mu mv me mw bi translated">缺点:</h2><ul class=""><li id="1db4" class="mx my iq ku b kv mg ky mh lb mz lf na lj nb ln nc nd ne nf bi translated">不如固态硬盘Mobilenet v1准确</li></ul><h1 id="fab5" class="lp lq iq bd kr lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">mt CNN——同步人脸检测和地标</h1><p id="ff8c" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">MTCNN(多任务级联卷积神经网络)是一种由3个阶段组成的算法，它检测图像中人脸的边界框及其5个点人脸标志(<a class="ae lo" href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/spl.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nl">链接到论文</em> </a> <em class="nl"> ) </em>)。每个阶段通过将其输入传递给CNN来逐渐改善检测结果，CNN返回候选边界框及其分数，随后是非最大抑制。</p><p id="e005" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在阶段1中，输入图像被多次缩小以构建一个<strong class="ku ir">图像金字塔</strong>，并且图像的每个缩放版本通过其CNN。在阶段2和3中，我们为每个边界框提取图像块并调整它们的大小(阶段2中的<strong class="ku ir"> 24x24 </strong>和阶段3中的<strong class="ku ir"> 48x48 </strong>),并通过该阶段的CNN转发它们。除了边界框和分数，阶段3还为每个边界框计算<strong class="ku ir"> 5个面部标志点</strong>。</p><p id="b5d1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在摆弄了一些MTCNN实现之后，事实证明，与SSD Mobilenet v1相比，即使在CPU上运行推理，您也可以在更低的推理时间内获得非常可靠的检测结果。作为额外的奖励，从5点面部标志，我们得到免费的面部对齐！这样，我们不必在计算面部描述符之前执行68点面部标志检测作为中间步骤。</p><p id="dfad" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">尽管这对我来说很有希望，但我还是在<strong class="ku ir"> tfjs-core中实现了它。经过几天的努力，我终于找到了一个可行的解决方案。:)<strong class="ku ir">让我们看看它的行动吧！</strong></strong></p><h1 id="6d87" class="lp lq iq bd kr lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">网络摄像头人脸跟踪和人脸识别</h1><p id="01c9" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">正如承诺的那样，我们现在将看看如何使用您的网络摄像头实现面部跟踪和面部识别。在这个例子中，我将再次使用我的网络摄像头来跟踪和识别一些《生活大爆炸》主角的脸，但是当然你也可以使用这段代码来相应地跟踪和识别你自己。</p><p id="aeb7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">要显示来自网络摄像头的帧，您只需使用视频元素，如下所示。此外，我将一个绝对定位的画布放在视频元素的顶部，具有相同的高度和宽度。我们将使用画布作为透明覆盖，稍后我们可以在上面绘制检测结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="39da" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一旦页面被加载，我们将加载MTCNN模型以及人脸识别模型，以计算人脸描述符。此外，我们正在使用<strong class="ku ir"><em class="nl">navigator . getuser media</em></strong>将我们的网络摄像头流附加到视频元素:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="f0b5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在应该会要求您授予浏览器访问您的网络摄像头的权限。在我们为视频元素指定的<strong class="ku ir"> onPlay </strong>回调中，我们将处理每一帧的实际处理。请注意，一旦视频开始播放，onplay被挂接的事件就会被触发。</p><h2 id="f8fb" class="ml lq iq bd kr mm mn dn lu mo mp dp ly lb mq mr ma lf ms mt mc lj mu mv me mw bi translated">人脸检测</h2><p id="d1c5" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">我说过，我们可以在这里配置一些检测参数。默认参数如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="d98c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了从你的摄像头跟踪人脸，我们将增加最小尺寸到至少200像素<strong class="ku ir">。</strong>只检测较大尺寸的面部使我们能够实现更短的推断时间，因为网络会以更大的系数缩小图像:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="8644" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如您所见，我们可以简单地向它提供视频元素，就像图像或画布元素一样。</p><p id="1244" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">通过MTCNN向前传递给我们一组<strong class="ku ir">面部检测</strong>(边界框+分数)以及每个检测到的面部的<strong class="ku ir">面部标记5 </strong>。现在，我们可以将结果绘制到覆盖图中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="62af" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">仅举一个例子，到目前为止，我们将得出以下结论:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f9756d8763b257ef37d3f46a37e912db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*AC5H5V6kF2CcwnBr5FaaDA.jpeg"/></div></figure><h2 id="f9e5" class="ml lq iq bd kr mm mn dn lu mo mp dp ly lb mq mr ma lf ms mt mc lj mu mv me mw bi translated">计算面部描述符</h2><p id="2d9b" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">从我之前的教程中，你应该已经知道，在计算任何人脸描述符之前，我们希望从人脸标志的位置对齐人脸边界框。从对齐的框中，我们提取对齐的面部张量，我们可以将它们传递给面部识别网络:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="c0b9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果对您来说代码太多，还有一个方便的快捷方式:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h2 id="f30f" class="ml lq iq bd kr mm mn dn lu mo mp dp ly lb mq mr ma lf ms mt mc lj mu mv me mw bi translated">人脸识别</h2><p id="cf2a" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">从现在开始，我们只是简单地以同样的方式进行，就像我们在之前的教程中所做的那样。回想一下，为了识别人脸，在运行主循环之前，我们必须从示例图像中预先计算(至少一个)人脸描述符，以识别我们想要识别的每个人(<strong class="ku ir">参考数据</strong>):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="3095" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了决定哪个人坐在摄像头前，我们使用<strong class="ku ir"> <em class="nl"> faceapi计算<strong class="ku ir">查询人脸描述符</strong>到参考数据中人脸描述符的距离。再次使用FaceMatcher </em>和</strong>并返回最相似的匹配:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="8bc1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你只是想跟踪自己，给自己拍一张照片并运行一次<strong class="ku ir"><em class="nl">faceapi . all faces</em></strong>来检索你自己脸部的脸部描述符(<strong class="ku ir">参考描述符</strong>)就足够了。然后您可以使用<strong class="ku ir"><em class="nl">faceapi . euclideandrance .</em></strong>直接计算查询人脸描述符与您的网络摄像头图像和参考描述符的距离</p><p id="efa7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，我们将带有预测标签和相对于边界框位置的距离的文本再次绘制到覆盖画布上:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2adb06909169963c5efab9b18e6c0122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*3ZmLD7_2hG0LPQkzoYOxQQ.jpeg"/></div></figure><p id="e61e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">之后，不要忘记调用<strong class="ku ir"> onPlay </strong>继续迭代处理最近的帧:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="4a7c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">就这样了！</p><h1 id="5a98" class="lp lq iq bd kr lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">一些最后的评论</h1><p id="6a0e" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">注意，为每一帧重新计算查询人脸描述符是一种非常幼稚的方法。显然，你可以想出一种更有效的方法，比如每隔<strong class="ku ir"><em class="nl"/></strong>帧跟踪并更新你的检测结果的面部描述符。通常被跟踪的人脸的姿势在几帧内不会有太大的变化。但是为了简单起见，我就让它保持原样。记住这一点，以防你想从中挤出更多的fps。</p><p id="3760" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，请务必查看<a class="ae lo" href="https://github.com/justadudewhohacks/face-api.js/blob/master/examples/" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir">示例</strong> </a>，当然，请继续关注进一步的更新和功能，它们可能会在未来成为face-api.js！；)</p><p id="b22b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><em class="nl">如果你喜欢这篇文章，请留下一些掌声，并在medium和/或</em><a class="ae lo" href="https://twitter.com/justadudewhohax" rel="noopener ugc nofollow" target="_blank"><em class="nl">Twitter</em></a><em class="nl">:)上关注我。也可以随意在</em> <a class="ae lo" href="https://github.com/justadudewhohacks/face-api.js" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir"> <em class="nl"> github资源库</em> </strong> </a> <em class="nl">上留下一颗星星。敬请关注更多教程！</em></p></div></div>    
</body>
</html>