<html>
<head>
<title>Serverless Analytics on AWS: Getting Started with Amazon EMR Serverless and Amazon MSK Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS上的无服务器分析:亚马逊EMR无服务器和亚马逊MSK无服务器入门</h1>
<blockquote>原文：<a href="https://itnext.io/serverless-analytics-on-aws-getting-started-with-amazon-emr-serverless-and-amazon-msk-serverless-67155fa0f5e0?source=collection_archive---------1-----------------------#2022-07-26">https://itnext.io/serverless-analytics-on-aws-getting-started-with-amazon-emr-serverless-and-amazon-msk-serverless-67155fa0f5e0?source=collection_archive---------1-----------------------#2022-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="18ca" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用最近发布的亚马逊EMR无服务器和亚马逊MSK无服务器，通过Apache Spark和Apache Kafka进行批处理和流分析</h2></div><h1 id="3f45" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><h2 id="bf0a" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">亚马逊EMR无服务器</h2><p id="57ca" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">AWS最近<a class="ae mi" href="https://aws.amazon.com/about-aws/whats-new/2022/06/amazon-emr-serverless-generally-available/" rel="noopener ugc nofollow" target="_blank">宣布<a class="ae mi" href="https://aws.amazon.com/emr/serverless/" rel="noopener ugc nofollow" target="_blank">亚马逊EMR无服务器</a>于2022年6月1日全面上市</a> (GA)。EMR Serverless是<a class="ae mi" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank">亚马逊EMR </a>中新的无服务器部署选项，除此之外还有EC2上的<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html" rel="noopener ugc nofollow" target="_blank">EMR</a>、EKS上的<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html" rel="noopener ugc nofollow" target="_blank">EMR</a>和AWS前哨上的<a class="ae mi" href="https://aws.amazon.com/emr/features/outposts/" rel="noopener ugc nofollow" target="_blank">EMR</a>。EMR Serverless提供了一个无服务器运行时环境，简化了使用最新开源框架的分析应用程序的操作，如<a class="ae mi" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>和<a class="ae mi" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Hive </a>。根据<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html" rel="noopener ugc nofollow" target="_blank"> AWS </a>的说法，有了EMR无服务器，你就不必配置、优化、保护或操作集群来运行这些框架的应用程序。</p><h2 id="0627" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">亚马逊MSK无服务器</h2><p id="9ab2" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">同样，2022年4月28日，AWS <a class="ae mi" href="https://aws.amazon.com/blogs/aws/amazon-msk-serverless-now-generally-available-no-more-capacity-planning-for-your-managed-kafka-clusters/" rel="noopener ugc nofollow" target="_blank">宣布<a class="ae mi" href="https://aws.amazon.com/msk/features/msk-serverless/?trk=e0324ae4-4a7e-4aa3-a9f8-d473d0398616" rel="noopener ugc nofollow" target="_blank">亚马逊MSK无服务器</a>的</a>全面上市。根据<a class="ae mi" href="https://aws.amazon.com/msk/features/msk-serverless/" rel="noopener ugc nofollow" target="_blank"> AWS </a>的说法，亚马逊MSK无服务器是<a class="ae mi" href="https://aws.amazon.com/msk/" rel="noopener ugc nofollow" target="_blank">亚马逊MSK </a>的一种集群类型，它可以轻松运行<a class="ae mi" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>而无需管理和扩展集群容量。MSK无服务器自动供应和扩展计算和存储资源，因此您可以按需使用Apache Kafka，并且只需为您传输和保留的数据付费。</p><h2 id="71a8" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">无服务器分析</h2><p id="56f4" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">在下面的帖子中，我们将了解如何使用这两种新的、强大的、经济高效的、易于操作的无服务器技术来执行批处理和流分析。本文中使用的<a class="ae mi" href="https://spark.apache.org/docs/latest/api/python/#pyspark-documentation" rel="noopener ugc nofollow" target="_blank"> PySpark </a>示例与之前两篇文章中的示例相似，这两篇文章都提到了非无服务器的替代方案<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html" rel="noopener ugc nofollow" target="_blank">亚马逊EC2上的EMR</a>和<a class="ae mi" href="https://aws.amazon.com/msk/" rel="noopener ugc nofollow" target="_blank">亚马逊MSK </a>。</p><div class="mj mk gp gr ml mm"><a rel="noopener  ugc nofollow" target="_blank" href="/getting-started-with-spark-structured-streaming-and-kafka-on-aws-using-amazon-msk-and-amazon-emr-91b1f2ef0162"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd iu gy z fp mr fr fs ms fu fw is bi translated">使用亚马逊MSK和亚马逊EMR在AWS上开始使用Spark结构化流和Kafka</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">使用批处理查询和Spark结构化流，使用Apache Kafka探索Apache Spark</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">itnext.io</p></div></div><div class="mv l"><div class="mw l mx my mz mv na nb mm"/></div></div></a></div><div class="mj mk gp gr ml mm"><a rel="noopener  ugc nofollow" target="_blank" href="/stream-processing-with-apache-spark-kafka-avro-and-apicurio-registry-on-amazon-emr-and-amazon-13080defa3be"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd iu gy z fp mr fr fs ms fu fw is bi translated">使用Amazon EMR和Amazon上的Apache Spark、Kafka、Avro和Apicurio Registry进行流处理…</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">在事件流分析架构中使用注册表将模式与消息分离</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">itnext.io</p></div></div><div class="mv l"><div class="nc l mx my mz mv na nb mm"/></div></div></a></div><h1 id="14c3" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">源代码</h1><p id="6ada" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">这篇文章中展示的所有源代码都是开源的，可以在<a class="ae mi" href="https://github.com/garystafford/emr-msk-serverless-demo/tree/main" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="dc05" class="la kj it ni b gy nm nn l no np">git clone --depth 1 -b main \<br/>    https://github.com/garystafford/emr-msk-serverless-demo.git</span></pre><h1 id="f651" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">体系结构</h1><p id="2f66" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">邮报的高层架构由亚马逊EMR无服务器应用程序、亚马逊MSK无服务器集群和亚马逊EC2 Kafka客户端实例组成。为了支持这三种资源，我们将需要两个亚马逊虚拟专用云(VPC)，至少三个子网，一个AWS互联网网关(IGW)或同等设备，一个亚马逊S3存储桶，多个AWS身份和访问管理(IAM)角色和策略，安全组和路由表，以及一个S3的VPC网关端点。所有资源都被限制到单个AWS帐户和单个AWS区域，<code class="fe nq nr ns ni b">us-east-1</code>。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nt"><img src="../Images/5b8414fd0c87e0ece14dc16a1b04b6f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BP8axIBwerA0Tm9P3mic4w.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">本文中使用的高级AWS无服务器分析架构</figcaption></figure><h1 id="dd5c" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">先决条件</h1><p id="cd26" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">作为此职位的先决条件，您需要创建以下资源:</p><ol class=""><li id="85b4" class="oe of it lr b ls og lv oh lf oi li oj ll ok mh ol om on oo bi translated">(1)亚马逊EMR无服务器应用；</li><li id="df92" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">(1)亚马逊MSK无服务器集群；</li><li id="1b46" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">(1)亚马逊S3桶；</li><li id="6d25" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">①VPC端点为S3；</li><li id="c9ee" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">(3)阿帕奇卡夫卡专题；</li><li id="bbc7" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">PySpark应用程序、相关的JAR依赖项和样本数据文件上传到亚马逊S3桶；</li></ol><p id="9b93" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">让我们逐一了解这些先决条件。</p><h2 id="132b" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">亚马逊EMR无服务器应用</h2><p id="430b" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">在继续之前，我建议你先熟悉一下亚马逊EMR无服务器的AWS文档，尤其是，<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html" rel="noopener ugc nofollow" target="_blank">什么是亚马逊EMR无服务器？</a>按照AWS文档创建一个新的EMR无服务器应用，<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/getting-started.html" rel="noopener ugc nofollow" target="_blank">Amazon EMR无服务器入门</a>。EMR无服务器应用程序的创建包括以下资源:</p><ol class=""><li id="a468" class="oe of it lr b ls og lv oh lf oi li oj ll ok mh ol om on oo bi translated">存储星火资源的亚马逊S3桶；</li><li id="df96" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">至少有两个私有子网和相关安全组的亚马逊VPC；</li><li id="4898" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">EMR无服务器运行时AWS IAM角色和关联的IAM策略；</li><li id="74d3" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">亚马逊EMR无服务器应用；</li></ol><p id="7046" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">对于本文，使用EMR Studio无服务器应用程序控制台中可用的最新版本EMR(最新发布的版本6.7.0)来创建Spark应用程序。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/eb07b67b7fc40740bb640f1b3a83de5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gIsNwrDUbGHVBHP2NUk0hQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序创建控制台</figcaption></figure><p id="d43b" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">保留默认的预初始化容量、应用程序限制和应用程序行为设置。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/61707dda8a0012cea71820782f8c4c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlAckW261FFzwHDxYCcOrg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序创建控制台</figcaption></figure><p id="2f8a" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">由于我们从EMR无服务器连接到MSK无服务器，我们需要配置VPC访问。选择新的VPC和不同可用性区域(az)中的至少两个专用子网。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/0ca614f5efef951fc99283b21ec30b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Va574RWke4QSSZM_WOGyg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序创建控制台</figcaption></figure><p id="39c0" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">根据<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/vpc-access.html" rel="noopener ugc nofollow" target="_blank">文档</a>，为EMR无服务器选择的子网必须是私有子网。子网的相关路由表不应包含通往Internet的直接路由。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/1e9f9ad7e3d1846846eb8c338478dedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XYw3vpKtDc_fK91RAzAJjg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">尝试将公共子网与EMR无服务器关联时出错</figcaption></figure><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/0074b603346b0c4153bf5950be1439d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P8ffdg4oV4qF5kQChlyENQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">显示新应用程序的EMR Studio无服务器应用程序详细信息控制台</figcaption></figure><h2 id="0640" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">亚马逊MSK无服务器集群</h2><p id="33ad" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">同样，在继续之前，我建议你熟悉一下亚马逊MSK无服务器版的AWS文档，尤其是<a class="ae mi" href="https://docs.aws.amazon.com/msk/latest/developerguide/serverless.html" rel="noopener ugc nofollow" target="_blank"> MSK无服务器版</a>。按照AWS文档<a class="ae mi" href="https://docs.aws.amazon.com/msk/latest/developerguide/serverless-getting-started.html" rel="noopener ugc nofollow" target="_blank">MSK无服务器集群使用入门</a>创建一个新的MSK无服务器集群。MSK无服务器集群的创建包括以下资源:</p><ol class=""><li id="fe83" class="oe of it lr b ls og lv oh lf oi li oj ll ok mh ol om on oo bi translated">Amazon EC2 Kafka客户端实例的AWS IAM角色和相关IAM策略；</li><li id="60e3" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">至少有一个公共子网和相关安全组的VPC；</li><li id="3fd4" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">Amazon EC2实例用作Apache Kafka客户端，在上述VPC的公共子网中提供；</li><li id="cd6f" class="oe of it lr b ls op lv oq lf or li os ll ot mh ol om on oo bi translated">亚马逊MSK无服务器集群；</li></ol><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/f1c8c6bbb4b8011645bda39d5b25f1b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BBHoQqX0LAmbkyWMfU2KrQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">亚马逊MSK无服务器创建集群控制台</figcaption></figure><p id="f8ce" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">将新的MSK无服务器群集与EMR无服务器应用程序的VPC和两个专用子网相关联。此外，将集群与基于EC2的Kafka客户端实例的VPC及其公共子网相关联。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/1765fdd28e43493adcf4fa8bc55a2ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qr98lxuZGZKXCjgaF0d4SQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">亚马逊MSK无服务器创建集群控制台— VPC 1</figcaption></figure><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/f37ae5ba20401656198fa3e075d4764b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5GSEBrYaOHeswUTKIRNUhA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">亚马逊MSK无服务器创建集群控制台— VPC 2</figcaption></figure><p id="24e8" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">根据AWS <a class="ae mi" href="https://docs.aws.amazon.com/msk/latest/developerguide/msk-create-cluster.html#create-cluster-cli" rel="noopener ugc nofollow" target="_blank">文档</a>，亚马逊MSK并不支持所有az。例如，我试图在<code class="fe nq nr ns ni b">us-east-1e</code>中使用一个子网时抛出了一个错误。如果发生这种情况，请选择另一个AZ。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oz"><img src="../Images/86a475b2a4df3708a77dd76ce6dc78a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mw5LIWTs16fU7b3v3bkeGA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">使用不支持的AZ导致错误</figcaption></figure><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/781655834bd47fab146a17c9d861f861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67FQJJU6Ol8Nw7WCFbIG1g.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">成功创建亚马逊MSK无服务器集群</figcaption></figure><h2 id="adcc" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">S3的VPC端点</h2><p id="0663" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">为了从运行在两个私有子网中的EMR无服务器访问亚马逊S3的Spark资源，我们需要一个用于S3的<a class="ae mi" href="https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.html#concepts-service-consumers" rel="noopener ugc nofollow" target="_blank"> VPC端点</a>。具体来说，一个<a class="ae mi" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3" rel="noopener ugc nofollow" target="_blank">网关端点</a>，它使用私有IP地址向亚马逊S3或DynamoDB发送流量。亚马逊S3的网关端点使您能够使用私有IP地址访问亚马逊S3，而无需暴露于公共互联网。EMR Serverless不需要公共IP地址，您也不需要互联网网关(IGW)、NAT设备或VPC中的虚拟专用网关来连接到S3。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/f4e3ee80a0a22f93801dd6081533e018.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zE5KCgthA6f6nIwO9aHr7g.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">与专用子网路由表相关联的S3 VPC端点</figcaption></figure><p id="529f" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">为S3 ( <em class="pa">网关端点</em>)创建VPC端点，并为两个EMR无服务器专用子网添加<a class="ae mi" href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html" rel="noopener ugc nofollow" target="_blank">路由表</a>。您可以向路由表中添加额外的路由，例如<a class="ae mi" href="https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html" rel="noopener ugc nofollow" target="_blank"> VPC对等</a>到Amazon Redshift或Amazon RDS等数据源的连接。但是，不要添加提供直接Internet访问的路由。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/0f2d9e876a6eb635cb6d065f17538315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C68-aiLPqcNSuns06x2WYA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">私有子网的路由表显示了VPC端点到S3的路由(显示的第一条路由)</figcaption></figure><h2 id="55cd" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">卡夫卡主题和示例消息</h2><p id="d5ff" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">一旦MSK无服务器集群和基于EC2的Kafka客户端实例被提供并运行，使用基于EC2的Kafka客户端实例创建三个必需的Kafka主题。我推荐使用<a class="ae mi" href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html" rel="noopener ugc nofollow" target="_blank"> AWS系统管理器会话管理器</a>作为<code class="fe nq nr ns ni b">ec2-user</code>用户连接到客户端实例。会话管理器提供安全和可审计的节点管理，无需打开入站端口、维护堡垒主机或管理SSH密钥。或者，您可以SSH到客户机实例。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/071238c2e27d153afe5e06da2841b6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFub5OTreKyXY2wKp38X4g.png"/></div></div></figure><p id="418b" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在创建主题之前，使用类似于<code class="fe nq nr ns ni b">telnet</code>的实用程序来确认Kafka客户端和MSK无服务器集群之间的连接。验证连接性将为您省去许多潜在的安全和网络问题。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="9419" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">确认MSK无服务器集群连接后，创建三个Kafka主题:<code class="fe nq nr ns ni b">topicA</code>、<code class="fe nq nr ns ni b">topicB</code>和<code class="fe nq nr ns ni b">topicC</code>。我使用AWS <a class="ae mi" href="https://docs.aws.amazon.com/msk/latest/developerguide/msk-serverless-create-topic.html" rel="noopener ugc nofollow" target="_blank">入门教程</a>中的默认分区和复制设置。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="3a50" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">为了创建一些快速的示例数据，我们将从GitHub项目中包含的文件<code class="fe nq nr ns ni b">sample_data/sales_messages.txt</code>中复制250条消息并粘贴到<code class="fe nq nr ns ni b">topicA</code>中。这些消息是简单的模拟销售交易。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="d1be" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">使用<code class="fe nq nr ns ni b">kafka-console-producer</code> Shell脚本将消息发布到Kafka主题。使用<code class="fe nq nr ns ni b">kafka-console-consumer</code> Shell脚本，通过使用一些消息来验证到达主题的消息。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="8f15" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">输出应该类似于下面的示例。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pd"><img src="../Images/a8dd7a1fbffa272a5ad5bb6c7cda1eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YO8C4OedZpNvFJUqc_HbRg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Kafka主题的示例消息输出</figcaption></figure><h2 id="d35b" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">亚马逊S3的星火资源</h2><p id="1c85" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">要提交并运行项目中包含的五个Spark作业，您需要将以下资源复制到您的Amazon S3 bucket中:(5) Apache Spark作业，(5)相关的JAR依赖项，以及(2)样本数据文件。</p><p id="24f6" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated"><strong class="lr iu"> PySpark应用程序<br/> </strong>首先，将五个PySpark应用程序复制到亚马逊S3桶内的<code class="fe nq nr ns ni b">scripts/</code>子目录中。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/c20f245319269effcf9a77f9e3aa92cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2u54IIbVBFEiqPfekzftaQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">上传到亚马逊S3桶的PySpark应用程序</figcaption></figure><p id="8428" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated"><strong class="lr iu">示例数据</strong> <br/>接下来，将这两个示例数据文件复制到亚马逊S3存储桶中的一个<code class="fe nq nr ns ni b">sample_data/</code>子目录中。大文件包含2000条消息，而小文件包含600条消息。这两个文件可以与帖子的最终流示例互换使用。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/e1fb8a7c35b6146bbb1b01eae7c678e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICvmBkB9wZou3LDdiZAxWw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">样本销售数据上传到亚马逊S3桶</figcaption></figure><p id="42cc" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">最后，PySpark应用程序有一些JAR依赖项，这些依赖项在作业运行时必须可用，默认情况下不在EMR无服务器类路径上。如果您不确定哪些jar已经在EMR无服务器类路径上，您可以检查Spark UI的<a class="ae mi" href="https://spark.apache.org/docs/3.1.2/web-ui.html#environment-tab" rel="noopener ugc nofollow" target="_blank">环境</a>选项卡的类路径条目部分。下面的第一个PySpark应用程序示例演示了如何访问Spark UI。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/691db829d282e153449276f407a1b29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*58ypIszRbDe2H0ne8dT3gQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的环境选项卡显示类路径条目</figcaption></figure><p id="c121" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">根据EMR和MSK使用的库的版本，选择每个JAR依赖项的正确版本是非常关键的。使用错误的版本或不一致的版本，尤其是Scala，会导致作业失败。具体来说，我们针对的是Spark 3.2.1和Scala 2.12 ( <a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-670-release.html" rel="noopener ugc nofollow" target="_blank"> EMR v6.7.0 </a>:亚马逊的Spark 3.2.1、Scala 2.12.15、<a class="ae mi" href="https://docs.aws.amazon.com/corretto/latest/corretto-8-ug/what-is-corretto-8.html" rel="noopener ugc nofollow" target="_blank">亚马逊Corretto 8 </a>版本的OpenJDK)、阿帕奇Kafka 2.8.1 (MSK无服务器:Kafka 2.8.1)。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="857d" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在本地下载这七个JAR文件，然后将它们复制到亚马逊S3桶中的一个<code class="fe nq nr ns ni b">jars/</code>子目录中。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/84cb2b7b94c6fe35ef037135a52f497e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9kw1wf8CvgU64BX1GOOqA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">上传到亚马逊S3桶的依赖关系jar</figcaption></figure><h1 id="3bca" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">PySpark应用示例</h1><p id="206c" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">随着EMR无服务器应用程序、MSK无服务器集群、Kafka主题和示例数据的创建，以及Spark资源上传到亚马逊S3，我们已经准备好探索四个不同的Spark示例。</p><h2 id="ce38" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">示例1: Kafka批处理聚合到控制台</h2><p id="00f0" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">第一个PySpark应用程序<code class="fe nq nr ns ni b">01_example_console.py</code>从您之前发布的<code class="fe nq nr ns ni b">topicA</code>中读取同样的250个示例销售消息，聚合这些消息，并将各个国家的总销售额和订单数量写入控制台(stdout)。</p><p id="34a8" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在任何PySpark应用程序示例中都没有硬编码的值。所有必需的特定于环境的变量，比如您的MSK无服务器引导服务器(主机和端口)和Amazon S3存储桶名称，将作为来自<code class="fe nq nr ns ni b">spark-submit</code>命令的参数传递给正在运行的Spark作业。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="a8ee" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">要向EMR无服务器应用程序提交您的第一个PySpark作业，请从AWS CLI使用<code class="fe nq nr ns ni b">emr-serverless</code> API。您将需要(4)个值:1)您的EMR无服务器应用程序的<code class="fe nq nr ns ni b">application-id</code>，2)您的EMR无服务器应用程序的执行IAM角色的ARN，3)您的MSK无服务器引导服务器(主机和端口)，以及4)您的包含Spark资源的Amazon S3存储桶的名称。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="162e" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">切换到EMR无服务器应用程序控制台，您应该可以在几个<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/job-states.html" rel="noopener ugc nofollow" target="_blank">作业状态</a>之一中看到您刚刚提交的新Spark作业。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/b91fd59eda2f0a42d79622fa09a54d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wH__rb6mQNxAWzkV2JIaDw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序详细信息控制台</figcaption></figure><p id="7686" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">你可以点击Spark job了解更多详情。注意从<code class="fe nq nr ns ni b">spark-submit</code>命令传入的脚本参数和Spark属性。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/f4ecd5778a9041dca12bd4ef16d82b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*any9Fou6UtkVkCMbAsZshw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序详细信息作业详细信息视图</figcaption></figure><p id="e071" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在Spark job details选项卡中，通过屏幕右上角的按钮访问Spark UI，也称为<a class="ae mi" href="https://spark.apache.org/docs/latest/web-ui.html" rel="noopener ugc nofollow" target="_blank"> Spark Web UI </a>。如果您有使用Spark的经验，您很可能熟悉Spark Web UI来监控和调优Spark作业。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/7fb077d84633214affa224f4bdfc0e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y2bCvs_jfXJUNKd1CEOdww.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark历史服务器用户界面</figcaption></figure><p id="930c" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在初始屏幕的Spark History Server选项卡上，单击App ID。您可以从Spark Web UI访问大量关于您的工作和EMR环境的Spark相关信息。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/821cfc225338bece29def0a4958e49bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCrv78dhAFD0qfmcYdCbeQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的<a class="ae mi" href="https://spark.apache.org/docs/3.1.2/web-ui.html#stages-tab" rel="noopener ugc nofollow" target="_blank">阶段</a>选项卡</figcaption></figure><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/c29e4b1a63880ab72e7b55981f86e485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucu5g1YkjThJmfHkOUrVnw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的<a class="ae mi" href="https://spark.apache.org/docs/3.1.2/web-ui.html#stages-tab" rel="noopener ugc nofollow" target="_blank"> Stages </a>选项卡显示有向无环图(DAG)可视化</figcaption></figure><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/360f71c8a1cc3e3a21ef6a12a946b509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqfVW8Qtj94EXu6XCMcXkw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的环境选项卡显示环境变量，包括Spark、Java和Scala的版本</figcaption></figure><p id="a82e" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated"><a class="ae mi" href="https://spark.apache.org/docs/3.1.2/web-ui.html#executors-tab" rel="noopener ugc nofollow" target="_blank"> Executors </a>选项卡将让您访问Spark作业的输出。我们最感兴趣的输出是<code class="fe nq nr ns ni b">driver</code>执行者的<code class="fe nq nr ns ni b">stderr</code>和<code class="fe nq nr ns ni b">stdout</code>(第二个表的<em class="pa">第一行，如下图</em>)。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/54d5363caefa898d53d1c2e739b1bbc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MnwBbUJRDsp-a5fRHC99zQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的执行者选项卡</figcaption></figure><p id="efba" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated"><code class="fe nq nr ns ni b">stderr</code>包含与运行火花作业相关的输出。下面我们看到一个Kafka消费者配置值输出到<code class="fe nq nr ns ni b">stderr</code>的例子。这些值中有几个是从Spark作业传入的，包括诸如<code class="fe nq nr ns ni b">kafka.bootstrap.servers</code>、<code class="fe nq nr ns ni b">security.protocol</code>、<code class="fe nq nr ns ni b">sasl.mechanism</code>和<code class="fe nq nr ns ni b">sasl.jaas.config</code>之类的项目。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/299de734350780add692008972efebb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPWdaHWR9WYBqe5b2aXPgA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">驱动程序执行器到控制台的stderr输出</figcaption></figure><p id="4a09" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">来自<code class="fe nq nr ns ni b">driver</code>执行器的<code class="fe nq nr ns ni b">stdout</code>包含来自Spark作业的控制台输出。下面我们看到第一个Spark作业的成功聚合结果，输出到<code class="fe nq nr ns ni b">stdout</code>。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="0f08" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">示例2:S3 Kafka批量聚合为CSV</h2><p id="5726" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">尽管控制台对于开发和调试很有用，但它通常不用于生产。相反，Spark通常将结果以CSV、JSON、Parquet或Arvo格式的文件发送给S3、Kafka、数据库或API端点。第二个PySpark应用程序，<code class="fe nq nr ns ni b">02_example_csv_s3.py</code>，从您之前发布的<code class="fe nq nr ns ni b">topicA</code>中读取同样的250个示例销售消息，聚合这些消息，并将各个国家的总销售额和订单数量写入亚马逊S3的CSV文件中。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="189a" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">要向EMR无服务器应用程序提交第二个PySpark作业，请从AWS CLI使用<code class="fe nq nr ns ni b">emr-serverless</code> API。与第一个例子类似，您将需要(4)个值:1)您的EMR无服务器应用程序的<code class="fe nq nr ns ni b">application-id</code>，2)您的EMR无服务器应用程序的执行IAM角色的ARN，3)您的MSK无服务器引导服务器(主机和端口)，以及4)您的包含Spark资源的Amazon S3存储桶的名称。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="dfa9" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">如果成功，Spark作业应该在指定的Amazon S3键(目录路径)中创建一个CSV文件和一个空的<code class="fe nq nr ns ni b">_SUCCESS</code>指示器文件。空的<code class="fe nq nr ns ni b">_SUCCESS</code>文件表示<code class="fe nq nr ns ni b">save()</code>操作正常完成。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/f3a574118e4165db30f275dfd1a2504a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSJqiKSXy9uqTNKmt5Tn5g.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">亚马逊S3桶显示由火花工作输出的CSV文件</figcaption></figure><p id="e0e8" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">下面我们看到第二个Spark作业的预期管道分隔输出。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="776e" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">示例3: Kafka批量聚合到Kafka</h2><p id="828a" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">第三个PySpark应用程序，<code class="fe nq nr ns ni b">03_example_kafka.py</code>，从您之前发布的<code class="fe nq nr ns ni b">topicA</code>中读取同样的250个示例销售消息，聚合这些消息，并将各个国家的总销售额和订单数量写入第二个Kafka主题，<code class="fe nq nr ns ni b">topicB</code>。该作业现在具有读取和写入选项。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="52c5" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">要向EMR无服务器应用程序提交您的下一个PySpark作业，请从AWS CLI使用<code class="fe nq nr ns ni b">emr-serverless</code> API。与前两个例子类似，您将需要(4)个值:1)您的EMR无服务器应用程序的<code class="fe nq nr ns ni b">application-id</code>，2)您的EMR无服务器应用程序的执行IAM角色的ARN，3)您的MSK无服务器引导服务器(主机和端口)，以及4)包含Spark资源的Amazon S3存储桶的名称。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="aa04" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">一旦作业完成，您可以通过返回到基于EC2的Kafka客户端来确认结果。使用之前使用的相同的<code class="fe nq nr ns ni b">kafka-console-consumer</code>命令显示来自<code class="fe nq nr ns ni b">topicB</code>的消息。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="2ef0" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">如果Spark作业和Kafka客户端命令成功运行，您应该会看到类似于以下示例输出的聚合消息。注意，我们没有对Kafka消息使用<a class="ae mi" href="https://docs.streamsets.com/platform-datacollector/latest/datacollector/UserGuide/Pipeline_Configuration/KMessageKey.html#concept_ujc_cml_smb" rel="noopener ugc nofollow" target="_blank">键</a>,只有这些简单示例的值。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pe"><img src="../Images/dfdaad78ca8f7cf5894ea9c7803d25f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8dkV24I-HqY-9_hyRVn_hQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">来自卡夫卡主题的聚合消息</figcaption></figure><h2 id="b374" class="la kj it bd kk lb lc dn ko ld le dp ks lf lg lh ku li lj lk kw ll lm ln ky lo bi translated">示例4: Spark结构化流</h2><p id="e07f" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">对于我们的最后一个例子，我们将从批处理切换到流处理——从<code class="fe nq nr ns ni b">read</code>到<code class="fe nq nr ns ni b">readstream</code>以及从<code class="fe nq nr ns ni b">write</code>到<code class="fe nq nr ns ni b">writestream</code>。在继续之前，我建议阅读<a class="ae mi" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">结构化流编程指南</a>。</p><div class="mj mk gp gr ml mm"><a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd iu gy z fp mr fr fs ms fu fw is bi translated">结构化流式节目指南</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">结构化流是一个基于Spark SQL引擎的可扩展和容错的流处理引擎。</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">spark.apache.org</p></div></div><div class="mv l"><div class="pf l mx my mz mv na nb mm"/></div></div></a></div><p id="2264" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">在本例中，我们将演示如何持续测量一个常见的业务指标——实时销售量。假设您正在全球销售产品，并希望实时了解不同地理区域的时间和购买模式之间的关系。对于任何给定的时间窗口——这15分钟、这一小时、这一天或这一周——您想要了解各个国家的当前销售量。您不是在回顾以前的销售周期或检查运行的销售总额，而是在滑动时间窗口内的实时销售。</p><p id="eeb0" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">我们将使用两个并发运行的PySpark作业来模拟这一指标。第一个应用程序<code class="fe nq nr ns ni b">04_stream_sales_to_kafka.py</code>通过向<code class="fe nq nr ns ni b">topicC</code>连续写入消息来模拟流数据——2000条消息，消息之间有0.5秒的延迟。在我的测试中，这个任务运行了大约28-29分钟。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="126e" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">与此同时，PySpark应用程序<code class="fe nq nr ns ni b">05_streaming_kafka.py</code>不断使用来自同一个主题<code class="fe nq nr ns ni b">topicC</code>的销售交易消息。然后，Spark在一个滑动的事件时间窗口内聚合消息，并将结果写入控制台。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="a54e" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">要向EMR无服务器应用程序提交两个PySpark作业，请从AWS CLI使用<code class="fe nq nr ns ni b">emr-serverless</code> API。同样，您将需要(4)个值:1)您的EMR无服务器应用程序的<code class="fe nq nr ns ni b">application-id</code>，2)您的EMR无服务器应用程序的执行IAM角色的ARN，3)您的MSK无服务器引导服务器(主机和端口)，以及4)包含Spark资源的Amazon S3存储桶的名称。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="52f0" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">切换到EMR无服务器应用程序控制台，您应该可以在几个<a class="ae mi" href="https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/job-states.html" rel="noopener ugc nofollow" target="_blank">作业状态</a>之一中看到您刚刚提交的两个Spark作业。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/0b27406fefd5886a6bdde4f31838549f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-WOCrUB0eoY-JNL68l8mg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序详细信息控制台</figcaption></figure><p id="4241" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">再次使用Spark UI，我们可以查看第二个作业<code class="fe nq nr ns ni b">05_streaming_kafka.py</code>的输出。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/dfaf541882eb2e59f240b4eb75db94dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J2AK_kxQodgvAajcgzaDmg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的作业选项卡</figcaption></figure><p id="cc67" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">对于Spark结构化流作业，我们在Spark UI中有一个额外的选项卡，<a class="ae mi" href="https://spark.apache.org/docs/3.1.2/web-ui.html#structured-streaming-tab" rel="noopener ugc nofollow" target="_blank">结构化流</a>。该选项卡显示所有正在运行的作业及其最新的[微]批次号、数据到达的总速率以及Spark处理数据的总速率。不幸的是，由于MSK无服务器，AWS似乎不允许通过运行ID访问详细的流查询统计数据，这大大降低了它的价值。单击运行ID超链接时，您会收到502错误。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/f682cb7a1349556defb3b485489fef45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v083VuBY5AnLBBAHk6g40w.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的结构化流标签</figcaption></figure><p id="3571" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">我们最感兴趣的输出再次包含在<code class="fe nq nr ns ni b">driver</code>执行程序的<code class="fe nq nr ns ni b">stderr</code>和<code class="fe nq nr ns ni b">stdout</code>中(第二个表的<em class="pa">第一行，显示在</em>下面)。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/c7d5070dedcfa34a556414a66d566778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ctjQEFyme7S3_465_tBeRQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark UI的执行者选项卡</figcaption></figure><p id="d018" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">下面我们看到来自<code class="fe nq nr ns ni b">stderr</code>的样本输出。输出显示了微批次的结果。根据Apache Spark <a class="ae mi" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">文档</a>，在内部，默认情况下，使用<em class="pa">微批处理</em>引擎处理结构化流查询。该引擎将数据流作为一系列小批量作业进行处理，实现了低至100毫秒的端到端延迟和一次性容错保证。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">火花结构流式微批次输出示例</figcaption></figure><p id="e388" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">与上面的微批处理输出相对应的输出如下所示。我们看到了最初的微批处理结果，从任何消息流到<code class="fe nq nr ns ni b">topicC</code>之前的第一个微批处理开始。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">Spark结构化流式微批次结果到控制台的示例</figcaption></figure><p id="de5f" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">如果您熟悉Spark结构化流，您可能会意识到这些Spark作业是连续运行的。换句话说，流式作业不会停止；他们不断地等待更多的流数据。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/0cc20e7cafdd11f8013401119f896ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xiGmCGjYxwKPy1cZ_DEJvg.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序详细信息控制台</figcaption></figure><p id="c2ca" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">第一个作业<code class="fe nq nr ns ni b">04_stream_sales_to_kafka.py</code>将运行大约28–29分钟，并以状态<code class="fe nq nr ns ni b">Sucess</code>停止。但是，第二个作业<code class="fe nq nr ns ni b">05_streaming_kafka.py</code>，Spark结构化流作业，必须手动取消。</p><figure class="nd ne nf ng gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ox"><img src="../Images/e543ba86fbc74aa2c6937cea8a357c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FBQt4uDFH43wkw-QatvE_g.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk translated">EMR Studio无服务器应用程序详细信息控制台</figcaption></figure><h1 id="be6b" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">清理</h1><p id="0bb1" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">您可以从AWS管理控制台或AWS CLI删除您的资源。但是，要删除您的Amazon S3存储桶，必须先删除存储桶中的所有对象(包括所有对象版本和删除标记)，然后才能删除存储桶本身。</p><figure class="nd ne nf ng gt nu"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h1 id="4f03" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="b470" class="pw-post-body-paragraph lp lq it lr b ls lt ju lu lv lw jx lx lf ly lz ma li mb mc md ll me mf mg mh im bi translated">在这篇文章中，我们发现在AWS上采用无服务器的分析方法是多么容易。使用EMR Serverless，您不必配置、优化、保护或操作集群来运行这些框架的应用程序。有了MSK无服务器版，你可以按需使用Apache Kafka，并为你传输和保留的数据付费。此外，MSK无服务器自动配置和扩展计算和存储资源。如果有合适的分析使用案例，EMR无服务器和MSK无服务器可能会节省您的时间、精力和费用。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="275c" class="pw-post-body-paragraph lp lq it lr b ls og ju lu lv oh jx lx lf ou lz ma li ov mc md ll ow mf mg mh im bi translated">这篇博客代表我的观点，而不是我的雇主亚马逊网络服务公司的观点。所有产品名称、徽标和品牌都是其各自所有者的财产。除非另有说明，所有图表和插图都是作者的财产。</p></div></div>    
</body>
</html>