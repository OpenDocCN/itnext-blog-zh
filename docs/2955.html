<html>
<head>
<title>How to create a simple ETL Job locally with PySpark, PostgreSQL and Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用PySpark、PostgreSQL和Docker在本地创建一个简单的ETL作业</h1>
<blockquote>原文：<a href="https://itnext.io/how-to-create-a-simple-etl-job-locally-with-pyspark-postgresql-and-docker-ea53cd43311d?source=collection_archive---------1-----------------------#2019-09-06">https://itnext.io/how-to-create-a-simple-etl-job-locally-with-pyspark-postgresql-and-docker-ea53cd43311d?source=collection_archive---------1-----------------------#2019-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/d6da23acf7410392a326e11ea2663729.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fTDEt8iL5ck37gWHsJ6_-w.png"/></div></div></figure><p id="462c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">简介</strong></p><p id="a05b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本文中，我将展示如何利用Apache Spark来编写Python中强大的ETL作业。如果您已经熟悉Python，并且每天都在处理数据，那么PySpark将帮助您创建更多可扩展的(大)数据处理和分析。</p><p id="a06b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我将使用的数据来自Ebay-Kleinanzeigen，这是Ebay的德国分公司，人们可以在这里为自己的房产做广告。在我们的例子中，我们将使用包含超过370000辆二手车信息的数据集；此外，需要注意的是数据的内容是德语的。</p><blockquote class="kz la lb"><p id="187f" class="kb kc lc kd b ke kf kg kh ki kj kk kl ld kn ko kp le kr ks kt lf kv kw kx ky im bi translated"><a class="ae lg" href="https://www.kaggle.com/orgesleka/used-cars-database" rel="noopener ugc nofollow" target="_blank"> <em class="it">链接到Kaggle上托管的数据</em> </a></p></blockquote><p id="21ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">什么是阿帕奇Spark </strong></p><p id="4260" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Apache Spark </strong>是最流行的大规模数据处理引擎之一。这是一个开源系统，它的API支持多种编程语言。数据处理是在内存中完成的，因此它比MapReduce快几倍。Spark自带支持多种任务的库，比如流、机器学习和SQL。它可以在本地计算机上运行，也可以扩展到由数百台服务器组成的集群。</p><p id="1c3a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">什么是ETL？</strong></p><p id="5262" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ETL ( <strong class="kd iu"> E </strong> xtract，<strong class="kd iu">T</strong>transform和<strong class="kd iu"> L </strong> oad)是将数据从一个系统迁移到另一个系统的过程。数据提取是从同构或异构数据源中检索数据以进行进一步数据处理和数据存储的过程。在数据处理过程中，数据被清理，不正确或不准确的记录被修改或删除。最后，经处理的数据被加载(例如，存储)到目标数据库中，例如数据仓库或数据湖。</p><p id="2849" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">提取</strong></p><p id="1e9e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每个Spark应用程序的起点都是创建SparkSession。这是一个驱动程序进程，它维护关于Spark应用程序的所有相关信息，还负责在所有执行器之间分发和调度应用程序。我们可以通过以下方式简单地创建一个SparkSession:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="9264" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果已经创建了一个SparkSession，那么<code class="fe ln lo lp lq b">getOrCreate</code>方法将尝试获取它，否则它将创建一个新的spark session。使用<code class="fe ln lo lp lq b">master</code>选项，可以指定正在连接的主URL。然而，因为我们在本地运行我们的作业，我们将指定<code class="fe ln lo lp lq b"><em class="lc">local[*]</em></code>参数。这意味着Spark将使用与您机器上的逻辑核心一样多的工作线程。我们用<code class="fe ln lo lp lq b">appName</code>选项设置应用名称，这个名称将出现在Spark UI和日志数据中。</p><p id="3db2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的下一步是读取CSV文件。在CSV中阅读可以通过与我们的SparkSession关联的<code class="fe ln lo lp lq b">DataFrameReader</code>来完成。这样，Spark允许我们指定是否使用模式推理以及其他一些选项:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="ca49" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">选择模式推理还是手动定义模式很大程度上取决于用例，在为生产环境编写ETL作业的情况下，强烈建议定义一个模式，以防止不准确的数据表示。模式推理的另一个限制是它会使Spark应用程序变慢，尤其是在使用CSV或JSON时。因此，我还展示了如何使用预先定义的模式读入数据:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="d191" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">变换</strong></p><p id="5af8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们现在准备更仔细地查看我们的数据，并开始做更有趣的事情:</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lr"><img src="../Images/14dfe5202ca2c974297bf89ab094fc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Le-yFQWGfMr-r9Wmt7ntVQ.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">汽车数据集的前五行</figcaption></figure><p id="70fc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如您所见，有多个包含<code class="fe ln lo lp lq b">null</code>值的列。我们可以通过多种选择来处理缺失数据。然而，讨论这一点超出了本文的范围。因此，我们选择将缺失值保留为<code class="fe ln lo lp lq b">null</code>。但是，这个数据集中有更多奇怪的值和列，因此需要一些基本的转换:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="5d3d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种清理的基本原理基于以下几点:列<code class="fe ln lo lp lq b">dateCrawled</code>和<code class="fe ln lo lp lq b">lastSeen</code>似乎对任何未来的分析都没有用处。列<code class="fe ln lo lp lq b">nrOfPictures</code>中的所有值都等于<code class="fe ln lo lp lq b">0</code>，因此我们决定删除该列。</p><pre class="lh li lj lk gt lw lq lx ly aw lz bi"><span id="347a" class="ma mb it lq b gy mc md l me mf"><strong class="lq iu">seller</strong><br/>gewerblich         3<br/>privat        371525</span><span id="7989" class="ma mb it lq b gy mg md l me mf"><strong class="lq iu">offerType</strong><br/>Angebot    371513<br/>Gesuch         12</span></pre><p id="b78d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">检查列<code class="fe ln lo lp lq b">seller</code>和<code class="fe ln lo lp lq b">offerType</code>得到以下数字。因此，我们可以删除包含“gewerblich”的三行，然后删除列<code class="fe ln lo lp lq b">seller</code>。同样的逻辑也适用于列<code class="fe ln lo lp lq b">offerType</code>，因此我们得到了一个更加平衡的数据集。为了举例，我们将数据集保留如下:</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mh"><img src="../Images/e50bba8fd0e3ecbbf515f6d8a0c698f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4PT02sDjdzEDFNetV-PcOw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">“清洁”汽车数据集的前五行</figcaption></figure><p id="3c38" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">装载</strong></p><p id="14d5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们已经将原始数据转换为可供分析的数据，因此我们准备将数据加载到本地运行的PostgreSQL数据库中，以便在不久的将来进行进一步分析。我们用pgAdmin和这个基本的<a class="ae lg" href="https://github.com/klimpie94/pyspark-etl-analytics/blob/master/docker-compose.yml" rel="noopener ugc nofollow" target="_blank"> docker-compose文件</a>构建了一个PostgreSQL数据库。这个docker-compose配置文件定义了我们当前设置中的所有容器及其相应的设置。例如，我们用名字<code class="fe ln lo lp lq b">cars</code>、用户名<code class="fe ln lo lp lq b">admin</code>和密码<code class="fe ln lo lp lq b">admin</code>初始化了一个PostgreSQL数据库。</p><p id="cdf1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Psycopg2 </strong>是Python最流行的PostgreSQL数据库驱动程序。它为与PostgreSQL实例进行交互提供了一种简单明了的方式。首先，我们建立到<code class="fe ln lo lp lq b">cars</code>数据库的连接:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="b262" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为此，我们必须为<code class="fe ln lo lp lq b">connect</code>函数提供一些通用参数。也有可能指定<code class="fe ln lo lp lq b">port</code>，但是，在我们的例子中，不需要指定端口，因为我们在默认端口<code class="fe ln lo lp lq b">5432</code>上运行PostgreSQL实例。所以，我们的课程开始了，我们连接到了Postgres。有了连接之后，就可以编写我们的命令(例如插入、更新)了，而<strong class="kd iu"> Psycopg2 </strong>允许我们用<code class="fe ln lo lp lq b">cursors</code>来做这件事。游标是在连接之外创建的，它将允许您与PostgreSQL进行通信。</p><pre class="lh li lj lk gt lw lq lx ly aw lz bi"><span id="462f" class="ma mb it lq b gy mc md l me mf"># cursor<br/>cur = conn.cursor()</span></pre><p id="58c2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们已经创建了一个游标，我们能够在我们的<code class="fe ln lo lp lq b">cars</code>数据库中创建一个名为<code class="fe ln lo lp lq b">cars_table</code>的表:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="f9f4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">创建表后，现在就可以用我们的数据集填充它了。我们可以通过将数据作为元组列表(其中每条记录是一个元组)提供给我们的<code class="fe ln lo lp lq b">INSERT</code>语句来逐行插入数据:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="f497" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，现在可以使用我们之前定义的光标来执行该命令:</p><pre class="lh li lj lk gt lw lq lx ly aw lz bi"><span id="5020" class="ma mb it lq b gy mc md l me mf">cur.execute(insert_query, cars_seq)</span></pre><p id="f777" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如您所见，多亏了<strong class="kd iu"> Psycopg2 </strong>，将数据从应用程序传输到后端数据库(如PostgreSQL)变得非常容易。最后，我们将使用<strong class="kd iu"> Psycopg2 </strong>查询最近填充的表:</p><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ll lm l"/></div></figure><p id="e99e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这在我们的终端中给出了以下输出:</p><pre class="lh li lj lk gt lw lq lx ly aw lz bi"><span id="5f84" class="ma mb it lq b gy mc md l me mf">Printing 2 rows<br/>Brand =  volkswagen<br/>Model =  golf<br/>Price  =  480</span><span id="eb4d" class="ma mb it lq b gy mg md l me mf">Brand =  audi<br/>Model =  None<br/>Price  =  18300</span></pre><p id="ede6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然而，我们仍然<em class="lc">缺少一段重要的</em>代码:<strong class="kd iu"> Psycopg </strong>符合Python DB-API，所以自动提交特性默认为<code class="fe ln lo lp lq b">off</code>。因此，我们需要调用以下代码将我们的事务提交给PostgreSQL:</p><pre class="lh li lj lk gt lw lq lx ly aw lz bi"><span id="d1ac" class="ma mb it lq b gy mc md l me mf">conn.commit()</span></pre><p id="7eb8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了确保这一点，我们可以在pgAdmin中检查PostgreSQL中是否正确加载了数据集:</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mi"><img src="../Images/d38f8a2240375cee8c120052adb358e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LbJJyFaLQsWzWdlX7ASDBA.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">pgAdmin中加载的Cars数据集</figcaption></figure><p id="73ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">结束语</strong></p><p id="9cd2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Pyspark </strong>对于任何试图构建可扩展数据应用程序的数据工程师或数据科学家来说，都是一个强大而有用的(大)数据工具。我绝对可以推荐大家认真看一下，试着把它融入到你未来的一个项目中。感谢<strong class="kd iu"> Docker </strong>，我们能够在不安装任何东西的情况下启动一个本地<strong class="kd iu"> PostgreSQL </strong>数据库！这篇文章的代码可以在<a class="ae lg" href="https://github.com/klimpie94/pyspark-etl-analytics" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。请随时向我提供任何反馈或意见，因为这是我在平台上的第一篇文章。</p><p id="df4a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另外，如果你有兴趣参加<a class="ae lg" href="https://www.linkit.nl/vacatures/data-engineering/0007529/data-engineering-apprenticeship-starts-feb-1st-2020" rel="noopener ugc nofollow" target="_blank">数据工程训练营</a>或者你只是好奇我是如何经历这两个‘紧张’月的，请随时联系我:)</p><p id="c859" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">参考文献</strong></p><ul class=""><li id="6a19" class="mj mk it kd b ke kf ki kj km ml kq mm ku mn ky mo mp mq mr bi translated"><a class="ae lg" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Spark官方网站</a></li><li id="f5eb" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">《星火:权威指南》，比尔·钱伯斯和马泰·扎哈里(奥莱利)。版权所有2018 Databricks，Inc .，978–1–491–91221–8。”</li><li id="6228" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><a class="ae lg" href="https://en.wikipedia.org/wiki/Extract,_transform,_load" rel="noopener ugc nofollow" target="_blank">什么是ETL？</a></li><li id="85a9" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><a class="ae lg" href="http://initd.org/psycopg/docs/" rel="noopener ugc nofollow" target="_blank"> Psycopg2文档</a></li></ul></div></div>    
</body>
</html>