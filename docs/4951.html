<html>
<head>
<title>Spark + Cassandra, All You Need to Know: Tips and Optimizations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark + Cassandra，所有你需要知道的:技巧和优化</h1>
<blockquote>原文：<a href="https://itnext.io/spark-cassandra-all-you-need-to-know-tips-and-optimizations-d3810cc0bd4e?source=collection_archive---------0-----------------------#2020-11-02">https://itnext.io/spark-cassandra-all-you-need-to-know-tips-and-optimizations-d3810cc0bd4e?source=collection_archive---------0-----------------------#2020-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6761376a79f82a309a700cdf6c79605d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mF3Sg3zymCZO9LMb"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@jamie452?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰米街</a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><h1 id="9236" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="ed35" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我将讨论运行<a class="ae kf" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark </strong> </a>与<a class="ae kf" href="https://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Cassandra </strong> </a>的含义，比较最常见的用例是使用深度存储系统，如<a class="ae kf" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"/>【S3】</a><a class="ae kf" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">【HDFS</strong></a>。</p><p id="9d24" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">目标是<strong class="lg iu">理解Spark和Cassandra </strong>的内部机制，这样你就可以尽可能高效地编写代码，真正利用这两个伟大工具的力量。</p><p id="d5e4" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我会给你一些关于火花调谐和Cassandra优化的提示，这样你就可以最大化性能和最小化成本。我假设你已经对Spark和Cassandra有了基本的了解。</p><p id="d689" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，让我们回顾一下当Spark和Cassandra一起运行时，您有哪些不同的<strong class="lg iu">部署选项</strong>。</p><h1 id="7afd" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">火花卡桑德拉星团</h1><p id="d3b9" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一般来说，我们可以认为<strong class="lg iu">有两大类火花簇</strong>:</p><ul class=""><li id="5208" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">商用Spark集群</strong>:这种类型的集群，是一种<strong class="lg iu">经济有效的</strong>处理大量数据的方式。他们使用运行在低成本硬件上的廉价但缓慢的存储系统。这个想法是利用Spark并行性以高效的方式处理大数据。这是迄今为止最著名的设置，无论是在本地使用<a class="ae kf" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"/></a>HDFS，还是在云中使用<a class="ae kf" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">【S3】</strong></a>或其他深度存储系统。</li><li id="5ee7" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">高性能集群</strong>:这些特殊的集群使用具有高端CPU和大量内存的高性能机器。他们还使用非常高效、低延迟的固态硬盘。这是Cassandra数据库集群中使用的类似设置，因此这些类型的集群可以在相同的机器类型上运行Spark + Cassandra，使用<strong class="lg iu"> Cassandra代替HDFS进行存储</strong>。</li></ul><p id="d646" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">高性能集群更加昂贵，它们可以安装在云中或perm上。如果使用正确，它们与Cassandra结合起来非常有效，但是如果使用不当，它们可能是资源的<strong class="lg iu">浪费</strong>。本文的目标是为您提供一些关于如何调优这些集群的技巧。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/8b2ff7d56f5910379e1a96dd3484e667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*4HsPNNIuVCxQsNlO"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">火花+卡珊德拉</figcaption></figure><p id="1764" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们更详细地了解一下这两种体系结构可能的样子…</p><h2 id="ef1b" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">云中运行的火花</h2><p id="ed8d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你在云中运行<strong class="lg iu">，你有两个选择</strong>:</p><p id="4080" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">托管服务</strong></p><p id="4af9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">使用类似AWS <a class="ae kf" href="https://aws.amazon.com/emr/?whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;whats-new-cards.sort-order=desc" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> EMR </strong> </a>或GCP <a class="ae kf" href="https://cloud.google.com/dataproc/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> DataProc </strong> </a>的<strong class="lg iu">托管服务</strong>。这些是托管解决方案，使用云提供商深度存储而不是HDFS，尽管HDFS也可用。这是<strong class="lg iu">商品星火集群</strong>，我们在云上运行之前谈过。</p><p id="ffe4" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">你必须意识到<strong class="lg iu"> S3 </strong>或者其他便宜的<strong class="lg iu">深度存储系统最终是一致的</strong>，并且不像HDFS那样依赖于<strong class="lg iu">数据局部性</strong>。他们使用<strong class="lg iu">REST</strong>T30】HTTP协议将数据加载到Spark集群中，HDFS仅用于缓存不适合内存的数据。HDFS是短暂的储藏，S3是永久的储藏。为了解决您可能会读取陈旧数据的最终一致性问题，云提供商实施了他们自己的<a class="ae kf" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html" rel="noopener ugc nofollow" target="_blank"/><a class="ae kf" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html" rel="noopener ugc nofollow" target="_blank">解决方案</a>，您应该了解一下并在必要时使用它。</p><p id="5cbb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">分离存储和计算</strong>提供了一种经济高效、灵活且<strong class="lg iu">可扩展的</strong>解决方案，这种解决方案已经变得非常流行，但请注意<strong class="lg iu">当读取数据</strong>时，您无法利用数据局部性，这是将Cassandra加入等式时的一个问题。</p><p id="048f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">打造自己的</strong></p><p id="7acf" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">另一种选择是启动<a class="ae kf" href="https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&amp;ec2-whats-new.sort-order=desc" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> EC2 </strong> </a>实例并自行安装Spark，这要繁琐得多，但可以让您完全控制，因此您可以优化硬件以满足运行特定工作负载所需的需求。如果您想在云中的同一个集群中运行Cassandra + Spark，这是您必须选择的选项。</p><h2 id="8845" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">在酒店内运行火花</h2><p id="f01b" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果您在本地运行，也有同样的选择。您将使用HDFS而不是S3作为文件系统。其优势在于，数据将位于处理节点的本地，并且不涉及网络调用，从而实现了更好的I/O吞吐量和稍低的延迟，但这些优势并不明显。</p><p id="f552" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在本地运行您可能会在高端服务器上获得更好的交易，因此在这种情况下，您应该考虑在同一个集群中运行Spark和Cassandra以实现高性能计算。</p><p id="31d3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">无论您在哪里运行工作负载，您都有两种方法可以用来集成Spark和Cassandra。您可以为每个工具创建一个集群，或者在同一个集群中运行它们，这是本文的重点。</p><h2 id="6d8a" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">不同集群的Spark + Cassandra</h2><p id="68cf" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这个场景中，您有两个集群，一个用于Cassandra，一个用于Spark。在这种情况下，Cassandra集群将使用良好的硬件和针对Cassandra优化的固态硬盘进行设置。另一方面，Spark将使用商用硬件进行安装，通常，它将拥有比Cassandra集群更多的节点。</p><p id="b187" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这是一个<strong class="lg iu">低成本</strong>的解决方案，并且更加<strong class="lg iu">灵活</strong>。它可以在内部或云中安装，尽管在云中安装更容易、更便宜。在这里，您通常将深层存储用于数据湖，并为OLAP工作负载运行Spark作业。您将使用<strong class="lg iu"> Cassandra进行OLTP </strong>，您的在线服务将向Cassandra写入数据，一夜之间，您的Spark作业将读取或写入您的主Cassandra数据库。</p><p id="7cf7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这种情况下，Cassandra不用于处理，而只是作为一个<strong class="lg iu">源或接收器</strong>进行初始读取或最终写入，但不写入中间结果。一个典型的例子是从Cassandra读取前一天的数据，从HDFS/S3读取其余数据，以在Spark上运行OLAP工作负载。然后，您将在Cassandra中编写一份数据摘要，为用户提供最新的见解，并将其余数据放回数据湖，供您的内部团队进行分析。</p><p id="3238" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，使用这种方法，Cassandra的写入和读取通过网络进行，有时会跨越不同的VPC或区域，因此从网络性能的角度来看，这不是太有效，但它是有成本效益的。</p><p id="4257" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当您的OLTP应用程序有Cassandra，并且您只需要从Spark查询数据时，通常会使用这种方法，但Cassandra本身并不用于您的工作，也没有针对OLAP进行优化。</p><p id="0886" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这是一种流行的方法，很容易设置。在云中，您将有自己的Cassandra集群在虚拟机上运行，并且您的托管Spark集群通过网络连接到Cassandra。</p><p id="1d75" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当不需要高性能时，或者您有大量的数据，Cassandra可能难以处理或者运行起来太昂贵时，请使用这种方法。</p><h2 id="23b7" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">Spark + Cassandra在同一个集群</h2><p id="c860" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这种情况下，你的目标是为你的数据处理管道获得<strong class="lg iu">最佳性能</strong>，以及<strong class="lg iu">利用Cassandra的获得吞吐量和低延迟</strong>，基本上你设置了一个Spark集群，但是<strong class="lg iu">使用Cassandra而不是HDFS </strong>。这对于迭代数据处理非常有用，例如<strong class="lg iu">机器学习</strong>需要经常读写磁盘。</p><p id="4ec3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您需要首先为集群获得一组机器。使用固态硬盘，在这种情况下，平衡您的垂直和水平扩展选项。我的意思是，与商用硬件Spark集群相比，您可能希望用更多内核和更多RAM的更好的机器来拥有更少的节点。</p><p id="6296" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">针对OLAP操作调整您的Cassandra集群，您希望通过低延迟获得高吞吐量，请记住，Spark将读写大量数据，但大多数情况下，它将是批处理的。</p><p id="9d13" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">关于如何在同一个集群上安装Cassandra和Spark的更多信息，您可以查看本文。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/5e16f7a3b185e761d5af66eb4675a1d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/0*02eEeOB5zvLbE37Z.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">和卡珊德拉擦出火花。资料来源:https://opencredo.com/blogs/deploy-spark-apache-cassandra/</figcaption></figure><p id="e8bf" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在以下情况下使用这种方法:</p><ul class=""><li id="4df6" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">您已经有一个Cassandra集群设置，但没有得到充分利用和/或</li><li id="1fdc" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">您的作业需要运行得非常快(流或小型批处理)，并且不消耗大量数据。</li></ul><p id="9c2b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">对于这种方法，首先您将<strong class="lg iu">将您的数据摄取到Cassandra </strong>中。您有几种选择:</p><ul class=""><li id="0a15" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">使用Spark </strong>:如果您的源数据已经处于静止状态，并且您需要将它转移到Cassandra以实现快速高性能ETL管道，那么这是一个不错的选择。</li><li id="5cac" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">使用Cassandra的<a class="ae kf" href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/tools/toolsBulkloader.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">批量加载器</strong> </a>向Cassandra导入数据。</li><li id="5b50" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">如果您需要从API中提取数据，您可以使用一些流解决方案编写自己的应用程序，如<a class="ae kf" href="https://doc.akka.io/docs/akka/2.4/java/stream/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Akka Streams </strong> </a>。这个我在<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/big-data-pipeline-recipe-c416c1782908">这篇<strong class="lg iu">文章</strong> </a>里讲过。</li></ul><p id="2f98" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦在Cassandra中有了数据，您将使用Spark读写数据到Cassandra来运行您的<strong class="lg iu"> ETL </strong>管道。请注意，尽管HDFS可以使用，<strong class="lg iu">但您不应该使用它</strong>，原因有二:</p><ul class=""><li id="bebc" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">首先，它不是表演性的。如果你有卡桑德拉使用它，而不是缓慢的文件系统。</li><li id="be63" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">它将与Cassandra争夺I/O。Spark HDFS写操作是相当繁重的I/O操作，它们会降低Cassandra集群的速度并使其挨饿。</li></ul><p id="9b0e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">本文的其余部分将主要关注在同一个集群中运行Spark和Cassandra，尽管如果在不同的集群中运行，许多优化也适用。</p><h1 id="2096" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">火花四射的卡珊德拉</h1><p id="ef43" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">使用<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">火花卡珊德拉连接器</strong> </a>与卡珊德拉通话。使用此连接器时，您有两种选择:</p><ul class=""><li id="5fb3" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">使用<strong class="lg iu">低杠杆RDD API </strong>。这提供了更多的灵活性和手动优化代码的能力</li><li id="8994" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">为Spark使用<strong class="lg iu">数据帧或数据集API</strong>。在这种情况下，您可以像使用HDFS和<strong class="lg iu">一样读写数据帧，连接器将在后台执行所有优化</strong>。</li></ul><p id="4944" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，我推荐使用<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/data_source_v1.md" rel="noopener ugc nofollow" target="_blank">数据帧/数据集API </a>。这样，您可以利用相同的API，像编写其他系统一样编写Cassandra。你只需要知道你的仓库是卡珊德拉，而不是HDFS。你需要了解如何为Cassandra优化Spark，并在你的连接器中设置正确的<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md" rel="noopener ugc nofollow" target="_blank">设置</a>。这个我们以后再说。</p><p id="8553" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要从Cassandra表中读取数据，只需指定不同的格式:"<em class="nn">org . Apache . spark . SQL . Cassandra</em>"</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="e029" class="na kh it np b gy nt nu l nv nw">val df = spark<br/>  .read<br/>  .format("org.apache.spark.sql.cassandra")<br/>  .options(Map( "table" -&gt; "words", "keyspace" -&gt; "test" ))<br/>  .load()</span></pre><p id="b222" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这将创建一个新的数据帧，它与关键字空间“<em class="nn"> test </em>”中的表“<em class="nn"> words </em>”相匹配。</p><p id="b6f7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果你导入"<em class="nn">org . Apache . spark . SQL . Cassandra . _</em>"你可以简单地写:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="404c" class="na kh it np b gy nt nu l nv nw">import org.apache.spark.sql.cassandra._<br/>val df = spark<br/>  .read<br/>  .cassandraFormat("words", "test")<br/>  .load()</span></pre><p id="e0bd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">其中第一个参数是表，第二个参数是键空间。</p><p id="c6f8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要将数据框中的数据写入Cassandra表:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="6647" class="na kh it np b gy nt nu l nv nw">df.write<br/>  .cassandraFormat("words_copy", "test")<br/>  .mode("append")<br/>  .save()</span></pre><p id="7d53" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，数据框的方案必须与表方案相匹配。</p><p id="29b9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">就这样，基本上从API perceptive开始，这就是你需要的全部，当然还有一些高级特性，我们将在后面提到。</p><h2 id="2e2f" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">Cassandra + Spark高性能集群</h2><p id="caa6" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果您选择在同一个集群中运行Cassandra和Spark，那么将Spark与Cassandra一起使用类似于将它与HDFS一起使用，但是您确实需要理解细微的差别。首先，<strong class="lg iu">本地数据很重要</strong>，和HDFS一样。您需要理解spark分区利用这一知识来最大化数据局部性，这在Cassandra中是至关重要的，您不希望一个节点中的Spark执行器进行网络调用来从不同的节点获取数据。这将是本文后面的一个大主题。</p><p id="d971" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">接下来，我们将回顾您应该知道的Spark优化，这些优化在您使用Cassandra运行Spark时也适用，然后我们将回顾Cassandra特定的优化。</p><h1 id="bd7f" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">火花优化</h1><p id="9662" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">许多<a class="ae kf" href="https://medium.com/analytics-vidhya/apache-spark-optimization-techniques-3e984444ea07" rel="noopener">文章</a>都是关于这个主题的，我将总结你在和Cassandra一起工作时需要注意的最重要的一些。</p><p id="6f6b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在Spark中，您编写转换数据的代码，这些代码被评估为<strong class="lg iu"> lazy </strong>，并在幕后被转换为<strong class="lg iu">查询计划</strong>，当您调用诸如<em class="nn"> collect </em>()或<em class="nn"> write </em>()之类的动作时，查询计划就会具体化。Spark将数据分成<strong class="lg iu">个分区</strong>，由<strong class="lg iu">个执行器</strong>处理，每个执行器处理一组分区。在单个分区内执行的操作称为<strong class="lg iu">窄操作</strong>，包括<em class="nn">映射</em>或<em class="nn">过滤器</em>等功能。另一方面，聚合是<strong class="lg iu">宽操作</strong>，需要跨节点移动数据，这是非常昂贵的。查询计划本身可以有两种主要类型:逻辑计划和物理<strong class="lg iu">计划，我们将在后面讨论。</strong></p><p id="b7fe" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">记住，关于Spark性能的主要规则是:<strong class="lg iu">最小化数据混洗</strong>。这是由Spark  中的<a class="ae kf" href="https://medium.com/@dvcanton/wide-and-narrow-dependencies-in-apache-spark-21acf2faf031" rel="noopener"> <strong class="lg iu">宽操作引起的，这样的连接或聚合<strong class="lg iu">非常昂贵</strong>因为数据混洗。</strong></a></p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f5e8fca618e58a992a8a958f21dd28a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*oMxuw9VFV_ui1KtM.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">宽依赖性与窄依赖性。来源:<a class="ae kf" href="https://medium.com/@dvcanton/wide-and-narrow-dependencies-in-apache-spark-21acf2faf031" rel="noopener">https://medium . com/@ dv canton/wide-and-narrow-dependencies-in-Apache-spark-21 ACF 2 faf 031</a></figcaption></figure><p id="9360" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">总是试图减少数据混洗的次数，实际上，我们将要谈到的大多数优化的目标都是试图这样做:<strong class="lg iu">减少通过网络发送的数据量。</strong></p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6db866669f92c0e4b760fc2b09a92140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*3DQF2wzAPXk4zgZI.jpg"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">来源:<a class="ae kf" href="https://luminousmen.com/" rel="noopener ugc nofollow" target="_blank">https://luminousmen.com/</a></figcaption></figure><p id="de5f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在让我们回顾一下一些优化…</p><h2 id="79b7" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">早期过滤</h2><p id="2448" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这真的很简单但是<strong class="lg iu">非常重要</strong>。<strong class="lg iu">尽可能早地过滤数据</strong>，这样你就不会处理那些以后会被丢弃的数据。特别是当使用Cassandra时，你可以将过滤器下推到Cassandra，特别是你可以通过分区键限制查询的地方，越好。如果可能，在filter语句中指定分区键的所有组成部分。此外，如果你打算不止一次使用来自Cassandra的一组数据，确保使用<strong class="lg iu"> <em class="nn">缓存</em> </strong> <em class="nn"> () </em>将它保存在Spark内存中，而不是每次都从Cassandra中读取。</p><p id="d1ef" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一个好的经验是在过滤数据后使用<strong class="lg iu"><em class="nn"/></strong><em class="nn">()</em>方法来减少分区的数量。</p><h2 id="286b" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">火花分区和火花连接</h2><p id="cb71" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是Spark中的<strong class="lg iu">关键</strong>，我真的推荐<a class="ae kf" href="https://luminousmen.com/post/spark-tips-partition-tuning" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">这篇</strong> <strong class="lg iu">文章</strong> </a>里面详细解释了不同的优化。</p><p id="7496" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">设置正确的分区数量</strong></p><p id="2411" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您需要<strong class="lg iu">将</strong> <strong class="lg iu">正确的分区数量设置为</strong> <strong class="lg iu">最大化您集群中的并行度</strong>。如果您的分区太少，那么您将无法利用集群中所有可用的核心，从而浪费资源。拥有太多分区将导致管理许多小任务的额外开销，以及降低性能的数据移动。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/9a787b8adb446f2d4d03d699aea396d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BKSUNXzJuJhmm6Im"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">火花隔板。来源:<a class="ae kf" href="https://luminousmen.com/post/spark-tips-partition-tuning" rel="noopener ugc nofollow" target="_blank">https://luminousmen.com/post/spark-tips-partition-tuning</a></figcaption></figure><p id="a840" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">对Spark的一般建议是，集群中可用于应用的内核数量为分区数量的4倍，当然，这取决于您的使用案例。当有疑问时，<strong class="lg iu">被</strong> <em class="nn"> </em> <strong class="lg iu">错在更大数量的任务</strong>一边是个好主意。这需要与执行程序的数量和每个执行程序的内存保持一致，我们将在后面讨论。</p><p id="5347" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">避免数据偏斜</strong></p><p id="0990" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一般来说，您希望您的数据在所有节点上均匀分布，这在执行连接时尤为重要。您的连接键应该均匀分布，以避免数据倾斜。<strong class="lg iu">偏斜的数据会导致并行处理的性能下降</strong>甚至OOM(内存不足)崩溃，应该避免。</p><p id="73b1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您可以通过查看<strong class="lg iu"> Spark UI </strong>并检查每项任务花费的时间来<strong class="lg iu">诊断数据的数据偏斜度</strong>。如果一个或多个任务比其他任务花费的时间长，那么您就有不平衡的分区。</p><p id="f2de" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一些<strong class="lg iu">解决方案</strong>可能是:</p><ul class=""><li id="091e" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">将数据</strong>重新分区到一个更均匀分布的键上。这是首选选项，在执行任何宽操作之前，使用一个<strong class="lg iu">键自然地将数据</strong>分布到各个分区。</li><li id="615d" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">使用<a class="ae kf" href="https://medium.com/appsflyer/salting-your-spark-to-scale-e6f1c87dd18" rel="noopener"> <strong class="lg iu"> salting </strong> </a>合成一个额外的随机密钥，以便更好地分配数据。</li><li id="8622" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">将数据分为偏斜数据和非偏斜数据</strong>并通过重新分配偏斜数据来并行处理它们。</li><li id="b4f9" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">如果要连接的数据集很小，比如一个事实表，使用<a class="ae kf" href="https://acadgild.com/blog/broadcast-variables-and-accumulators-in-spark" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">广播变量</strong> </a>，我们将在后面讨论。这对于在事实表上进行查找很有用。</li><li id="84b1" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">使用<a class="ae kf" href="https://mungingdata.com/apache-spark/broadcast-joins/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">广播连接</strong> </a>当连接两个数据集且其中一个很小时，这与广播变量有相同的好处。一个更高级的特性是迭代广播连接，我们分割数据，做许多小的广播连接，而不是大的。</li></ul><p id="f243" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们更详细地看看联播吧…</p><p id="8079" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">火花连接</strong></p><p id="5d6c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">默认情况下，Spark user<a class="ae kf" href="https://en.wikipedia.org/wiki/Sort-merge_join" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Sort Merge</strong><strong class="lg iu">Join</strong></a>非常适合大型数据集。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ed148d93390fa73f717b39424c166e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/0*GVtoozKseq5d7Ztt.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">排序合并联接。来源:<a class="ae kf" href="https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c" rel="noopener" target="_blank">https://towards data science . com/the-art-of-joining-in-spark-dcbd 33d 693 c</a></figcaption></figure><p id="9f0e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">想法是在连接之前对分区进行排序，以减少数据混洗的数量，但是排序本身是一个昂贵的操作，这个连接的性能会根据连接两端的源数据而有很大的变化，如果数据已经混洗了，它会非常快，如果没有，Spark将需要执行交换和排序，这将导致数据混洗。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/23847d9ecd90e24215d3747551f09216.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F_lsr3vgKTcmx63m.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">需要交换时排序合并联接。来源:<a class="ae kf" href="https://towardsdatascience.com/should-i-repartition-836f7842298c" rel="noopener" target="_blank">https://towards data science . com/should-I-repartition-836 f 7842298 c</a></figcaption></figure><p id="6976" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当两个数据集都很大时，这些连接技术非常有效，但是当您将一个表与一个小的事实表连接时，优势就丧失了。在这种情况下，特别是如果你有一个集群有足够的内存可用，你可以使用<strong class="lg iu">广播加入</strong>。</p><p id="b77b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">广播加入</strong></p><p id="c560" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在广播连接的情况下，<strong class="lg iu"> Spark会将数据的副本发送给每个执行器，并保存在内存中</strong>，这可以将性能提高70%，在某些情况下甚至更高。广播连接的概念类似于我们将在后面讨论的广播变量，但是广播连接是由Spark自动处理的，您需要做的只是告诉Spark您想要广播哪个表:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="4886" class="na kh it np b gy nt nu l nv nw"><br/>df = fact_table.join(<strong class="np iu">broadcast</strong>(dimension_table),                        fact_table.col("dimension_id") === dimension_table.col("id"))</span></pre><p id="2518" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，当使用广播连接时，数据在内核之间共享，但每个执行器都有自己的副本，因此平衡内核和执行器很重要，我们将在后面讨论这一点。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/06cbd69d59fa93df345ed3fb0551b026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/0*Sarv0BwexqqPMd0N.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">广播加入。来源:<a class="ae kf" href="https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c" rel="noopener" target="_blank">https://towards data science . com/the-art-of-joining-in-spark-dcbd 33d 693 c</a></figcaption></figure><p id="9b99" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">更多关于Spark joins的信息，请查看<a class="ae kf" href="https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c" rel="noopener" target="_blank">这篇文章</a>。</p><p id="4eaa" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">在昂贵或多重连接之前重新分配</strong></p><p id="3eed" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu"> <em class="nn"> repartition() </em> </strong>方法允许我们更改集群上的数据分布。这将导致数据混乱，代价很高，但是如果在某些类型的连接或多个连接之前进行，将会提高性能，只要您指定列名。正如我们之前看到的，Spark需要知道数据分布，以便在排序合并连接之前使用它。这可以使用分桶来完成，分桶以预混洗和可能预排序的状态存储数据，其中关于分桶的信息存储在metastore中。但是，即使您的数据已经排序并在磁盘上对其中一个表进行了混洗，Spark也不会知道，仍然会对两个表进行重新排序和完全混洗。这就是为什么需要<strong class="lg iu">对数据进行重新分区，以匹配连接</strong>一端的分区，并且可以减少数据混乱，因此只有连接的一端(表)分布在网络上。其思想是，通过指定列，Spark将元数据添加到逻辑计划中，因此它知道不需要移动数据。例如，如果一个表按ID划分为100个分区。通过重新划分数据，您可以避免数据混乱:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="a7e9" class="na kh it np b gy nt nu l nv nw">df<strong class="np iu">.repartition(100, "id")</strong>.join(..., "id") </span></pre><p id="bed3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">目标是在连接的两端有相同数量的分区，以避免数据交换。如果分区数量与此属性不同，也会发生数据混洗:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="59d2" class="na kh it np b gy nt nu l nv nw">spark.sql.shuffle.partitions // default 200</span></pre><p id="4216" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">它控制shuffle期间的<strong class="lg iu">分区数量，</strong>并由排序合并连接使用，以便在连接之前对数据进行重新分区和排序。我非常推荐阅读<a class="ae kf" href="https://towardsdatascience.com/should-i-repartition-836f7842298c" rel="noopener" target="_blank"> <strong class="lg iu">这篇</strong> <strong class="lg iu">文章</strong> </a>，它更详细地介绍了连接和数据分区是如何工作的。</p><p id="fb30" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一个很好的经验是，在多次连接或非常昂贵的连接之前尝试重新分区，以避免排序合并连接一次又一次地重新洗牌。</p><p id="c580" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果您需要减少分区的数量，请使用<strong class="lg iu"> coalesce </strong>而不是<em class="nn"> repartition() </em>方法，因为它最大限度地减少了数据混乱，并且不会触发数据交换。在过滤之后，记得使用<em class="nn"> coalesce()，</em>，因为你会有更少的数据，这比<em class="nn"> repartition() </em>更有效，因为它最小化了数据混乱。此外，在重新分区后，始终保持或缓存您的数据，以最大限度地减少数据混乱。但是请记住，重新分区本身是一项开销很大的操作，它会在整个集群中移动数据，所以尽量只在完全必要时使用一次；并且永远记得先做窄操作。</p><p id="bd63" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">重要的是要记住<strong class="lg iu">一些宽操作，比如group by，会改变分区的数量</strong>。</p><p id="ccae" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">写入存储前重新分区</strong></p><p id="ba1e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">以一种优化阅读的方式编写数据总是一个好主意。在HDFS，当执行基于列的操作时，您希望使用列格式，如<a class="ae kf" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Parquet </strong> </a>来提高读取操作的性能。我在<a class="ae kf" href="https://towardsdatascience.com/big-data-file-formats-explained-dfaabe9e8b33" rel="noopener" target="_blank"> <strong class="lg iu">这篇</strong> <strong class="lg iu">篇</strong> </a>中谈到了这一点。其思想是，如果使用正确的文件夹结构创建分区，那么读操作不需要扫描磁盘中的所有数据，而只需要扫描指定的文件夹/分区。</p><p id="9e37" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您可以使用以下方法在写入时对数据进行分区:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="e4d9" class="na kh it np b gy nt nu l nv nw">df.write.partitionBy('key').json('/path...')</span></pre><p id="0c19" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在Cassandra中，端表应该已经分区，为了提高写性能，同样的原理也适用，并且您可以使用<em class="nn"> partitionBy </em>来实现数据局部性，这样当写入磁盘时(当使用高性能集群时)，数据将在正确的Cassandra节点中；然而，<strong class="lg iu"> Cassandra连接器在协调器节点上为您做了这件事</strong>,它已经知道Cassandra分区，并将数据成批发送到正确的分区。您只需要调整一些我们稍后将讨论的属性。</p><p id="4abf" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">避免磁盘溢出</strong></p><p id="b3c7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当加入大型数据集时，Spark需要在数据洗牌期间存储中间数据，如果执行器没有足够的内存，它会将其移动到磁盘，然后加入将变得非常慢，请确保为每个执行器设置正确的内存量(<em class="nn"> spark.executor.memory </em>)，并减少您的数据大小。您也可以通过设置来更改缓冲区的大小:<em class="nn">spark . shuffle . file . buffer</em></p><h2 id="0716" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">设置正确数量的执行器、内核和内存</h2><p id="8ac9" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">重要的是<strong class="lg iu">根据分区数量</strong>设置执行人数量。你的目标是最大化并行性，并且<strong class="lg iu">确保你的Spark执行器在整个作业期间都很忙，并且所有的内核都在节点中使用</strong>。</p><p id="64b8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">记住，每个执行器处理一个数据子集，也就是一组分区。此外，每个执行器使用一个或多个内核，如属性所设置:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="10d8" class="na kh it np b gy nt nu l nv nw">spark.executor.cores</span></pre><p id="09ad" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">带纱运行时设置为1。</p><p id="9093" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在Spark中，我们通过将数据分割成分区来实现并行性，这是Spark分割数据的方式。分区分布在不同的节点上，每个节点都有一组执行器。然后每个执行器管理一个或多个分区。请注意，在计算级别，每个执行器执行一组任务，因此每个执行器将向同一个分区应用一组函数。所以，这就是为什么您可能希望每个执行器有<strong class="lg iu">多个内核，这样您就可以并行运行独立的任务。重要的是要明白，每个执行器在内存中都有自己的本地和独立数据，包括广播变量(将在后面讨论)和累加器，这两者都使用相当多的内存；但是，这些在内核之间共享。因此，每个执行器只有一个内核意味着需要为每个执行器复制所有数据。此外，I/O操作，特别是对可拆分文件格式或Cassandra的I/O操作，可以在读写分区时利用多个内核，从而最大限度地提高吞吐量。</strong></p><p id="de64" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">总之，当您使用广播变量、累加器或者您读取/写入大量数据时，您希望每个执行器有多个内核，但不能太多，否则一些内核将无法使用。更多信息请查看<a class="ae kf" href="https://spoddutur.github.io/spark-notes/distribution_of_executors_cores_and_memory_for_spark_application.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">这篇</strong> <strong class="lg iu">文章</strong> </a>。</p><p id="87fb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据经验<strong class="lg iu">每个执行器3-5个内核是一个不错的选择</strong>。当然，这取决于分区的数量和分区的大小。如果您有非常小的分区，并且不像广播变量那样使用很多内存，那么建议使用较少的内核。</p><p id="576b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您的目标是找到执行器和内核数量之间的平衡，以及每个执行器的合适内存量。运行<a class="ae kf" href="https://spark.apache.org/docs/latest/submitting-applications.html" rel="noopener ugc nofollow" target="_blank"> spark-submit </a>时，可以设置执行器内存、执行器数量和内核数量。</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="bb27" class="na kh it np b gy nt nu l nv nw"><em class="nn"># Run on a Spark standalone cluster in cluster deploy mode with supervise</em><br/>./bin/spark-submit <strong class="np iu">\</strong><br/>  <strong class="np iu">--class</strong> org.apache.spark.examples.SparkPi <strong class="np iu">\</strong><br/>  <strong class="np iu">--master</strong> spark://207.184.161.138:7077 <strong class="np iu">\</strong><br/>  <strong class="np iu">--deploy-mode</strong> cluster <strong class="np iu">\</strong><br/>  <strong class="np iu">--supervise</strong> <strong class="np iu">\</strong><br/>  <strong class="np iu">--executor-memory</strong> 20G <strong class="np iu">\</strong><br/>  <strong class="np iu">--total-executor-cores</strong> 100 <strong class="np iu">\</strong><br/>  /path/to/examples.jar <strong class="np iu">\</strong><br/>  1000</span></pre><p id="a90e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">也可以将它们作为Spark属性传递。</p><p id="ce8d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">为每个执行器设置正确数量的<strong class="lg iu">内存</strong>也很重要，这需要基于您使用的累加器、广播变量以及在执行连接时数据的大小，正如我们之前看到的，数据是无序的。确保你<strong class="lg iu">设置了警报</strong>，这样你就知道数据溢出是非常低效的。</p><h2 id="9da3" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">广播变量</h2><p id="5e0b" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们已经讨论过广播连接，它非常有用并且非常受欢迎，例如，因为连接小数据集和大数据集是很常见的；当你用一个从<em class="nn"> CSV </em>文件上传的小事实表连接你的表时。</p><p id="651f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这种情况下，想法是<strong class="lg iu">将数据复制到每个执行器</strong>中，因此不需要移动数据，并且连接是在本地完成的，因为连接的一端完全存储在每个节点的内存中。这是Spark中广播的思想，对于连接和变量都是如此。</p><p id="b085" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">连接由Spark在幕后为您管理，因此易于使用。需要在代码中创建广播变量。您可以存储任何<em class="nn"> JVM </em>对象，只要它是可序列化的。我们将在下一节讨论序列化。</p><p id="15b3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要创建广播变量:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="9547" class="na kh it np b gy nt nu l nv nw">val df = spark.sparkContext.broadcast(data)</span></pre><p id="b5a7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">注意，数据不能是数据帧或数据集，需要是一个常规对象，所以需要调用<em class="nn"> collect() </em>方法获取所有数据，然后发送给执行者。</p><h2 id="5231" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">Spark序列化</h2><p id="1f4c" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有几篇文章和几本书教你如何优化你的Spark代码，然而，你能做的提高所有代码的Spark性能的最有效的事情就是<strong class="lg iu">去除Java序列化。</strong></p><p id="1a8d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Java序列化效率很低，也不安全；会拖慢你的工作。</p><p id="af8c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您需要了解Spark如何运行应用程序。简而言之，驱动程序需要序列化您的代码并将其发送到所有节点，因此广播变量和作业本身需要通过网络传输，此外，中间数据和元数据也需要序列化。这种情况在发动机罩下经常发生，它可能会成为您应用的一个瓶颈。</p><p id="a2ed" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果您在Spark中遇到过著名的“<em class="nn">任务不可序列化</em>”错误，那么您应该知道我在说什么。理解代码的哪些部分需要序列化，哪些不需要是至关重要的。您的目标是识别这些对象，并通过使用另一种可序列化的格式来优化它们。要解决连载问题，我真的建议看一看<a class="ae kf" href="https://medium.com/swlh/spark-serialization-errors-e0eebcf0f6e6" rel="noopener"> <strong class="lg iu">这篇</strong> <strong class="lg iu">篇</strong> </a>。一般来说，<strong class="lg iu">确保传递给闭包的所有对象都是可序列化的。</strong></p><p id="3970" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Java序列化最著名的Spark替代方案是<a class="ae kf" href="https://github.com/EsotericSoftware/kryo" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Kryo序列化</strong> </a> <strong class="lg iu"> </strong>，可以将序列化性能提高几个数量级。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f54605b12f084d2c7477dd2f049aa500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/0*a0mLtS-XmfzKF_dL.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">Kryo性能vs Java，Source:<a class="ae kf" href="https://docs.mulesoft.com/mule-runtime/3.9/improving-performance-with-the-kryo-serializer" rel="noopener ugc nofollow" target="_blank">https://docs . mulesoft . com/mule-runtime/3.9/用kryo-serializer提高性能</a></figcaption></figure><p id="2198" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">许多Spark开发人员选择不使用它，因为您需要使用以下方法注册您使用的每个类:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="d3d3" class="na kh it np b gy nt nu l nv nw">Kryo kryo = new Kryo();<br/>kryo.register(SomeClass.class);</span></pre><p id="a70f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">但是我真的建议你从项目一开始就启用Kryo来利用性能提升。<strong class="lg iu">注意</strong>如果你依赖数据集API，那么你可能不需要Kryo，因为你的类将使用比Kryo更有效的钨编码器，我们将在后面讨论它们。</p><h2 id="5a8e" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">火花催化剂</h2><p id="85c2" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我把最好的优化留到了最后。Spark有一个秘密武器，可以极大地提高你的工作效率，最棒的是，你几乎不用做任何事情就可以使用它，它在引擎盖下运行。我们之前已经接触过这个特性:<a class="ae kf" href="https://databricks.com/glossary/catalyst-optimizer" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">火花催化发动机</strong> </a> <strong class="lg iu">。</strong>它基本上以一种最佳的方式重写了你的代码。</p><p id="7227" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Catalyst在数据框API和部分数据集API中可用。<strong class="lg iu">RDD API</strong>中没有。它是<a class="ae kf" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark SQL </strong> </a>层的一部分，其背后的想法是使用RDBMS世界多年来完成的所有优化，并将它们带到<a class="ae kf" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark SQL </strong> </a>。由于SQL提供了一个已知的数学模型，Spark Catalyst可以理解数据，做出假设并优化代码。在引擎盖下，Spark运行一个复杂的工作流程，将你的代码完全改写成一个更难理解但更有效的代码。</p><p id="fa65" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">把Spark数据帧API想象成一种<strong class="lg iu">声明性</strong>语言，而不是真正的代码。你就像是在这个引擎上写东西，这个引擎会解释你的代码并优化它。这是在Spark中触发动作时发生的过程:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/54c09667fe896fabdcb48d1e987759be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FfEa03tmDsPdjYRs"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">催化剂工作流程</figcaption></figure><p id="0f6a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">简而言之，<strong class="lg iu">它创建了一个优化的逻辑计划，该计划被分成多个物理计划</strong>。然后，它为物理计划生成代码，并将代码分发给执行者(还记得为什么序列化很重要吗？).Catalyst通过在逻辑查询计划上应用一系列转换，如谓词下推、列修剪和常量折叠，从逻辑查询计划生成优化的物理查询计划。</p><p id="ae9a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Catalyst Optimizer有两种类型的优化:</p><ul class=""><li id="b0e1" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">基于成本的优化器</strong>:由于数据帧是基于SQL的，Catalyst可以计算每条路径的成本，并分析哪条路径更便宜，然后执行该路径以改善查询执行。</li><li id="6009" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">基于规则的优化器</strong>:包括常量合并、谓词下推、投影修剪、空传播、布尔简化和其他规则。</li></ul><p id="baa7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Catalyst还将<strong class="lg iu">自动执行广播连接</strong>当连接的一端很小时，可以使用该属性设置阈值:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="b304" class="na kh it np b gy nt nu l nv nw">spark.sql.autoBroadcastJoinThreshold</span></pre><h2 id="ec2f" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated"><strong class="ak">钨项目</strong></h2><p id="c495" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数据帧和数据集API也有利于<a class="ae kf" href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">项目</strong> <strong class="lg iu">钨</strong> </a>，该项目旨在修复我们之前提到的<strong class="lg iu">序列化</strong>问题、内存管理和<strong class="lg iu">性能</strong>。它使用优化的内存格式和不需要垃圾收集的堆外内存。</p><p id="3a21" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">它通过执行以下操作来优化Spark作业的CPU和内存效率:</p><ol class=""><li id="ea7b" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb of mn mo mp bi translated">堆外内存管理使用二进制内存数据表示，这是钨行格式。</li><li id="d7c6" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb of mn mo mp bi translated">高速缓存局部性，这是关于高速缓存感知计算和高速缓存感知布局，以实现高高速缓存命中率。</li><li id="2ad5" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb of mn mo mp bi translated">全阶段代码生成(CodeGen)。</li></ol><p id="e266" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这就是为什么在使用数据集API时需要使用<a class="ae kf" href="https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Encoders.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">编码器</strong> </a>的原因，这些负责堆外优化。您可以在数据框和数据集API中免费获得，但数据集会得到更好的优化。更多信息请查看这篇<a class="ae kf" href="https://www.linkedin.com/pulse/catalyst-tungsten-apache-sparks-speeding-engine-deepak-rajak/?articleId=6674601890514378752" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">伟大的</strong> <strong class="lg iu">文章</strong> </a>。</p><ul class=""><li id="8e2a" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu"><em class="nn">RDDs呢？</em> </strong>催化剂毫无办法，这是你自己动手的方法。实际上Catalyst生成RDD代码，这是最终结果。此外，您需要管理序列化。</li><li id="1c16" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu"><em class="nn">Catalyst是否优化数据集API？</em> </strong>是和否。最初，数据集API较慢，因为Catalyst " <em class="nn">看不到</em>"您在代码中做了什么，因为数据集语法比固定的SQL语法更广泛。但是如果你用的是最新版本的Spark ( <em class="nn"> 3.0 </em>)，那么大部分优化都是可用的。尽管如此，数据框架API在优化您的查询方面会更有效一些；对于数据集，你需要更加小心，但是如果你写了好的Spark代码，差别是很小的。此外，数据集具有<a class="ae kf" href="https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html" rel="noopener ugc nofollow" target="_blank">更好的空间和速度性能</a>，数据集钨优化优于数据帧。我的建议是<strong class="lg iu"> Spark SQL和数据帧</strong>应该由<strong class="lg iu">数据科学家</strong>使用，他们对Spark没有深入的了解，Catalyst会为他们优化代码。<strong class="lg iu">数据集API是Scala工程师的理想选择</strong>,他们对Spark内部有很好的了解。</li></ul><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi og"><img src="../Images/b7306097becf7c04df7a001676bfc1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0T8JhndIhZZRPW1m.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">Spark APIs比较。来源:<a class="ae kf" href="https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html" rel="noopener ugc nofollow" target="_blank">https://databricks . com/blog/2016/07/14/a-tale-of-three-Apache-spark-APIs-rdds-data frames-and-datasets . html</a></figcaption></figure><ul class=""><li id="5c68" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu"> <em class="nn">如果使用数据集API，需要Kryo吗？</em> </strong>是也不是。钨将使用编码器管理你的case类，但仍有其他部分的代码需要序列化，启用Kryo会有所帮助。如果你使用数据集API，我建议跳过Kryo，除非你需要最大化性能。</li></ul><h2 id="f1a9" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">其他Spark优化</h2><ul class=""><li id="45ab" class="mh mi it lg b lh li ll lm lp oh lt oi lx oj mb mm mn mo mp bi translated">尽可能使用<strong class="lg iu"><em class="nn">reduce by/aggregate by</em></strong>方法，而不是<strong class="lg iu"> <em class="nn"> groupBy </em> </strong>，因为它们减少了数据混乱。它工作得更快，因为Spark在混合数据之前知道每个分区上的公共键的组合输出。</li><li id="3f86" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">避免<strong class="lg iu"> <em class="nn"> reduceByKey </em> </strong>当输入输出值类型不同时，用use <code class="fe ok ol om np b"><strong class="lg iu">aggregateByKey</strong> </code>代替；<strong class="lg iu">如果类型相同，使用<em class="nn"> reduceByKey </em>如果不相同<em class="nn">aggregate by key</em>T40】。</strong></li><li id="66c3" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">在重新分区和写入之前，使用<strong class="lg iu"><em class="nn">local check point</em></strong><em class="nn">()</em>方法。这是为了在混洗阶段和写入操作之间创建阶段屏障。</li><li id="2213" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">不要用<strong class="lg iu"> <em class="nn">收</em> </strong> <em class="nn"> () </em>的方法。它会尝试将所有数据移动到驱动程序中，在那里它可能会耗尽内存并崩溃。仅将它用于调试目的或创建定义为小尺寸的广播变量。</li><li id="86ae" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">使用正确的<a class="ae kf" href="https://towardsdatascience.com/big-data-file-formats-explained-dfaabe9e8b33" rel="noopener" target="_blank"> <strong class="lg iu">文件格式</strong> </a>。<a class="ae kf" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Avro </strong> </a> <strong class="lg iu">用于行级操作</strong> <a class="ae kf" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">用于列级操作</strong> </a> <strong class="lg iu">或ORC</strong>等Spark SQL。压缩数据并确保格式是可拆分的，这样它就可以被Spark阅读器并行读取。<strong class="lg iu">可拆分格式有lso、bzip2、snappy </strong>等。不可分割的gzip，zip，lz4…</li><li id="1287" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">监控和可观察性</strong>关键是火花。在写入磁盘之前，作为最后一步，使用<strong class="lg iu"> <em class="nn"> explain() </em> </strong>方法来验证我们谈到的所有优化都发生了。检查预期的Catalyst优化是否已完成，过滤器是否已推送到源，查询是否已重新安排，数据混乱是否已最小化，等等。启用<a class="ae kf" href="https://supergloo.com/spark-monitoring/spark-performance-monitoring-history-server/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark历史服务器</strong> </a>来分析和观察您的作业的进展，并检测任何可能导致性能问题的变化。</li></ul><p id="0e44" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如您所见，所有这些优化的目标都是减少数据移动。为此，总是<strong class="lg iu">尽可能多地过滤</strong>数据。尝试<strong class="lg iu">最小化宽操作</strong>。如果数据集将被多次使用，则缓存这些数据集。在执行连接或写入磁盘之前，确保您的<strong class="lg iu">数据被均匀分区</strong>。注意数据局部性，记得使用<strong class="lg iu"> Spark UI </strong>和<em class="nn"> explain() </em>方法来理解Spark逻辑和物理计划。</p><h1 id="c163" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">火花卡珊德拉优化</strong></h1><p id="c64d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">首先，我们提到的Spark优化也适用于在同一个集群或不同的集群上使用Cassandra。旨在过滤掉你不需要的数据，平衡分区，依靠Spark广播连接。</p><p id="f15a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">与Catalyst引擎相同的<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connecto" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark Cassandra连接器</strong> </a>也优化了数据集和数据帧API。因此，提到的一些方法只用于rdd，并且是在使用高级API时自动添加的。</p><p id="7dd3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在让我们回顾一下有关Cassandra及其连接器的具体细节…</p><h2 id="b7b4" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">Spark和Cassandra分区</h2><p id="acdf" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们讨论了很多关于Spark分区的内容，如果您在同一个集群中运行Spark和Cassandra，您需要注意一些额外的事情。</p><p id="3006" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">最重要的规则是这条:<strong class="lg iu">将Spark分区匹配到Cassandra分区</strong>。第二条规则是:<strong class="lg iu"> Cassandra分区不同于Spark分区:</strong></p><ul class=""><li id="940f" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu"> Cassandra分区:</strong>这些是Cassandra跨节点分割数据并确定您的数据存储在哪个Cassandra节点上的单元。Cassandra分区键是在为Cassandra表定义模式时设置的。每个分区都包含在一个节点上(每个副本)。</li><li id="f794" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu"> Spark分区:</strong>Spark将数据(在内存中)划分给不同的工作线程。Spark分区还决定了Spark在处理数据时可以应用的并行度(每个分区都可以并行处理)。分区的数量和分区键既可以由Spark自动确定，也可以显式设置。</li></ul><p id="bc10" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">了解这两者之间的区别并编写代码来利用分区是至关重要的。<strong class="lg iu">您的目标是拥有正确数量的Spark分区，以允许Spark高效地并行处理计算。</strong></p><p id="0d68" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在许多情况下，会有比Cassandra分区更少的火花分区，因为Cassandra更细粒度；但是在可能的情况下，您希望Cassandra数据从Spark分区所在的Cassandra节点读取和写入。正如我们之前提到的，您还希望有足够多的Spark分区，每个分区都适合可用的executor内存，这样每个分区的每个处理步骤不会运行太长时间，但也不会太多，以至于每个步骤都很小，从而导致过多的开销。正确的数字取决于您的使用情形。在Spark中，特别是在Cassandra中，您必须运行性能和压力测试，并调整这些参数以获得正确的值。一个好的经验法则是每个执行器至少有30个分区。</p><p id="a3ac" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">好消息是，在许多情况下，Cassandra连接器会自动为您处理这些问题。当你使用Cassandra Spark连接器时，它会自动创建与Cassandra分区键一致的Spark分区！。这就是为什么在Cassandra中设置正确的分区很重要。Cassandra spark连接器尝试估计表格的大小，并将其除以参数<code class="fe ok ol om np b">spark.cassandra.input.split.size_in_mb</code>(默认情况下<em class="nn">64MB</em>)。但是也要记住，有些Spark函数会改变分区的数量。</p><p id="0070" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当您使用不同的分区键连接Cassandra表或进行多步处理时，您需要小心。请记住，像聚合这样的一些操作会改变分区的数量。因此，在这种情况下，您从一组大小合适的分区开始，但是随后极大地改变了数据的大小，导致分区数量不合适。解决这个问题的一个方法是使用连接器<code class="fe ok ol om np b"><strong class="lg iu">repartitionByCassandraReplica</strong>()</code>方法来调整Spark分区的大小和/或重新分配数据。这将重新分配Spark在内存中的数据副本，以匹配指定的Cassandra表的分布，并为每个执行器分配指定数量的Spark分区。</p><p id="bc86" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">连接器还提供了一个有趣的方法来执行连接:</p><pre class="mw mx my mz gt no np nq nr aw ns bi"><span id="ab2e" class="na kh it np b gy nt nu l nv nw">JoinWithCassandraTable()</span></pre><p id="e7ce" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">它只提取与Cassandra的RDD条目相匹配的分区键，因此它只处理速度更快的分区键。建议您在<em class="nn"> JoinWithCassandraTable </em>之前调用<code class="fe ok ol om np b">repartitionByCassandraReplica</code>来获得数据局部性，这样每个spark分区将只需要查询它们的本地节点。</p><p id="f89a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，当您使用数据集或数据帧API时，连接器会在幕后使用这些方法。</p><h2 id="d0aa" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">写入设置</h2><p id="e301" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">关于向Cassandra读取和写入数据，我非常推荐观看这个来自<a class="ae kf" href="https://www.youtube.com/channel/UCqA6zOSMpQ55vvguq4Y0jAg" rel="noopener ugc nofollow" target="_blank"> DataStax </a>会议的视频:</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="51ad" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在连接器中有许多参数<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#write-tuning-parameters" rel="noopener ugc nofollow" target="_blank">可以设置，但一般来说，从Spark向Cassandra写入数据有两种方法:</a></p><ul class=""><li id="be41" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">t:这个想法是让许多并行的单个写操作异步执行。如果因为没有单独的分区键而不能选择批处理，那么这种方法可以很好地执行。</li><li id="21b0" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">批处理</strong>:在这种情况下，我们创建批处理。为了实现这一点，我们需要确保通过一个Cassandra键对数据进行分区，这样每一批数据都进入同一个分区，查看视频了解更多细节。</li></ul><p id="6dfd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在写入Cassandra之前，您总是可以使用spark <em class="nn">重新分区</em>()方法来实现数据局部性，但是这很慢，而且有些矫枉过正，因为Spark Cassandra连接器已经在幕后更有效地实现了这一点。<strong class="lg iu">连接器自动以最佳方式为您批量处理数据</strong>。</p><p id="4ea1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据经验，如果您不确定某件事，不要去做，让连接器和Spark Catalyst为您优化代码。</p><p id="8b8d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据数据大小和目标表分区，您可能希望对每个作业进行以下设置:</p><ul class=""><li id="1f41" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">"<em class="nn">spark . Cassandra . output . batch . grouping . key</em>":Cassandra connector将根据该值对批处理进行分组，默认为partition，因此它将尝试重新分区，以便每个批处理都进入同一个分区，并依次进入同一个节点。您可以将其设置为replica_set。</li><li id="2c18" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu"><em class="nn">spark . Cassandra . output . batch . grouping . buffer . size</em></strong>:这是司机给你做批处理的时候，批处理的大小。这需要根据您的数据大小进行设置。默认值为1000。</li><li id="1b89" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">"<em class="nn">spark . Cassandra . output . batch . size . row</em>s】:批量大小，以行为单位，它将覆盖以前的属性，默认为auto。</li><li id="511d" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">"<em class="nn">spark . Cassandra . output . concurrent . writes</em></strong>":并发写的次数，这个属性和前面两个成正比，批量越大你想要的并发写越少。通过根据数据大小和分区调整这两个参数，您可以获得最佳性能。</li><li id="9a56" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">"<em class="nn">Cassandra . output . throughput _ MB _ per _ sec</em>"(默认值:无限制):每个内核的最大写吞吐量。您需要根据每个执行器的内核数量来设置。默认情况下，Spark会尽可能快地(无限制)写给Cassandra。对于长时间运行的作业来说，这不是很好，因为Cassandra节点将会不堪重负而崩溃。您应该为长时间运行的作业设置一些值。作为一般指导，我们建议从设置为5开始。</li></ul><p id="2369" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要使用fire and forget方法，请将<em class="nn">spark . Cassandra . output . batch . size . row</em>s设置为1，并将<em class="nn">spark . Cassandra . output . concurrent . writes</em><strong class="lg iu"><em class="nn"/></strong>设置为一个大数。</p><h2 id="5c5f" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">读取设置</h2><p id="c6ca" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当从Cassandra读取大量数据时，请确保使用正确的分区键对数据进行分区。您可以设置几个<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#read-tuning-parameters" rel="noopener ugc nofollow" target="_blank">属性</a>来提高连接器的读取性能。记住，<strong class="lg iu">读数据调优主要是关于分区的</strong>，我们已经讨论过了。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="op oo l"/></div></figure><p id="3b56" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">将<em class="nn">spark . Cassandra . concurrent . reads</em>设置为高于内核数量的数字，以便每个内核可以并行读取数据。当从Cassandra读取数据时，由于吞吐量更高，您需要比使用HDFS时更大的每个执行器的内核比率，<strong class="lg iu">尽可能利用Cassandra的优势</strong>。</p><p id="7f44" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当读取数据时，连接器将根据对spark数据大小的估计来确定分区的大小，如果您想将更多的数据放入Spark，可以增加"<em class="nn">Spark . Cassandra . input . split . sizeinmb</em>"但是要注意不要保存太多的数据，否则会遇到问题。一般来说，您的执行器应该设置为保持<strong class="lg iu"> <em class="nn">内核数量*分区大小* 1.2 </em> </strong>以避免内存不足问题或垃圾收集问题。</p><p id="5836" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">由Cassandra中的大分区导致的热点</strong>也会导致Spark中的问题，因为我们已经提到过数据偏斜的问题。</p><p id="6587" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">还要记住，读取速度主要由Cassandra的分页速度决定，分页速度是使用"<em class="nn">spark . Cassandra . input . fetch . sizeinrows</em>"属性设置的，这意味着在读取当前批处理时将异步请求多少行。</p><p id="c8b0" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">关注即将发布的<strong class="lg iu"> </strong> <a class="ae kf" href="https://issues.apache.org/jira/browse/CASSANDRA-9259" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">这款</strong></a><strong class="lg iu">Cassandra新功能</strong>，支持从Cassandra批量阅读。</p><h2 id="299c" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">性能测试</h2><p id="6706" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后但同样重要的是，您将不得不花费大量时间来调整所有这些参数。确保您使用的测试数据集在数据大小和形状方面与生产环境相似。您的环境应该是稳定的，测试应该是可重复的。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/aa0e723d1cb09643d7d720fdb90400dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j0pVhTMy7-MNNsfe.jpg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">火花调谐。来源:<a class="ae kf" href="https://luminousmen.com/post/spark-tips-dataframe-api" rel="noopener ugc nofollow" target="_blank">https://luminousmen.com/post/spark-tips-dataframe-api</a></figcaption></figure><p id="5ec8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">可以用Spark Cassandra<a class="ae kf" href="https://github.com/datastax/spark-cassandra-stress" rel="noopener ugc nofollow" target="_blank">T29】压力工具T31】来测试Cassandra。还要检查连接器暴露的</a><a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/11_metrics.md" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">度量</strong> </a>。</p><h1 id="84c5" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="9821" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们展开了Spark的内部结构，以便能够理解它是如何工作的以及如何优化它。关于Spark，我们可以用两个要点来总结我们的经验:</p><ul class=""><li id="c533" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">最小化数据混乱，最大化数据局部性。</strong></li><li id="4338" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">使用数据帧或数据集高级API来利用Spark优化。</strong></li></ul><p id="0656" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果你是Scala开发人员，请记住Spark高阶函数与Scala中的不同，你真的需要理解Spark和Catalyst引擎是如何工作的。</p><p id="a5f6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果您有一个单独的Cassandra集群，并且您只是将Cassandra用作汇聚源，那么<strong class="lg iu">会专注于优化读写设置，以最大化并行性</strong>。请记住，设置正确数量的平衡分区非常重要。如果你有一个高性能的Spark + Cassandra集群，你需要<strong class="lg iu">理解Spark和Cassandra分区</strong>之间的关系，并尝试利用Cassandra的速度和<strong class="lg iu">性能</strong>。</p><p id="f6c2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">记得关注<a class="ae kf" href="https://databricks.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> DataBricks </strong> </a>的Spark更新和<a class="ae kf" href="https://www.datastax.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Datastax </strong> </a>的Cassandra更新，因为他们是这些技术背后的公司。此外，检查一下<a class="ae kf" href="https://www.scylladb.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> ScyllaDB </strong> </a>，它是卡珊德拉的绝佳替代者。</p><p id="8ca7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu"> <em class="nn">祝您大数据之旅好运！</em>T25】</strong></p><p id="33a7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果你喜欢这篇文章，记得鼓掌，并关注我的更多更新！</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="5a51" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae kf" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"><em class="nn">me</em></strong></a><strong class="lg iu"><em class="nn"/></strong><em class="nn">进行未来的帖子。</em></p></div></div>    
</body>
</html>