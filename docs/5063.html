<html>
<head>
<title>Big Data Ingestion Options</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据接收选项</h1>
<blockquote>原文：<a href="https://itnext.io/big-data-ingestion-options-2d95851410d3?source=collection_archive---------1-----------------------#2020-11-30">https://itnext.io/big-data-ingestion-options-2d95851410d3?source=collection_archive---------1-----------------------#2020-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/b5bcce0cecd33f6f9c797d0a7f9606b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mq20AEpkF_lpHlxP"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@r3dmax?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔纳森派</a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><h1 id="7780" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="38c9" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">本文基于我之前的文章“<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/big-data-pipeline-recipe-c416c1782908?source=your_stories_page-------------------------------------"> <strong class="lg iu"> <em class="mc">大数据管道秘方</em> </strong> </a>”，在这篇文章中，我简要概述了大数据世界的方方面面。</p><p id="0fcf" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">在本文中，我将更详细地回顾关键的<strong class="lg iu">数据摄取</strong>过程，并讨论不同的选项。</p><p id="8e64" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">这是建立数据管道的第一步，也可能是最关键的一步。<strong class="lg iu">需要仔细规划和设计</strong>，因为这一过程为数据管道的其余部分奠定了基础。</p><h1 id="341c" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">数据摄取</h1><p id="6b14" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">第一步是获取数据，<strong class="lg iu">这个阶段的目标是获取您需要的所有数据，并将其以原始格式存储在一个存储库中。</strong>这通常由其他团队所有，他们将数据推送到<a class="ae kf" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Kafka </a>或数据存储中。</p><p id="4969" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">对于没有大量数据的简单管道，您可以构建一个简单的微服务工作流，在单个管道中接收、丰富和转换数据(<em class="mc">接收+转换</em>)，您可以使用<a class="ae kf" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Apache air flow</strong></a>等工具来编排依赖关系。在本文中，我们将重点关注需要分成几个阶段的大数据。</p><p id="a7d6" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">对于大数据，建议您<strong class="lg iu">将接收与处理</strong>分开，可以并行运行的大规模处理引擎不太适合处理阻塞调用、重试、反压力等。因此，建议在开始处理之前保存所有数据。</p><p id="4d9d" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">作为摄取的一部分，您应该通过调用其他系统来丰富您的数据，以确保所有数据(包括参考数据)在处理之前都已进入湖中。</p><p id="54e4" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">有两种摄取方式:</p><ul class=""><li id="10f8" class="mi mj it lg b lh md ll me lp mk lt ml lx mm mb mn mo mp mq bi translated"><strong class="lg iu">拉取</strong>:从数据库、文件系统、队列或API等地方拉取数据</li><li id="7b69" class="mi mj it lg b lh mr ll ms lp mt lt mu lx mv mb mn mo mp mq bi translated"><strong class="lg iu">推送</strong>:应用程序也可以将数据推送到你的湖中，但我们总是建议在两者之间有一个像<strong class="lg iu">卡夫卡</strong>那样的消息平台。一个常见的模式是<strong class="lg iu">变更数据捕获</strong> ( <a class="ae kf" href="https://en.wikipedia.org/wiki/Change_data_capture" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> CDC </strong> </a>)，它允许我们实时地将数据从数据库和其他系统转移到湖中。</li></ul><p id="e703" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">正如我们已经提到的，使用<strong class="lg iu"/><a class="ae kf" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Kafka</strong></a><strong class="lg iu">或</strong><a class="ae kf" href="https://pulsar.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Pulsar</strong></a><strong class="lg iu"/>作为数据摄取的<strong class="lg iu">中介</strong>来实现持久性、反压、并行化和对摄取的监控是非常常见的。然后，使用<a class="ae kf" href="https://docs.confluent.io/current/connect/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Kafka Connect </strong> </a>将数据保存到您的数据湖中。这个想法是，您的OLTP系统将向Kafka发布事件，然后将它们摄取到您的湖中。这是首选选项；如果源系统可以直接将数据推入数据湖，那么就采用这种方法，因为您不必管理对其他系统和团队的依赖。一般来说，<strong class="lg iu">依赖性管理对于摄取过程</strong>至关重要；您通常会从各种系统中获取数据，有些是新系统，有些是遗留系统；您将需要管理数据或API上的任何更改。</p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mw"><img src="../Images/109103f49a19852ef8e43fe1314aac73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*idOG68wunCV3oaTw"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">Kafka是数据摄取的关键组件</figcaption></figure><p id="03f3" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Domain-driven_design" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">领域驱动设计</strong> </a>可以用来管理依赖关系，管理变更，设置正确的职责。</p><p id="cd44" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">如果源系统无法将数据推入数据湖，而您需要从其他系统中提取数据。切记:<strong class="lg iu">避免直接通过API</strong>批量摄取数据；您可能会将HTTP端点称为数据<strong class="lg iu">浓缩</strong>，但请记住，从API获取数据在大数据世界中并不是一个好主意，因为它速度慢、容易出错(网络问题、延迟……)，并且会关闭源系统。虽然，API在OLTP世界中设置领域边界是很棒的，但是这些边界是由数据存储(<em class="mc">批处理</em>)或主题(<em class="mc">实时</em> ) <strong class="lg iu">在大数据</strong> <strong class="lg iu">世界</strong>中设置的。当然，这总是取决于你的数据的大小，但是如果你没有其他选择的话，尽可能使用Kafka或者Pulsar。从API中以流式方式提取少量数据，而不是批量提取。对于数据库，使用<a class="ae kf" href="https://debezium.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Debezium </strong> </a>等工具将数据流式传输到Kafka (CDC)。</p><p id="e4bd" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">同样，<strong class="lg iu">为了最小化依赖性</strong>，如果<strong class="lg iu">源系统将数据推送到Kafka </strong>而不是您的团队拉数据，这总是更容易，因为您将与其他源系统紧密耦合。如果这是不可能的，并且您仍然需要拥有摄取过程，我们可以看一下<strong class="lg iu">摄取的两大类别:</strong></p><h2 id="bfcc" class="nb kh it bd ki nc nd dn km ne nf dp kq lp ng nh ku lt ni nj ky lx nk nl lc nm bi translated"><strong class="ak">未管理的解决方案</strong></h2><p id="fa4d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这些是您开发的将数据吸收到您的数据湖中的应用程序；您可以在任何地方运行它们，这是一个定制的解决方案。当从没有现成解决方案的API或其他I/O阻塞系统获取数据时，或者当您没有使用Hadoop生态系统时，这种情况非常常见。</p><p id="0565" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">这个想法是使用流库从不同的主题、端点、队列或文件系统接收数据。因为你在开发应用程序，所以你有充分的灵活性。大多数库提供重试、反压、监控、批处理等等。这是一种<strong class="lg iu">自己编码</strong>的方法，因此您将需要其他工具来进行编排和部署。你得到了更多的控制和更好的性能，但需要付出更多的努力。</p><p id="495c" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">您可以让单个整体或微服务使用服务总线进行通信，或者使用外部工具进行编排。一些可用的库有Apache <a class="ae kf" href="https://camel.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Camel </strong> </a>或<a class="ae kf" href="https://akka.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Akka生态系统</strong></a><strong class="lg iu"/>(<a class="ae kf" href="https://doc.akka.io/docs/akka-http/current/index.html" rel="noopener ugc nofollow" target="_blank">Akka HTTP</a>+<a class="ae kf" href="https://doc.akka.io/docs/akka/current/stream/index.html" rel="noopener ugc nofollow" target="_blank">Akka Streams</a>+<a class="ae kf" href="https://doc.akka.io/docs/akka/current/index-cluster.html" rel="noopener ugc nofollow" target="_blank">Akka Cluster</a>+<a class="ae kf" href="https://doc.akka.io/docs/akka/current/typed/index-persistence.html" rel="noopener ugc nofollow" target="_blank">Akka Persistence</a>+<a class="ae kf" href="https://doc.akka.io/docs/alpakka/current/index.html" rel="noopener ugc nofollow" target="_blank">alpa kka</a>)。根据摄入管道的复杂程度，你可以将它部署为一个整体或微服务(T21)。</p><p id="3e60" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">如果你使用<strong class="lg iu"> Kafka或Pulsar </strong>，你可以用它们作为摄取编排工具来获取数据并丰富它。每个阶段将数据移动到一个新的主题，通过使用主题进行依赖管理，在基础结构本身中创建一个<a class="ae kf" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> DAG </strong> </a> <strong class="lg iu">。如果您没有Kafka，并且想要一个更加可视化的工作流，您可以使用<a class="ae kf" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Apache air flow</strong></a>来编排依赖项并运行DAG。这个想法是要有一系列的服务来接收和丰富数据，然后将数据存储在某个地方。每一步完成后，执行下一步，由气流协调。最后，数据被存储在某种存储器中。</strong></p><h2 id="a9db" class="nb kh it bd ki nc nd dn km ne nf dp kq lp ng nh ku lt ni nj ky lx nk nl lc nm bi translated"><strong class="ak">托管解决方案</strong></h2><p id="b7ea" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这种情况下，您可以使用部署在集群中用于接收的工具。这在Hadoop生态系统中很常见，您可以使用工具<a class="ae kf" href="https://sqoop.apache.org/docs/1.99.7/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Sqoop </strong> </a>从OLTP数据库中获取数据，使用<a class="ae kf" href="https://flume.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Flume </strong> </a>获取流数据。这些工具提供监控、重试、增量加载、压缩等等。</p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/142cbeea1bb407dfa740a2465b6156bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ULHgvomPZzJ14oP3"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">底部有摄取选项的Hadoop生态系统</figcaption></figure><h2 id="b456" class="nb kh it bd ki nc nd dn km ne nf dp kq lp ng nh ku lt ni nj ky lx nk nl lc nm bi translated"><a class="ae kf" href="https://nifi.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">阿帕奇尼菲</strong>T3】</a></h2><p id="6087" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="lg iu"> NiFi </strong>就是这些难以归类的工具之一。它本身就是一头野兽。它可以用于接收、编排甚至简单的转换。所以理论上，它可以解决简单的大数据问题。这是一个<strong class="lg iu">托管解决方案</strong>。它有一个<strong class="lg iu">可视界面</strong>，你可以拖放组件并使用它们来获取和丰富数据。它有超过300个内置处理器，可以执行许多任务，你可以通过实现你自己的来扩展它。</p><figure class="mx my mz na gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/1a3f9a4e9315fbe97b5f7cc70e99a4c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*U7U8SgiLfqTkIByf.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">NiFi工作流</figcaption></figure><p id="28c9" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">它有自己的架构，所以它不使用任何数据库或HDFS，但它与Hadoop生态系统中的许多工具进行了集成。可以调用API，集成Kafka，FTP，很多文件系统和云存储。您可以管理执行路由、过滤和基本ETL的数据流。对于某些用例，NiFi可能就是你所需要的。</p><p id="bd84" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">然而，NiFi不能扩展到超过某个点，因为超过10个节点的集群中的节点间通信会变得低效。它倾向于更好地垂直扩展，但是您可能会达到它的极限，特别是对于复杂的ETL。但是，您可以将它与Spark等工具集成在一起来处理数据。<strong class="lg iu"> NiFi是获取和丰富数据的绝佳工具。</strong></p><h1 id="63c9" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="cc0b" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="lg iu">数据摄取至关重要</strong>，确保您分析了不同的选项，并选择了<strong class="lg iu">最大限度减少依赖性的方法</strong>。使用<strong class="lg iu">领域驱动设计来管理变更和设定界限</strong>。可能的话，试着将<strong class="lg iu">数据推送到你的数据湖</strong>中，而不是拉出来。如果您需要拉动它，尽可能使用<strong class="lg iu">管理解决方案</strong>。如果你需要拉数据，试着使用<strong class="lg iu">流解决方案</strong>，它提供反压力、持久性和错误处理。</p><p id="a6f5" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated"><em class="mc">祝您的数据之旅好运！</em></p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><p id="5a51" class="pw-post-body-paragraph le lf it lg b lh md lj lk ll me ln lo lp mf lr ls lt mg lv lw lx mh lz ma mb im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae kf" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"><em class="mc">me</em></strong></a><strong class="lg iu"><em class="mc"/></strong><em class="mc">进行未来岗位。</em></p></div></div>    
</body>
</html>