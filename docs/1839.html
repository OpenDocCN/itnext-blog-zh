<html>
<head>
<title>Understanding the LMAX Disruptor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解LMAX干扰器</h1>
<blockquote>原文：<a href="https://itnext.io/understanding-the-lmax-disruptor-caaaa2721496?source=collection_archive---------0-----------------------#2019-02-09">https://itnext.io/understanding-the-lmax-disruptor-caaaa2721496?source=collection_archive---------0-----------------------#2019-02-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ff39d4cfc6539e14ba7ccc3bd3b44ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5bFxhPzYxQp0unW0MUG0g.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">演职员表:<a class="ae kc" href="https://pixabay.com" rel="noopener ugc nofollow" target="_blank"> pixabay </a></figcaption></figure><p id="528f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di"> L </span> MAX Disruptor是金融交易平台公司<a class="ae kc" href="https://www.lmax.com" rel="noopener ugc nofollow" target="_blank"> LMAX Exchange </a>编写的<a class="ae kc" href="https://github.com/LMAX-Exchange/disruptor" rel="noopener ugc nofollow" target="_blank">开源</a> Java库。这是一个优雅的，尤其是高性能的线程间消息传递解决方案。</p><p id="f7c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们将首先描述与跨线程共享内存和传统排队系统相关的问题。然后，我们将尝试了解LMAX干扰器的特别之处，以及如何使用它。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/2bef1a9377773642528168f64457d492.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*faUySbv7t8aAFm0X1zTMwg.png"/></div></figure><ul class=""><li id="5533" class="lp lq iq kf b kg kh kk kl ko lr ks ls kw lt la lu lv lw lx bi translated">LMAX Disruptor解决方案比Java <code class="fe ly lz ma mb b">ArrayBlockingQueue</code>和<code class="fe ly lz ma mb b">LinkedBlockingQueue</code>更快。</li><li id="b681" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">机械同情(对底层硬件的良好理解)应该会让你成为一个更好的开发者。</li><li id="4bf3" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">线程间共享内存容易出问题，需要小心操作。</li><li id="ab36" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">CPU缓存比主内存快，但是对它们的工作原理(缓存线等)理解不深。)会毁了你的表现。</li></ul><h1 id="018b" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">共享记忆的幻觉</h1><p id="3818" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi lb translated">让我们从一个简单的用例开始。我们需要使用一个循环将计数器从0递增到<code class="fe ly lz ma mb b">MAX</code>:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="a358" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为<code class="fe ly lz ma mb b">MAX</code>可能很大，而且我们可以在多核处理器上运行这个程序，出于性能考虑，我们可能希望将这个任务分成两个独立的线程。大概是这样的:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="c3bc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，这种实现有两个主要问题。</p><p id="9254" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们用等于一百万的<code class="fe ly lz ma mb b">MAX</code>运行它多次。显然，我们期望打印<code class="fe ly lz ma mb b">counter=1000000</code>，不是吗？</p><pre class="ll lm ln lo gt nm mb nn no aw np bi"><span id="bd41" class="nq mi iq mb b gy nr ns l nt nu">counter=522388<br/>counter=733903<br/>counter=532331</span></pre><p id="32ab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于变量<code class="fe ly lz ma mb b">sharedCounter</code>上的竞争条件，执行是不确定的。</p><p id="4e8b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当结果依赖于进程/线程的顺序或计时时，就会出现争用情况。在这种情况下，因为<code class="fe ly lz ma mb b">sharedCounter</code>被两个线程<strong class="kf ir">同时修改，没有任何保护</strong>。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="f63d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次，关于性能。如果<code class="fe ly lz ma mb b">MAX</code>被设置为一个足够大的值，使得两个线程的管理可以忽略不计，执行仍然比慢3倍以上。原因是什么？</p><p id="40e2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于两个线程都是CPU密集型的，操作系统很可能会将它们安排在两个不同的CPU内核上。此外，我们可能认为运行在两个不同内核上的两个线程可以自由共享内存。然而，我们已经忘记了<strong class="kf ir"> CPU缓存</strong>的概念:</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/659f8165315ab026727daa255e61e92c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*I_7Ju4oDPgTYO6Y-uPqdQg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">记忆层</figcaption></figure><p id="2ad8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CPU将在其内部缓存中缓存数据，而不是每次都查询DRAM来访问内存地址:本地L1和L2缓存以及远程共享的L3缓存。</p><p id="a288" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看看酷睿i7至强5500处理器的一些<a class="ae kc" href="https://software.intel.com/sites/products/collateral/hpc/vtune/performance_analysis_guide.pdf" rel="noopener ugc nofollow" target="_blank">数据</a>:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="2dbc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当一个处理器想要访问一个内存地址时，它将首先检查L1。如果它不在那里，它将产生一个<strong class="kf ir">缓存未命中</strong>，这意味着处理器将在L2进行检查。L2和L3也是如此，处理器最终会签入比L1慢60倍的DRAM。</p><p id="f9a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的例子中，因为<code class="fe ly lz ma mb b">sharedCounter</code>由两个CPU内核同时更新，它将在两个本地L1缓存之间反弹变量，这将大大降低执行速度。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="b6e8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，关于CPU缓存，还有一个重要的概念需要理解:它们被组织成<strong class="kf ir">缓存行</strong>。</p><p id="0a18" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">高速缓存行是连续字节的2的幂，通常是64个字节。它作为一个非链式哈希映射来管理，内存中的每个地址都被分配给一个给定的缓存行。</p><p id="ad2b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们以两个变量<code class="fe ly lz ma mb b">x</code>和<code class="fe ly lz ma mb b">y</code>为例，这两个变量由两个不同内核上调度的两个线程访问。几秒钟后，第一个线程修改了<code class="fe ly lz ma mb b">x</code>，第二个线程修改了<code class="fe ly lz ma mb b">y</code>。</p><p id="766c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果两个变量都是同一高速缓存行的一部分(散列它们的地址给出相同的高速缓存行)，第二个内核将看到其整个行被标记为<strong class="kf ir">无效</strong>，即使程序只对<code class="fe ly lz ma mb b">y</code>感兴趣而不是<code class="fe ly lz ma mb b">x</code>。因此，第二个内核将从其他地方(L2、L3或DRAM)获取该行的更新副本。</p><p id="15c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个问题被称为<strong class="kf ir">假共享</strong>，将导致严重的性能损失(尽管CPU将保证执行是确定性的)。</p><h1 id="efc5" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">并行执行</h1><p id="bce1" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di"> C </span>当前执行的代码必须首先保证<strong class="kf ir">互斥</strong>。这意味着访问同一资源的多个线程需要协调。</p><p id="29af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，当进行更改时，必须将其标记为对其他线程可见。这叫做<strong class="kf ir">变化的可见性</strong>。</p><p id="b35f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是并发的两个主要概念。</p><h2 id="549d" class="nq mi iq bd mj od oe dn mn of og dp mr ko oh oi mv ks oj ok mz kw ol om nd on bi translated">互斥现象</h2><p id="a6bc" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated"><strong class="kf ir">锁定</strong>是实现互斥的一种可能的解决方案。然而，它们非常昂贵，因为满足时需要仲裁。这种仲裁是通过上下文切换到操作系统来实现的，操作系统将挂起等待该锁的线程，直到它被释放。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oo"><img src="../Images/3fbc76522ccd294ede71a0491fb09f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQ69pzwlftT3XeFKGc6KCQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">演职员表:【ancientpages.com T2】</figcaption></figure><p id="a5ac" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，在此上下文切换期间(但也在将控制释放给可能决定做其他任务的OS时)，执行上下文可能会丢失先前缓存的数据和指令。</p><p id="b984" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们检查一些<a class="ae kc" href="http://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf" rel="noopener ugc nofollow" target="_blank">数字</a>来理解在一个循环中运行5亿次的64位计数器的锁的影响:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="f7b1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">锁的替代方法是<strong class="kf ir"> CAS </strong>(比较和交换)操作。CAS操作是一种机器指令，它允许将<a class="ae kc" href="https://stackoverflow.com/a/7750439" rel="noopener ugc nofollow" target="_blank">字</a>有条件地设置为原子操作(全有或全无)。</p><p id="6e38" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，变量的旧值和期望值是作为参数提供的。在操作结束时，如果新值与预期值匹配，则变量被更新。否则，由线程决定是否重试另一个CAS操作。</p><p id="218f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Java中，<code class="fe ly lz ma mb b">AtomicInteger</code>这样的<code class="fe ly lz ma mb b">Atomic*</code>类就是基于这个操作的。</p><p id="e549" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们比较一下性能结果:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="2b00" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后但同样重要的是，值得一提的是，如果关键部分(受保护的部分)不适合单个原子操作，它将需要多个CAS操作的编排，并且处理起来会更加复杂和昂贵。</p><h2 id="8fdd" class="nq mi iq bd mj od oe dn mn of og dp mr ko oh oi mv ks oj ok mz kw ol om nd on bi translated">变化的可见性</h2><p id="c7b7" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">变更的可见性可以通过<strong class="kf ir">内存屏障</strong>(也称为内存栅栏)来实现。</p><blockquote class="op oq or"><p id="ee50" class="kd ke os kf b kg kh ki kj kk kl km kn ot kp kq kr ou kt ku kv ov kx ky kz la ij bi translated">存储器屏障使CPU对屏障指令之前和之后发出的存储器操作实施排序约束。</p><p id="4d30" class="kd ke os kf b kg kh ki kj kk kl km kn ot kp kq kr ou kt ku kv ov kx ky kz la ij bi translated">来源:维基百科</p></blockquote><p id="5c96" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为什么我们需要这样的机制？出于性能原因，大多数现代CPU采用性能优化，这可能会导致无序执行。</p><p id="1b84" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们回到第一个例子:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="13e7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个例子中，何时更新循环计数器并不重要，因为循环中没有操作使用它。CPU可以自由地<strong class="kf ir">重新排序指令</strong>以优化执行性能。</p><p id="a7ad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种重新排序在单线程执行的情况下不是问题，但在并发执行的情况下可能变得不可预测。</p><p id="756a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是记忆障碍的目标:</p><ul class=""><li id="489b" class="lp lq iq kf b kg kh kk kl ko lr ks ls kw lt la lu lv lw lx bi translated">确保从另一个CPU内核观察屏障两侧的所有指令时，它们以正确的顺序出现。</li><li id="f9df" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">通过将数据传播到底层缓存使内存可见。</li></ul><p id="8973" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有不同类型的记忆障碍:</p><ul class=""><li id="a6a0" class="lp lq iq kf b kg kh kk kl ko lr ks ls kw lt la lu lv lw lx bi translated">Read:为屏障前排序的写操作提供一致的视图。</li><li id="16d5" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">写:给出屏障前商店运营的有序视图。</li><li id="2478" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">满:阅读和满栏的组合。</li></ul><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ow"><img src="../Images/7b05b2213c24e824aecec6f67fd1b609.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fPGrtZi8xjULvcvoG4jbRw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">演职员表:<a class="ae kc" href="http://barriersdirect.co.uk" rel="noopener ugc nofollow" target="_blank">barriersdirect.co.uk</a></figcaption></figure><p id="e13b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Java中，使用一个<em class="os"> volatile </em>字段在我们写入它之后插入一个写屏障指令，在我们读取它之前插入一个读屏障指令。同时，一旦构造函数完成，一个类的<em class="os"> final </em>字段使用写屏障变得可见。</p><p id="e823" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">也可以从<em class="os">不安全</em>库中访问这些指令。</p><p id="30c4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们修改我们的多线程实现，在访问<code class="fe ly lz ma mb b">sharedCounter</code>之前使用读内存屏障，在访问之后使用写内存屏障:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="4504" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们在<code class="fe ly lz ma mb b">MAX</code>等于100万的情况下再次运行这个实现。请记住，我们仍然期望在执行结束时打印<code class="fe ly lz ma mb b">counter=1000000</code>:</p><pre class="ll lm ln lo gt nm mb nn no aw np bi"><span id="671c" class="nq mi iq mb b gy nr ns l nt nu">-- First multi-threaded implementation without a memory barrier<br/>counter=522388<br/>counter=733903<br/>counter=532331</span><span id="dc07" class="nq mi iq mb b gy ox ns l nt nu">-- New implementation with memory barriers<br/>counter=999890<br/>counter=999868<br/>counter=999770</span></pre><p id="466c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所见，由于记忆障碍，我们越来越接近预期结果，这是不可否认的影响。然而，执行是不确定的，因为内存屏障仍然不足以防止非原子操作的竞争情况。</p><h1 id="da40" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">传统队列</h1><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oy"><img src="../Images/c28a8425f3d9fc8901a237448d0cc16d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pX-zOhchRgU7jJKTVtW9dw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">演职员表:<a class="ae kc" href="http://chipverify.com" rel="noopener ugc nofollow" target="_blank">chipverify.com</a></figcaption></figure><p id="0bd0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">线程间共享内存的另一种选择是消息传递范例:<strong class="kf ir">通过通信共享内存</strong>。</p><p id="9a45" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着我们需要线程间的东西来处理通信。解决方案之一是使用传统的<strong class="kf ir">队列</strong>，比如Java中的<code class="fe ly lz ma mb b">LinkedBlockingQueue</code>或<code class="fe ly lz ma mb b">ArrayBlockingQueue</code>。</p><p id="6d99" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，它不能解决并发问题，因为即使是队列也必须确保互斥和变化的可见性。</p><p id="2865" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们看一下<code class="fe ly lz ma mb b">ArrayBlockingQueue</code>的<code class="fe ly lz ma mb b">put</code>方法，我们可以验证这两个方面都得到了处理:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="b47c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对队列的访问被锁定，并且一旦添加了元素，就向等待的线程发送信号。</p><p id="e3b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">非常有趣的是，LMAX团队注意到，通常情况下，由于消费者和生产者之间的速度差异，队列往往<strong class="kf ir">总是接近满或接近空</strong>。这种现象导致了高度的争用和/或昂贵的高速缓存管理。</p><p id="f426" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果队列接近满，将导致生产者之间的争用，导致上下文切换，并且可能丢失缓存的数据和指令。</p><p id="a967" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，在传统的排队系统中，生产者要求队列的头，而消费者要求队列的尾。如果队列接近空，很可能头、尾和队列大小都属于<strong class="kf ir">同一条缓存线</strong>，这可能导致上述假共享问题。</p><h1 id="662e" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">LMAX干扰器</h1><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/1ac2990915b5aa0fc7f7034b2dd47891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*q5N4j_PrALLLpZLEU3c5FA.jpeg"/></div></figure><p id="7a79" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">LMAX干扰器的创造者也因发明了机械共鸣的概念而闻名。简而言之，在设计算法、数据结构等方面，理解底层硬件应该使你成为一名开发人员。基于这一理念，该团队已经能够创建这个伟大的库:</p><blockquote class="op oq or"><p id="37b5" class="kd ke os kf b kg kh ki kj kk kl km kn ot kp kq kr ou kt ku kv ov kx ky kz la ij bi translated">与同类方法相比，中断器的写入争用显著减少，并发开销更低，缓存更友好，所有这些都导致吞吐量更高，抖动更少，延迟更低。</p><p id="a533" class="kd ke os kf b kg kh ki kj kk kl km kn ot kp kq kr ou kt ku kv ov kx ky kz la ij bi translated">来源:<a class="ae kc" href="https://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf" rel="noopener ugc nofollow" target="_blank">干扰器技术论文</a></p></blockquote><p id="d339" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们来试着分析一下原因。</p><p id="433c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，中断器基于一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Circular_buffer" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">环形缓冲区结构</strong> </a>(也称为循环缓冲区)，这是一个简单的固定大小的缓冲区，就好像它是端到端连接的一样:</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/60cc4ee61222c4ba60e4bed421f92826.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*soxodeCvj-FY8vrl_WY6kA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">环形缓冲结构</figcaption></figure><p id="5d03" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">启动时，根据提供的大小(必须是2的幂)和初始化事件的工厂来分配内存:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="97c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们在启动时分配了<code class="fe ly lz ma mb b">MyEvent</code>类的<code class="fe ly lz ma mb b">ringBufferSize</code>个实例。</p><p id="982a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同时，我们提供了一个为事件处理器创建线程的工厂和一个定义如何处理慢速订阅者的等待策略(这些策略在这里<a class="ae kc" href="https://github.com/LMAX-Exchange/disruptor/wiki/Getting-Started#alternative-wait-strategies" rel="noopener ugc nofollow" target="_blank">描述</a>)。稍后我们将讨论生产者类型。</p><p id="7917" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事件实例将被重用，并在<code class="fe ly lz ma mb b">Disruptor</code>实例的持续时间内存在，以消除<strong class="kf ir">垃圾收集</strong>的问题，因为在传统队列中，事件可能会存在更长时间。</p><p id="3404" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在内部，环形缓冲区由对象数组支持。据创造者说，这是有充分理由的。在硬件级别，阵列具有可预测的访问模式。这些条目可以预加载，所以处理器不会不断地回到主存储器来加载环中的下一个条目。这样，我们可以比用链表支持的队列更有效地迭代。</p><p id="951d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">配置使用者可以这样完成:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="0b57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们为<code class="fe ly lz ma mb b">handleEventsWith()</code>提供了一个lambda表达式。这个λ有三个输入:</p><ul class=""><li id="05a1" class="lp lq iq kf b kg kh kk kl ko lr ks ls kw lt la lu lv lw lx bi translated">事件本身</li><li id="2a8f" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">序列标识符</li><li id="2d65" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">用于批处理管理的布尔值</li></ul><p id="30ef" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在多个生产者的情况下，他们都将接收每一个事件。如果我们想要分配负载，我们可以基于序列标识符实现一个<strong class="kf ir">分片</strong>策略。大概是这样的:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="8ee5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们可以启动中断器，它返回一个<code class="fe ly lz ma mb b">RingBuffer</code>实例:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="c6a7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦<code class="fe ly lz ma mb b">Disruptor</code>实例被启动，我们可以通过以下方式发布事件:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="9a99" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">序列标识符是事件在环形缓冲区结构中的位置。</p><p id="9000" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们创建一个<code class="fe ly lz ma mb b">Disruptor</code>实例时，我们还传递了一个<code class="fe ly lz ma mb b">producerType</code>变量，它可以等于<code class="fe ly lz ma mb b">ProducerType.SINGLE</code>或<code class="fe ly lz ma mb b">ProducerType.MULTI</code>。这向<code class="fe ly lz ma mb b">Disruptor</code>表明我们将有单个还是多个生产者。</p><p id="62f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在单个生产者的情况下，<code class="fe ly lz ma mb b">ringBuffer.next()</code>是完全<strong class="kf ir">无锁</strong>。另一方面，如果我们有多个生产者，这个函数依赖CAS操作来提供环形缓冲区中可用的下一个序列标识符。</p><p id="6acc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过添加左<strong class="kf ir">和右</strong>填充符来管理序列标识符本身，以确保它不会与任何其他东西一起出现在缓存行中:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="6124" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，发布一个事件会创建一个内存屏障，以确保缓存与该事件保持同步。它允许在环形缓冲区结构中添加一个事件，<strong class="kf ir">而没有任何锁定，这给了我们巨大的性能提升。</strong></p><p id="80ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后要提的一点。我们说过环形缓冲区由一个简单的数组支持。这意味着，开发人员有责任防止属于<strong class="kf ir">相同缓存行</strong>的多个事件的潜在错误共享问题。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="2631" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过分享LMAX团队在比较颠覆者和<code class="fe ly lz ma mb b">ArrayBlockingQueue</code>时产生的性能结果来结束这篇文章。</p><p id="ef9b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">吞吐量性能测试，单位为ops/sec (P代表提供商，C代表消费者):</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="11a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以纳秒/秒为单位的延迟性能测试:</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="aeb0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">非常欢迎任何与此帖子相关的建议或改进！</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><a href="https://twitter.com/teivah"><div class="gh gi pb"><img src="../Images/388d05660a4fea61e324f15683e09318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*QyMprmi8cEMAswS5nC9Ytg.png"/></div></a></figure><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/29a72d1ac4cdb84f06d437910025f898.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*5rknE72qfQ3TIxTNOqNaTg.png"/></div></figure><h1 id="c004" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">进一步阅读</h1><div class="pd pe gp gr pf pg"><a href="https://github.com/LMAX-Exchange/disruptor" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">LMAX-交换/中断器</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">高性能线程间消息库。通过创建一个……</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu jw pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a href="https://github.com/teivah/disruptor-demo" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">tei vah/干扰器-演示</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">在GitHub上创建一个帐户，为teivah/disruptor-demo开发做贡献。</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pv l pr ps pt pp pu jw pg"/></div></div></a></div><ul class=""><li id="8a1c" class="lp lq iq kf b kg kh kk kl ko lr ks ls kw lt la lu lv lw lx bi translated">LMAX团队的<a class="ae kc" href="http://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf" rel="noopener ugc nofollow" target="_blank">颠覆者技术论文</a></li><li id="18f7" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated"><a class="ae kc" href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-why-its-so-fast.html" rel="noopener ugc nofollow" target="_blank">解剖颠覆者:为什么这么快(上)锁是坏的</a></li><li id="50af" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated"><a class="ae kc" href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-why-its-so-fast_22.html" rel="noopener ugc nofollow" target="_blank">剖析干扰器:为什么这么快(第二部分)魔法缓存线填充</a>Trisha Gee著</li><li id="1b16" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">Trisha Gee的《解剖破坏者:揭开记忆障碍的神秘面纱》</li><li id="3d6d" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated">马丁·汤普森<a class="ae kc" href="https://mechanical-sympathy.blogspot.com/2011/07/memory-barriersfences.html" rel="noopener ugc nofollow" target="_blank">记忆屏障/栅栏</a></li><li id="befb" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated"><a class="ae kc" href="https://martinfowler.com/articles/lmax.html" rel="noopener ugc nofollow" target="_blank">马丁·福勒的LMAX架构</a></li><li id="13ce" class="lp lq iq kf b kg mc kk md ko me ks mf kw mg la lu lv lw lx bi translated"><a class="ae kc" href="https://github.com/smartystreets/go-disruptor" rel="noopener ugc nofollow" target="_blank">smarty streets的LMAX中断器到Go语言的一个端口</a></li></ul></div></div>    
</body>
</html>