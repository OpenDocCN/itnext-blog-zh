<html>
<head>
<title>Cassandra Optimizations for Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">针对Apache Spark的Cassandra优化</h1>
<blockquote>原文：<a href="https://itnext.io/cassandra-optimizations-with-apache-spark-3ddf7f81ce43?source=collection_archive---------2-----------------------#2021-02-08">https://itnext.io/cassandra-optimizations-with-apache-spark-3ddf7f81ce43?source=collection_archive---------2-----------------------#2021-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3b2a7b04e9d447767fd7ef077b0cc757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ndJ3V4llkrIvgthf"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">托拜厄斯·菲舍尔在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="9930" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="a5a3" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我将讨论运行<a class="ae kf" href="https://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Cassandra </strong> </a>与<a class="ae kf" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark </strong> </a> <strong class="lg iu">的含义。</strong></p><p id="e389" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">目标是<strong class="lg iu">理解Spark和Cassandra </strong>的内部结构，这样你就可以尽可能高效地编写代码，真正利用这两个伟大工具的力量。</p><p id="13bd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我会给你一些关于用Spark优化Cassandra的提示，这样你就可以最大化性能，最小化成本，T21。我假设你已经对Spark和Cassandra有了基本的了解。</p><p id="83a6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这是我上一篇<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/spark-cassandra-all-you-need-to-know-tips-and-optimizations-d3810cc0bd4e"> <strong class="lg iu">文章</strong> </a>的节选，看完这一篇推荐阅读。</p><h1 id="dead" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">火花四射的卡珊德拉</h1><p id="2aa3" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">要将Spark与Cassandra集成，您需要使用<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark Cassandra连接器</strong> </a>。使用此连接器时，您有两种选择:</p><ul class=""><li id="a5cd" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">使用<strong class="lg iu">低杠杆RDD API </strong>。这提供了更多的灵活性和手动优化代码的能力</li><li id="0302" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">为Spark使用<strong class="lg iu">数据帧或数据集API</strong>。在这种情况下，您可以像使用HDFS和<strong class="lg iu">一样读写数据帧，连接器将在</strong>下进行所有优化。</li></ul><p id="3762" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，我推荐使用<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/data_source_v1.md" rel="noopener ugc nofollow" target="_blank">数据帧/数据集API </a>。这样，您可以利用相同的API，像编写其他系统一样编写Cassandra。你只需要知道你的仓库是卡珊德拉，而不是HDFS。您需要了解如何为Cassandra优化Spark，并在连接器中设置正确的<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md" rel="noopener ugc nofollow" target="_blank">设置</a>。这个我们以后再说。</p><p id="6e2e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要从Cassandra表中读取数据，只需指定不同的格式:"<em class="mv">org . Apache . spark . SQL . Cassandra</em>"</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="cdc0" class="nf kh it nb b gy ng nh l ni nj">val df = spark<br/>  .read<br/>  .format("org.apache.spark.sql.cassandra")<br/>  .options(Map( "table" -&gt; "words", "keyspace" -&gt; "test" ))<br/>  .load()</span></pre><p id="6895" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这将创建一个新的数据帧，它与关键字空间“<em class="mv">测试</em>中的表“<em class="mv">单词</em>”相匹配。</p><p id="4d8c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果你导入"<em class="mv">org . Apache . spark . SQL . Cassandra . _</em>"你可以简单地写:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="67a4" class="nf kh it nb b gy ng nh l ni nj">import org.apache.spark.sql.cassandra._<br/>val df = spark<br/>  .read<br/>  .cassandraFormat("words", "test")<br/>  .load()</span></pre><p id="64ba" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">其中第一个参数是表，第二个参数是键空间。</p><p id="c40f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要将数据框中的数据写入Cassandra表:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="c2a1" class="nf kh it nb b gy ng nh l ni nj">df.write<br/>  .cassandraFormat("words_copy", "test")<br/>  .mode("append")<br/>  .save()</span></pre><p id="d412" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，数据框的方案必须与表方案相匹配。</p><p id="e90f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">就这样，基本上从API perceptive开始，这就是你需要的全部，当然还有一些高级特性，我们将在后面提到。</p><h1 id="7285" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">火花卡珊德拉优化</h1><p id="e3e8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">与Spark Catalyst引擎相同的<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connecto" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Spark Cassandra连接器</strong> </a>，也优化了数据集和数据帧API。因此，提到的一些方法只用于rdd，并且是在使用高级API时自动添加的。</p><p id="37d8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在让我们回顾一下有关Cassandra及其连接器的具体细节…</p><h2 id="4258" class="nf kh it bd ki nk nl dn km nm nn dp kq lp no np ku lt nq nr ky lx ns nt lc nu bi translated">Spark和Cassandra分区</h2><p id="fd48" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们讨论了很多关于Spark分区的内容，如果您在同一个集群中运行Spark和Cassandra，您需要注意一些额外的事情。</p><p id="360f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">最重要的规则是这条:<strong class="lg iu">将Spark分区匹配到Cassandra分区</strong>。第二条规则是:<strong class="lg iu"> Cassandra分区不同于Spark分区:</strong></p><ul class=""><li id="c568" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu"> Cassandra分区:</strong>这些是Cassandra跨节点分割数据并确定您的数据存储在哪个Cassandra节点上的单元。Cassandra分区键是在为Cassandra表定义模式时设置的。每个分区包含在单个节点上(每个副本<em class="mv"/>)。</li><li id="5c70" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu"> Spark分区:</strong>Spark将数据(在内存中)划分给不同的工作线程。Spark分区还决定了Spark在处理数据时可以应用的并行度(每个分区都可以并行处理)。分区的数量和分区键既可以由Spark自动确定，也可以显式设置。</li></ul><p id="093e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">了解这两者之间的区别并编写代码来利用分区是至关重要的。你的目标是拥有正确数量的Spark分区，以允许Spark高效地并行处理计算。</p><p id="4ef6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在许多情况下，会有比Cassandra分区更少的火花分区，因为Cassandra更细粒度；但是在可能的情况下，您希望Cassandra数据从Spark分区所在的Cassandra节点读取和写入。正如我们之前提到的，您还希望有足够多的Spark分区，每个分区都适合可用的executor内存，这样每个分区的每个处理步骤不会运行太长时间，但也不会太多，以至于每个步骤都很小，从而导致过多的开销。正确的数字取决于您的使用情形。在Spark中，特别是在Cassandra中，您必须运行性能和压力测试，并调整这些参数以获得正确的值。一个好的经验法则是每个执行器至少有30个分区。</p><p id="7a54" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">好消息是，在许多情况下，Cassandra连接器会自动为您处理这些问题。当你使用Cassandra Spark连接器时，它会自动创建与Cassandra分区键一致的Spark分区！。这就是为什么在Cassandra中设置正确的分区很重要。Cassandra spark连接器尝试估计表格的大小，并将其除以参数<code class="fe nv nw nx nb b">spark.cassandra.input.split.size_in_mb</code>(默认情况下<em class="mv">64MB</em>)。但是也要记住，有些Spark函数会改变分区的数量。</p><p id="ceea" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当您使用不同的分区键连接Cassandra表或进行多步处理时，您需要小心。请记住，像聚合这样的一些操作会改变分区的数量。因此，在这种情况下，您从一组大小合适的分区开始，但是随后极大地改变了数据的大小，导致分区数量不合适。解决这个问题的一个方法是使用连接器<code class="fe nv nw nx nb b"><strong class="lg iu">repartitionByCassandraReplica</strong>()</code>方法来调整Spark分区的大小和/或重新分配数据。这将重新分配Spark在内存中的数据副本，以匹配指定的Cassandra表的分布，并为每个执行器分配指定数量的Spark分区。</p><p id="2dc3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">连接器还提供了一个有趣的方法来执行连接:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="88f7" class="nf kh it nb b gy ng nh l ni nj">JoinWithCassandraTable()</span></pre><p id="6168" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">它只提取与Cassandra的RDD条目相匹配的分区键，因此它只处理速度更快的分区键。建议您在<em class="mv"> JoinWithCassandraTable </em>之前调用<code class="fe nv nw nx nb b">repartitionByCassandraReplica</code>来获得数据局部性，这样每个spark分区将只需要查询它们的本地节点。</p><p id="1699" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请注意，当您使用数据集或数据帧API时，连接器会在幕后使用这些方法。</p><h2 id="e4b8" class="nf kh it bd ki nk nl dn km nm nn dp kq lp no np ku lt nq nr ky lx ns nt lc nu bi translated">写入设置</h2><p id="4585" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">关于向Cassandra读取和写入数据，我非常推荐观看这个来自<a class="ae kf" href="https://www.youtube.com/channel/UCqA6zOSMpQ55vvguq4Y0jAg" rel="noopener ugc nofollow" target="_blank"> DataStax </a>会议的视频:</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="1819" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在连接器中有许多可以设置的参数<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#write-tuning-parameters" rel="noopener ugc nofollow" target="_blank"/>，但是一般来说，从Spark向Cassandra写入数据有两种方法:</p><ul class=""><li id="4474" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated"><strong class="lg iu">异步发射和锻造</strong> t:这个想法是让许多并行的单次写入异步执行。如果因为没有单独的分区键而不能选择批处理，那么这种方法可以很好地执行。</li><li id="7ae8" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">批处理</strong>:在这种情况下，我们创建批处理。为了实现这一点，我们需要确保通过一个Cassandra键对数据进行分区，这样每一批数据都进入同一个分区，查看视频了解更多细节。</li></ul><p id="13fc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在写入Cassandra之前，您总是可以使用spark <em class="mv"> repartition </em>()方法来实现数据局部性，但是这样做很慢，而且有些矫枉过正，因为Spark Cassandra连接器已经更有效地实现了这一点。<strong class="lg iu">连接器自动以最佳方式为您批量处理数据</strong>。</p><p id="9498" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据经验，如果您不确定某件事，不要去做，让连接器和Spark Catalyst为您优化代码。</p><p id="c7c9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据数据大小和目标表分区，您可能希望对每个作业进行以下设置:</p><ul class=""><li id="0793" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">"<em class="mv">spark . Cassandra . output . batch . grouping . key</em>":Cassandra connector将根据该值对批处理进行分组，默认为partition，因此它将尝试重新分区，以便每个批处理都进入同一个分区，并依次进入同一个节点。您可以将其设置为replica_set。</li><li id="de54" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">"<em class="mv">spark . Cassandra . output . batch . grouping . buffer . size</em>"</strong>:这是司机给你做批处理时的批量大小。这需要根据您的数据大小进行设置。默认值为1000。</li><li id="1ef1" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">"<em class="mv">spark . Cassandra . output . batch . size . row</em>s】:批量大小，以行为单位，它将覆盖以前的属性，默认为auto。</li><li id="afe7" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated"><strong class="lg iu">"<em class="mv">spark . Cassandra . output . concurrent . writes</em></strong>":并发写的次数，这个属性和前面两个成正比，批量越大你想要的并发写越少。通过根据数据大小和分区调整这两个参数，您可以获得最佳性能。</li><li id="af56" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">"<em class="mv">Cassandra . output . throughput _ MB _ per _ sec</em>"(默认值:无限制):每个内核的最大写吞吐量。您需要根据每个执行器的内核数量来设置。默认情况下，Spark会尽可能快地(无限制)写给Cassandra。对于长时间运行的作业来说，这不是很好，因为Cassandra节点将会不堪重负而崩溃。您应该为长时间运行的作业设置一些值。作为一般指导，我们建议从将<em class="mv">Cassandra . output . throughput _ MB _ per _ sec</em>设置为5开始。</li></ul><p id="9b40" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">要使用“解雇并忘记”方法，请将<em class="mv">spark . Cassandra . output . batch . size . row</em>s设置为1，并将<em class="mv">spark . Cassandra . output . concurrent . writes</em><strong class="lg iu"><em class="mv"/></strong>设置为一个大数字。</p><h1 id="9e95" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">读取设置</h1><p id="95e4" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当从Cassandra读取大量数据时，请确保使用正确的分区键对数据进行分区。您可以设置几个<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#read-tuning-parameters" rel="noopener ugc nofollow" target="_blank">属性</a>来提高连接器的读取性能。记住，<strong class="lg iu">读数据调优主要是关于分区的</strong>，我们已经讨论过了。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="oa nz l"/></div></figure><p id="8b45" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">将<em class="mv">spark . Cassandra . concurrent . reads</em>与内核数量相匹配。当从Cassandra读取数据时，由于吞吐量更高，您需要比使用HDFS时更大的每个执行器的内核比率，<strong class="lg iu">尽可能利用Cassandra的优势</strong>。</p><p id="8f20" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">当读取数据时，连接器将根据对spark数据大小的估计来确定分区的大小，如果您想将更多的数据放入Spark，您可以增加"<em class="mv">Spark . Cassandra . input . split . sizeinmb</em>"但是注意不要保存太多的数据，否则会遇到问题。一般来说，您的执行器应该设置为持有<strong class="lg iu"> <em class="mv">个内核*分区大小* 1.2个</em> </strong>以避免内存不足问题或垃圾收集问题。</p><p id="c0ff" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">由于我们已经提到的数据偏斜问题，Cassandra中由大分区引起的热点也会在Spark中引起问题。</p><p id="3cbe" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">还要记住，读取速度主要由Cassandra的分页速度决定，分页速度是使用“<em class="mv">spark . Cassandra . input . fetch . sizeinrows</em>”属性设置的，这意味着在读取当前批处理时将异步请求多少行。</p><p id="c8d3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请关注即将发布的<strong class="lg iu"> </strong> <a class="ae kf" href="https://issues.apache.org/jira/browse/CASSANDRA-9259" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">这款</strong></a><strong class="lg iu">Cassandra新功能</strong>，支持从Cassandra批量读取。</p><h1 id="acea" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">性能测试</h1><p id="c261" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后但同样重要的是，您将不得不花费大量时间来调整所有这些参数。确保您使用的测试数据集在数据大小和形状方面与生产环境相似。您的环境应该是稳定的，测试应该是可重复的。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/8b729c4d0d623d7112532772ece5bff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BS3lif-fQ-XIiVnx.jpg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">火花调谐。来源:https://luminousmen.com/post/spark-tips-dataframe-api</figcaption></figure><p id="c28c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">可以用Spark Cassandra<a class="ae kf" href="https://github.com/datastax/spark-cassandra-stress" rel="noopener ugc nofollow" target="_blank">T3压力工具</a>来测试Cassandra。还要检查连接器暴露的<a class="ae kf" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/11_metrics.md" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">度量</strong> </a>。</p><h1 id="b67b" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="b81d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">记得<strong class="lg iu">重点优化读写设置，最大化并行度</strong>。请记住，设置正确数量的平衡分区非常重要。</p><p id="e3ec" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">此外，遵循<a class="ae kf" href="https://databricks.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> DataBricks </strong> </a>进行Spark更新，遵循<a class="ae kf" href="https://www.datastax.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Datastax </strong> </a>进行Cassandra更新，因为他们是这些技术背后的公司。此外，检查<a class="ae kf" href="https://www.scylladb.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> ScyllaDB </strong> </a>这是卡珊德拉的一个很好的替代。</p><p id="4d67" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu"> <em class="mv">祝您大数据之旅好运！</em> </strong></p><p id="9cb7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果你喜欢这篇文章，记得鼓掌，并关注我的更多更新！</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="29c6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae kf" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"><em class="mv">me</em></strong></a><strong class="lg iu"><em class="mv"/></strong><em class="mv">进行未来岗位。</em></p></div></div>    
</body>
</html>