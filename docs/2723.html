<html>
<head>
<title>EKS GPU Cluster from Zero to Hero</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">EKS GPU集群从零到英雄</h1>
<blockquote>原文：<a href="https://itnext.io/eks-gpu-cluster-from-zero-to-hero-8df92cf720a5?source=collection_archive---------0-----------------------#2019-07-20">https://itnext.io/eks-gpu-cluster-from-zero-to-hero-8df92cf720a5?source=collection_archive---------0-----------------------#2019-07-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/915d2cb93e8fab13bf0f739ad4117ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*stVtdjCQruYUImwypRMNiQ.png"/></div></div></figure><h1 id="6c70" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">介绍</h1><p id="6034" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">如果您曾经尝试在Kubernetes集群上运行GPU工作负载，您会知道这项任务需要一个不小的配置，并且成本很高(GPU实例非常昂贵)。</p><p id="5ee5" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">这篇文章展示了如何以经济高效的方式在Kubernetes集群上运行GPU工作负载，使用了<a class="ae mc" href="https://aws.amazon.com/eks/" rel="noopener ugc nofollow" target="_blank">亚马逊EKS </a>集群、<a class="ae mc" href="https://aws.amazon.com/autoscaling/" rel="noopener ugc nofollow" target="_blank"> AWS自动缩放</a>、<a class="ae mc" href="https://aws.amazon.com/ec2/spot/" rel="noopener ugc nofollow" target="_blank">亚马逊EC2 Spot实例</a>，以及一些Kubernetes资源和配置。</p><h1 id="2add" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">EKS集群计划</h1><p id="a1a7" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">首先，我们需要创建一个由混合节点组成的Kubernetes集群:用于管理和一般Kubernetes工作负载的非GPU节点，以及运行GPU密集型任务(如机器学习、医疗分析、地震勘探、视频转码等)的更昂贵的GPU驱动节点。</p><p id="50d1" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">对于一般节点，这些节点组应该能够按需扩展(向外扩展和向内扩展)，对于昂贵的GPU实例，可以从0扩展到所需的数量，然后再回到0。不仅如此，为了节省成本，我们将对通用节点和GPU节点都使用<a class="ae mc" href="https://aws.amazon.com/ec2/spot/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2 Spot实例</a>。</p><h1 id="5c16" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">AWS EC2 Spot实例</h1><p id="cbc4" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">使用<a class="ae mc" href="https://aws.amazon.com/ec2/spot/" rel="noopener ugc nofollow" target="_blank">Amazon EC2 Spot Instances</a>Instances，与按需价格相比，您可以节省高达90%的费用。以前，Spot实例按出价升序终止。因此，市场价格经常波动。在目前的模型中，现货价格更容易预测，更新频率更低，并且由亚马逊EC2备用容量决定，而不是投标价格。当特定可用性区域中的特定实例没有足够的容量时，AWS EC2服务可以回收Spot实例。当将要被Amazon EC2服务回收时，Spot实例会收到一个2分钟的警报，并且可以使用这个时间进行正常关闭和状态更改。</p><h1 id="72f6" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">工作流程</h1><h1 id="01b1" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">1.创建EKS集群</h1><p id="880a" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">可以使用<a class="ae mc" href="https://docs.aws.amazon.com/cli/latest/reference/eks" rel="noopener ugc nofollow" target="_blank">亚马逊EKS CLI </a>、CloudFormation或Terraform、<a class="ae mc" href="https://aws.amazon.com/cdk/" rel="noopener ugc nofollow" target="_blank"> AWS CDK </a>或<a class="ae mc" href="https://eksctl.io" rel="noopener ugc nofollow" target="_blank"> eksctl </a>创建<a class="ae mc" href="https://aws.amazon.com/eks/" rel="noopener ugc nofollow" target="_blank">亚马逊EKS </a>集群。</p><h2 id="22c2" class="md kc it bd kd me mf dn kh mg mh dp kl lk mi mj kp lo mk ml kt ls mm mn kx mo bi translated">eksctl CLI工具</h2><p id="1e67" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">本文使用了<code class="fe mp mq mr ms b">eksctl</code>(在EKS上创建集群的CLI工具)。可以将所有参数作为CLI标志或配置文件传递给该工具。使用配置文件使过程更加可重复和自动化友好。</p><p id="9cdd" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated"><code class="fe mp mq mr ms b">eksctl</code>可以使用CloudFormation堆栈创建或更新EKS集群和其他所需的AWS资源。</p><p id="6b76" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">使用配置文件自定义您的集群。快跑吧</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="24ff" class="md kc it ms b gy nb nc l nd ne">eksctl create cluster -f cluster.yaml</span></pre><p id="e88a" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">要应用<code class="fe mp mq mr ms b">cluster.yaml</code>文件:</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="c464" class="md kc it ms b gy nb nc l nd ne">apiVersion: eksctl.io/v1alpha5 <br/>kind: ClusterConfig</span><span id="0897" class="md kc it ms b gy nf nc l nd ne">metadata: <br/>  name: test-cluster<br/>  region: us-west-2</span><span id="1984" class="md kc it ms b gy nf nc l nd ne">nodeGroups: <br/>  - name: ng<br/>    instanceType: t3.micro<br/>    desiredCapacity: 10</span></pre><p id="1ee2" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">将创建一个具有10个<code class="fe mp mq mr ms b">t3.micro</code>按需EC2工作节点的新EKS集群，并将集群凭证添加到<code class="fe mp mq mr ms b">~/.kube/config</code>文件中。</p><h1 id="a3f8" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">2.创建节点组</h1><p id="820f" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">按照计划，我们将为Kubernetes工作节点创建两个节点组:</p><ol class=""><li id="21a3" class="ng nh it lb b lc lx lg ly lk ni lo nj ls nk lw nl nm nn no bi translated"><em class="np">常规</em>节点组—使用Spot实例运行Kubernetes系统工作负载和非GPU工作负载的自动扩展组</li><li id="276b" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nl nm nn no bi translated"><em class="np"> GPU </em>节点组——具有GPU支持的Spot实例的自动扩展组，可以从0扩展到所需的实例数，然后返回到0。</li></ol><p id="7d9e" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">幸运的是，<code class="fe mp mq mr ms b">eksctl</code>支持向EKS集群添加Kubernetes节点组，这些节点组可以由纯Spot实例或者Spot和按需实例的混合组成。</p><h2 id="d549" class="md kc it bd kd me mf dn kh mg mh dp kl lk mi mj kp lo mk ml kt ls mm mn kx mo bi translated">2.1常规节点组</h2><p id="23c5" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated"><code class="fe mp mq mr ms b">eksctl</code>配置文件包含跨越3个可用性区域的<code class="fe mp mq mr ms b">us-west-2</code>中的EKS集群和在多样化的Spot实例上运行的第一个<em class="np">通用</em>自动扩展(从2个节点到20个节点)节点组。</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="90bd" class="md kc it ms b gy nb nc l nd ne">---<br/>apiVersion: eksctl.io/v1alpha5<br/>kind: ClusterConfig</span><span id="786c" class="md kc it ms b gy nf nc l nd ne">metadata:<br/>  name: gaia-kube<br/>  region: us-west-2</span><span id="4268" class="md kc it ms b gy nf nc l nd ne">availabilityZones: ["us-west-2a", "us-west-2b", "us-west-2c"]</span><span id="d74c" class="md kc it ms b gy nf nc l nd ne">nodeGroups:<br/>  # spot workers NG - multi AZ, scale from 3<br/>  - name: spot-ng<br/>    ami: auto<br/>    instanceType: mixed<br/>    desiredCapacity: 2<br/>    minSize: 2<br/>    maxSize: 20<br/>    volumeSize: 100<br/>    volumeType: gp2<br/>    volumeEncrypted: true<br/>    iam:<br/>      attachPolicyARNs:<br/>        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM<br/>        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy<br/>        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy<br/>        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly<br/>      withAddonPolicies:<br/>        autoScaler: true<br/>        ebs: true<br/>        albIngress: true<br/>        cloudWatch: true<br/>    instancesDistribution:<br/>      onDemandPercentageAboveBaseCapacity: 0<br/>      instanceTypes:<br/>        - m4.2xlarge<br/>        - m4.4xlarge<br/>        - m5.2xlarge<br/>        - m5.4xlarge<br/>        - m5a.2xlarge<br/>        - m5a.4xlarge<br/>        - c4.2xlarge<br/>        - c4.4xlarge<br/>        - c5.2xlarge<br/>        - c5.4xlarge<br/>      spotInstancePools: 15<br/>    tags:<br/>      k8s.io/cluster-autoscaler/enabled: 'true'<br/>    labels:<br/>      lifecycle: Ec2Spot<br/>    privateNetworking: true<br/>    availabilityZones: ["us-west-2a", "us-west-2b", "us-west-2c"]</span><span id="c100" class="md kc it ms b gy nf nc l nd ne"># next: GPU node groups ...</span></pre><p id="4ea7" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">现在是解释上面配置文件中使用的一些参数的时候了。</p><ul class=""><li id="44b8" class="ng nh it lb b lc lx lg ly lk ni lo nj ls nk lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">ami: auto</code> - <code class="fe mp mq mr ms b">eksctl</code>根据指定的AWS区域、EKS版本和实例类型，自动发现工作节点的最新EKS优化AMI映像。参见用户指南中的<a class="ae mc" href="https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html" rel="noopener ugc nofollow" target="_blank">亚马逊EKS优化AMI </a>章节</li><li id="d851" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">instanceType: mixed</code> -指定实际实例类型将是<code class="fe mp mq mr ms b">instancesDistribution</code>部分中定义的实例类型之一</li><li id="b41c" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">iam</code>包含预定义的和适当的IAM策略列表；<code class="fe mp mq mr ms b">eksctl</code>使用指定的策略创建一个新的<a class="ae mc" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html" rel="noopener ugc nofollow" target="_blank"> IAM角色</a>，并将该角色附加到每个EKS工作节点。您需要将几个IAM策略附加到每个EKS工作节点，请阅读用户指南中的<a class="ae mc" href="https://docs.aws.amazon.com/eks/latest/userguide/worker_node_IAM_role.html" rel="noopener ugc nofollow" target="_blank">亚马逊EKS工作节点IAM角色</a>部分和<code class="fe mp mq mr ms b"><a class="ae mc" href="https://eksctl.io/usage/iam-policies/" rel="noopener ugc nofollow" target="_blank">eksctl</a></code>IAM策略文档</li><li id="63af" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">instancesDistribution</code> -为EC2自动缩放组指定混合实例策略，阅读AWS<a class="ae mc" href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_MixedInstancesPolicy.html" rel="noopener ugc nofollow" target="_blank">MixedInstancesPolicy</a>文档</li><li id="e59f" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">spotInstancePools</code> -指定要使用的Spot实例池的数量，<a class="ae mc" href="https://alexei-led.github.io/post/eks_gpu_spot/#Spot-Instance-Pools" rel="noopener ugc nofollow" target="_blank">阅读更多信息</a></li><li id="fb0d" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">tags</code> - AWS标签添加到EKS工人节点</li><li id="6380" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">k8s.io/cluster-autoscaler/enabled</code>将使用此标签进行Kubernetes集群自动缩放自动发现</li><li id="716d" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">privateNetworking: true</code> -所有EKS工作节点将被置于专用子网中</li></ul><p id="56cd" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated"><strong class="lb iu">现货实例池</strong></p><p id="670a" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">当您使用Spot实例作为工作节点时，您需要将使用分散到尽可能多的<em class="np"> Spot实例池</em>。一个<em class="np"> Spot实例池</em>是一组未使用的EC2实例，它们具有相同的实例类型(例如<code class="fe mp mq mr ms b">m5.large</code>)、操作系统、可用性区域和网络平台。</p><p id="b1c0" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated"><code class="fe mp mq mr ms b">eksctl</code>目前支持单点配置模式:<code class="fe mp mq mr ms b">lowestPrice</code>分配策略。这种策略允许创建一个既便宜又多样化的Spot实例群。ASG会根据您指定的现货池数量中的当前现货价格，自动部署最便宜的实例类型和可用性区域组合。这种组合可以避免最昂贵的Spot实例。</p><p id="d196" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">Spot实例多样化还增加了工作节点的可用性，通常不是所有的<em class="np"> Spot实例池</em>都会同时中断，因此只有一小部分工作负载会被中断，EC2自动伸缩组将替换其他<em class="np"> Spot实例池</em>中被中断的实例。</p><p id="fdc5" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">另外，请考虑为数据集、培训进度(检查点)和日志使用专用卷。该卷应该是持久的，不受实例终止的影响。</p><h2 id="50f3" class="md kc it bd kd me mf dn kh mg mh dp kl lk mi mj kp lo mk ml kt ls mm mn kx mo bi translated">2.2 GPU驱动的节点组</h2><p id="7ea7" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我们的<code class="fe mp mq mr ms b">eksctl</code>配置文件的下一部分包含第一个<em class="np"> GPU </em>自动缩放(从<code class="fe mp mq mr ms b">0</code>到<code class="fe mp mq mr ms b">10</code>节点)节点组，该节点组运行在各种GPU支持的Spot实例上。</p><p id="912a" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">当使用GPU支持的Spot实例时，建议为每个可用性区域创建<em class="np"> GPU </em>节点组，并配置Kubernetes集群自动缩放器，以避免自动<a class="ae mc" href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html#arch-AutoScalingMultiAZ" rel="noopener ugc nofollow" target="_blank"> ASG重新平衡</a>。</p><p id="2df9" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">为什么重要？一些GPU驱动的EC2 Spot实例具有相对较高的<em class="np">中断频率</em>率(对于某些GPU实例类型为<code class="fe mp mq mr ms b">&gt;20%</code>);检查<a class="ae mc" href="https://aws.amazon.com/ec2/spot/instance-advisor/" rel="noopener ugc nofollow" target="_blank"> Spot Instance Advisor </a>，使用多个AZ并禁用自动集群自动缩放器平衡有助于最大限度地减少GPU工作负载中断。</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="cbb0" class="md kc it ms b gy nb nc l nd ne"># ... EKS cluster and General node group ...</span><span id="ceaa" class="md kc it ms b gy nf nc l nd ne"># spot GPU NG - west-2a AZ, scale from 0<br/>  - name: gpu-spot-ng-a<br/>    ami: auto<br/>    instanceType: mixed<br/>    desiredCapacity: 0<br/>    minSize: 0<br/>    maxSize: 10<br/>    volumeSize: 100<br/>    volumeType: gp2<br/>    volumeEncrypted: true<br/>    iam:<br/>      attachPolicyARNs:<br/>        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM<br/>        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy<br/>        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy<br/>        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly<br/>      withAddonPolicies:<br/>        autoScaler: true<br/>        ebs: true<br/>        fsx: true<br/>        efs: true<br/>        albIngress: true<br/>        cloudWatch: true<br/>    instancesDistribution:<br/>      onDemandPercentageAboveBaseCapacity: 0<br/>      instanceTypes:<br/>        - p3.2xlarge<br/>        - p3.8xlarge<br/>        - p3.16xlarge<br/>        - p2.xlarge<br/>        - p2.8xlarge<br/>        - p2.16xlarge<br/>      spotInstancePools: 5<br/>    tags:<br/>      k8s.io/cluster-autoscaler/node-template/taint/dedicated: nvidia.com/gpu=true<br/>      k8s.io/cluster-autoscaler/node-template/label/nvidia.com/gpu: 'true'<br/>      k8s.io/cluster-autoscaler/enabled: 'true'<br/>    labels:<br/>      lifecycle: Ec2Spot<br/>      nvidia.com/gpu: 'true'<br/>      k8s.amazonaws.com/accelerator: nvidia-tesla<br/>    taints:<br/>      nvidia.com/gpu: "true:NoSchedule"<br/>    privateNetworking: true<br/>    availabilityZones: ["us-west-2a"]</span><span id="5f64" class="md kc it ms b gy nf nc l nd ne"># create additional node groups for `us-west-2b` and `us-west-2c` availability zones ...</span></pre><p id="ffb4" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">现在，是时候解释一些用于配置GPU驱动的节点组的参数了。</p><ul class=""><li id="0d11" class="ng nh it lb b lc lx lg ly lk ni lo nj ls nk lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">ami: auto</code> - <code class="fe mp mq mr ms b">eksctl</code>根据指定的AWS地区、EKS版本和实例类型，自动发现最新的EKS优化的AMI映像，支持工作节点的GPU。参见<a class="ae mc" href="https://docs.aws.amazon.com/eks/latest/userguide/gpu-ami.html" rel="noopener ugc nofollow" target="_blank">支持GPU的亚马逊EKS优化AMI</a>用户指南</li><li id="2933" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">iam: withAddonPolicies</code> -如果计划的工作负载需要访问AWS存储服务，则必须包含额外的IAM策略(由<code class="fe mp mq mr ms b">eksctl</code>自动生成)</li><li id="4d40" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">tags</code> - AWS标签添加到EKS工人节点</li><li id="83b0" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">k8s.io/cluster-autoscaler/node-template/taint/dedicated: nvidia.com/gpu=true</code> - Kubernetes节点污染</li><li id="6e9b" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">k8s.io/cluster-autoscaler/node-template/label/nvidia.com/gpu: 'true'</code> -集群自动缩放器使用的Kubernetes节点标签，用于将ASG从/缩放到0</li><li id="cefc" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">nvidia.com/gpu: “true:NoSchedule”</code> — Kubernetes GPU节点污点；有助于避免在昂贵的GPU节点上放置非GPU工作负载</li></ul><p id="e3d4" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated"><strong class="lb iu">支持GPU的EKS优化AMI图像</strong></p><p id="8050" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">除了标准的亚马逊EKS优化AMI配置，GPU AMI还包括以下内容:</p><ul class=""><li id="9a0e" class="ng nh it lb b lc lx lg ly lk ni lo nj ls nk lw nv nm nn no bi translated">NVIDIA驱动程序</li><li id="0b08" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">nvidia-docker2</code>套餐</li><li id="09e7" class="ng nh it lb b lc nq lg nr lk ns lo nt ls nu lw nv nm nn no bi translated"><code class="fe mp mq mr ms b">nvidia-container-runtime</code>(作为默认运行时)</li></ul><p id="b01c" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">将节点组缩放到0或从0开始缩放</p><p id="1333" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">来自Kubernetes<a class="ae mc" href="https://github.com/kubernetes/autoscaler/" rel="noopener ugc nofollow" target="_blank">Cluster auto scaler</a>0 . 6 . 1—假设满足所有向上和向下扩展的条件，可以将节点组扩展到0或从0扩展。</p><p id="4463" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">如果你使用的是<code class="fe mp mq mr ms b">nodeSelector</code>，你需要用节点模板键<code class="fe mp mq mr ms b">k8s.io/cluster-autoscaler/node-template/label/</code>和<code class="fe mp mq mr ms b">k8s.io/cluster-autoscaler/node-template/taint/</code>标记ASG，如果你使用的是污点。</p><h1 id="15c9" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">3.调度GPU工作负载</h1><h2 id="393f" class="md kc it bd kd me mf dn kh mg mh dp kl lk mi mj kp lo mk ml kt ls mm mn kx mo bi translated">3.1基于GPU资源的调度</h2><p id="b3f5" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">用于Kubernetes的NVIDIA设备插件<a class="ae mc" href="https://github.com/NVIDIA/k8s-device-plugin" rel="noopener ugc nofollow" target="_blank">显示了集群中每个节点上的GPU数量。一旦安装了插件，就可以在GPU节点上使用<code class="fe mp mq mr ms b">nvidia/gpu</code> Kubernetes资源并用于Kubernetes工作负载。</a></p><p id="dca3" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">运行此命令，使用<code class="fe mp mq mr ms b">tolerations</code>和<code class="fe mp mq mr ms b">nodeAffinity</code>将Nvidia Kubernetes设备插件作为<code class="fe mp mq mr ms b">daemonset</code>应用于仅在AWS GPU驱动的工作节点上运行</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="a908" class="md kc it ms b gy nb nc l nd ne">kubectl create -f kubernetes/nvidia-device-plugin.yaml</span><span id="ada0" class="md kc it ms b gy nf nc l nd ne">kubectl get daemonset -nkube-system</span></pre><p id="6431" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">使用<code class="fe mp mq mr ms b">nvidia-device-plugin.yaml</code> Kubernetes资源文件</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="af7a" class="md kc it ms b gy nb nc l nd ne">apiVersion: extensions/v1beta1<br/>kind: DaemonSet<br/>metadata:<br/>  name: nvidia-device-plugin-daemonset-1.12<br/>  namespace: kube-system<br/>spec:<br/>  updateStrategy:<br/>    type: RollingUpdate<br/>  template:<br/>    metadata:<br/>      labels:<br/>        name: nvidia-device-plugin-ds<br/>    spec:<br/>      tolerations:<br/>      - key: nvidia.com/gpu<br/>        operator: Exists<br/>        effect: NoSchedule<br/>      containers:<br/>      - image: nvidia/k8s-device-plugin:1.11<br/>        name: nvidia-device-plugin-ctr<br/>        securityContext:<br/>          allowPrivilegeEscalation: false<br/>          capabilities:<br/>            drop: ["ALL"]<br/>        volumeMounts:<br/>          - name: device-plugin<br/>            mountPath: /var/lib/kubelet/device-plugins<br/>      volumes:<br/>        - name: device-plugin<br/>          hostPath:<br/>            path: /var/lib/kubelet/device-plugins<br/>      affinity:<br/>        nodeAffinity:<br/>          requiredDuringSchedulingIgnoredDuringExecution:<br/>            nodeSelectorTerms:<br/>            - matchExpressions:<br/>              - key: beta.kubernetes.io/instance-type<br/>                operator: In<br/>                values:<br/>                - p3.2xlarge<br/>                - p3.8xlarge<br/>                - p3.16xlarge<br/>                - p3dn.24xlarge<br/>                - p2.xlarge<br/>                - p2.8xlarge<br/>                - p2.16xlarge</span></pre><h2 id="40b8" class="md kc it bd kd me mf dn kh mg mh dp kl lk mi mj kp lo mk ml kt ls mm mn kx mo bi translated">3.2污点和容忍</h2><p id="f1a7" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">Kubernetes <em class="np">污点</em>允许一个节点击退一组豆荚。污染和容忍一起工作，以确保pod不会被安排到不适当的节点上。一个或多个污点被应用到一个节点；这标志着节点不应该接受任何不容忍污染的pod。容忍适用于pod，并允许(但不要求)pod调度到具有匹配污点的节点上。</p><p id="e0fd" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">更多细节见Kubernetes <a class="ae mc" href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" rel="noopener ugc nofollow" target="_blank">污染和容忍</a>文档。</p><p id="9ee8" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">要在GPU支持的Spot实例节点上运行GPU工作负载，带有<code class="fe mp mq mr ms b">nvidia.com/gpu: "true:NoSchedule"</code>污点，工作负载必须包括匹配的<code class="fe mp mq mr ms b">tolerations</code>和<code class="fe mp mq mr ms b">nodeSelector</code>配置。</p><p id="3bf2" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">Kubernetes部署带有限制为<code class="fe mp mq mr ms b">nvidia/gpu: 1</code>的<code class="fe mp mq mr ms b">10</code> pod副本:</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="b7e7" class="md kc it ms b gy nb nc l nd ne">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: cuda-vector-add<br/>  labels:<br/>    app: cuda-vector-add<br/>spec:<br/>  replicas: 10<br/>  selector:<br/>    matchLabels:<br/>      app: cuda-vector-add<br/>  template:<br/>    metadata:<br/>      name: cuda-vector-add<br/>      labels:<br/>        app: cuda-vector-add<br/>    spec:<br/>      nodeSelector:<br/>        nvidia.com/gpu: "true"<br/>      tolerations:<br/>      - key: "nvidia.com/gpu"<br/>        operator: "Exists"<br/>        effect: "NoSchedule"<br/>      containers:<br/>        - name: cuda-vector-add<br/>          image: "k8s.gcr.io/cuda-vector-add:v0.1"<br/>          resources:<br/>            limits:<br/>              nvidia.com/gpu: 1 # requesting 1 GPU</span></pre><p id="6028" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">部署<code class="fe mp mq mr ms b">cuda-vector-add</code>部署，看看新的GPU驱动的节点是如何添加到EKS集群的。</p><pre class="mt mu mv mw gt mx ms my mz aw na bi"><span id="dd1c" class="md kc it ms b gy nb nc l nd ne"># list Kubernetes nodes before running GPU workload<br/>kubectl get nodes --output="custom-<br/>columns=NAME:.metadata.name,TYPE:.metadata.labels.beta\.kubernetes\.io\/instance-type"</span><span id="5df1" class="md kc it ms b gy nf nc l nd ne">NAME                                            TYPE<br/>ip-192-168-151-104.us-west-2.compute.internal   c4.4xlarge<br/>ip-192-168-171-140.us-west-2.compute.internal   c4.4xlarge</span><span id="12b8" class="md kc it ms b gy nf nc l nd ne"># deploy GPU workload on EKS cluster with tolerations for nvidia/gpu=true<br/>kubectl create -f kubernetes/examples/vector/vector-add-dpl.yaml</span><span id="99bc" class="md kc it ms b gy nf nc l nd ne"># list Kubernetes nodes after several minutes to see new GPU nodes added to the cluster<br/>kubectl get nodes --output="custom-columns=NAME:.metadata.name,TYPE:.metadata.labels.beta\.kubernetes\.io\/instance-type"</span><span id="9fee" class="md kc it ms b gy nf nc l nd ne">NAME                                            TYPE<br/>ip-192-168-101-60.us-west-2.compute.internal    p2.16xlarge<br/>ip-192-168-139-227.us-west-2.compute.internal   p2.16xlarge<br/>ip-192-168-151-104.us-west-2.compute.internal   c4.4xlarge<br/>ip-192-168-171-140.us-west-2.compute.internal   c4.4xlarge<br/>ip-192-168-179-248.us-west-2.compute.internal   p2.16xlarge</span></pre><p id="e0f3" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated">正如您所看到的，3个新的GPU驱动的节点(<code class="fe mp mq mr ms b">p2.16xlarge</code>)，跨3个AZ，被添加到集群中。当您删除GPU工作负载时，群集将在10分钟后将GPU节点组缩减为0。</p><h1 id="2f4c" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">摘要</h1><p id="314f" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">按照本教程创建一个EKS (Kubernetes)集群，该集群具有GPU支持的节点组，在Spot实例上运行，可从/向0节点扩展。</p><h1 id="895d" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">参考</h1><p id="47a0" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">- <a class="ae mc" href="https://github.com/alexei-led/eks-spot-cluster" rel="noopener ugc nofollow" target="_blank"> EKS Spot集群</a> GitHub存储库，包含本博客的代码<br/> - <a class="ae mc" rel="noopener ugc nofollow" target="_blank" href="/the-definitive-guide-to-running-ec2-spot-instances-as-kubernetes-worker-nodes-68ef2095e767">运行EC2 Spot实例作为Kubernetes工作节点的权威指南</a>作者Ran shein Berg<br/>-<a class="ae mc" href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler" rel="noopener ugc nofollow" target="_blank">Kubernetes集群自动缩放器</a>-<br/>-<a class="ae mc" href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" rel="noopener ugc nofollow" target="_blank">污点和容忍</a> Kubernetes文档</p><h1 id="f9f4" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">放弃</h1><p id="85fd" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我在哪里工作并不重要，我所有的意见都是我自己的。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="7e1f" class="pw-post-body-paragraph kz la it lb b lc lx le lf lg ly li lj lk lz lm ln lo ma lq lr ls mb lu lv lw im bi translated"><em class="np">草稿发布于</em><a class="ae mc" href="https://alexei-led.github.io/post/eks_gpu_spot/" rel="noopener ugc nofollow" target="_blank"><em class="np">https://Alexei-led . github . io</em></a><em class="np">。</em></p></div></div>    
</body>
</html>