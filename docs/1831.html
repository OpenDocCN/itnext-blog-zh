<html>
<head>
<title>Kubernetes Ingress Controllers: How to choose the right one: Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes入口控制器:如何选择正确的控制器:第1部分</h1>
<blockquote>原文：<a href="https://itnext.io/kubernetes-ingress-controllers-how-to-choose-the-right-one-part-1-41d3554978d2?source=collection_archive---------0-----------------------#2019-02-08">https://itnext.io/kubernetes-ingress-controllers-how-to-choose-the-right-one-part-1-41d3554978d2?source=collection_archive---------0-----------------------#2019-02-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d716" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将分享我使用3种主要Kubernetes ingress解决方案的经验。让我们来看看它们的优缺点，找出哪一个适合你的需求。</p><h1 id="3033" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak"> Nginx入口控制器</strong></h1><h2 id="08df" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">它在幕后是如何工作的？</h2><p id="4b27" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">首先，让我们部署一个hello-world服务，其中有2个Pods运行在demo名称空间中。接下来，我们应用hello-world入口资源文件，如下所示。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1b44" class="lj km iq mf b gy mj mk l ml mm">apiVersion: extensions/v1beta1<br/>kind: Ingress<br/>metadata:<br/>  name: hello-world<br/>spec:<br/>  rules:<br/>  - http:<br/>      paths:<br/>      - path: /api/hello-world<br/>        backend:<br/>          serviceName: hello-world<br/>          servicePort: 80</span></pre><p id="18e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来看看当一个ingress资源被部署时，Ingress控制器是如何将其翻译成Nginx配置的？<br/>对于API路径<code class="fe mn mo mp mf b">/api/hello-world,</code>,通过下面的<a class="ae mq" href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream" rel="noopener ugc nofollow" target="_blank">上游</a>指令，它会将传入流量路由到服务<code class="fe mn mo mp mf b">hello-world</code>,该服务在名称空间<code class="fe mn mo mp mf b">demo</code>中的容器端口8080上有2个目的地Pod IPs。很简单，对吧？它与我们的<a class="ae mq" href="https://medium.com/@ericyuliu/kubernetes-network-deep-dive-7492341e0ab5" rel="noopener"> iptables或ipvs路由表</a>非常相似。</p><figure class="ma mb mc md gt mr"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="ca54" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak"> Nginx Ingress依靠传统的负载均衡器(ELB) </strong></h2><p id="2019" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">Nginx ingress控制器可以部署在任何地方，在AWS中初始化时，会创建一个经典的ELB，将Nginx Ingress控制器暴露在一个<code class="fe mn mo mp mf b">Type=LoadBalancer</code>的服务后面。对于一些人来说，这可能是一个问题，因为ELB被认为是一项遗留技术，AWS建议将现有的ELB迁移到网络负载平衡器(NLB)。但是，在正常的交通量下，这对于我们来说从来都不是问题。<br/>如果NLB是您的集群中的首选，好消息是:从1.10.0版开始，它就作为ALPHA特性受到支持，如下所示。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="53a7" class="lj km iq mf b gy mj mk l ml mm">annotations:    <br/>  # by default the type is elb<br/>  service.beta.kubernetes.io/aws-load-balancer-type: nlb</span></pre><h2 id="4caa" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">支持分布式入口变化</strong></h2><p id="425e" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在微服务环境中，应用程序一直在创建或停用。包含所有入口规则、主机和路径的集中式路由文件变得更难由所有微服务团队共享和维护。我们听说优步在KubeCon 2018的一个会议上有4000个微服务。想象一下，对于每一个环境，你都必须使用一个巨大的配置文件来管理数以千计的入口规则。对于需要协作的团队来说，这听起来像是一场噩梦。</p><p id="bccc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不仅需要专用管道来保持它们在所有环境中的部署和同步。竞争条件可能是另一个潜在的问题。此外，我们(DevOps)不希望与这些单片路由配置斗争，成为开发团队频繁变更的瓶颈。每个微服务开发团队最好拥有自己的入口，并能够根据自己的喜好进行更改。因此，对于每个应用程序舵图，我们在templates文件夹下添加一个ingress.yaml，这些路由规则可以与应用程序代码一起部署或推广到不同的环境，无需任何干预。</p><p id="3071" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们认为可能发生的一个潜在问题是，不同的应用程序入口规则可能在API名称空间上相互冲突。然而，在真实的开发周期中，人们总是检查所有现有API的<a class="ae mq" href="https://swagger.io/tools/" rel="noopener ugc nofollow" target="_blank"> swagger </a>，进行代码审查和编写测试自动化。这种潜在的API冲突永远不会成为真正的问题。</p><h2 id="fbc3" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">不要使用没有定义范围的Nginx入口</strong></h2><p id="51c7" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">开始时，人们倾向于创建一个带有默认值的入口控制器，并开始尝试一些东西，例如部署仪表板或迁移一些应用程序。这很常见，我们也是这么做的。一开始，一切都很顺利，我们不断向我们的Kubernetes集群添加新的环境。直到突然，我们遇到了第一个路由问题。在这个onboarding environments过程中，Nginx配置迅速增长到20万行，并开始出现配置重载问题。<br/>我们仔细查看了<a class="ae mq" href="https://github.com/helm/charts/tree/master/stable/nginx-ingress" rel="noopener ugc nofollow" target="_blank"> Nginx入口控制器舵图</a>，它有以下设置:</p><ul class=""><li id="d9a3" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated"><code class="fe mn mo mp mf b">controller.scope.enabled</code>:默认为false，监视所有名称空间</li><li id="99e0" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><code class="fe mn mo mp mf b">controller.scope.namespace</code>监视入口的名称空间，默认为空</li></ul><p id="2c58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着，默认情况下，每个入口控制器将侦听来自所有名称空间的所有入口事件，并将相应的指令和规则添加到Nginx配置文件中。</p><p id="9e5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们再看一下入口控制器的部署，如下所示。注意，当图表被部署时，这些设置被转换成一个名为<code class="fe mn mo mp mf b">--watch-namespace.</code>的容器参数，这可能会派上用场，并在调试过程中为您节省一些时间。(一致的命名约定很难。)</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0edc" class="lj km iq mf b gy mj mk l ml mm">kgd demo-nginx-ingress-controller -o yaml<br/># Less Typing?  <a class="ae mq" rel="noopener ugc nofollow" target="_blank" href="/pimp-my-kubernetes-shell-f144710232a0">Cuz I pimp my k8s shell!</a></span><span id="dfef" class="lj km iq mf b gy ni mk l ml mm">...<br/>containers:<br/>      - args:<br/>        - /nginx-ingress-controller<br/>        - --election-id=ingress-controller-leader<br/>        - --ingress-class=nginx<br/>        - --configmap=demo/demo-nginx-ingress-controller<br/>        - --watch-namespace=demo</span></pre><h2 id="4016" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">多个环境不共享Nginx入口</strong></h2><p id="2625" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在30多个环境中滥用共享入口控制器后，Nginx配置文件变得非常庞大，重新加载非常缓慢。POD IPs变得陈旧，我们开始看到5xx个错误。继续扩大相同的入口控制器部署似乎无法解决问题。<br/>从那时起，我们开始为每个环境使用专用的入口控制器。此外，该解决方案还有额外的优势:</p><ul class=""><li id="20c6" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated">对每个Nginx入口服务的粒度访问控制，定制的AWS安全组可以应用于每个入口ELB。</li><li id="cdfe" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">为特殊环境调整配置，例如混沌测试和性能测试。这些设置管理起来更灵活，也更便于我们尝试。</li></ul><h2 id="3a82" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">调整工作进程和内存设置</strong></h2><p id="ccee" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">Nginx有一个默认设置<code class="fe mn mo mp mf b"><strong class="jp ir">worker_processes</strong> <strong class="jp ir">auto</strong></code>，这意味着<br/>工作进程号与主机VM上的CPU内核数量相同。<br/>注意到我提到了主机虚拟机而不是容器资源吗？这是因为Nginx不支持CPU-cgroup，入口控制器将忽略以下两个约束:</p><ul class=""><li id="d063" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated"><code class="fe mn mo mp mf b"><strong class="jp ir">spec.containers[].resources.limits.cpu</strong></code></li><li id="97d6" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><code class="fe mn mo mp mf b"><strong class="jp ir">spec.containers[].resources.requests.cpu</strong></code></li></ul><p id="340d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们将集群虚拟机节点从M4 . XL large(4个vCPU核心)升级到C5.4xlarge(16个vCPU核心)时，在持续的入口更改过程中，我们的入口控制器pod突然开始出现故障。登录pod并检查<code class="fe mn mo mp mf b">/etc/nginx/nginx.conf</code>后，我们发现每个入口控制器pod有16个工作进程，而不是4个。当频繁的入口变化发生时，nginx会不断地重新加载所有16个工作进程的配置，很快它就会消耗掉我们为pod分配的所有内存，并使它们OOM-killed。<br/>然而，有几个解决这个问题的方法:</p><ul class=""><li id="a633" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated">为pod中的Nginx容器分配更多内存。</li><li id="b01c" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">使用Pod Affinity将入口控制器部署到CPU内核较少的虚拟机。</li><li id="d749" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">通过<a class="ae mq" href="https://github.com/helm/charts/blob/master/stable/nginx-ingress/values.yaml#L13" rel="noopener ugc nofollow" target="_blank">舵图配置</a>调整worker_process号</li></ul><p id="2054" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于第一个解决方案，在我们的负载测试中，当部署在具有16个CPU核心的C5.4xlarge上时，Nginx容器启动了16个工作进程。凭借1G内存(从500M增加)，它可以无故障地处理负载。</p><h1 id="9064" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak"> AWS ALB入口控制器</strong></h1><p id="6e6a" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">AWS应用负载平衡器(ALB)是一种流行且成熟的服务，用于对应用层(L7)上的流量进行负载平衡。支持基于路径和基于主机的路由规则。自从AWS服务推出以来，我们一直在利用它。在Kubernetes Ingress控制器的早期评估阶段，<a class="ae mq" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller" rel="noopener ugc nofollow" target="_blank"> AWS ALB Ingress控制器</a>是我的首选。然而，在那个时候，这个开源项目还没有捐赠给Kubernetes SIG-AWS，也没有得到AWS的官方支持。我们的需求缺少一些关键功能。最近，我们决定再试一次，发现一些功能非常有前途。</p><h2 id="5ac0" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">使用原生支持L7路由</strong>的AWS ALB</h2><p id="1a86" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">AWS ALB本地支持应用层路由，每个<em class="nj">目标组</em>代表一个Kubernetes服务，并以IP模式将传入的请求路由到该服务的pod所在的工作节点(我将在后面详细解释)。<br/>这将所有运营维护以及可扩展性和可用性问题转移给了AWS，因为它是一项完全托管的服务。此外，没有必要钻研Nginx，成为专家来解决所有问题。</p><figure class="ma mb mc md gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/9f61701907ee982590a4f2274eb8bd03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1op8p9s7DwlnghrE"/></div></div></figure><p id="3dc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了ALB的原生L7路由之外，AWS还不断为该服务添加新功能，有几个功能对我们非常有益:</p><ul class=""><li id="a3c1" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated"><a class="ae mq" href="https://aws.amazon.com/waf/" rel="noopener ugc nofollow" target="_blank"> AWS Web应用防火墙(WAF) </a>集成支持(WAF太棒了，少了一个需要维护的主要基础设施，耶！)</li><li id="1e1a" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">本机将不安全的HTTP请求重定向到HTTPS请求(我知道，对吗？)</li><li id="fffa" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">支持不转发到应用程序的固定响应(不是花哨的404页面，但很接近！)</li><li id="3eee" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://aws.amazon.com/blogs/aws/built-in-authentication-in-alb/" rel="noopener ugc nofollow" target="_blank">ALB上的认证</a> : OIDC、脸书、Google Auth、AWS Cognito</li></ul><p id="876b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当您开始在您的环境中保护和生产Kubernetes Ingress控制器时，这些功能会非常方便。</p><h2 id="fe20" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">要求在一个地方定义所有入口资源</strong></h2><p id="3461" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在<a class="ae mq" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller" rel="noopener ugc nofollow" target="_blank">当前版本</a>中，当ALB入口控制器从yaml文件中接收到新的入口资源时，它不会通过添加新的入口规则来更新现有的ALB。相反，它会完全覆盖并只应用最新文件中的规则。</p><p id="f331" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果所有入口规则都是静态的，并在一个中心文件中预定义，这可能根本不是问题。然而，在某些情况下，正如在<em class="nj">章节中提到的，Nginx ingress支持分布式的ingress变更，</em>我们在不同的时间有来自不同团队的ingress变更。我们更喜欢自助和自动化的解决方案。</p><p id="03aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，社区听到了我们的请求，并积极致力于这个<a class="ae mq" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller/issues/298" rel="noopener ugc nofollow" target="_blank">创建选项，以重用现有的ALB </a>功能。我非常兴奋，迫不及待地想尝试一下。</p><h2 id="18b1" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><strong class="ak">带AWS CNI插件的IP模式下的ALB入口</strong></h2><p id="1cd0" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">AWS ALB入口控制器支持两种流量模式:实例模式和IP模式。</p><blockquote class="nr ns nt"><p id="b185" class="jn jo nj jp b jq jr js jt ju jv jw jx nu jz ka kb nv kd ke kf nw kh ki kj kk ij bi translated">实例模式:入口流量从ALB开始，到达为您的服务打开的<a class="ae mq" href="https://kubernetes.io/docs/concepts/services-networking/service/#nodeport" rel="noopener ugc nofollow" target="_blank">节点端口</a>。然后，流量被路由到集群内的集装箱箱。在这种模式下，数据包到达目的地的跳数总是2。</p><p id="a476" class="jn jo nj jp b jq jr js jt ju jv jw jx nu jz ka kb nv kd ke kf nw kh ki kj kk ij bi translated">ip模式:入口流量从ALB开始，直接到达集群内的容器箱。为了使用这种模式，Kubernetes集群的网络插件必须使用ENI上的辅助IP地址作为pod IP，也就是用于Kubernetes的<a class="ae mq" href="https://github.com/aws/amazon-vpc-cni-k8s" rel="noopener ugc nofollow" target="_blank"> AWS CNI插件</a>。<strong class="jp ir">在此模式下，数据包到达目的地的跳数始终为1。</strong></p></blockquote><figure class="ma mb mc md gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nx"><img src="../Images/f70161e7e6d51029abd8aee36769ab5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQo8z4twffMy0fdJfhvEcw.png"/></div></div></figure><p id="9b61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每当创建入口资源时，入口控制器将:</p><ul class=""><li id="400a" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated">如果ALB和侦听器(80/443)尚不存在，则创建它们</li><li id="be1e" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">在ALB上为每个K8S服务创建一个目标组。</li><li id="7ec4" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">更新每个目标组上的路径和主机入口配置</li><li id="81d1" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">仅将运行后端pod的虚拟机(而不是所有虚拟机)添加到目标组。</li></ul><p id="f46f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是的，每个目标组只在运行pods的极少数节点上进行负载平衡，而不是在集群中的所有工作节点上设置负载平衡器。与ALB入口控制器(实例模式)或Nginx入口控制器相比，这是非常独特的。</p><p id="c56e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，这也大大减少了负载平衡器将流量路由到不相关的虚拟机，然后依靠本地Kube代理和网络代理(即calico-node)来找到pod真正运行的目标虚拟机的机会。</p><p id="750a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，我们还要考虑一个网络复杂性。当使用流行的K8S网络插件(如Calico或法兰绒)时，覆盖网络在同一子网内是可选的，但对于跨子网流量是必需的。这是静态内部数据中心的预期情况。然而，当部署在诸如AWS之类的云中时，增加了一个额外的EC2-VPC结构层。我们的网络堆栈将变得更加复杂。</p><p id="c988" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，为了获得简单高效的网络堆栈，这种AWS ALB入口控制器(IP模式)解决方案看起来非常有前途，原因如下:</p><ul class=""><li id="0e72" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated">第一次，<strong class="jp ir">一个负载均衡器可以被</strong> <strong class="jp ir"> pod位置感知</strong>。</li><li id="62b5" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">数据包到达目的地的跳数是<strong class="jp ir">总是一个</strong>。</li><li id="3c8e" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><strong class="jp ir">与直接在云中使用网络插件(Calico，法兰绒)相比，没有额外的覆盖网络(AWS，GCP，Azure)</strong></li></ul><p id="7c95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前，AWS CNI插件的最新版本是1.3.0，你可以从<a class="ae mq" href="https://github.com/aws/amazon-vpc-cni-k8s/releases" rel="noopener ugc nofollow" target="_blank">这里</a>获得并试用它。</p><p id="f2e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我的“Kubernetes入口控制器:如何选择正确的一个”的第1部分。在下一节课中，我将分享我在第三类产品<strong class="jp ir">基于Envoy的入口控制器方面的经验。</strong>我们将深入探讨这一流行选项，并讨论其利弊。</p><h1 id="0260" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">参考</h1><ul class=""><li id="af30" class="mu mv iq jp b jq lv ju lw jy ny kc nz kg oa kk mz na nb nc bi translated"><a class="ae mq" href="https://aws.amazon.com/blogs/opensource/kubernetes-ingress-aws-alb-ingress-controller/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/blogs/open source/kubernetes-ingress-AWS-ALB-ingress-controller/</a></li><li id="c6e1" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://medium.com/@ericyuliu/kubernetes-network-deep-dive-7492341e0ab5" rel="noopener">https://medium . com/@ ericyuliu/kubernetes-network-deep-dive-7492341 E0 ab 5</a></li><li id="233c" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS/Amazon-VPC-CNI-k8s/blob/master/docs/CNI-proposal . MD</a></li><li id="a6e7" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller" rel="noopener ugc nofollow" target="_blank">https://github . com/kubernetes-sigs/AWS-ALB-ingress-controller</a></li><li id="fa94" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://danielfm.me/posts/painless-nginx-ingress.html" rel="noopener ugc nofollow" target="_blank">https://danielfm.me/posts/painless-nginx-ingress.html</a></li><li id="2846" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae mq" href="https://github.com/helm/charts/tree/master/stable/nginx-ingress" rel="noopener ugc nofollow" target="_blank">https://github . com/helm/charts/tree/master/stable/nginx-ingress</a></li></ul></div></div>    
</body>
</html>