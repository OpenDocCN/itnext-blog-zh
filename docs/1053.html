<html>
<head>
<title>Algorithmic Reverb and Web Audio API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">算法混响和网络音频API</h1>
<blockquote>原文：<a href="https://itnext.io/algorithmic-reverb-and-web-audio-api-e1ccec94621a?source=collection_archive---------2-----------------------#2018-07-12">https://itnext.io/algorithmic-reverb-and-web-audio-api-e1ccec94621a?source=collection_archive---------2-----------------------#2018-07-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="07a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">“混响和网络音频API”系列第二部分</strong><strong class="jp ir"/></p><p id="2373" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章是<a class="ae kl" href="https://medium.com/@a.miselaytes/convolution-reverb-and-web-audio-api-8ee65108f4ae" rel="noopener">第一部分卷积混响和网络音频API </a>的延续。如果你还没有读过，你也许应该从第一部分开始。在这一部分中，我们将看看如何使用Audio Worklet实现一个<em class="km">单延迟线</em>并使用现有的web音频节点构建<em class="km"> Freeverb </em>。</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/c37ebd8ca411c7b69536107fa4253730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVqcEpkZRx3pfLtEWfHivA.png"/></div></div></figure><p id="262a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">一条单独的延迟线</strong></p><p id="f8a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建数字算法混响有很多不同的方法。让我们从一个非常简单的开始，它基于<a class="ae kl" href="https://en.wikipedia.org/wiki/Digital_delay_line" rel="noopener ugc nofollow" target="_blank">延迟线</a>的想法。想象一下，如果你的朋友杰克刚刚用棍子打了一个小军鼓，声波将从振动的鼓传播到你的耳朵，但它也会传播到天花板，从那里反射并稍微延迟一会儿到达你的耳朵(因为它需要传播更长的距离)。由于部分波被空气吸收了，它也可能声音小一点。在编程中实现这种延迟的声音称为延迟线。在现实世界中，任何房间都会有很多延迟线，因为声音会从所有的墙壁、天花板反射，也许还会从你的狗尾巴反射。</p><p id="e556" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建单个延迟线非常简单。人们只需获取输入声音(例如麦克风)的<a class="ae kl" href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)" rel="noopener ugc nofollow" target="_blank">样本</a>，除了将它们直接输出到输出端(扬声器)之外，还可以将它们存储在一个数组中，因此稍后可以检索这些样本，并将其添加到模拟回声的输出中。</p><p id="bdfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了一个叫做<a class="ae kl" href="https://en.wikipedia.org/wiki/Circular_buffer" rel="noopener ugc nofollow" target="_blank">循环缓冲区</a>的过程，它基本上是一个固定长度的数组，有一个写指针和一个读指针。每当读指针到达数组的末尾时，它又开始从头开始读。每当写指针到达数组的末尾时，它又开始写数组的开头。我们可以只使用一个动态大小的数组，但这意味着它的长度会无限增长，而我们只使用它的一小部分(尾部)。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lg"><img src="../Images/221e69c5bf402e0f9b1a27a01fd56f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_hmqwgse8mUg0PLq6dMcbQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">单延迟线</figcaption></figure><p id="1b98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了实现1秒的延迟线(44100个样本，如果我们的采样率是每秒44100个样本),我们:</p><ol class=""><li id="f4f5" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk lq lr ls lt bi translated">从输入信号中取样</li><li id="0a56" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">从我们的循环缓冲区中取一个样本，这个样本是一秒钟前(或者44100个样本)写在那里的</li><li id="188a" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">将这两者相加(将缓冲器中的样本乘以某个小于1的衰减系数)</li><li id="4cfe" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">将结果写入输出信号</li><li id="eb02" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">将结果写入延迟缓冲区(这样我们可以再次读取它，并在以后的第2点中使用它)</li></ol><p id="922b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在JavaScript实现:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="00a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">肖邦&amp;音频小作品</strong></p><p id="6d0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，现在我们有了延迟线，但是我们如何在网络音频API中使用它呢？答案是Audio Worklet。要了解更多，你可以去<a class="ae kl" href="https://developers.google.com/web/updates/2017/12/audio-worklet" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae kl" href="https://googlechromelabs.github.io/web-audio-samples/audio-worklet/" rel="noopener ugc nofollow" target="_blank">这里</a>。简而言之，它允许你编写定制的音频处理代码，这些代码将在浏览器中的一个单独的音频线程中运行，因此具有最小的延迟。</p><p id="fcc8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的例子中，我们将首先播放一段没有混响的钢琴录音，然后使用我们漂亮的单延迟线混响。所以我再次强烈建议阅读上面的参考资料，但是基本上worklet有两个部分:</p><ul class=""><li id="2729" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk mb lr ls lt bi translated">音频线程中的实际声音处理器代码(将包括我们的延迟线代码)</li><li id="7cae" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk mb lr ls lt bi translated">在主线程中注册并调用这段代码</li></ul><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="lz ma l"/></div></figure><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="mc ma l"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">原创</figcaption></figure><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="mc ma l"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">使用单个延迟线(基本上是回声)</figcaption></figure><p id="d642" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/miselaytes-anton/web-audio-experiments/tree/master/packages/audio-worklet-delay-app" rel="noopener ugc nofollow" target="_blank"> GitHub </a></p><p id="b4fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">如何改进算法</strong></p><p id="0208" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的单线混响很棒，但听起来不是很有趣。我们可以做的一个明显的改进是增加更多的延迟线。我们还需要确保这些延迟线不会相互干扰(想想延迟时间的质数)。这样我们就不会听到不同线路的回声同时出现，听起来更像是真实生活的混响。我们还可以添加所谓的<em class="km">早期回声，</em>从附近表面反射的尖锐声音。</p><p id="3e6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种方法的缺点是，要获得真正真实的混响，我们需要太多的延迟线。同样的效果可以通过全通滤波器和梳状滤波器的组合来实现，这一点我们将在下一节中讨论。</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><p id="c772" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Freeverb(只是一堆滤镜)</strong></p><p id="8378" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Freeverb是一种基于<a class="ae kl" href="https://en.wikipedia.org/wiki/All-pass_filter" rel="noopener ugc nofollow" target="_blank">全通</a>和<a class="ae kl" href="https://en.wikipedia.org/wiki/Comb_filter#Feedback_form" rel="noopener ugc nofollow" target="_blank">反馈低通梳状滤波器</a>组合的算法混响。它由德国物理学家曼弗雷德·施罗德设计。</p><p id="a835" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Freeverb的所有元素都可以使用现有的web音频节点来实现。<em class="km">湿</em>和<em class="km">干</em>分别对应修改和未修改的音频信号，可以使用<a class="ae kl" href="https://developer.mozilla.org/en-US/docs/Web/API/GainNode" rel="noopener ugc nofollow" target="_blank">增益</a>节点实现。由于我们处理左右声道的方式不同，我们需要一个<a class="ae kl" href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelSplitterNode" rel="noopener ugc nofollow" target="_blank">分路器</a>和一个<a class="ae kl" href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelMergerNode" rel="noopener ugc nofollow" target="_blank">合并器</a>。剩下的是最重要也是最有趣的部分——<em class="km">梳状滤波器</em>和<em class="km">全通滤波器</em>。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi md"><img src="../Images/272ec123a77bb0e7f8a10a8785ea9236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZmMzSfzE0_3hH93GfdkEg.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">自由动词</figcaption></figure><p id="cf63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">梳状滤波器</strong></p><p id="0002" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">web audio中没有梳状滤波器节点，但我们可以使用其他音频节点轻松制作一个。然而，让我们首先试着理解它是什么，为什么我们需要它。</p><p id="74ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">梳状滤波器输出原始输入信号及其延迟版本的总和，从而模拟回声效果(很像我们的延迟线)。将信号添加到延迟的self会导致信号幅度在某些地方增加(波的拾取匹配)而在其他地方减少(拾取相互抵消)，从而使其看起来像梳子:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi me"><img src="../Images/19e4a3f09d4ea8429106ae9b03e2d38d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*VCJxmWRqsePIjZD_MnAisA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated"><a class="ae kl" href="https://en.wikipedia.org/wiki/Comb_filter#/media/File:Comb_filter_response_ff_pos.svg" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure><p id="392f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用其中的8个(每个立体声通道4个)，每个滤波器模拟一条延迟线，或者换句话说，产生我们输入声音的回声或混响。每个滤波器的延迟时间都是由Shroeder先生精心选择的，所以听起来特别悦耳。为了在网络音频中构建它，我们将使用几个基本节点:增益、延迟和低通滤波器。</p><p id="47e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们获取输入信号，并通过增益将其原封不动地传递到输出端。然后，我们还让输入通过延迟来模拟回声，并通过低通来模拟空气对声音的吸收。混响时间在较高频率下会减少，因为空气会更好地吸收这些频率。然后，我们还需要通过低于1的增益传递信号，以防止音量随时间上升。</p><p id="337f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它可以用JavaScript实现，如下所示:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="72db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，问题是这个过滤器是静态的，这意味着我们不能轻易地调整参数，例如延迟时间，所以我们需要公开它们。理想情况下，我们会这样做，即我们的梳状滤波器的接口完全遵循<a class="ae kl" href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode" rel="noopener ugc nofollow" target="_blank">音频节点</a>的API。不幸的是，这不是一个简单的任务，到目前为止，最好使用这种<a class="ae kl" href="https://github.com/GoogleChromeLabs/web-audio-samples/wiki/CompositeAudioNode" rel="noopener ugc nofollow" target="_blank">式的肮脏方法</a>来完成。使用这个复合节点类，我们可以显示共振、阻尼和延迟时间参数:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="fdd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">全通滤波器</strong></p><p id="39cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们需要一个全通滤波器，以使我们的8个梳状滤波器延迟线听起来更沉闷，或者更模糊，如果你喜欢，模拟波的消散和空气的吸收。这个全通是个多么奇怪的家伙。与低通、高通或带通不同，它实际上不会阻挡任何频率。取而代之的是，它根据频率随时间不同地改变信号的相位。因此，如果您的信号由多个频率组成(这几乎肯定会发生)，每个频率都会发生偏移，因此信号会变得<em class="km">更长</em>和<em class="km">更模糊</em>，或者换句话说，信号会在<em class="km">中扩展</em>和<em class="km">扩散</em>。如果在这一点上，它仍然听起来模糊不清，尝试阅读<a class="ae kl" href="https://ccrma.stanford.edu/~jos/pasp/Schroeder_Allpass_Sections.html" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><p id="01cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，全通滤波器是标准音频节点的一部分，所以我们不必自己构建它。</p><p id="e8d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">将所有这些放在一起</strong></p><p id="8894" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，当我们拥有所有元素并理解它们的含义时，剩下的唯一事情就是正确连接所有节点，并确保我们为最终用户提供过滤器的参数以进行调整。这里唯一棘手的部分是我们想同时改变所有梳状滤波器的谐振和衰减，我们可以用<a class="ae kl" href="https://gist.github.com/miselaytes-anton/7d795d6efcc7774b136c2b73dc38ed32" rel="noopener ugc nofollow" target="_blank"> merge params utility </a>存档。</p><p id="9078" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终结果如下所示:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="ca00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://amiselaytes.com/freeverb/" rel="noopener ugc nofollow" target="_blank">Demo</a>T22】Github</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><p id="1f21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">代替结论</strong></p><p id="495b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望这篇文章已经展示了网络音频确实给了你实现混响算法的所有工具，从非常简单到非常复杂。如果你想了解更多关于混响或音频编程的知识，这里有一些资源:</p><p id="4b69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">- <a class="ae kl" href="http://teropa.info/blog/2016/08/19/what-is-the-web-audio-api.html" rel="noopener ugc nofollow" target="_blank"> Teropa great Web Audio教程系列</a><br/>-<a class="ae kl" href="https://developers.google.com/web/updates/2017/12/audio-worklet" rel="noopener ugc nofollow" target="_blank">Audio Worklet</a><br/>-<a class="ae kl" href="https://physics.info/music/" rel="noopener ugc nofollow" target="_blank">关于声音相关数学的文章写得很好，插图也很好</a><br/>-<a class="ae kl" href="http://www.pd-tutorial.com/english/" rel="noopener ugc nofollow" target="_blank">PD中的音频编程</a> <br/> - <a class="ae kl" href="http://www.dspguide.com/pdfbook.htm" rel="noopener ugc nofollow" target="_blank">一本很棒的DSP书籍</a></p></div></div>    
</body>
</html>