<html>
<head>
<title>Monitoring Kafka in Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在库伯内特斯监视卡夫卡</h1>
<blockquote>原文：<a href="https://itnext.io/monitoring-kafka-in-kubernetes-7b46c9bf42b6?source=collection_archive---------2-----------------------#2019-04-09">https://itnext.io/monitoring-kafka-in-kubernetes-7b46c9bf42b6?source=collection_archive---------2-----------------------#2019-04-09</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="b069" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">没有普罗米修斯的《库伯涅茨》中的卡夫卡</h2></div><h2 id="bb35" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">TL；速度三角形定位法(dead reckoning)</h2><p id="7a55" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">如果你不能或者不愿意使用普罗米修斯，这篇文章主要关注于监控你在Kubernetes的Kafka部署。卡夫卡通过JMX揭示了它的尺度。为了能够在您最喜欢的报告后端(例如InfluxDB或Graphite)收集指标，您需要一种使用JMX协议查询指标并传输它们的方法。这就是jmxtrans 派上用场的地方。经过一些小的调整，在Kafka pods中把它作为边车运行，让它查询指标并把它们传输到您的报告后端是非常有效的。对于不耐烦的人:所有的<a class="ae ly" href="https://github.com/jeroenr/kafka-k8s-monitoring" rel="noopener ugc nofollow" target="_blank">示例代码都可以在这里</a>找到。</p><h2 id="db38" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">为什么要监视卡夫卡</h2><p id="c05c" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">消息传递越来越成为不同应用之间共享数据的流行选择，使得Kafka这样的工具成为你架构的主干。一个运行良好的Kafka集群能够处理大量数据，但是Kafka集群运行状况不佳或降级可能会导致整个堆栈出现问题。因此，掌握这一问题并提供仪表板以提供必要的见解是至关重要的。</p><h2 id="7d22" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">度量，度量，度量</h2><p id="d7cc" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">Kafka提供了大量关于性能和资源利用的指标，这些指标(默认情况下)可以通过JMX记者获得。我花了一段时间才弄清楚哪些指标是可用的，以及如何访问它们。更糟糕的是，随着卡夫卡的发行，它也发生了几次变化。Confluent提供了一个<a class="ae ly" href="https://docs.confluent.io/current/kafka/monitoring.html" rel="noopener ugc nofollow" target="_blank">好的(并且大部分是正确的)概述</a>在最近的Kafka版本中可用的度量标准。Kafka指标可以分为三类:</p><ul class=""><li id="7f31" class="lz ma iu lh b li mb ll mc ks md kw me la mf lx mg mh mi mj bi translated">经纪人指标</li><li id="9c80" class="lz ma iu lh b li mk ll ml ks mm kw mn la mo lx mg mh mi mj bi translated">生产者指标</li><li id="6934" class="lz ma iu lh b li mk ll ml ks mm kw mn la mo lx mg mh mi mj bi translated">消费者指标</li></ul><p id="069d" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">有一篇<a class="ae ly" href="https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/" rel="noopener ugc nofollow" target="_blank">很好的文章</a>介绍了每个类别中哪些指标很重要。对于我们来说，复制分区不足和消费者延迟是关键指标，还有几个与吞吐量相关的指标。</p><h2 id="83d0" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">配置Kafka部署以公开指标</h2><p id="f080" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">所以让我们假设以下Kafka在Kubernetes上的设置。Kafka pods作为StatefulSet的一部分运行，我们有一个无头服务来为我们的经纪人创建DNS记录。然后，我们必须配置Kafka通过JMX报告指标。这是通过配置<code class="fe ms mt mu mv b">JMX_PORT</code>环境变量来完成的。我们将得到一个类似于下面的YAML文件</p><figure class="mw mx my mz gu na"><div class="bz fq l di"><div class="nb nc l"/></div></figure><p id="8211" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">同样，这里重要的部分是我们将<code class="fe ms mt mu mv b">JMX_PORT</code>环境值设置为<code class="fe ms mt mu mv b">9010</code>的值，这意味着我们将在该端口上公开Kafka指标。您可以使用JConsole之类的工具来验证是否可以连接到这个端口。</p><h2 id="7ada" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">将Kafka指标导出到您的报告后端</h2><p id="24eb" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">很好，我们已经确认Kafka的指标已经公开，可以导出到您的报告后端。如果你碰巧使用普罗米修斯，你应该设置<a class="ae ly" href="https://github.com/danielqsj/kafka_exporter" rel="noopener ugc nofollow" target="_blank">卡夫卡出口</a>或者<a class="ae ly" href="https://github.com/prometheus/jmx_exporter" rel="noopener ugc nofollow" target="_blank"> JMX出口</a>然后搞定它。你可以跳过这篇文章的其余部分，因为普罗米修斯将做引入指标的艰苦工作。然而，大多数其他报告后端(例如InfluxDB、Graphite)是基于推送的，因此您需要自己提取和加载指标。</p><p id="f1a6" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">如果你不想和(自定义)Kafka Metrics Reporters <a class="ae ly" href="https://github.com/jmxtrans/jmxtrans/wiki" rel="noopener ugc nofollow" target="_blank">混在一起，jmxtrans </a>可能会让你感兴趣。Jmxtrans是一个工具，它能够查询多个JVM通过JMX公开的属性，并使用可配置的输出编写器输出结果。它为许多流行的报告后端提供了输出编写器，例如:<a class="ae ly" href="https://aws.amazon.com/cloudwatch/" rel="noopener ugc nofollow" target="_blank"> Amazon CloudWatch </a>，InfluxDB，Graphite，Ganglia，StatsD等。</p><p id="ae03" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">我现在将展示我们与InfluxDB一起使用的设置。以下是InfluxDB的jmxtrans配置示例:</p><pre class="mw mx my mz gu nd mv ne nf aw ng bi"><span id="3bcd" class="kj kk iu mv b gz nh ni l nj nk">{<br/>  "servers" : [ {<br/>    "port" : "8081",<br/>    "host" : "kafka.my-namespace.svc.cluster.local",<br/>    "queries" : [ {<br/>      "obj" : "java.lang:type=Memory",<br/>      "attr" : [ "HeapMemoryUsage", "NonHeapMemoryUsage" ],<br/>      "resultAlias":"jvmMemory",<br/>      "outputWriters" : [ {<br/>        "@class" : "com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory",<br/>        "url" : "http://127.0.0.1:8086/",<br/>        "username" : "admin",<br/>        "password" : "admin",<br/>        "database" : "jmxDB",<br/>        "tags"     : {"application" : "kafka"}<br/>      } ]<br/>    } ]<br/>  } ]<br/>}</span></pre><p id="60c9" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">如您所见，您为每个服务器指定了一个查询列表，您可以在其中查询属性列表。对于每个查询，您可以指定一个输出编写器列表。我不确定为什么为每个查询重新定义一个输出编写器列表是有用的。对于Kafka用例，您最终会得到一个很大的配置文件，其中包含许多重复的内容。</p><p id="9917" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">如果我们可以在这里使用某种模板，那就太好了。我的模板看起来会像这样</p><pre class="mw mx my mz gu nd mv ne nf aw ng bi"><span id="4bc7" class="kj kk iu mv b gz nh ni l nj nk">{<br/> "servers": [{<br/>  "port": "${kafkaJmxPort}",<br/>  "host": "localhost",<br/>  "alias": "${alias}",<br/>  "queries": [<br/>    {{#metrics}} {<br/>   "outputWriters": [{<br/>    "<a class="ae ly" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>": "com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory",<br/>    "url": "${influxUrl}",<br/>    "database": "${influxDatabase}",<br/>    "retentionPolicy": "${retentionPolicy}",<br/>    "createDatabase": false,<br/>    "username": "${influxUser}",<br/>    "password": "${influxPass}"<br/>   }],<br/>   "obj": {{obj}},<br/>   "attr": {{attribute}},<br/>   "resultAlias": {{resultAlias}}<br/>  } {{/metrics}}<br/>  ]<br/> }]<br/>}</span></pre><p id="b20d" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated"><a class="ae ly" href="https://hub.docker.com/r/jmxtrans/jmxtrans/" rel="noopener ugc nofollow" target="_blank"> jmxtrans docker image </a>支持JSON配置文件中的提要，并支持使用JVM参数进行变量替换。所以我可以用它来注入像<code class="fe ms mt mu mv b">${influxPass}</code>这样的秘密。然而，我仍然需要一个不必为每个指标重复输出编写器的解决方案。为了保持务实，我使用<code class="fe ms mt mu mv b">jq</code>来呈现基于一系列指标的jmxtrans配置文件模板。模板需要在启动实际的jmxtrans容器之前呈现，所以我使用一个<a class="ae ly" href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" rel="noopener ugc nofollow" target="_blank"> Init容器</a>来完成这项工作。Init容器类似于常规容器，但是在其他容器启动之前运行。这非常适合生成配置文件。让我们创建一个Init容器来生成jmxtrans配置</p><figure class="mw mx my mz gu na"><div class="bz fq l di"><div class="nb nc l"/></div></figure><p id="bf63" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">如您所见，度量列表是从一个<code class="fe ms mt mu mv b">ConfigMap</code>挂载的，生成的<code class="fe ms mt mu mv b">kafka.json</code>文件被写入另一个卷挂载。参见下面的<code class="fe ms mt mu mv b">ConfigMap</code></p><figure class="mw mx my mz gu na"><div class="bz fq l di"><div class="nb nc l"/></div></figure><p id="53d4" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">注意，在这个<code class="fe ms mt mu mv b">ConfigMap</code>中，我们还放置了一个简单的引导脚本来注入JVM参数，以便由jmxtrans本身进行替换。该脚本将作为docker容器的入口点。</p><p id="6060" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">现在我们只需要将jmxtrans容器描述符添加到我们现有的kafka pod模板中。我将把它添加为边车，这样查询JMX将只发生在pod内部。</p><figure class="mw mx my mz gu na"><div class="bz fq l di"><div class="nb nc l"/></div></figure><p id="05da" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">重要的是，我们挂载包含我们生成的配置文件的文件夹(<code class="fe ms mt mu mv b">jmxtrans-input</code>)，挂载<code class="fe ms mt mu mv b">boot.sh</code>脚本，并在第32行中使用它作为docker入口点。</p><p id="3e84" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">精彩！一旦我们<code class="fe ms mt mu mv b">kubectl apply</code>了整个事情，我们就可以将我们的数据源添加到Grafana，并创建漂亮的卡夫卡图表，如</p><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj nl"><img src="../Images/e9e37cdd43ce686fb842225bf6b8d13f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*posaThVRpmn-ndDz_wYPhA.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">一段时间内每个主题的消息</figcaption></figure><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj nw"><img src="../Images/bdc379b49df41d8bfa0ae4131d2ebd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cv69sMH67Dl8wJOxF6zC9w.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">一段时间内每秒记录数</figcaption></figure><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj nx"><img src="../Images/18d2cd1631ca75efa3cab5d2b585e034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*THlcbZ8sSjOvjyVI83bKnw.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">随着时间的推移，分区复制不足</figcaption></figure><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ny"><img src="../Images/92abb5446d23cc78c7885b06a749b742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yRAQXSEYIizr5mI81CMIg.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">消费者滞后一段时间</figcaption></figure><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj nz"><img src="../Images/4bc92da271f5227c68abd5f23126f7e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ydDl44Egh4Qmwu0KQyafQ.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">一段时间内的分区计数与领导者计数</figcaption></figure><figure class="mw mx my mz gu na gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj oa"><img src="../Images/36c5eb73a1e7daeceed30202c681c602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5v45BilcZLsXhMjkwUP7w.png"/></div></div><figcaption class="ns nt gk gi gj nu nv bd b be z dk translated">一段时间内每秒提交的次数</figcaption></figure><h2 id="7473" class="kj kk iu bd kl km kn dn ko kp kq dp kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">保持jmxtrans的活力</h2><p id="0fd8" class="pw-post-body-paragraph lf lg iu lh b li lj jv lk ll lm jy ln ks lo lp lq kw lr ls lt la lu lv lw lx in bi translated">这种设置工作得相当好，但是当在生产中运行这种设置一段时间后，我们遇到了诸如<a class="ae ly" href="https://github.com/jmxtrans/jmxtrans/issues/685" rel="noopener ugc nofollow" target="_blank">https://github.com/jmxtrans/jmxtrans/issues/685</a>这样的问题。这实际上将jmxtrans容器变成了僵尸。容器将继续运行，但不会导出任何指标！通过在容器上配置一个活跃度探测器，我发现了一个相当难看的解决方法，该探测器跟踪到我们的报告后端的传出tcp连接。在我们的例子中，这是在端口8086上运行的InfluxDB。</p><pre class="mw mx my mz gu nd mv ne nf aw ng bi"><span id="8221" class="kj kk iu mv b gz nh ni l nj nk">livenessProbe:<br/>  exec:<br/>    command: ["/bin/sh", "-c", "exec netstat -n | grep -q :8086"]</span></pre><p id="37e4" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">如果在端口8086 (InfluxDB)上找不到任何活动连接，那么<code class="fe ms mt mu mv b">grep</code>命令将会失败，这将最终导致容器重新启动。请注意，这只是重新启动边车，而不是Kafka容器，它将影响Pod准备就绪！只有当一个pod的所有容器都准备好了(并且其他<a class="ae ly" href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate" rel="noopener ugc nofollow" target="_blank">就绪门条件为真</a>)时，该pod才被评估为就绪。这将导致您的代理不被headless服务列为活动的。我仍然希望找到一个更好的解决方案，我很乐意接受建议！</p><p id="80ca" class="pw-post-body-paragraph lf lg iu lh b li mb jv lk ll mc jy ln ks mp lp lq kw mq ls lt la mr lv lw lx in bi translated">感谢阅读！所有的<a class="ae ly" href="https://github.com/jeroenr/kafka-k8s-monitoring" rel="noopener ugc nofollow" target="_blank">示例代码都可以在我的github </a>获得。</p></div></div>    
</body>
</html>