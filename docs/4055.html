<html>
<head>
<title>Kafka Connect on Kubernetes, the easy way!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kafka Connect on Kubernetes，简单的方法！</h1>
<blockquote>原文：<a href="https://itnext.io/kafka-connect-on-kubernetes-the-easy-way-b5b617b7d5e9?source=collection_archive---------0-----------------------#2020-04-18">https://itnext.io/kafka-connect-on-kubernetes-the-easy-way-b5b617b7d5e9?source=collection_archive---------0-----------------------#2020-04-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="853c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个教程，通过一个例子展示了如何在Kubernetes上使用<code class="fe km kn ko kp b"><a class="ae kl" href="https://strimzi.io/" rel="noopener ugc nofollow" target="_blank">Strimzi</a></code>设置和使用<a class="ae kl" href="https://kafka.apache.org/documentation/#connect" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>。</p><p id="11e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka Connect是一个工具，使用源和接收器连接器在Apache Kafka和其他系统之间可伸缩和可靠地传输数据。虽然在Kubernetes上部署一个Kafka Connect集群并不太难(<a class="ae kl" href="https://en.wikipedia.org/wiki/Do_it_yourself" rel="noopener ugc nofollow" target="_blank">只需“DIY”！</a>)，我喜欢的是，<code class="fe km kn ko kp b">Strimzi</code>在<a class="ae kl" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" rel="noopener ugc nofollow" target="_blank">自定义资源定义</a>的帮助下，使用<a class="ae kl" href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="noopener ugc nofollow" target="_blank">操作符模式</a>实现了一种Kubernetes本地的方式。</p><blockquote class="kq kr ks"><p id="daed" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">除了引导/安装Kafka Connect之外，这也适用于扩展Connect集群、部署和管理连接器等操作。(在这篇博客的过程中，你会看到这一点)</p></blockquote><p id="ce27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将经历在Kubernetes上部署Kafka Connect集群、安装连接器和测试的过程——所有这些都使用了<code class="fe km kn ko kp b">kubectl</code>和一些<code class="fe km kn ko kp b">YAML</code>(当然！).我将使用<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Event Hubs </a>作为Kafka broker，使用<a class="ae kl" href="https://docs.microsoft.com/azure/aks/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Kubernetes Service </a>作为Kubernetes集群——请随意使用其他替代方案(例如，在您的笔记本电脑上使用本地<code class="fe km kn ko kp b">minikube</code>集群)</p><blockquote class="kq kr ks"><p id="ab12" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">GitHub</em>上所有的 <a class="ae kl" href="https://github.com/abhirockzz/strimzi-kafka-connect-eventhubs" rel="noopener ugc nofollow" target="_blank"> <em class="iq">神器都有</em></a></p></blockquote><p id="8bb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">Strimzi</code>负责所有的重物搬运..如果你还不知道，这里有一个要点</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="8a76" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">Strimzi概述</h1><blockquote class="kq kr ks"><p id="b418" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">Strimzi文档很详细，但组织得很好，也很清晰！以下段落的大部分内容直接取自文件</p></blockquote><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/da0853694651448174335531dfd87b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/0*9gFlyQBLppFWo-Q4.png"/></div></figure><p id="4da2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">Strimzi</code>简化在Kubernetes集群中运行Apache Kafka的过程。它提供了在Kubernetes上运行Kafka的容器映像和操作符。它是作为<code class="fe km kn ko kp b"><a class="ae kl" href="https://www.cncf.io/sandbox-projects/" rel="noopener ugc nofollow" target="_blank">Sandbox</a></code> <a class="ae kl" href="https://www.cncf.io/sandbox-projects/" rel="noopener ugc nofollow" target="_blank">项目</a><code class="fe km kn ko kp b"><a class="ae kl" href="https://strimzi.io/blog/2019/09/06/cncf/" rel="noopener ugc nofollow" target="_blank">Cloud Native Computing Foundation</a></code>的一个<a class="ae kl" href="https://strimzi.io/blog/2019/09/06/cncf/" rel="noopener ugc nofollow" target="_blank">部分(在撰写本文时)</a></p><p id="9adf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">Strimzi Operators</code>是项目的基础。这些操作人员具有专业的操作知识，能够有效地管理Kafka。运营商简化了以下过程:部署和运行Kafka集群和组件，配置和保护对Kafka的访问，升级和管理Kafka，甚至负责管理主题和用户。</p><p id="9595" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是对操作员角色的10，000英尺概述:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/726eabacc2c33ab67c9b9d0d539afd47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-7EiB1IweXe3WwKv.png"/></div></div></figure><blockquote class="kq kr ks"><p id="4651" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">在这篇文章中，我不打算深入讨论使用Strimzi部署Kafka的细节——这可能是我将在未来的博客中处理的事情</p></blockquote></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="a03e" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">先决条件</h1><p id="5076" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">https://kubernetes.io/docs/tasks/tools/install-kubectl/<code class="fe km kn ko kp b">kubectl</code>-<a class="ae kl" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" rel="noopener ugc nofollow" target="_blank"/></p><p id="9185" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你选择使用Azure Event Hubs、Azure Kubernetes服务(或者两者都用)，你将需要一个<a class="ae kl" href="https://docs.microsoft.com/azure/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">微软Azure账户</a>。去吧<a class="ae kl" href="https://azure.microsoft.com/free/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">报名免费一个！</a></p><p id="a7b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">Azure CLI</code>或<code class="fe km kn ko kp b">Azure Cloud Shell</code> -如果你还没有安装<a class="ae kl" href="https://docs.microsoft.com/cli/azure/install-azure-cli?view=azure-cli-latest&amp;WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>，你可以选择安装它(应该很快！)或者直接从你的浏览器使用<a class="ae kl" href="https://azure.microsoft.com/features/cloud-shell/?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure云壳</a>。</p><h2 id="dfb2" class="mu lf iq bd lg mv mw dn lk mx my dp lo jy mz na ls kc nb nc lw kg nd ne ma nf bi translated">舵</h2><p id="4591" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">我将使用<code class="fe km kn ko kp b">Helm</code>来安装<code class="fe km kn ko kp b">Strimzi</code>。这里是安装【https://helm.sh/docs/intro/install/】<a class="ae kl" href="https://helm.sh/docs/intro/install/" rel="noopener ugc nofollow" target="_blank"><code class="fe km kn ko kp b">Helm</code>本身的文档</a></p><blockquote class="kq kr ks"><p id="fd3b" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">你也可以使用<code class="fe km kn ko kp b">YAML</code>文件直接安装<code class="fe km kn ko kp b">Strimzi</code>。点击此处查看快速入门指南-<a class="ae kl" href="https://strimzi.io/docs/quickstart/latest/#proc-install-product-str" rel="noopener ugc nofollow" target="_blank">https://strim zi . io/docs/quick start/latest/# proc-install-product-str</a></p></blockquote><p id="48fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从设置所需的Azure服务开始(如果您没有使用Azure，请跳过这一部分，但请确保您有Kafka集群的详细信息，即代理URL和身份验证凭据，如果适用)</p><blockquote class="kq kr ks"><p id="5c54" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated">我建议将下面的服务作为单个<a class="ae kl" href="https://docs.microsoft.com/azure/azure-resource-manager/management/overview?WT.mc_id=medium-blog-abhishgu#resource-groups" rel="noopener ugc nofollow" target="_blank"> Azure资源组</a>的一部分安装，这样可以很容易地清理这些服务</p></blockquote><h2 id="a680" class="mu lf iq bd lg mv mw dn lk mx my dp lo jy mz na ls kc nb nc lw kg nd ne ma nf bi translated">Azure活动中心</h2><p id="4d4d" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-about?%5BWT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Event Hubs </a>是一个数据流平台和事件摄取服务。它每秒可以接收和处理数百万个事件。<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">它还提供了一个Kafka端点</a>，现有的基于Kafka的应用程序可以使用它作为运行自己的Kafka集群的替代方案。Event Hubs支持Apache Kafka protocol 1.0和更高版本，并与Kafka生态系统中现有的Kafka客户端应用程序和其他工具配合使用，包括<code class="fe km kn ko kp b">Kafka Connect</code>(在本博客中演示过)、<code class="fe km kn ko kp b">MirrorMaker</code>等。</p><p id="591a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要设置Azure Event Hubs集群，你可以从各种选项中进行选择，包括<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-create?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">Azure门户</a>、<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-quickstart-cli?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>、<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-quickstart-powershell?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure PowerShell </a>或<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-resource-manager-namespace-event-hub?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">ARM模板</a>。一旦设置完成，您将需要连接字符串(将在后续步骤中使用)用于<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/authenticate-shared-access-signature?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">认证到事件中心</a> — <a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-get-connection-string?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank">使用本指南</a>完成此步骤。</p><blockquote class="kq kr ks"><p id="4a80" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">请确保您还创建了一个事件中心(与Kafka主题相同),作为我们Kafka Connect连接器的目标(详情见后续章节)</em></p></blockquote><h2 id="9e84" class="mu lf iq bd lg mv mw dn lk mx my dp lo jy mz na ls kc nb nc lw kg nd ne ma nf bi translated">蓝色库伯内特服务</h2><p id="9204" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated"><a class="ae kl" href="https://docs.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Kubernetes服务(AKS) </a>让在Azure中部署托管的Kubernetes集群变得简单。它通过将大部分责任转移给Azure，降低了管理Kubernetes的复杂性和运营开销。以下是如何使用<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>、<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure portal </a>或<a class="ae kl" href="https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-rm-template?WT.mc_id=medium-blog-abhishgu" rel="noopener ugc nofollow" target="_blank"> ARM模板</a>设置AKS集群的示例</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="fc12" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">基础安装</h1><p id="292a" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">首先，我们将安装<code class="fe km kn ko kp b">Strimzi</code>和Kafka Connect，然后是文件流源连接器</p><h2 id="cf21" class="mu lf iq bd lg mv mw dn lk mx my dp lo jy mz na ls kc nb nc lw kg nd ne ma nf bi translated">安装Strimzi</h2><p id="cb63" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">使用<code class="fe km kn ko kp b">Helm</code>安装Strimzi非常简单:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="6b0b" class="mu lf iq kp b gy nk nl l nm nn">//add helm chart repo for Strimzi<br/>helm repo add strimzi https://strimzi.io/charts/</span><span id="237e" class="mu lf iq kp b gy no nl l nm nn">//install it! (I have used strimzi-kafka as the release name)<br/>helm install strimzi-kafka strimzi/strimzi-kafka-operator</span></pre><p id="e579" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将安装<code class="fe km kn ko kp b">Strimzi</code>操作符(它只是一个<code class="fe km kn ko kp b">Deployment</code>)、自定义资源定义和其他Kubernetes组件，如<code class="fe km kn ko kp b">Cluster Roles</code>、<code class="fe km kn ko kp b">Cluster Role Bindings</code>和<code class="fe km kn ko kp b">Service Accounts</code></p><p id="4aef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更多详情，请点击此链接</p><blockquote class="kq kr ks"><p id="9781" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">删除，只需</em>T5】</p></blockquote><p id="e440" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确认Strimzi操作器已经被部署，检查它的<code class="fe km kn ko kp b">Pod</code>(它应该在一段时间后转换到<code class="fe km kn ko kp b">Running</code>状态)</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="946c" class="mu lf iq kp b gy nk nl l nm nn">kubectl get pods -l=name=strimzi-cluster-operator</span><span id="83e5" class="mu lf iq kp b gy no nl l nm nn">NAME                                        READY   STATUS    RESTARTS   AGE<br/>strimzi-cluster-operator-5c66f679d5-69rgk   1/1     Running   0          43s</span></pre><p id="4757" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还要检查自定义资源定义:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="7f3e" class="mu lf iq kp b gy nk nl l nm nn">kubectl get crd | grep strimzi</span><span id="56d5" class="mu lf iq kp b gy no nl l nm nn">kafkabridges.kafka.strimzi.io           2020-04-13T16:49:36Z<br/>kafkaconnectors.kafka.strimzi.io        2020-04-13T16:49:33Z<br/>kafkaconnects.kafka.strimzi.io          2020-04-13T16:49:36Z<br/>kafkaconnects2is.kafka.strimzi.io       2020-04-13T16:49:38Z<br/>kafkamirrormaker2s.kafka.strimzi.io     2020-04-13T16:49:37Z<br/>kafkamirrormakers.kafka.strimzi.io      2020-04-13T16:49:39Z<br/>kafkas.kafka.strimzi.io                 2020-04-13T16:49:40Z<br/>kafkatopics.kafka.strimzi.io            2020-04-13T16:49:34Z<br/>kafkausers.kafka.strimzi.io             2020-04-13T16:49:33Z</span></pre><p id="4656" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想叫出代表Kubernetes中卡夫卡集群的<code class="fe km kn ko kp b">kafkas.kafka.strimzi.io</code>。我们将重点关注分别代表Kafka Connect集群和连接器的<code class="fe km kn ko kp b">kafkaconnects.kafka.strimzi.io</code>和<code class="fe km kn ko kp b">kafkaconnectors.kafka.strimzi.io</code>。</p><blockquote class="kq kr ks"><p id="ab17" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">我将跳过其他组件，但您可以从中找出，例如集群角色</em> <code class="fe km kn ko kp b"><em class="iq">kubectl get clusterrole | grep strimzi</em></code></p></blockquote><p id="fc5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了“大脑”(Strimzi操作符)，让我们使用它吧！</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="b55d" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">卡夫卡连接</h1><p id="6b95" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">在部署Kafka Connect本身之前，我们需要创建一些helper Kubernetes组件。</p><p id="cf36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在继续之前，克隆<a class="ae kl" href="https://github.com/abhirockzz/strimzi-kafka-connect-eventhubs" rel="noopener ugc nofollow" target="_blank"> GitHub项目</a></p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="e6c1" class="mu lf iq kp b gy nk nl l nm nn">git clone https://github.com/abhirockzz/strimzi-kafka-connect-eventhubs<br/>cd strimzi-kafka-connect-eventhubs</span></pre><p id="416a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka Connect将需要引用现有的Kafka集群(在本例中是Azure Event Hubs)。我们可以将集群的认证信息存储为一个<a class="ae kl" href="https://kubernetes.io/docs/concepts/configuration/secret/" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a> <code class="fe km kn ko kp b"><a class="ae kl" href="https://kubernetes.io/docs/concepts/configuration/secret/" rel="noopener ugc nofollow" target="_blank">Secret</a></code>，稍后可以在Kafka Connect定义中使用。</p><p id="acc7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更新<code class="fe km kn ko kp b">eventhubs-secret.yaml</code>文件以包含Azure事件中心的凭证。在<code class="fe km kn ko kp b">eventhubspassword</code>属性中输入连接字符串。</p><p id="02cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="b5a0" class="mu lf iq kp b gy nk nl l nm nn">apiVersion: v1<br/>kind: Secret<br/>metadata:<br/>  name: eventhubssecret<br/>type: Opaque<br/>stringData:<br/>  eventhubsuser: $ConnectionString<br/>  eventhubspassword: Endpoint=sb://&lt;eventhubs-namespace&gt;.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=&lt;access-key&gt;</span></pre><blockquote class="kq kr ks"><p id="5440" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">保持</em> <code class="fe km kn ko kp b"><em class="iq">eventhubsuser: $ConnectionString</em></code> <em class="iq">不变</em></p></blockquote><p id="3374" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建<code class="fe km kn ko kp b">Secret</code>:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="3890" class="mu lf iq kp b gy nk nl l nm nn">kubectl apply -f eventhubs-secret.yaml</span></pre><p id="85ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">默认情况下，Kafka Connect被配置为向<code class="fe km kn ko kp b">stdout</code>发送日志。我们将使用一个定制配置(<code class="fe km kn ko kp b">log4j</code>)来确保日志被存储到<code class="fe km kn ko kp b">/tmp/connect-worker.log</code>(除了<code class="fe km kn ko kp b">stdout</code>)——您马上就会明白为什么要这样做</p><blockquote class="kq kr ks"><p id="1594" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">配置本身存储在</em>T4中</p></blockquote><p id="8042" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">日志配置可以存储在<code class="fe km kn ko kp b">ConfigMap</code>中，稍后Kafka Connect定义将引用该配置。详情请查看<a class="ae kl" href="https://strimzi.io/docs/latest/#con-kafka-connect-logging-deployment-configuration-kafka-connect" rel="noopener ugc nofollow" target="_blank">https://strim zi . io/docs/latest/# con-Kafka-connect-logging-deployment-configuration-Kafka-connect</a></p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="561f" class="mu lf iq kp b gy nk nl l nm nn">kubectl create configmap connect-logging-configmap --from-file=log4j.properties</span></pre><p id="d96b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们部署Kafka Connect之前，让我们看看它的定义。你可以在这里看到它的全部，但我会浏览重要的部分。</p><p id="29af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，资源<code class="fe km kn ko kp b">kind</code>是<code class="fe km kn ko kp b">KafkaConnect</code>——它是一个定制的资源定义。另一个有趣的部分是<code class="fe km kn ko kp b">annotations</code>(我稍后会对此进行解释)</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="d71d" class="mu lf iq kp b gy nk nl l nm nn">apiVersion: kafka.strimzi.io/v1beta1<br/>kind: KafkaConnect<br/>metadata:<br/>  name: my-connect-cluster<br/>  annotations:<br/>    strimzi.io/use-connector-resources: "true"</span></pre><p id="dc27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">bootstrapServers</code>指向一个卡夫卡经纪人。对于HA群集中的节点，这可能是一个逗号分隔的值。在这种情况下，它是Azure Event Hubs的一个Kafka端点(是的，这就是你所需要的！)</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="b2fb" class="mu lf iq kp b gy nk nl l nm nn">spec:<br/>  version: 2.4.0<br/>  replicas: 1<br/>  bootstrapServers: &lt;eventhubs-namespace&gt;.servicebus.windows.net:9093</span></pre><p id="0dbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">config</code>是一个不错的老式Kafka Connect配置，类似于您在<code class="fe km kn ko kp b"><a class="ae kl" href="https://kafka.apache.org/documentation/#connect_configuring" rel="noopener ugc nofollow" target="_blank">connect-distributed.properties</a></code>中使用的配置</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="d3fb" class="mu lf iq kp b gy nk nl l nm nn">config:<br/>    group.id: connect-cluster<br/>    offset.storage.topic: connect-cluster-offsets<br/>    config.storage.topic: connect-cluster-configs<br/>    status.storage.topic: connect-cluster-status</span></pre><p id="241e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">认证部分简单地引用了Kubernetes的秘密。在本例中，我们之前创建了一个名为<code class="fe km kn ko kp b">eventhubssecret</code>的服务，它的键<code class="fe km kn ko kp b">eventhubspassword</code>包含azure事件中心的连接字符串</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="2e7c" class="mu lf iq kp b gy nk nl l nm nn">authentication:<br/>    type: plain<br/>    username: $ConnectionString<br/>    passwordSecret:<br/>      secretName: eventhubssecret<br/>      password: eventhubspassword</span></pre><p id="b255" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是引用带有<code class="fe km kn ko kp b">log4j</code>配置的<code class="fe km kn ko kp b">ConfigMap</code>的地方。这将自动配置Kafka Connect使用此配置</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="8878" class="mu lf iq kp b gy nk nl l nm nn">logging:<br/>    type: external<br/>    name: connect-logging-configmap</span></pre><p id="7e2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe km kn ko kp b">tls</code>部分用于配置TLS证书(咄！).在事件中心的情况下，虽然我们使用<code class="fe km kn ko kp b">SASL</code>而不是<code class="fe km kn ko kp b">PLAINTEXT</code>，但是<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview?WT.mc_id=medium-blog-abhishgu#shared-access-signature-sas" rel="noopener ugc nofollow" target="_blank">要求您使用SSL </a>(即设置<code class="fe km kn ko kp b">security.protocol</code>为<code class="fe km kn ko kp b">SASL_SSL</code>)。我最初面对的<a class="ae kl" href="https://strimzi.io/docs/latest/#sasl_based_plain_authentication" rel="noopener ugc nofollow" target="_blank">是这个</a>的一个问题，这个问题很快就被澄清了！因此添加了这段配置:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="594f" class="mu lf iq kp b gy nk nl l nm nn">tls:<br/>    trustedCertificates: []</span></pre><p id="8b02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">酷！我们准备创建一个Kafka Connect实例。在此之前，确保用Azure Event Hubs主机名(例如</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="077b" class="mu lf iq kp b gy nk nl l nm nn">spec:<br/>  version: 2.4.0<br/>  replicas: 1<br/>  bootstrapServers: &lt;replace-with-eventhubs-namespace&gt;.servicebus.windows.net:9093</span></pre><p id="1552" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要创建Kafka Connect实例，请执行以下操作:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="499d" class="mu lf iq kp b gy nk nl l nm nn">kubectl apply -f kafka-connect.yaml</span></pre><p id="bba5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要确认:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="5a88" class="mu lf iq kp b gy nk nl l nm nn">kubectl get kafkaconnects</span><span id="ab8a" class="mu lf iq kp b gy no nl l nm nn">NAME                 DESIRED REPLICAS<br/>my-connect-cluster   1</span></pre><p id="5962" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将创建一个<code class="fe km kn ko kp b">Deployment</code>和一个相应的<code class="fe km kn ko kp b">Pod</code></p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="b89c" class="mu lf iq kp b gy nk nl l nm nn">kubectl get pod -l=strimzi.io/cluster=my-connect-cluster</span><span id="9214" class="mu lf iq kp b gy no nl l nm nn">NAME                                          READY   STATUS    RESTARTS   AGE<br/>my-connect-cluster-connect-5bf9db5d9f-9ttg4   1/1     Running   0          1h</span></pre><p id="c069" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您在Kubernetes拥有Kafka Connect集群！使用<code class="fe km kn ko kp b">kubectl logs &lt;pod name&gt;</code>查看日志</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="15c9" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">安装文件流源连接器</h1><p id="1051" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">让我们部署一个连接器！为了简单起见，我们将使用默认情况下与Kafka Connect捆绑在一起的文件流源连接器。安装和管理连接器的一种常见方式是使用Kafka Connect REST API，但是<code class="fe km kn ko kp b">Strimzi</code>提供了另一种方式。这是一种以Kubernetes为中心的方法，其中Kakfa Connect连接器由一个名为<code class="fe km kn ko kp b">KafkaConnector</code>的定制资源定义来表示。我们所需要做的就是创建/更新/删除带有连接器细节的<code class="fe km kn ko kp b">KafkaConnector</code>定义，剩下的事情由<code class="fe km kn ko kp b">Strimzi</code>来完成！</p><blockquote class="kq kr ks"><p id="7380" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">详见</em> <code class="fe km kn ko kp b"><em class="iq">Strimzi</em></code> <em class="iq">文档</em><a class="ae kl" href="https://strimzi.io/docs/latest/#con-creating-managing-connectors-str" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://strim zi . io/docs/latest/# con-creating-managing-connectors-str</em></a></p></blockquote><p id="1935" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们的连接器的定义是:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="6de3" class="mu lf iq kp b gy nk nl l nm nn">apiVersion: kafka.strimzi.io/v1alpha1<br/>kind: KafkaConnector<br/>metadata:<br/>  name: my-source-connector<br/>  labels:<br/>    strimzi.io/cluster: my-connect-cluster<br/>spec:<br/>  class: org.apache.kafka.connect.file.FileStreamSourceConnector<br/>  tasksMax: 2<br/>  config:<br/>    file: "/tmp/connect-worker.log"<br/>    topic: strimzi</span></pre><p id="413d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就像我们之前做的一样，让我们了解每个组件的含义:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="4f28" class="mu lf iq kp b gy nk nl l nm nn">apiVersion: kafka.strimzi.io/v1alpha1<br/>kind: KafkaConnector<br/>metadata:<br/>  name: my-source-connector</span></pre><p id="e4c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个名为<code class="fe km kn ko kp b">my-source-connector</code>的<code class="fe km kn ko kp b">KafkaConnector</code>资源(由<code class="fe km kn ko kp b">kind</code>指定)</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="3bf1" class="mu lf iq kp b gy nk nl l nm nn">labels:<br/>    strimzi.io/cluster: my-connect-cluster</span></pre><p id="af8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是我们提到Kafka Connect集群的地方——还记得上面显示的Kafka Connect定义中的注释吗？</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="225c" class="mu lf iq kp b gy nk nl l nm nn">annotations:<br/>    strimzi.io/use-connector-resources: "true"</span></pre><p id="d714" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这只是“激活”了这个特性，并确保我们能够使用<code class="fe km kn ko kp b">KafkaConnector</code> CRD部署连接器，我们只是使用<code class="fe km kn ko kp b">strimzi.io/cluster</code>标签来引用我们的<code class="fe km kn ko kp b">kafkaconnect</code>资源的名称</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="3b6b" class="mu lf iq kp b gy nk nl l nm nn">spec:<br/>  class: org.apache.kafka.connect.file.FileStreamSourceConnector<br/>  tasksMax: 2<br/>  config:<br/>    file: "/tmp/connect-worker.log"<br/>    topic: strimzi</span></pre><p id="518b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，在连接器规范中，我们定义了连接器的属性。注意指向<code class="fe km kn ko kp b">/tmp/connect-worker.log</code>文件的<code class="fe km kn ko kp b">config</code>属性？回想一下，我们修改了Kafka Connect实例，将日志推送到这个文件中。现在，我们已经配置了我们的文件源连接器来传输这个(日志)文件的内容，并将其发送到一个名为<code class="fe km kn ko kp b">strimzi</code>的Kafka主题。这是一个很好的演示，因为文件会不断更新，我们应该能够在目的地Kafka主题中看到每一行不同的消息(在Azure Event Hubs中)</p><blockquote class="kq kr ks"><p id="3856" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">我已经用了</em> <code class="fe km kn ko kp b"><em class="iq">strimzi</em></code> <em class="iq">作为题目名称。这需要与上一节中创建的事件中心相同(在设置Azure事件中心时)</em></p></blockquote><p id="0606" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了看到这一点，让我们部署连接器</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="90b2" class="mu lf iq kp b gy nk nl l nm nn">kubectl apply -f filestream-source-connector.yaml</span></pre><p id="d7f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要进行确认，只需列出连接器:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="97c4" class="mu lf iq kp b gy nk nl l nm nn">kubectl get kafkaconnectors</span><span id="f572" class="mu lf iq kp b gy no nl l nm nn">NAME                  AGE<br/>my-source-connector   70s</span></pre><blockquote class="kq kr ks"><p id="be10" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">您也可以安装其他连接器。实现这一点的方法之一(也是最简单的IMO)是扩展</em> <code class="fe km kn ko kp b"><em class="iq">Strimzi</em></code> <em class="iq">基础映像，并在其上添加所需的连接器构件。查看文档</em><a class="ae kl" href="https://strimzi.io/docs/latest/#using-kafka-connect-with-plug-ins-str" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://strim zi . io/docs/latest/# using-Kafka-connect-with-plug-ins-str</em></a></p></blockquote></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="b7c5" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">卡夫卡连接在行动…</h1><p id="0b22" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">首先，让我们确认Kafka Connect日志正在通过管道传输到预定的位置。这很重要，因为我们使用日志文件作为文件流连接器的来源。为此，我们需要窥视卡夫卡连接的内部。</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="1df3" class="mu lf iq kp b gy nk nl l nm nn">kubectl exec -it &lt;kafka_connect_pod_name&gt; -- tail -f /tmp/connect-worker.log</span></pre><p id="1274" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要简化这一过程，只需使用下面的命令:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="7f0c" class="mu lf iq kp b gy nk nl l nm nn">kubectl exec -it $(kubectl get pod -l=strimzi.io/cluster=my-connect-cluster -o jsonpath='{.items[0].metadata.name}') -- tail -f /tmp/connect-worker.log</span></pre><p id="8a00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，你应该看到Kafka连接日志…</p><p id="e771" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在不同的终端窗口中，启动连接到Azure Event Hubs主题的消费者流程。<a class="ae kl" href="https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/quickstart/kafkacat" rel="noopener ugc nofollow" target="_blank">我使用了</a> <code class="fe km kn ko kp b"><a class="ae kl" href="https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/quickstart/kafkacat" rel="noopener ugc nofollow" target="_blank">kafkacat</a></code>，但也有其他选项，如Kafka CLI本身的<a class="ae kl" href="https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/quickstart/kafka-cli" rel="noopener ugc nofollow" target="_blank">控制台消费者</a>或使用Java的<a class="ae kl" href="https://docs.microsoft.com/azure/event-hubs/apache-kafka-developer-guide?WT.mc_id=medium-blog-abhishgu#quickstarts-in-github" rel="noopener ugc nofollow" target="_blank">编程消费者。网，围棋等。</a>(尽管在这种情况下可能有点矫枉过正)</p><p id="fa62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您应该在这里看到相同的日志！例如</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="df5f" class="mu lf iq kp b gy nk nl l nm nn">...<br/>{"schema":{"type":"string","optional":false},"payload":"[2020-04-16 04:59:25,731] INFO WorkerSourceTask{id=my-source-connector-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)"}<br/>{"schema":{"type":"string","optional":false},"payload":"[2020-04-16 04:59:25,785] INFO WorkerSourceTask{id=my-source-connector-0} Finished commitOffsets successfully in 55 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)"}<br/>...</span></pre><blockquote class="kq kr ks"><p id="9082" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">日志本身作为</em> <code class="fe km kn ko kp b"><em class="iq">payload</em></code> <em class="iq">的一部分被捕获，例如</em> <code class="fe km kn ko kp b"><em class="iq">[2020-04-16 04:59:25,785] INFO WorkerSourceTask{id=my-source-connector-0} Finished commitOffsets successfully in 55 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)</em></code></p></blockquote><h2 id="7dd1" class="mu lf iq bd lg mv mw dn lk mx my dp lo jy mz na ls kc nb nc lw kg nd ne ma nf bi translated">管理Kafka Connect资源</h2><p id="dd8b" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">要横向扩展Kafka Connect，只需更新<code class="fe km kn ko kp b">spec</code>中的副本数量，例如从<code class="fe km kn ko kp b">1</code>到<code class="fe km kn ko kp b">2</code>，在本例中:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="5b64" class="mu lf iq kp b gy nk nl l nm nn">spec:<br/>  version: 2.4.0<br/>  replicas: 2</span></pre><p id="fa07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Appy更新后的清单</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="63d5" class="mu lf iq kp b gy nk nl l nm nn">kubectl apply -f kafka-connect.yaml</span></pre><blockquote class="kq kr ks"><p id="8c10" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">请确保通过更新清单而不是使用</em> <code class="fe km kn ko kp b"><em class="iq">kubectl scale</em></code> <em class="iq">更新</em> <code class="fe km kn ko kp b"><em class="iq">Deployment</em></code> <em class="iq">来增加副本的数量。这是因为，</em> <code class="fe km kn ko kp b"><em class="iq">Strimzi</em></code> <em class="iq">运算符协调循环将检查</em> <code class="fe km kn ko kp b"><em class="iq">KafkaConnect</em></code> <em class="iq">资源，发现</em> <code class="fe km kn ko kp b"><em class="iq">replicas</em></code> <em class="iq">计数是</em> <code class="fe km kn ko kp b"><em class="iq">1</em></code> <em class="iq">并缩放</em> <code class="fe km kn ko kp b"><em class="iq">Deployment</em></code> <em class="iq">回</em></p></blockquote><p id="f48e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在应该有两个<code class="fe km kn ko kp b">Pods</code>:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="cfd9" class="mu lf iq kp b gy nk nl l nm nn">kubectl get pod -l=strimzi.io/cluster=my-connect-cluster<br/></span><span id="c289" class="mu lf iq kp b gy no nl l nm nn">NAME                                          READY   STATUS    RESTARTS   AGE<br/>my-connect-cluster-connect-5bf9db5d9f-9ttg4   1/1     Running   0          45m<br/>my-connect-cluster-connect-5bf9db5d9f-pzn95   1/1     Running   0          1m5s</span></pre><blockquote class="kq kr ks"><p id="2415" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><code class="fe km kn ko kp b"><em class="iq">my-connect-cluster-connect-5bf9db5d9f-pzn95</em></code> <em class="iq">是新的</em> <code class="fe km kn ko kp b"><em class="iq">Pod</em></code></p></blockquote><p id="b813" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以更新连接器规格。例如，为了分配更多的任务，将<code class="fe km kn ko kp b">tasksMax</code>从<code class="fe km kn ko kp b">2</code>更新为<code class="fe km kn ko kp b">5</code></p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="ce38" class="mu lf iq kp b gy nk nl l nm nn">...<br/>spec:<br/>  class: org.apache.kafka.connect.file.FileStreamSourceConnector<br/>  tasksMax: 5<br/>...</span></pre><blockquote class="kq kr ks"><p id="7146" class="jn jo kt jp b jq jr js jt ju jv jw jx ku jz ka kb kv kd ke kf kw kh ki kj kk ij bi translated"><em class="iq">注意:这将重启连接器</em></p></blockquote></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="c515" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">打扫</h1><p id="2ba1" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy mr ka kb kc ms ke kf kg mt ki kj kk ij bi translated">要删除连接器和Kafka Connect实例，请执行以下操作:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="9179" class="mu lf iq kp b gy nk nl l nm nn">kubectl delete -f filestream-source-connector.yaml<br/>kubectl delete -f kafka-connect.yaml</span></pre><p id="cd62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要清理AKS集群和Azure事件中心，只需删除资源组:</p><pre class="md me mf mg gt ng kp nh ni aw nj bi"><span id="d3ba" class="mu lf iq kp b gy nk nl l nm nn">az group delete --name $AZURE_RESOURCE_GROUP --yes --no-wait</span></pre><p id="d5f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇博文到此结束！</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="605a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我提到的，Strimzi文档很详细，但是非常清晰，易于浏览。作为总结，除了我在文章中提到的内容之外，我还会从Strimzi文档中找到一些有用的参考资料:</p><h1 id="e886" class="le lf iq bd lg lh np lj lk ll nq ln lo lp nr lr ls lt ns lv lw lx nt lz ma mb bi translated">Strimzi文档参考</h1><ul class=""><li id="6277" class="nu nv iq jp b jq mp ju mq jy nw kc nx kg ny kk nz oa ob oc bi translated">配置Kafka Connect—<a class="ae kl" href="https://strimzi.io/docs/latest/#proc-configuring-kafka-connect-deployment-configuration-kafka-connect" rel="noopener ugc nofollow" target="_blank">https://strim zi . io/docs/latest/# proc-configuring-Kafka-Connect-deployment-configuration-Kafka-Connect</a></li><li id="1f72" class="nu nv iq jp b jq od ju oe jy of kc og kg oh kk nz oa ob oc bi translated"><code class="fe km kn ko kp b">KafkaConnect</code>模式<a class="ae kl" href="https://strimzi.io/docs/latest/#type-KafkaConnect-reference" rel="noopener ugc nofollow" target="_blank">https://strimzi.io/docs/latest/#type-KafkaConnect-reference</a></li><li id="81a9" class="nu nv iq jp b jq od ju oe jy of kc og kg oh kk nz oa ob oc bi translated"><code class="fe km kn ko kp b">KafkaConnector</code>模式引用<a class="ae kl" href="https://strimzi.io/docs/latest/#type-KafkaConnector-reference" rel="noopener ugc nofollow" target="_blank">https://strim zi . io/docs/latest/# type-KafkaConnector-reference</a></li><li id="af35" class="nu nv iq jp b jq od ju oe jy of kc og kg oh kk nz oa ob oc bi translated">Kafka <code class="fe km kn ko kp b">SASL</code>认证配置<a class="ae kl" href="https://strimzi.io/docs/latest/#sasl_based_plain_authentication" rel="noopener ugc nofollow" target="_blank">https://strim zi . io/docs/latest/# sasl _ based _ plain _ authentic ation</a></li></ul><p id="68ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望它对您在Kubernetes上开始使用Kafka Connect很有用:)</p></div></div>    
</body>
</html>