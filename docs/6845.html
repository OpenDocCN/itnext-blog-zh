<html>
<head>
<title>Troubleshooting Rook CephFS Mounting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Rook CephFS安装故障排除</h1>
<blockquote>原文：<a href="https://itnext.io/troubleshooting-rook-cephfs-mounting-6009e1130ec8?source=collection_archive---------1-----------------------#2022-03-20">https://itnext.io/troubleshooting-rook-cephfs-mounting-6009e1130ec8?source=collection_archive---------1-----------------------#2022-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/22d6d4302d918b3c5ce3f9903aaeb0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwGPRM5GYh8oCztuaBFPYA.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">图片来自<a class="ae kf" href="https://pixabay.com/users/oadtz-3657813/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1862077" rel="noopener ugc nofollow" target="_blank">Thanapat pimphol</a>来自<a class="ae kf" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1862077" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><p id="294c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在设置最新的轮班。像往常一样，我使用Rook操作符来提供私有注册中心所需的存储。RWX (ReadWriteMany)访问持久性卷是通过使用CephFS存储类实现的。</p><p id="c56b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">克隆最新的Rook存储库，设置操作符，创建Rook集群和存储类，创建PVC，将其分配给私有注册表。一切进展顺利，所有的车舱都在运行，存储类已创建，PVC已绑定。但是注册表窗格在长时间等待后无法运行。</p><p id="2450" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过描述pod来检查pod事件，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="77b7" class="ln lo it lj b gy lp lq l lr ls">oc -n openshift-image-registry describe pods image-registry-c45fcf748-szrnq</span><span id="6a20" class="ln lo it lj b gy lt lq l lr ls">...<br/> Warning  FailedMount             58s                  kubelet                  <strong class="lj iu">MountVolume.MountDevice failed </strong>for volume "pvc-0787c032-46a8-4e2a-9c74-38d592cbb550" : rpc error: code = Internal desc = an error (exit status 32) occurred while running mount args: [-t ceph 172.30.129.111:3300,172.30.139.94:3300,172.30.254.66:3300:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00 /var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-0787c032-46a8-4e2a-9c74-38d592cbb550/globalmount -o name=csi-cephfs-node,secretfile=/tmp/csi/keys/keyfile-3975689489,mds_namespace=rook-cephfs,_netdev] stderr: mount error 110 = Connection timed out</span></pre><p id="f763" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">挂载失败。但是让我们确认其余的工作正常。</p><h2 id="2c69" class="ln lo it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">验证车</h2><p id="7e6c" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">运行<code class="fe mq mr ms lj b">oc -n rook-ceph get pods</code>以确认所有的pod正在运行并准备就绪。</p><p id="a262" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Exec进入工具舱检查ceph状态，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="088e" class="ln lo it lj b gy lp lq l lr ls">oc exec -it rook-ceph-tools-d6d7c985c-mn8hr -- ceph status<br/>  cluster:<br/>    id:     f0f2a152-ece9-491d-a45b-2f60a439c16a<br/>    health: HEALTH_OK</span><span id="14d6" class="ln lo it lj b gy lt lq l lr ls">  services:<br/>    mon: 3 daemons, quorum a,b,c (age 3d)<br/>    mgr: a(active, since 3d)<br/>    mds: 1/1 daemons up, 1 hot standby<br/>    osd: 3 osds: 3 up (since 3d), 3 in (since 3d)</span><span id="84d0" class="ln lo it lj b gy lt lq l lr ls">  data:<br/>    volumes: 1/1 healthy<br/>    pools:   4 pools, 97 pgs<br/>    objects: 27 objects, 119 KiB<br/>    usage:   22 MiB used, 450 GiB / 450 GiB avail<br/>    pgs:     97 active+clean</span><span id="97e8" class="ln lo it lj b gy lt lq l lr ls">  io:<br/>    client:   1.2 KiB/s rd, 2 op/s rd, 0 op/s wr</span></pre><p id="0448" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来Rook/ Ceph运行良好。</p><h2 id="1b1a" class="ln lo it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">验证安装</h2><p id="93f1" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">pod的错误消息表明错误出在“mount”命令上。让我们测试挂载本身，如pod事件所示</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="cc71" class="ln lo it lj b gy lp lq l lr ls">[-t ceph 172.30.129.111:3300,172.30.139.94:3300,172.30.254.66:3300:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00 /var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-0787c032-46a8-4e2a-9c74-38d592cbb550/globalmount -o name=csi-cephfs-node,secretfile=/tmp/csi/keys/keyfile-3975689489,mds_namespace=rook-cephfs,_netdev]</span></pre><p id="f22c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">描述PVC的相应PV，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="1ca9" class="ln lo it lj b gy lp lq l lr ls">$ oc describe pv pvc-0787c032-46a8-4e2a-9c74-38d592cbb550<br/>Name:            pvc-0787c032-46a8-4e2a-9c74-38d592cbb550<br/>Labels:          &lt;none&gt;<br/>Annotations:     pv.kubernetes.io/provisioned-by: rook-ceph.cephfs.csi.ceph.com<br/>Finalizers:      [kubernetes.io/pv-protection]<br/>StorageClass:    rook-cephfs<br/>Status:          Bound<br/>Claim:           openshift-image-registry/pvc-image-registry<br/>Reclaim Policy:  Delete<br/>Access Modes:    RWX<br/>VolumeMode:      Filesystem<br/>Capacity:        200Gi<br/>Node Affinity:   &lt;none&gt;<br/>Message:<br/>Source:<br/>    Type:              CSI (a Container Storage Interface (CSI) volume source)<br/>    Driver:            rook-ceph.cephfs.csi.ceph.com<br/>    FSType:<br/>    VolumeHandle:      0001-0009-rook-ceph-0000000000000001-0c0965ad-a826-11ec-8b93-0a580a80020f<br/>    ReadOnly:          false<br/>    VolumeAttributes:      clusterID=rook-ceph<br/>                           fsName=rook-cephfs<br/>                           pool=rook-cephfs-data0<br/>                                    storage.kubernetes.io/csiProvisionerIdentity=1647491897305-8081-rook-ceph.cephfs.csi.ceph.com<br/>                           subvolumeName=csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f<br/>                           subvolumePath=/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00<br/>Events:                &lt;none&gt;</span></pre><p id="f4c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">子卷路径与pod事件中的mount命令相匹配。</p><p id="30d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们通过测试mount命令，在运行pod的节点上对它进行测试。</p><p id="ff57" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在此之前，先拿到Ceph的证书。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f240" class="ln lo it lj b gy lp lq l lr ls">$ oc exec -it rook-ceph-tools-d6d7c985c-mn8hr -- ceph auth ls<br/>mds.rook-cephfs-a<br/> key: AQCVvDJi1uQGNhAAuOt9w4pSNUmbVZWDD+DFAA==<br/> caps: [mds] allow<br/> caps: [mon] allow profile mds<br/> caps: [osd] allow *<br/>...<br/>client.admin<br/> key: <strong class="lj iu">AQD9ujJiKPRqMRAA2a65UJMMV844FgSFNrrKAQ==</strong><br/> caps: [mds] allow *<br/> caps: [mgr] allow *<br/> caps: [mon] allow *<br/> caps: [osd] allow *<br/>...</span></pre><p id="29ce" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以使用<code class="fe mq mr ms lj b">ceph auth print-key client.admin</code>来打印出密钥。</p><p id="6ee6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">登录到运行pods的节点，sudo到root，运行mount命令，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="502b" class="ln lo it lj b gy lp lq l lr ls">[core@dev-410-worker2 ~]$ sudo -i<br/># mkdir -p /mnt/ceph<br/># mount -t ceph 172.30.129.111:3300,172.30.139.94:3300,172.30.254.66:3300:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00 /mnt/ceph -o name=admin,secret=AQD9ujJiKPRqMRAA2a65UJMMV844FgSFNrrKAQ==</span></pre><p id="ce39" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该命令的输出是，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ed3c" class="ln lo it lj b gy lp lq l lr ls">mount: /var/mnt/ceph: mount(2) system call failed: Connection timed out.</span></pre><p id="42a7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同时，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f91b" class="ln lo it lj b gy lp lq l lr ls"># dmesg | tail -f<br/>[284657.294544] libceph: mon0 (1)172.30.129.111:3300 socket closed (con state V1_BANNER)<br/>[284658.318751] libceph: mon1 (1)172.30.139.94:3300 socket closed (con state V1_BANNER)<br/>[284658.582452] libceph: mon1 (1)172.30.139.94:3300 socket closed (con state V1_BANNER)<br/>[284659.095492] libceph: mon1 (1)172.30.139.94:3300 socket closed (con state V1_BANNER)<br/>[284660.302497] libceph: mon1 (1)172.30.139.94:3300 socket closed (con state V1_BANNER)<br/>[284661.326709] libceph: mon2 (1)172.30.254.66:3300 socket closed (con state V1_BANNER)<br/>[284661.590463] libceph: mon2 (1)172.30.254.66:3300 socket closed (con state V1_BANNER)<br/>[284662.102229] libceph: mon2 (1)172.30.254.66:3300 socket closed (con state V1_BANNER)<br/>[284663.310139] libceph: mon2 (1)172.30.254.66:3300 socket closed (con state V1_BANNER)<br/>[284664.205628] ceph: No mds server is up or the cluster is laggy</span></pre><p id="97f5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">端口阻塞？验证连接，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="de42" class="ln lo it lj b gy lp lq l lr ls"># curl 172.30.129.111:3300<br/>ceph v2<br/>Warning: Binary output can mess up your terminal. Use "--output -" to tell<br/>Warning: curl to output it to your terminal anyway, or consider "--output<br/>Warning: &lt;FILE&gt;" to save to a file.</span></pre><p id="386f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">连接很好。由于rook集群处于健康状态，连接也没有被阻塞，所以问题更可能出在客户端。</p><p id="41ef" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">错误<code class="fe mq mr ms lj b">mon2 (1)172.30.254.66:3300 socket closed (con state V1_BANNER)</code>似乎表明其使用V1旗帜。而3300端口在V2是相对较新的东西。让我们转到V1港6789，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="aeca" class="ln lo it lj b gy lp lq l lr ls">mount -t ceph 172.30.129.111:6789,172.30.139.94:6789,172.30.254.66:6789:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00 /mnt/ceph -o name=admin,secret=AQD9ujJiKPRqMRAA2a65UJMMV844FgSFNrrKAQ==</span></pre><p id="02d8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">命令立即返回，没有任何错误，这可以用</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="5faf" class="ln lo it lj b gy lp lq l lr ls"># df -h /mnt/ceph<br/>Filesystem                                                                                                                                                Size  Used Avail Use% Mounted on<br/>172.30.129.111:6789,172.30.139.94:6789,172.30.254.66:6789:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00  200G     0  200G   0% /var/mnt/ceph</span></pre><h2 id="401a" class="ln lo it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">修复</h2><p id="361b" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">要修复它，我们需要将端口从V2(3300)改回V1 (6789)。但是通过查看ceph <a class="ae kf" href="https://docs.ceph.com/en/latest/man/8/mount.ceph/#basic" rel="noopener ugc nofollow" target="_blank"> mount命令</a>的手册，我们找到了一个选项<code class="fe mq mr ms lj b">ms_mode</code>来指定消息的V1或V2格式。用V2选项进行测试，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="9ae7" class="ln lo it lj b gy lp lq l lr ls">mount -t ceph 172.30.129.111:3300,172.30.139.94:3300,172.30.254.66:3300:/volumes/csi/csi-vol-0c0965ad-a826-11ec-8b93-0a580a80020f/269b71dd-1dd4-4ee0-961d-10831f05fd00 /mnt/ceph -o name=admin,secret=AQD9ujJiKPRqMRAA2a65UJMMV844FgSFNrrKAQ==,ms_mode=crc</span></pre><p id="7848" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CephFS已成功装载。</p><p id="2076" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Kubernetes中，可以在StorageClass定义中添加CephFS挂载选项，</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="85bb" class="ln lo it lj b gy lp lq l lr ls">apiVersion: storage.k8s.io/v1<br/>kind: StorageClass<br/>metadata:<br/>  name: rook-cephfs<br/>provisioner: rook-ceph.cephfs.csi.ceph.com<br/>parameters:<br/>  clusterID: rook-ceph<br/>  fsName: rook-cephfs<br/>  <br/>  pool: rook-cephfs-data0<br/>  <strong class="lj iu">kernelMountOptions: "ms_mode=crc"</strong><br/>  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner<br/>  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph<br/>  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner<br/>  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph<br/>  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node<br/>  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph<br/>reclaimPolicy: Delete</span></pre><p id="667b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重新创建此存储类，重新创建PVC ( <code class="fe mq mr ms lj b"><em class="mt">need to edit the PVC to delete the finalizers</em></code>)，删除pod。现在，卷已连接，并且pod已成功运行。</p><p id="1d2b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">小贴士:</p><p id="967f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">验证“rook-ceph-csi-config”的配置图，找出监视器使用的默认端口。</p></div></div>    
</body>
</html>