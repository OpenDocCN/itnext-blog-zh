<html>
<head>
<title>18 Tips for Training your own Tensorflow.js Models in the Browser</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在浏览器中训练自己的Tensorflow.js模型的18个技巧</h1>
<blockquote>原文：<a href="https://itnext.io/18-tips-for-training-your-own-tensorflow-js-models-in-the-browser-3e40141c9091?source=collection_archive---------0-----------------------#2018-10-01">https://itnext.io/18-tips-for-training-your-own-tensorflow-js-models-in-the-browser-3e40141c9091?source=collection_archive---------0-----------------------#2018-10-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c12e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用Tensorflow.js训练高效的Web图像分类器和对象检测器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0072d5453642af6744026c47d0657dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ABPTTdDwnseUDPsYIVFqCQ.jpeg"/></div></div></figure><p id="3841" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在移植了现有的对象检测、人脸检测、人脸识别和什么不要<a class="ae ln" href="https://github.com/tensorflow/tfjs" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> tensorflow.js </strong> </a>的模型后，我发现一些模型没有表现出最佳性能，而其他模型在浏览器中的表现则相当不错。如果你想到浏览器内机器学习的潜力以及tensorflow.js等库为我们web开发人员提供的所有可能性，这实际上有点令人惊讶。</p><p id="2e54" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然而，随着深度学习模型直接在浏览器中运行，我们也面临着一些现有模型的新挑战和限制，这些模型可能不是专门为在浏览器中运行客户端而设计的，更不用说在移动浏览器中了。就拿最先进的物体检测器作为例子:它们通常需要大量的计算资源来以合理的fps运行，更不用说实时速度了。此外，在一个简单的web应用程序中，将100MB以上的模型权重下载到客户端浏览器是完全不可行的。</p><h1 id="a50d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">为网络训练有效的深度学习模型</h1><p id="d323" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">但是希望最后消失！让我告诉你，我们能够公平地构建和训练<strong class="kt ir">体面的模型</strong>，通过考虑一些基本原则，这些模型被优化用于在网络环境中运行。信不信由你:我们实际上可以训练出相当不错的图像分类——甚至是物体检测模型，这些模型最终只有<strong class="kt ir">几兆字节</strong>大小，甚至<strong class="kt ir">只有几千字节</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/6342a1f9c237868aac87f22256ad6621.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*uQ2e-GhqAxNzJk3mmySs9w.png"/></div></figure><p id="0285" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇文章中，我想给你一些开始训练你自己的卷积神经网络(CNN)的一般技巧，但也有一些技巧，直接针对在浏览器中用tensorflow.js为web和移动设备训练CNN。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/3df4b77b57de5e17cc684ef8b6727daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Q5SBIQusgK24WBHWWtdi_Q.jpeg"/></div></figure><p id="14f4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在你可能会想:为什么我要在浏览器中用tensorflow.js训练我的模型，而我可以在我的机器上用tensorflow简单地训练它们？当然你可以这么做，前提是你的机器配备了NVIDIA卡。浏览器内深度学习框架的一个巨大优势是:你不需要NVIDIA GPU来训练一个模型。在发现tensorflow.js之后，这真的是我第一次能够在我的AMD GPU上训练深度学习模型。</p><p id="7e62" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，如果你的机器配备了NVIDIA卡，你可以简单地采用标准tensorflow方法(在这种情况下，你可以用python编写你的训练代码，或者你也可以使用<a class="ae ln" href="https://github.com/tensorflow/tfjs-node" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> tfjs-node </strong> </a>包装器并坚持使用tfjs ),忽略浏览器特定的提示。但是现在，让我们开始吧！</p><h1 id="e64a" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">网络体系结构</h1><p id="becd" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在开始训练我们自己的图像分类器、对象检测器或其他东西之前，我们显然必须首先实现一个网络架构。经常有人建议选择现有的架构，比如<strong class="kt ir"> Yolo </strong>、<strong class="kt ir"> SSD </strong>、<strong class="kt ir"> ResNet </strong>、<strong class="kt ir"> MobileNet </strong>等。已经被证明是可行的。</p><p id="43a3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就个人而言，我认为在您自己的体系结构中使用那些体系结构所采用的一些概念是有价值的。然而，正如我最初指出的那样，在我看来，简单地采用这些架构不会使它适用于web，因为我们希望我们的模型尺寸<strong class="kt ir">小</strong>，<strong class="kt ir">推理快</strong>(理想情况下是实时的)并且尽可能<strong class="kt ir">易于训练</strong>。</p><p id="4538" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">无论你是想改造现有的架构，还是完全从头开始，我都想给你以下的建议，这些建议对我设计高效的网络CNN架构帮助很大:</p><h2 id="9097" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">1.从小型网络架构开始！</h2><p id="7584" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">请记住，我们的网络越小，在解决我们的问题时仍能达到良好的准确性，它在推理时的执行速度就越快，客户端下载和缓存该模型就越容易。此外，较小的模型具有较少的参数，因此在训练时会收敛得更快。</p><p id="910d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您发现您当前的网络架构性能不太好，或者没有达到您希望的精度水平，您仍然可以逐步增加网络的规模，例如，通过增加每层卷积滤波器的数量，或者通过堆叠更多层来使您的网络更深。</p><h2 id="717e" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">2.使用深度方向可分离卷积！</h2><p id="79b0" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">既然我们正在训练一个新的模型，我们肯定希望在普通2D卷积上使用深度方向可分卷积。深度方向可分离卷积将常规卷积运算拆分为深度方向卷积和点方向(1×1)卷积。与常规卷积运算相比，它们具有更少的参数，从而导致更少的浮点运算，并且更容易并行化，这意味着推理将更快(我甚至看到通过简单地将常规卷积替换为深度方向可分离的卷积，推理的速度提高了高达<strong class="kt ir">10倍</strong>)并且消耗的资源更少(这可以大大提高移动设备的性能)。此外，因为它们的参数较少，所以训练它们所需的时间也较少。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/8c72fad105d3c498141d09b88014a6a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKEaitLzL73W0r-cZQc1ag.png"/></div></div></figure><p id="e3f1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">深度方向可分离卷积的思想被用于<strong class="kt ir"> MobileNet </strong>和<strong class="kt ir">exception</strong>中，例如，你可以在tensorflow.js模型中找到它们。深度方向可分卷积是否会导致不太精确的模型可能是一个公开的争论，但是从我的经验来看，它们绝对是web(和移动)模型的必由之路。</p><p id="aee6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">长话短说:我建议在你的第一层中使用常规的<strong class="kt ir"> <em class="na"> conv2d </em> </strong>操作，它通常没有太多的参数，以保持提取的特征中RGB通道之间的关系。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="9edb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于其余的卷积，只需采用深度方向可分的卷积。因此，我们将得到一个<strong class="kt ir"> <em class="na"> 3 x 3 x通道_in x 1 </em> </strong>深度方向过滤器和一个<strong class="kt ir"> <em class="na"> 1 x 1 x通道_in x通道_out </em> </strong> <em class="na"> </em>点方向过滤器，而不是一个内核。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="a3c3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们不使用形状为<strong class="kt ir">【3，3，32，64】</strong>的<strong class="kt ir"> <em class="na"> tf.conv2d </em> </strong>，而是简单地使用形状为<strong class="kt ir">【3，3，32，1】<strong class="kt ir">【1，1，32，64】</strong>的<strong class="kt ir"><em class="na">TF . separableconv2d</em></strong></strong></p><h2 id="d695" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">3.跳过连接和密集连接的块</h2><p id="725d" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一旦我决定建立更深层次的网络，我很快就面临训练神经网络最常见的问题之一:消失梯度问题。经过一段时间后，损失只会以非常小的步长减少，这要么导致训练时间长得离谱，要么导致模型根本不收敛。</p><p id="a461" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">ResNet和DenseNet中采用的跳过连接允许构建更深层次的架构，同时减轻消失梯度问题。我们所要做的就是在应用激活函数之前，将先前层的输出添加到位于我们网络更深处的层的输入中，<strong class="kt ir">:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/df583f86211670735e98e2910dcb92c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Vhd39FU4B-ZDmRQ2m-fPA.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk translated">跳过连接</figcaption></figure><p id="1948" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">跳过连接是可行的，因为通过快捷方式连接层，我们至少可以学习标识函数。这项技术背后的直觉是，梯度不必仅通过卷积(或全连接)层反向传播，一旦梯度到达网络的早期层，就会导致梯度减弱。他们可以通过跳过连接的添加操作来“跳过”层。</p><p id="a37d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">显然，这样做的一个要求是，假设您想要连接层A和层B，A的输出形状必须与B的输入形状匹配。如果您想要构建剩余或密集连接的块，只需确保在该块的卷积中保持<strong class="kt ir">相同数量的过滤器</strong>，并保持<strong class="kt ir">步长为1 </strong>，填充<strong class="kt ir">相同</strong>。顺便提一下，也有不同的方法，要么填充A的输出，使其与输入B的形状相匹配，要么连接先前图层的特征地图，使连接图层的深度再次匹配。</p><p id="b2ad" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">起初，我使用了一种类似ResNet的方法，简单地在每隔一层之间引入一个跳过连接，如上图所示，但很快就发现，密集连接的块工作得更好，并极大地减少了模型达到收敛所需的时间:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/bec6d6da12f84367f2f642049a029b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nh9mdv_YeOjD-VWS-dbJMQ.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk translated">Denseblock的草图</figcaption></figure><p id="0435" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面是一个密集块实现的例子，我用它作为<a class="ae ln" href="https://github.com/justadudewhohacks/face-api.js/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> face-api.js </strong> </a>的68点人脸标志检测器的基本构建块。这些块中的一个包括4个深度方向可分离的卷积层(注意，第一个密集块的第一个卷积是常规卷积)，每个块的第一个卷积运算使用步长2来缩小输入:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h2 id="c983" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">4.使用ReLU类型的激活函数！</h2><p id="ea38" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">除非你有特别的理由使用其他类型的激活函数，否则我会简单地使用<strong class="kt ir"> <em class="na"> tf.relu </em> </strong>。原因很简单，ReLU类型的激活函数有助于缓解渐变消失的问题。</p><p id="ad6e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您还可以尝试ReLU的变体，例如Yolo架构中正在使用的<strong class="kt ir"> leaky ReLU、</strong>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="0338" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或Mobilenet采用的<strong class="kt ir"> ReLU-6 </strong>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="0d71" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">培养</h1><p id="140a" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一旦我们有了一个初始的架构，我们就可以开始训练我们的模型。</p><h2 id="2c1e" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">5.如果有疑问，只需使用亚当优化！</h2><p id="fdd5" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">当我第一次开始训练自己的模型时，我想知道，哪个优化器最好？我从使用普通的<strong class="kt ir"> SGD </strong>开始，它似乎有时会陷入局部最小值，甚至导致爆炸梯度，导致模型权重无限增长，最终导致NaNs。</p><p id="5d32" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我并不是说<strong class="kt ir"> Adam </strong>是解决所有问题的最佳选择，但是我发现这是训练新模型的最简单和最健壮的方法，只需使用Adam的默认参数和学习率<strong class="kt ir"> 0.001 </strong>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h2 id="3151" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">6.调整学习速度</h2><p id="0b05" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一旦损失不再大幅减少，我们的模型就有可能收敛(或停滞)并且无法进一步学习。在这一点上，我们还不如停止训练过程，以防止我们的模型过度拟合(或者尝试不同的架构)。</p><p id="94c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然而，也有可能，你可以通过调整(降低)此时的学习率，从训练过程中挤出更多的数字。特别是如果在训练集上计算的总损失开始<strong class="kt ir">振荡</strong>(上下跳动)，这是一个指标，表明尝试降低学习率可能是一个好主意。</p><p id="16d8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面是一个示例，显示了训练68点人脸标志模型时的总体误差图。在时期46，损失值开始振荡。如您所见，从第46个时期的检查点继续训练10个时期，学习率为<strong class="kt ir"> 0.0001 </strong>而不是<strong class="kt ir"> 0.001，</strong>我能够进一步降低整体误差:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/8c740623378e5f6a46478043a1a7751d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ef_dtkBBvJQ-2HmZKjDaew.png"/></div></div></figure><h2 id="ed4b" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">7.重量初始化</h2><p id="8480" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">如果您不知道如何正确初始化您的模型权重(就像我开始时没有任何想法一样):作为一个简单的经验法则，用零(<strong class="kt ir"><em class="na">TF . zeros(shape)</em></strong>)初始化您的所有偏差，用非零值初始化您的权重(卷积的核和完全连接层的权重)，从某种正态分布中提取。例如，你可以简单地使用<strong class="kt ir"><em class="na">TF . random normal(shape)</em></strong>，但是现在我更喜欢使用<strong class="kt ir"> glorot正态分布</strong>，它在<strong class="kt ir"> tfjs-layers </strong>中可用，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h2 id="d4c3" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">8.打乱你的输入！</h2><p id="efd9" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">训练神经网络的一个常见建议是，通过在每个时期开始时洗牌，使训练样本的出现顺序随机化。为了方便起见，我们可以使用<strong class="kt ir"><em class="na">TF . utils . shuffle</em></strong>来实现这一目的，它将随机排列一个任意的数组:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h2 id="11b8" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">9.使用FileSaver.js保存模型检查点</h2><p id="0157" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">由于我们正在浏览器中训练我们的模型，您现在可能会问自己:我们如何在训练时自动保存模型权重的检查点？我们简单的用<a class="ae ln" href="https://github.com/eligrey/FileSaver.js" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> FileSaver.js </strong> </a>。该脚本公开了一个名为<strong class="kt ir"> <em class="na"> saveAs </em> </strong>的函数，我们可以使用它来存储任意类型的文件，这些文件将最终保存在我们的下载文件夹中。</p><p id="75e6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这样我们可以节省模型重量:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="f9d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或者甚至是json文件，例如保存一个时期的累积损失:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="6f05" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">解决纷争</h1><p id="1d99" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在花大量时间训练您的模型之前，您希望确保您的模型实际上正在学习它应该做的事情，并消除任何潜在的错误和缺陷。如果你不考虑下面的建议，你可能最终会浪费时间去训练完全的垃圾，并且你最终会疑惑:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/6ce91f07690a95301ea85189effdceae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7uWQS3Z6DMQWWdm9IiQBow.jpeg"/></div></figure><h2 id="9cc6" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">10.检查您的输入数据，预处理和后处理逻辑！</h2><p id="ec32" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">如果你把垃圾传入你的网络，它会把垃圾扔回给你。因此，请确保输入数据标注正确，并且网络输入符合您的预期。特别是如果你已经实现了一些预处理逻辑，如随机裁剪、填充、平方、居中、均值减法或其他，确保在预处理后可视化你的输入<strong class="kt ir">。我也强烈建议对这些步骤进行单元测试。当然，后期处理也是如此！</strong></p><p id="f8e5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我知道这听起来像一个乏味的额外工作，但它是值得的！你不会相信，我花了多少时间试图弄清楚，为什么我的对象检测器根本没有学会检测人脸，直到我最终发现我的预处理逻辑由于不正确的裁剪和扭曲而将输入变成垃圾。</p><h2 id="d73f" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">11.检查你的损失函数！</h2><p id="eedb" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">现在大多数情况下tensorflow.js很幸运的为你提供了你需求的损失函数。但是，万一你需要实现自己的损失函数，你一定要对它进行单元测试！不久前，我使用tfjs-core API实现了Yolo v2 loss函数，为web训练Yolo对象检测器。让我告诉你，这可能会变得非常棘手，除非你分解问题，并确保各个组件计算出它们应该做的事情。</p><h2 id="080d" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">12.首先在小数据集上过度拟合！</h2><p id="4758" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一般来说，对训练数据的一个小子集进行过度拟合是一个好主意，以验证损失正在收敛，并且您的模型实际上正在学习一些有用的东西。因此，您应该简单地从您的训练数据中挑选<strong class="kt ir"> 10到20张图像</strong>，并训练一些时期。一旦损失收敛，对这10到20个图像进行推理并可视化结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/29841fbc798ac8de751d7873abc97414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*w3TWyVbZR8zSCgeEhLwezA.gif"/></div></figure><p id="c130" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是一个非常重要的步骤，它将帮助您消除网络实现、预处理和后处理逻辑中的各种错误来源，因为您的模型不太可能在代码中存在大量错误的情况下学会做出所需的预测。</p><p id="02d8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">特别是，如果你正在实现你自己的损失函数。)你一定要确保你的模型在开始训练之前能够收敛！</p><h1 id="7361" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">表演</h1><p id="3e49" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">最后，我想给你一些建议，通过考虑一些基本原则，这将帮助你尽可能地减少训练时间，并防止你的浏览器因内存泄漏而崩溃。</p><h2 id="abcb" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">13.防止明显的内存泄漏</h2><p id="7ae0" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">除非您对tensorflow.js完全陌生，否则您可能已经知道，我们必须通过调用<strong class="kt ir"> <em class="na"> tensor.dispose() </em> </strong>或在<strong class="kt ir"> <em class="na"> tf.tidy </em> </strong>块中包装我们的操作来手动处理未使用的张量以释放它们的内存。确保没有因为没有正确处理张量而导致的内存泄漏，否则你的应用程序迟早会耗尽内存。</p><p id="003d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">识别这些类型的内存泄漏非常容易。只需记录几次迭代的<strong class="kt ir"> <em class="na"> tf.memory() </em> </strong>即可验证张量的数量不会因每次迭代而意外增加:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/9711f574bf31d14388ca0716f4ba86d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*DQUsPpbAg1oE9KaWrPDZVA.png"/></div></figure><h2 id="ff3b" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">14.调整你的画布，而不是你的张量！</h2><p id="e86b" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">请注意，以下语句仅在tfjs-core的当前状态下有效(我目前使用的是tfjs-core版本0.12.14 ),直到这个问题最终得到解决。</p><p id="dd99" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我知道这听起来可能有点奇怪:为什么不使用<strong class="kt ir"><em class="na">TF . resize双线性</em> </strong> <em class="na">，</em> <strong class="kt ir"> <em class="na"> tf.pad </em> </strong>等来将你的输入张量重塑成你想要的网络输入形状呢？tfjs目前有一个公开的<a class="ae ln" href="https://github.com/tensorflow/tfjs/issues/604" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">问题</strong> </a>，说明了这个问题。</p><p id="34fe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> TLDR </strong>:在调用<strong class="kt ir"><em class="na">TF . from pixels</em></strong>之前，为了将你的画布转换为张量，调整你的画布的大小，使它们具有你的网络可接受的大小，否则你会很快耗尽GPU内存，这取决于你的训练数据中图像的各种不同输入大小。如果您的训练图像大小相等，这就不是什么问题，但是如果您必须明确地调整它们的大小，您可以使用下面的代码片段:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h2 id="e1a1" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">15.计算出最佳批量</h2><p id="21a1" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">不要过分批量处理你的输入！尝试不同的批量大小，并测量反向传播所需的时间。显然，最佳批量取决于您的GPU统计数据、输入大小以及网络的复杂性。在某些情况下，你根本不想批量输入。</p><p id="5249" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，如果有疑问，我总是选择批量为1。就我个人而言，我发现在某些情况下增加批处理大小并不能真正帮助提高性能，但在其他情况下，我可以看到在一个相当小的网络大小下，通过创建大小为<strong class="kt ir"> 16 </strong>到<strong class="kt ir"> 24 </strong>的批处理，输入图像大小为<strong class="kt ir"> 112 x 112像素</strong>，总体加速大约为<strong class="kt ir"> 1.5到2.0 </strong>倍。</p><h2 id="0fd6" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">16.缓存，脱机存储，索引数据库</h2><p id="2de4" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们的训练图像(和标签)可能相当大，可能高达1GB甚至更多，这取决于图像的大小和数量。由于我们不能简单地在浏览器中从磁盘读取图像，我们将使用文件代理，这可能是一个简单的express服务器，来托管我们的训练数据，浏览器将获取每个单独的数据项。</p><p id="b90a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">显然，这是非常低效的，但我们在浏览器中训练时必须记住这一点。如果您的数据集足够小，您可能会尝试将所有数据保存在内存中，但这显然也不是很有效。最初，我试图增加浏览器缓存大小，以简单地缓存磁盘上的全部数据，但这在Chrome的后续版本中似乎不再有效，我在FireFox上也没有运气。</p><p id="064c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我决定使用<strong class="kt ir"> Indexeddb </strong>，这是一个浏览器数据库，以防你不熟悉，我们可以利用它来存储我们的整个训练和测试数据集。开始使用Indexeddb非常简单，因为我们只需要几行代码就可以将整个数据作为键值存储来存储和查询。使用Indexeddb，我们可以方便地将标签存储为普通的json对象，将图像数据存储为blobs。查看这篇<a class="ae ln" href="https://hacks.mozilla.org/2012/02/storing-images-and-files-in-indexeddb/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">博客文章</strong> </a> <strong class="kt ir">，</strong>，它很好地解释了如何在Indexeddb中持久保存图像数据和其他文件。</p><p id="ddd1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">查询Indexeddb非常快，至少我发现查询每个数据项比一次又一次地从代理获取文件要快得多。另外，在将你的数据转移到Indexeddb之后，现在训练在技术上完全离线工作，这意味着我们可能不再需要代理服务器。</p><h2 id="f206" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">17.异步损失报告</h2><p id="30d5" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">这是一个简单但非常有效的技巧，它帮助我在训练时减少了很多迭代次数。主要思想是，如果我们想要检索由<strong class="kt ir"><em class="na">optimizer . minimize</em></strong>返回的损失张量的值，我们当然会这样做，因为我们想要在训练时跟踪我们的损失，我们想要避免等待由<strong class="kt ir"> <em class="na"> loss.data() </em> </strong>返回的承诺，以防止在每次迭代中等待CPU和GPU同步。相反，我们想要做类似下面这样的事情来报告迭代的损失值:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="3c66" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们只需记住，我们的损失现在是异步报告的，所以如果我们想在每个时期结束时将总损失保存到一个文件中，我们将不得不等待最后的承诺解决，然后再这样做。我通常只是通过使用一个<strong class="kt ir"> <em class="na"> setTimeout </em> </strong>在一个时期结束后大约10秒保存总损失值来解决这个问题:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="9d74" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">在成功训练模型之后</h1><h2 id="3e66" class="mn lp iq bd lq mo mp dn lu mq mr dp ly la ms mt ma le mu mv mc li mw mx me my bi translated">18.重量定量</h2><p id="be61" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一旦我们完成了模型的训练，并且对它的性能感到满意，我会建议通过应用权重量化来缩小模型的大小。通过量化我们的模型权重，我们可以将我们的模型尺寸减小到原始尺寸的1/4。尽可能减小模型的大小对于将模型权重快速交付给客户端应用程序是至关重要的，特别是如果我们基本上可以免费获得它的话。</p><p id="39ee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，请务必查看我关于使用tensorflow.js进行权重量化的指南:<a class="ae ln" rel="noopener ugc nofollow" target="_blank" href="/shrink-your-tensorflow-js-web-model-size-with-weight-quantization-6ddb4fcb6d0d"> <strong class="kt ir">使用权重量化缩小您的Tensorflow.js Web模型大小</strong> </a>。</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><p id="aa3b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="na">如果你喜欢这篇文章，欢迎留下一些掌声，并在medium和/或</em><a class="ae ln" href="https://twitter.com/justadudewhohax" rel="noopener ugc nofollow" target="_blank"><em class="na">Twitter</em></a><em class="na">:)上关注我。也请继续关注进一步的文章，如果你有兴趣，请查看我的</em> <a class="ae ln" href="https://github.com/justadudewhohacks" rel="noopener ugc nofollow" target="_blank"> <em class="na">开源作品</em> </a> <em class="na">！</em></p></div></div>    
</body>
</html>