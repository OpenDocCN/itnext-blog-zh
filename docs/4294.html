<html>
<head>
<title>How To Visualize Public Transport Using Kibana, Elasticsearch, Logstash (Elastic Stack) and Kafka Streams on top of Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Docker上使用Kibana、Elasticsearch、Logstash (Elastic Stack)和Kafka流来可视化公共交通</h1>
<blockquote>原文：<a href="https://itnext.io/how-to-visualize-public-transport-using-kibana-elasticserach-logstash-elastic-stack-and-kafka-eabc6975255a?source=collection_archive---------3-----------------------#2020-06-01">https://itnext.io/how-to-visualize-public-transport-using-kibana-elasticserach-logstash-elastic-stack-and-kafka-eabc6975255a?source=collection_archive---------3-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a2750f1e36579a8738d2833e75a0465d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zZiC7IWbnXQio0Al.png"/></div></div></figure><div class=""/><p id="6ede" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您是否考虑过分析和可视化地理数据？为什么不试试Elasticsearch？所谓的。ELK(elastic search+log stash+ki Bana)或Elatic Stack不仅仅是一个NoSQL数据库。这是一个完整的系统，允许实时存储、搜索、分析和可视化来自任何来源的数据。在这种情况下，我们将使用华沙公共交通位置的公开数据。在这个故事中，我将使用<a class="ae kz" href="https://medium.com/@zorteran/calculating-speed-bearing-and-distance-using-kafka-streams-processor-api-9e95834b9e3d" rel="noopener">这个故事</a>中提到的<a class="ae kz" href="https://medium.com/@zorteran/dockerizing-a-kafka-streams-app-6a5ea71fe1ef" rel="noopener">dockered</a>Kafka Streams应用程序。</p><h1 id="7c88" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">环境</h1><p id="8556" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">docker-compose包含Elasticsearch、Kibana、Zookeeper、Kafka、Logstash和我上传到Docker Hub的应用程序Kafka Streams。Kafka用户急切地等待摆脱Zookeeper :-)。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="9822" class="mm lb je mi b gy mn mo l mp mq">version: '3.3'<br/>services:<br/>    elasticsearch:<br/>        image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0<br/>        restart: unless-stopped<br/>        environment:<br/>        - discovery.type=single-node<br/>        - bootstrap.memory_lock=true<br/>        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"<br/>        ulimits:<br/>            memlock:<br/>                soft: -1<br/>                hard: -1<br/>        volumes:<br/>        - esdata:/usr/share/elasticsearch/data<br/>        ports:<br/>        - 9200:9200<br/> <br/>    kibana:<br/>        image: docker.elastic.co/kibana/kibana:7.6.2<br/>        restart: unless-stopped<br/>        depends_on:<br/>            - elasticsearch<br/>        ports:<br/>            - 5601:5601<br/>        volumes:<br/>            - kibanadata:/usr/share/kibana/data<br/> <br/>    zookeeper:<br/>        image: 'bitnami/zookeeper:3'<br/>        ports:<br/>            - '2181:2181'<br/>        volumes:<br/>            - 'zookeeper_data:/bitnami'<br/>        environment:<br/>            - ALLOW_ANONYMOUS_LOGIN=yes<br/>             <br/>    kafka:<br/>        image: 'bitnami/kafka:2'<br/>        ports:<br/>            - '9092:9092'<br/>            - '29092:29092'<br/>        volumes:<br/>            - 'kafka_data:/bitnami'<br/>        environment:<br/>            - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181<br/>            - ALLOW_PLAINTEXT_LISTENER=yes<br/>            - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:29092<br/>            - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT<br/>            - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092<br/>        depends_on:<br/>            - zookeeper<br/> <br/>    ztm_kafka_streams:<br/>        image: "maciejszymczyk/ztm_stream:1.0"<br/>        environment:<br/>          - APPLICATION_ID_CONFIG=awesome_overrided_ztm_stream_app_id<br/>          - BOOTSTRAP_SERVERS_CONFIG=kafka:9092<br/>        depends_on:<br/>          - kafka<br/> <br/>    logstash:<br/>        image: docker.elastic.co/logstash/logstash:7.7.0<br/>        volumes:<br/>            - "./pipeline:/usr/share/logstash/pipeline"<br/>        environment:<br/>            LS_JAVA_OPTS: "-Xmx256m -Xms256m"<br/>        depends_on:<br/>            - elasticsearch<br/>            - kafka<br/>   <br/>volumes:<br/>    esdata:<br/>        driver: local<br/>    kibanadata:<br/>        driver: local<br/>    zookeeper_data:<br/>        driver: local<br/>    kafka_data:<br/>        driver: local</span></pre><h1 id="0f82" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">数据流</h1><p id="18b3" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">让我们解释一下这个场景中的数据流是什么样子的:</p><ol class=""><li id="2dc3" class="mr ms je kd b ke kf ki kj km mt kq mu ku mv ky mw mx my mz bi translated">Python脚本下载API数据并上传到Apache Kafka</li><li id="546a" class="mr ms je kd b ke na ki nb km nc kq nd ku ne ky mw mx my mz bi translated">Kafka Streams应用程序处理记录，添加速度、旋转和距离，然后在下一个主题中保存它们</li><li id="3ada" class="mr ms je kd b ke na ki nb km nc kq nd ku ne ky mw mx my mz bi translated">Logstash从topic中提取记录，将字段(lat，lon)放入location对象，以便Elasticsearch可以将其索引为geo_point(在Kafka Streams中我忘记了)。他将记录放入弹性搜索</li><li id="9c17" class="mr ms je kd b ke na ki nb km nc kq nd ku ne ky mw mx my mz bi translated">弹性搜索使用ILM索引记录</li><li id="9d5d" class="mr ms je kd b ke na ki nb km nc kq nd ku ne ky mw mx my mz bi translated">我们在基巴纳观察地图上正在发生的事情。</li></ol><h1 id="0eae" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Python脚本</h1><p id="0562" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我不得不承认，我用Python写了一个带有无限循环的粗糙脚本，而不是用Apache Airflow写的。这种概念验证和附带项目的魅力:-)。阿帕奇气流将有单独的职位。剧本中需要的令牌可以在这里获得:【https://api.um.warszawa.pl/#<a class="ae kz" href="https://api.um.warszawa.pl/#" rel="noopener ugc nofollow" target="_blank"/></p><figure class="md me mf mg gt iv"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h1 id="63a9" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">卡夫卡溪流</h1><p id="73c2" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">您将在之前的故事中了解Kafka Streams应用程序(<a class="ae kz" href="https://medium.com/@zorteran/calculating-speed-bearing-and-distance-using-kafka-streams-processor-api-9e95834b9e3d?source=your_stories_page---------------------------" rel="noopener">这个</a>和<a class="ae kz" href="https://medium.com/@zorteran/dockerizing-a-kafka-streams-app-6a5ea71fe1ef" rel="noopener">那个</a>)。</p><h1 id="c898" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Logstash</h1><p id="aa62" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我忘记了geo_point字段需要特定的JSON模式。Logstash除了将数据从Kafka转移到Elasticsearch之外，还修复了这个错误。最终，我认为最好改进卡夫卡流。然后，您可以用另一个应用程序替换Logstash，例如Kafka Connect。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="7762" class="mm lb je mi b gy mn mo l mp mq">input {<br/>    kafka {<br/>        topics =&gt; "ztm-output"<br/>        bootstrap_servers =&gt; "kafka:9092"<br/>            codec =&gt; "json"<br/>    }<br/>}<br/>filter {<br/>    mutate {<br/>        add_field =&gt; {<br/>            "[location][lat]" =&gt; "%{lat}"<br/>            "[location][lon]" =&gt; "%{lon}"<br/>            }<br/>        remove_field =&gt; ["lat","lon"]<br/>    }<br/>}<br/>output {<br/> <br/>    elasticsearch {<br/>            hosts =&gt; ["elasticsearch:9200"]<br/>            index =&gt; "ztm"<br/>    }<br/>}<br/></span></pre><h1 id="1609" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">弹性搜索</h1><p id="0ce8" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我没有像ztm-2020.05.24、ztm-2020.05.25那样将记录放入索引中，而是使用了索引生命周期管理机制。它允许您自动化索引的生命周期。它会自动进行汇总，并根据您配置策略的方式更改索引属性(热-暖-冷体系结构)。假设我希望在索引达到1GB或30天后进行转存。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="a4e5" class="mm lb je mi b gy mn mo l mp mq">PUT _ilm/policy/ztm_policy<br/>{<br/>  "policy": {<br/>    "phases": {<br/>      "hot":{<br/>        "actions": {<br/>          "rollover": {<br/>            "max_size": "1gb",<br/>            "max_age": "30d"<br/>          }<br/>        }<br/>      }<br/>    }<br/>  }<br/>}<br/></span></pre><p id="6f56" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您还需要一个带有适当映射的模板，ztm_policy将与该模板挂钩。如果没有映射，Elasticsearch不会猜到geo_point的位置和时间字段将是纯文本。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="4716" class="mm lb je mi b gy mn mo l mp mq">PUT _template/ztm_template<br/>{<br/>  "index_patterns": ["ztm-*"],<br/>  "settings": {<br/>    "number_of_shards": 3,<br/>    "number_of_replicas": 1,<br/>    "index.lifecycle.name":"ztm_policy",<br/>    "index.lifecycle.rollover_alias": "ztm"<br/>  },<br/>  "mappings": {<br/>    "properties": {<br/>      "<a class="ae kz" href="http://twitter.com/timestamp" rel="noopener ugc nofollow" target="_blank">@timestamp</a>": {<br/>        "type": "date"<br/>      },<br/>      "<a class="ae kz" href="http://twitter.com/version" rel="noopener ugc nofollow" target="_blank">@version</a>": {<br/>        "type": "text",<br/>        "fields": {<br/>          "keyword": {<br/>            "type": "keyword",<br/>            "ignore_above": 256<br/>          }<br/>        }<br/>      },<br/>      "bearing": {<br/>        "type": "float"<br/>      },<br/>      "brigade": {<br/>        "type": "keyword"<br/>      },<br/>      "distance": {<br/>        "type": "float"<br/>      },<br/>      "lines": {<br/>        "type": "keyword"<br/>      },<br/>      "location": {<br/>        "type": "geo_point"<br/>      },<br/>      "speed": {<br/>        "type": "float"<br/>      },<br/>      "time": {<br/>        "type": "date",<br/>        "format":"MMM d, yyyy h:mm:ss a"<br/>      },<br/>      "vehicleNumber": {<br/>        "type": "keyword"<br/>      }<br/>    }<br/>  }<br/>}<br/></span></pre><p id="770b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在是时候用合适的别名创建第一个索引了。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="7789" class="mm lb je mi b gy mn mo l mp mq">PUT ztm-000001<br/>{<br/>  "aliases": {<br/>    "ztm": {<br/>      "is_write_index":true<br/>    }<br/>  }<br/>}</span></pre><h1 id="d68a" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">基巴纳</h1><p id="4ac7" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">索引模式使用<a class="ae kz" href="http://twitter.com/timestamp" rel="noopener ugc nofollow" target="_blank">@时间戳</a>字段作为记录的参考时间点。从API中获取的时间会有所偏移，并且有所延迟。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/c2adb895741135a15ac6d712cd0db023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z79Nv77ZzfWWX7yk.png"/></div></div></figure><h2 id="1460" class="mm lb je bd lc ni nj dn lg nk nl dp lk km nm nn lo kq no np ls ku nq nr lw ns bi translated">地图</h2><p id="6923" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我们使用索引模式ztm和位置字段添加一个地图，然后添加一个新层。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/fb488a39f2851f9dea30097160d9e58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*3PGmRKWAjlDthNAG.png"/></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk translated">我们只想看到每辆车的最新记录</figcaption></figure><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6e9a01a85e74c1be0d7bde9a75f6a00d.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*LF48zBhV6bASNsNy.png"/></div></figure><p id="07f9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">已更改的属性:<br/> -符号类型=箭头-es <br/> -填充颜色=取决于车速<br/> -符号方向=取决于车辆旋转<br/> -标签=行号</p><h1 id="16d3" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">它还活着！</h1><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/67e5693f064bd46282572d14ee728ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*u3o9NxEtjVq_dH4M.gif"/></div></div></figure><p id="e55b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">API不允许更频繁的采样，但是效果仍然很有趣。</p><h1 id="d07f" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">贮藏室ˌ仓库</h1><p id="d6ef" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated"><a class="ae kz" href="https://github.com/zorteran/wiadro-danych-kafka-to-es-ztm" rel="noopener ugc nofollow" target="_blank">https://github.com/zorteran/wiadro-danych-kafka-to-es-ztm</a></p></div></div>    
</body>
</html>